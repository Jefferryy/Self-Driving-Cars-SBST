2020-09-01 13:46:20 | [drl] epoch #0 | Obtaining samples...
2020-09-01 13:46:20 | [drl] epoch #0 | Obtaining samples for iteration 0...
2020-09-01 13:46:27 | [drl] epoch #0 | Logging diagnostics...
2020-09-01 13:46:27 | [drl] epoch #0 | Optimizing policy...
2020-09-01 13:46:27 | [drl] epoch #0 | Computing loss before
2020-09-01 13:46:27 | [drl] epoch #0 | Computing KL before
2020-09-01 13:46:28 | [drl] epoch #0 | Optimizing
2020-09-01 13:46:28 | [drl] epoch #0 | Start CG optimization: #parameters: 19852, #inputs: 100, #subsample_inputs: 100
2020-09-01 13:46:28 | [drl] epoch #0 | computing loss before
2020-09-01 13:46:28 | [drl] epoch #0 | computing gradient
2020-09-01 13:46:28 | [drl] epoch #0 | gradient computed
2020-09-01 13:46:28 | [drl] epoch #0 | computing descent direction
2020-09-01 13:46:29 | [drl] epoch #0 | descent direction computed
2020-09-01 13:46:30 | [drl] epoch #0 | backtrack iters: 6
2020-09-01 13:46:30 | [drl] epoch #0 | optimization finished
2020-09-01 13:46:30 | [drl] epoch #0 | Computing KL after
2020-09-01 13:46:30 | [drl] epoch #0 | Computing loss after
2020-09-01 13:46:30 | [drl] epoch #0 | Fitting baseline...
2020-09-01 13:46:30 | [drl] epoch #0 | Saving snapshot...
2020-09-01 13:46:30 | [drl] epoch #0 | Saved
2020-09-01 13:46:30 | [drl] epoch #0 | Time 9.25 s
2020-09-01 13:46:30 | [drl] epoch #0 | EpochTime 9.25 s
---------------------------------------  --------------
AverageDiscountedReturn                  -622.701
AverageReturn                            -786.729
Entropy                                     8.51363
EnvExecTime                                 1.83847
Extras/EpisodeRewardMean                 -786.729
Iteration                                   0
LinearFeatureBaseline/ExplainedVariance     3.75069e-08
MaxReturn                                -538.656
MinReturn                                -842.04
NumTrajs                                  100
Perplexity                               4982.22
PolicyExecTime                              4.04964
ProcessExecTime                             0.0965977
StdReturn                                  36.4843
lstm_policy/Entropy                         8.27718
lstm_policy/KL                              0.563965
lstm_policy/KLBefore                        0.000978823
lstm_policy/LossAfter                       0.00379731
lstm_policy/LossBefore                      0.0053426
lstm_policy/dLoss                           0.00154529
---------------------------------------  --------------
2020-09-01 13:46:30 | [drl] epoch #1 | Obtaining samples...
2020-09-01 13:46:30 | [drl] epoch #1 | Obtaining samples for iteration 1...
2020-09-01 13:46:36 | [drl] epoch #1 | Logging diagnostics...
2020-09-01 13:46:36 | [drl] epoch #1 | Optimizing policy...
2020-09-01 13:46:36 | [drl] epoch #1 | Computing loss before
2020-09-01 13:46:36 | [drl] epoch #1 | Computing KL before
2020-09-01 13:46:36 | [drl] epoch #1 | Optimizing
2020-09-01 13:46:36 | [drl] epoch #1 | Start CG optimization: #parameters: 19852, #inputs: 108, #subsample_inputs: 108
2020-09-01 13:46:36 | [drl] epoch #1 | computing loss before
2020-09-01 13:46:36 | [drl] epoch #1 | computing gradient
2020-09-01 13:46:37 | [drl] epoch #1 | gradient computed
2020-09-01 13:46:37 | [drl] epoch #1 | computing descent direction
2020-09-01 13:46:38 | [drl] epoch #1 | descent direction computed
2020-09-01 13:46:38 | [drl] epoch #1 | Line search condition violated. Rejecting the step!
2020-09-01 13:46:38 | [drl] epoch #1 | Violated because loss not improving
2020-09-01 13:46:38 | [drl] epoch #1 | backtrack iters: 14
2020-09-01 13:46:38 | [drl] epoch #1 | optimization finished
2020-09-01 13:46:38 | [drl] epoch #1 | Computing KL after
2020-09-01 13:46:38 | [drl] epoch #1 | Computing loss after
2020-09-01 13:46:38 | [drl] epoch #1 | Fitting baseline...
2020-09-01 13:46:38 | [drl] epoch #1 | Saving snapshot...
2020-09-01 13:46:38 | [drl] epoch #1 | Saved
2020-09-01 13:46:38 | [drl] epoch #1 | Time 17.63 s
2020-09-01 13:46:38 | [drl] epoch #1 | EpochTime 8.36 s
---------------------------------------  -------------
AverageDiscountedReturn                  -531.163
AverageReturn                            -654.757
Entropy                                     8.29337
EnvExecTime                                 1.82169
Extras/EpisodeRewardMean                 -645.557
Iteration                                   1
LinearFeatureBaseline/ExplainedVariance     0.703877
MaxReturn                                -408.842
MinReturn                                -804.354
NumTrajs                                  108
Perplexity                               3997.29
PolicyExecTime                              3.95095
ProcessExecTime                             0.0963614
StdReturn                                 132.929
lstm_policy/Entropy                         8.27718
lstm_policy/KL                              0.0135801
lstm_policy/KLBefore                        0.0135801
lstm_policy/LossAfter                      -0.00451497
lstm_policy/LossBefore                     -0.00451497
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:46:38 | [drl] epoch #2 | Obtaining samples...
2020-09-01 13:46:38 | [drl] epoch #2 | Obtaining samples for iteration 2...
2020-09-01 13:46:45 | [drl] epoch #2 | Logging diagnostics...
2020-09-01 13:46:45 | [drl] epoch #2 | Optimizing policy...
2020-09-01 13:46:45 | [drl] epoch #2 | Computing loss before
2020-09-01 13:46:45 | [drl] epoch #2 | Computing KL before
2020-09-01 13:46:45 | [drl] epoch #2 | Optimizing
2020-09-01 13:46:45 | [drl] epoch #2 | Start CG optimization: #parameters: 19852, #inputs: 105, #subsample_inputs: 105
2020-09-01 13:46:45 | [drl] epoch #2 | computing loss before
2020-09-01 13:46:45 | [drl] epoch #2 | computing gradient
2020-09-01 13:46:45 | [drl] epoch #2 | gradient computed
2020-09-01 13:46:45 | [drl] epoch #2 | computing descent direction
2020-09-01 13:46:46 | [drl] epoch #2 | descent direction computed
2020-09-01 13:46:46 | [drl] epoch #2 | backtrack iters: 6
2020-09-01 13:46:46 | [drl] epoch #2 | optimization finished
2020-09-01 13:46:46 | [drl] epoch #2 | Computing KL after
2020-09-01 13:46:46 | [drl] epoch #2 | Computing loss after
2020-09-01 13:46:46 | [drl] epoch #2 | Fitting baseline...
2020-09-01 13:46:46 | [drl] epoch #2 | Saving snapshot...
2020-09-01 13:46:46 | [drl] epoch #2 | Saved
2020-09-01 13:46:46 | [drl] epoch #2 | Time 25.75 s
2020-09-01 13:46:46 | [drl] epoch #2 | EpochTime 8.10 s
---------------------------------------  --------------
AverageDiscountedReturn                  -535.202
AverageReturn                            -661.165
Entropy                                     8.29749
EnvExecTime                                 1.82688
Extras/EpisodeRewardMean                 -659.552
Iteration                                   2
LinearFeatureBaseline/ExplainedVariance     0.768979
MaxReturn                                -399.56
MinReturn                                -801.944
NumTrajs                                  105
Perplexity                               4013.8
PolicyExecTime                              3.86896
ProcessExecTime                             0.0989225
StdReturn                                 131.334
lstm_policy/Entropy                         8.75331
lstm_policy/KL                              0.215079
lstm_policy/KLBefore                        0.0147891
lstm_policy/LossAfter                       0.0246473
lstm_policy/LossBefore                      0.0248037
lstm_policy/dLoss                           0.000156347
---------------------------------------  --------------
2020-09-01 13:46:46 | [drl] epoch #3 | Obtaining samples...
2020-09-01 13:46:46 | [drl] epoch #3 | Obtaining samples for iteration 3...
2020-09-01 13:46:53 | [drl] epoch #3 | Logging diagnostics...
2020-09-01 13:46:53 | [drl] epoch #3 | Optimizing policy...
2020-09-01 13:46:53 | [drl] epoch #3 | Computing loss before
2020-09-01 13:46:53 | [drl] epoch #3 | Computing KL before
2020-09-01 13:46:53 | [drl] epoch #3 | Optimizing
2020-09-01 13:46:53 | [drl] epoch #3 | Start CG optimization: #parameters: 19852, #inputs: 101, #subsample_inputs: 101
2020-09-01 13:46:53 | [drl] epoch #3 | computing loss before
2020-09-01 13:46:53 | [drl] epoch #3 | computing gradient
2020-09-01 13:46:53 | [drl] epoch #3 | gradient computed
2020-09-01 13:46:53 | [drl] epoch #3 | computing descent direction
2020-09-01 13:46:54 | [drl] epoch #3 | descent direction computed
2020-09-01 13:46:54 | [drl] epoch #3 | backtrack iters: 5
2020-09-01 13:46:54 | [drl] epoch #3 | optimization finished
2020-09-01 13:46:54 | [drl] epoch #3 | Computing KL after
2020-09-01 13:46:54 | [drl] epoch #3 | Computing loss after
2020-09-01 13:46:54 | [drl] epoch #3 | Fitting baseline...
2020-09-01 13:46:54 | [drl] epoch #3 | Saving snapshot...
2020-09-01 13:46:54 | [drl] epoch #3 | Saved
2020-09-01 13:46:54 | [drl] epoch #3 | Time 33.83 s
2020-09-01 13:46:54 | [drl] epoch #3 | EpochTime 8.06 s
---------------------------------------  -------------
AverageDiscountedReturn                  -599.606
AverageReturn                            -753.797
Entropy                                     8.74702
EnvExecTime                                 1.84562
Extras/EpisodeRewardMean                 -753.621
Iteration                                   3
LinearFeatureBaseline/ExplainedVariance     0.882409
MaxReturn                                -454.538
MinReturn                                -820.883
NumTrajs                                  101
Perplexity                               6291.89
PolicyExecTime                              3.82604
ProcessExecTime                             0.102357
StdReturn                                  86.2602
lstm_policy/Entropy                         8.43744
lstm_policy/KL                              0.349481
lstm_policy/KLBefore                        0.00322501
lstm_policy/LossAfter                      -0.0102691
lstm_policy/LossBefore                      0.00401419
lstm_policy/dLoss                           0.0142833
---------------------------------------  -------------
2020-09-01 13:46:54 | [drl] epoch #4 | Obtaining samples...
2020-09-01 13:46:54 | [drl] epoch #4 | Obtaining samples for iteration 4...
2020-09-01 13:47:01 | [drl] epoch #4 | Logging diagnostics...
2020-09-01 13:47:01 | [drl] epoch #4 | Optimizing policy...
2020-09-01 13:47:01 | [drl] epoch #4 | Computing loss before
2020-09-01 13:47:01 | [drl] epoch #4 | Computing KL before
2020-09-01 13:47:01 | [drl] epoch #4 | Optimizing
2020-09-01 13:47:01 | [drl] epoch #4 | Start CG optimization: #parameters: 19852, #inputs: 101, #subsample_inputs: 101
2020-09-01 13:47:01 | [drl] epoch #4 | computing loss before
2020-09-01 13:47:01 | [drl] epoch #4 | computing gradient
2020-09-01 13:47:01 | [drl] epoch #4 | gradient computed
2020-09-01 13:47:01 | [drl] epoch #4 | computing descent direction
2020-09-01 13:47:02 | [drl] epoch #4 | descent direction computed
2020-09-01 13:47:02 | [drl] epoch #4 | backtrack iters: 1
2020-09-01 13:47:02 | [drl] epoch #4 | optimization finished
2020-09-01 13:47:02 | [drl] epoch #4 | Computing KL after
2020-09-01 13:47:02 | [drl] epoch #4 | Computing loss after
2020-09-01 13:47:02 | [drl] epoch #4 | Fitting baseline...
2020-09-01 13:47:02 | [drl] epoch #4 | Saving snapshot...
2020-09-01 13:47:02 | [drl] epoch #4 | Saved
2020-09-01 13:47:02 | [drl] epoch #4 | Time 41.90 s
2020-09-01 13:47:02 | [drl] epoch #4 | EpochTime 8.06 s
---------------------------------------  -------------
AverageDiscountedReturn                  -593.103
AverageReturn                            -746.985
Entropy                                     8.43834
EnvExecTime                                 1.84824
Extras/EpisodeRewardMean                 -746.724
Iteration                                   4
LinearFeatureBaseline/ExplainedVariance     0.945228
MaxReturn                                -437.252
MinReturn                                -806.441
NumTrajs                                  101
Perplexity                               4620.86
PolicyExecTime                              3.85876
ProcessExecTime                             0.095818
StdReturn                                  63.8167
lstm_policy/Entropy                         7.81717
lstm_policy/KL                              0.717636
lstm_policy/KLBefore                        0.00220648
lstm_policy/LossAfter                      -0.0196774
lstm_policy/LossBefore                     -0.00116654
lstm_policy/dLoss                           0.0185109
---------------------------------------  -------------
2020-09-01 13:47:02 | [drl] epoch #5 | Obtaining samples...
2020-09-01 13:47:02 | [drl] epoch #5 | Obtaining samples for iteration 5...
2020-09-01 13:47:09 | [drl] epoch #5 | Logging diagnostics...
2020-09-01 13:47:09 | [drl] epoch #5 | Optimizing policy...
2020-09-01 13:47:09 | [drl] epoch #5 | Computing loss before
2020-09-01 13:47:09 | [drl] epoch #5 | Computing KL before
2020-09-01 13:47:09 | [drl] epoch #5 | Optimizing
2020-09-01 13:47:09 | [drl] epoch #5 | Start CG optimization: #parameters: 19852, #inputs: 104, #subsample_inputs: 104
2020-09-01 13:47:09 | [drl] epoch #5 | computing loss before
2020-09-01 13:47:09 | [drl] epoch #5 | computing gradient
2020-09-01 13:47:09 | [drl] epoch #5 | gradient computed
2020-09-01 13:47:09 | [drl] epoch #5 | computing descent direction
2020-09-01 13:47:10 | [drl] epoch #5 | descent direction computed
2020-09-01 13:47:11 | [drl] epoch #5 | Line search condition violated. Rejecting the step!
2020-09-01 13:47:11 | [drl] epoch #5 | Violated because loss not improving
2020-09-01 13:47:11 | [drl] epoch #5 | backtrack iters: 14
2020-09-01 13:47:11 | [drl] epoch #5 | optimization finished
2020-09-01 13:47:11 | [drl] epoch #5 | Computing KL after
2020-09-01 13:47:11 | [drl] epoch #5 | Computing loss after
2020-09-01 13:47:11 | [drl] epoch #5 | Fitting baseline...
2020-09-01 13:47:11 | [drl] epoch #5 | Saving snapshot...
2020-09-01 13:47:11 | [drl] epoch #5 | Saved
2020-09-01 13:47:11 | [drl] epoch #5 | Time 50.16 s
2020-09-01 13:47:11 | [drl] epoch #5 | EpochTime 8.25 s
---------------------------------------  ------------
AverageDiscountedReturn                  -504.377
AverageReturn                            -623.824
Entropy                                     7.87853
EnvExecTime                                 1.85734
Extras/EpisodeRewardMean                 -626.376
Iteration                                   5
LinearFeatureBaseline/ExplainedVariance     0.691428
MaxReturn                                -364.492
MinReturn                                -773.177
NumTrajs                                  104
Perplexity                               2639.98
PolicyExecTime                              3.90035
ProcessExecTime                             0.0982785
StdReturn                                 139.52
lstm_policy/Entropy                         7.81717
lstm_policy/KL                              0.0656477
lstm_policy/KLBefore                        0.0656477
lstm_policy/LossAfter                      -0.0103375
lstm_policy/LossBefore                     -0.0103375
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:47:11 | [drl] epoch #6 | Obtaining samples...
2020-09-01 13:47:11 | [drl] epoch #6 | Obtaining samples for iteration 6...
2020-09-01 13:47:17 | [drl] epoch #6 | Logging diagnostics...
2020-09-01 13:47:17 | [drl] epoch #6 | Optimizing policy...
2020-09-01 13:47:17 | [drl] epoch #6 | Computing loss before
2020-09-01 13:47:17 | [drl] epoch #6 | Computing KL before
2020-09-01 13:47:17 | [drl] epoch #6 | Optimizing
2020-09-01 13:47:17 | [drl] epoch #6 | Start CG optimization: #parameters: 19852, #inputs: 105, #subsample_inputs: 105
2020-09-01 13:47:17 | [drl] epoch #6 | computing loss before
2020-09-01 13:47:17 | [drl] epoch #6 | computing gradient
2020-09-01 13:47:17 | [drl] epoch #6 | gradient computed
2020-09-01 13:47:17 | [drl] epoch #6 | computing descent direction
2020-09-01 13:47:19 | [drl] epoch #6 | descent direction computed
2020-09-01 13:47:19 | [drl] epoch #6 | backtrack iters: 5
2020-09-01 13:47:19 | [drl] epoch #6 | optimization finished
2020-09-01 13:47:19 | [drl] epoch #6 | Computing KL after
2020-09-01 13:47:19 | [drl] epoch #6 | Computing loss after
2020-09-01 13:47:19 | [drl] epoch #6 | Fitting baseline...
2020-09-01 13:47:19 | [drl] epoch #6 | Saving snapshot...
2020-09-01 13:47:19 | [drl] epoch #6 | Saved
2020-09-01 13:47:19 | [drl] epoch #6 | Time 58.32 s
2020-09-01 13:47:19 | [drl] epoch #6 | EpochTime 8.14 s
---------------------------------------  -------------
AverageDiscountedReturn                  -497.4
AverageReturn                            -612.939
Entropy                                     7.88749
EnvExecTime                                 1.85059
Extras/EpisodeRewardMean                 -613.305
Iteration                                   6
LinearFeatureBaseline/ExplainedVariance     0.718966
MaxReturn                                -358.258
MinReturn                                -754.584
NumTrajs                                  105
Perplexity                               2663.74
PolicyExecTime                              3.87565
ProcessExecTime                             0.104732
StdReturn                                 143.75
lstm_policy/Entropy                         7.11604
lstm_policy/KL                              0.83808
lstm_policy/KLBefore                        0.0754555
lstm_policy/LossAfter                      -0.0200005
lstm_policy/LossBefore                      0.00531277
lstm_policy/dLoss                           0.0253133
---------------------------------------  -------------
2020-09-01 13:47:19 | [drl] epoch #7 | Obtaining samples...
2020-09-01 13:47:19 | [drl] epoch #7 | Obtaining samples for iteration 7...
2020-09-01 13:47:25 | [drl] epoch #7 | Logging diagnostics...
2020-09-01 13:47:25 | [drl] epoch #7 | Optimizing policy...
2020-09-01 13:47:25 | [drl] epoch #7 | Computing loss before
2020-09-01 13:47:25 | [drl] epoch #7 | Computing KL before
2020-09-01 13:47:25 | [drl] epoch #7 | Optimizing
2020-09-01 13:47:25 | [drl] epoch #7 | Start CG optimization: #parameters: 19852, #inputs: 104, #subsample_inputs: 104
2020-09-01 13:47:25 | [drl] epoch #7 | computing loss before
2020-09-01 13:47:25 | [drl] epoch #7 | computing gradient
2020-09-01 13:47:26 | [drl] epoch #7 | gradient computed
2020-09-01 13:47:26 | [drl] epoch #7 | computing descent direction
2020-09-01 13:47:27 | [drl] epoch #7 | descent direction computed
2020-09-01 13:47:27 | [drl] epoch #7 | backtrack iters: 4
2020-09-01 13:47:27 | [drl] epoch #7 | optimization finished
2020-09-01 13:47:27 | [drl] epoch #7 | Computing KL after
2020-09-01 13:47:27 | [drl] epoch #7 | Computing loss after
2020-09-01 13:47:27 | [drl] epoch #7 | Fitting baseline...
2020-09-01 13:47:27 | [drl] epoch #7 | Saving snapshot...
2020-09-01 13:47:27 | [drl] epoch #7 | Saved
2020-09-01 13:47:27 | [drl] epoch #7 | Time 66.41 s
2020-09-01 13:47:27 | [drl] epoch #7 | EpochTime 8.07 s
---------------------------------------  -------------
AverageDiscountedReturn                  -525.737
AverageReturn                            -659.038
Entropy                                     7.14528
EnvExecTime                                 1.83013
Extras/EpisodeRewardMean                 -660.482
Iteration                                   7
LinearFeatureBaseline/ExplainedVariance     0.823866
MaxReturn                                -382.006
MinReturn                                -748.132
NumTrajs                                  104
Perplexity                               1268.11
PolicyExecTime                              3.85045
ProcessExecTime                             0.0998929
StdReturn                                 104.202
lstm_policy/Entropy                         6.60346
lstm_policy/KL                              0.658567
lstm_policy/KLBefore                        0.0451335
lstm_policy/LossAfter                      -0.030541
lstm_policy/LossBefore                     -0.0277734
lstm_policy/dLoss                           0.00276758
---------------------------------------  -------------
2020-09-01 13:47:27 | [drl] epoch #8 | Obtaining samples...
2020-09-01 13:47:27 | [drl] epoch #8 | Obtaining samples for iteration 8...
2020-09-01 13:47:33 | [drl] epoch #8 | Logging diagnostics...
2020-09-01 13:47:33 | [drl] epoch #8 | Optimizing policy...
2020-09-01 13:47:33 | [drl] epoch #8 | Computing loss before
2020-09-01 13:47:33 | [drl] epoch #8 | Computing KL before
2020-09-01 13:47:33 | [drl] epoch #8 | Optimizing
2020-09-01 13:47:33 | [drl] epoch #8 | Start CG optimization: #parameters: 19852, #inputs: 127, #subsample_inputs: 127
2020-09-01 13:47:33 | [drl] epoch #8 | computing loss before
2020-09-01 13:47:33 | [drl] epoch #8 | computing gradient
2020-09-01 13:47:34 | [drl] epoch #8 | gradient computed
2020-09-01 13:47:34 | [drl] epoch #8 | computing descent direction
2020-09-01 13:47:35 | [drl] epoch #8 | descent direction computed
2020-09-01 13:47:35 | [drl] epoch #8 | backtrack iters: 14
2020-09-01 13:47:35 | [drl] epoch #8 | optimization finished
2020-09-01 13:47:35 | [drl] epoch #8 | Computing KL after
2020-09-01 13:47:35 | [drl] epoch #8 | Computing loss after
2020-09-01 13:47:35 | [drl] epoch #8 | Fitting baseline...
2020-09-01 13:47:35 | [drl] epoch #8 | Saving snapshot...
2020-09-01 13:47:35 | [drl] epoch #8 | Saved
2020-09-01 13:47:35 | [drl] epoch #8 | Time 74.83 s
2020-09-01 13:47:35 | [drl] epoch #8 | EpochTime 8.40 s
---------------------------------------  -------------
AverageDiscountedReturn                  -361.652
AverageReturn                            -426.665
Entropy                                     6.86786
EnvExecTime                                 1.81393
Extras/EpisodeRewardMean                 -435.105
Iteration                                   8
LinearFeatureBaseline/ExplainedVariance     0.479998
MaxReturn                                -324.669
MinReturn                                -672.362
NumTrajs                                  127
Perplexity                                960.89
PolicyExecTime                              3.90159
ProcessExecTime                             0.101997
StdReturn                                  99.0101
lstm_policy/Entropy                         6.74642
lstm_policy/KL                              0.938671
lstm_policy/KLBefore                        0.885168
lstm_policy/LossAfter                      -0.0443471
lstm_policy/LossBefore                     -0.0360156
lstm_policy/dLoss                           0.00833151
---------------------------------------  -------------
2020-09-01 13:47:35 | [drl] epoch #9 | Obtaining samples...
2020-09-01 13:47:35 | [drl] epoch #9 | Obtaining samples for iteration 9...
2020-09-01 13:47:42 | [drl] epoch #9 | Logging diagnostics...
2020-09-01 13:47:42 | [drl] epoch #9 | Optimizing policy...
2020-09-01 13:47:42 | [drl] epoch #9 | Computing loss before
2020-09-01 13:47:42 | [drl] epoch #9 | Computing KL before
2020-09-01 13:47:42 | [drl] epoch #9 | Optimizing
2020-09-01 13:47:42 | [drl] epoch #9 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:47:42 | [drl] epoch #9 | computing loss before
2020-09-01 13:47:42 | [drl] epoch #9 | computing gradient
2020-09-01 13:47:42 | [drl] epoch #9 | gradient computed
2020-09-01 13:47:42 | [drl] epoch #9 | computing descent direction
2020-09-01 13:47:43 | [drl] epoch #9 | descent direction computed
2020-09-01 13:47:44 | [drl] epoch #9 | backtrack iters: 7
2020-09-01 13:47:44 | [drl] epoch #9 | optimization finished
2020-09-01 13:47:44 | [drl] epoch #9 | Computing KL after
2020-09-01 13:47:44 | [drl] epoch #9 | Computing loss after
2020-09-01 13:47:44 | [drl] epoch #9 | Fitting baseline...
2020-09-01 13:47:44 | [drl] epoch #9 | Saving snapshot...
2020-09-01 13:47:44 | [drl] epoch #9 | Saved
2020-09-01 13:47:44 | [drl] epoch #9 | Time 83.13 s
2020-09-01 13:47:44 | [drl] epoch #9 | EpochTime 8.29 s
---------------------------------------  -------------
AverageDiscountedReturn                  -425.65
AverageReturn                            -517.394
Entropy                                     6.86705
EnvExecTime                                 1.81144
Extras/EpisodeRewardMean                 -511.39
Iteration                                   9
LinearFeatureBaseline/ExplainedVariance     0.646476
MaxReturn                                -330.095
MinReturn                                -702.715
NumTrajs                                  117
Perplexity                                960.108
PolicyExecTime                              3.94976
ProcessExecTime                             0.108605
StdReturn                                 119.317
lstm_policy/Entropy                         6.59376
lstm_policy/KL                              0.515673
lstm_policy/KLBefore                        0.412918
lstm_policy/LossAfter                      -0.00867094
lstm_policy/LossBefore                      0.00604612
lstm_policy/dLoss                           0.0147171
---------------------------------------  -------------
2020-09-01 13:47:44 | [drl] epoch #10 | Obtaining samples...
2020-09-01 13:47:44 | [drl] epoch #10 | Obtaining samples for iteration 10...
2020-09-01 13:47:50 | [drl] epoch #10 | Logging diagnostics...
2020-09-01 13:47:50 | [drl] epoch #10 | Optimizing policy...
2020-09-01 13:47:50 | [drl] epoch #10 | Computing loss before
2020-09-01 13:47:50 | [drl] epoch #10 | Computing KL before
2020-09-01 13:47:50 | [drl] epoch #10 | Optimizing
2020-09-01 13:47:50 | [drl] epoch #10 | Start CG optimization: #parameters: 19852, #inputs: 110, #subsample_inputs: 110
2020-09-01 13:47:50 | [drl] epoch #10 | computing loss before
2020-09-01 13:47:50 | [drl] epoch #10 | computing gradient
2020-09-01 13:47:50 | [drl] epoch #10 | gradient computed
2020-09-01 13:47:50 | [drl] epoch #10 | computing descent direction
2020-09-01 13:47:51 | [drl] epoch #10 | descent direction computed
2020-09-01 13:47:52 | [drl] epoch #10 | Line search condition violated. Rejecting the step!
2020-09-01 13:47:52 | [drl] epoch #10 | Violated because constraint mean_kl is violated
2020-09-01 13:47:52 | [drl] epoch #10 | backtrack iters: 14
2020-09-01 13:47:52 | [drl] epoch #10 | optimization finished
2020-09-01 13:47:52 | [drl] epoch #10 | Computing KL after
2020-09-01 13:47:52 | [drl] epoch #10 | Computing loss after
2020-09-01 13:47:52 | [drl] epoch #10 | Fitting baseline...
2020-09-01 13:47:52 | [drl] epoch #10 | Saving snapshot...
2020-09-01 13:47:52 | [drl] epoch #10 | Saved
2020-09-01 13:47:52 | [drl] epoch #10 | Time 91.29 s
2020-09-01 13:47:52 | [drl] epoch #10 | EpochTime 8.15 s
---------------------------------------  ------------
AverageDiscountedReturn                  -384.19
AverageReturn                            -459.499
Entropy                                     6.9598
EnvExecTime                                 1.8374
Extras/EpisodeRewardMean                 -462.717
Iteration                                  10
LinearFeatureBaseline/ExplainedVariance     0.687291
MaxReturn                                -308.776
MinReturn                                -666.657
NumTrajs                                  110
Perplexity                               1053.42
PolicyExecTime                              3.84039
ProcessExecTime                             0.0993881
StdReturn                                 113.464
lstm_policy/Entropy                         6.59376
lstm_policy/KL                              1.2181
lstm_policy/KLBefore                        1.2181
lstm_policy/LossAfter                      -0.0570603
lstm_policy/LossBefore                     -0.0570603
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:47:52 | [drl] epoch #11 | Obtaining samples...
2020-09-01 13:47:52 | [drl] epoch #11 | Obtaining samples for iteration 11...
2020-09-01 13:47:58 | [drl] epoch #11 | Logging diagnostics...
2020-09-01 13:47:58 | [drl] epoch #11 | Optimizing policy...
2020-09-01 13:47:58 | [drl] epoch #11 | Computing loss before
2020-09-01 13:47:58 | [drl] epoch #11 | Computing KL before
2020-09-01 13:47:58 | [drl] epoch #11 | Optimizing
2020-09-01 13:47:58 | [drl] epoch #11 | Start CG optimization: #parameters: 19852, #inputs: 110, #subsample_inputs: 110
2020-09-01 13:47:58 | [drl] epoch #11 | computing loss before
2020-09-01 13:47:58 | [drl] epoch #11 | computing gradient
2020-09-01 13:47:59 | [drl] epoch #11 | gradient computed
2020-09-01 13:47:59 | [drl] epoch #11 | computing descent direction
2020-09-01 13:48:00 | [drl] epoch #11 | descent direction computed
2020-09-01 13:48:00 | [drl] epoch #11 | backtrack iters: 6
2020-09-01 13:48:00 | [drl] epoch #11 | optimization finished
2020-09-01 13:48:00 | [drl] epoch #11 | Computing KL after
2020-09-01 13:48:00 | [drl] epoch #11 | Computing loss after
2020-09-01 13:48:00 | [drl] epoch #11 | Fitting baseline...
2020-09-01 13:48:00 | [drl] epoch #11 | Saving snapshot...
2020-09-01 13:48:00 | [drl] epoch #11 | Saved
2020-09-01 13:48:00 | [drl] epoch #11 | Time 99.49 s
2020-09-01 13:48:00 | [drl] epoch #11 | EpochTime 8.18 s
---------------------------------------  ------------
AverageDiscountedReturn                  -390.384
AverageReturn                            -468.457
Entropy                                     6.94324
EnvExecTime                                 1.84328
Extras/EpisodeRewardMean                 -468.129
Iteration                                  11
LinearFeatureBaseline/ExplainedVariance     0.689816
MaxReturn                                -325.45
MinReturn                                -682.494
NumTrajs                                  110
Perplexity                               1036.13
PolicyExecTime                              3.93012
ProcessExecTime                             0.114398
StdReturn                                 120.327
lstm_policy/Entropy                         6.45151
lstm_policy/KL                              0.909338
lstm_policy/KLBefore                        1.11516
lstm_policy/LossAfter                      -0.0608097
lstm_policy/LossBefore                     -0.0426364
lstm_policy/dLoss                           0.0181732
---------------------------------------  ------------
2020-09-01 13:48:00 | [drl] epoch #12 | Obtaining samples...
2020-09-01 13:48:00 | [drl] epoch #12 | Obtaining samples for iteration 12...
2020-09-01 13:48:06 | [drl] epoch #12 | Logging diagnostics...
2020-09-01 13:48:06 | [drl] epoch #12 | Optimizing policy...
2020-09-01 13:48:06 | [drl] epoch #12 | Computing loss before
2020-09-01 13:48:06 | [drl] epoch #12 | Computing KL before
2020-09-01 13:48:06 | [drl] epoch #12 | Optimizing
2020-09-01 13:48:06 | [drl] epoch #12 | Start CG optimization: #parameters: 19852, #inputs: 128, #subsample_inputs: 128
2020-09-01 13:48:06 | [drl] epoch #12 | computing loss before
2020-09-01 13:48:06 | [drl] epoch #12 | computing gradient
2020-09-01 13:48:07 | [drl] epoch #12 | gradient computed
2020-09-01 13:48:07 | [drl] epoch #12 | computing descent direction
2020-09-01 13:48:08 | [drl] epoch #12 | descent direction computed
2020-09-01 13:48:08 | [drl] epoch #12 | backtrack iters: 7
2020-09-01 13:48:08 | [drl] epoch #12 | optimization finished
2020-09-01 13:48:08 | [drl] epoch #12 | Computing KL after
2020-09-01 13:48:08 | [drl] epoch #12 | Computing loss after
2020-09-01 13:48:08 | [drl] epoch #12 | Fitting baseline...
2020-09-01 13:48:08 | [drl] epoch #12 | Saving snapshot...
2020-09-01 13:48:08 | [drl] epoch #12 | Saved
2020-09-01 13:48:08 | [drl] epoch #12 | Time 107.72 s
2020-09-01 13:48:08 | [drl] epoch #12 | EpochTime 8.22 s
---------------------------------------  ------------
AverageDiscountedReturn                  -351.307
AverageReturn                            -411.946
Entropy                                     6.805
EnvExecTime                                 1.82827
Extras/EpisodeRewardMean                 -411.468
Iteration                                  12
LinearFeatureBaseline/ExplainedVariance     0.647007
MaxReturn                                -310.649
MinReturn                                -686.031
NumTrajs                                  128
Perplexity                                902.352
PolicyExecTime                              3.8377
ProcessExecTime                             0.102243
StdReturn                                 105.78
lstm_policy/Entropy                         6.1723
lstm_policy/KL                              0.977449
lstm_policy/KLBefore                        0.611002
lstm_policy/LossAfter                      -0.0504548
lstm_policy/LossBefore                     -0.0242625
lstm_policy/dLoss                           0.0261922
---------------------------------------  ------------
2020-09-01 13:48:08 | [drl] epoch #13 | Obtaining samples...
2020-09-01 13:48:08 | [drl] epoch #13 | Obtaining samples for iteration 13...
2020-09-01 13:48:15 | [drl] epoch #13 | Logging diagnostics...
2020-09-01 13:48:15 | [drl] epoch #13 | Optimizing policy...
2020-09-01 13:48:15 | [drl] epoch #13 | Computing loss before
2020-09-01 13:48:15 | [drl] epoch #13 | Computing KL before
2020-09-01 13:48:15 | [drl] epoch #13 | Optimizing
2020-09-01 13:48:15 | [drl] epoch #13 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 13:48:15 | [drl] epoch #13 | computing loss before
2020-09-01 13:48:15 | [drl] epoch #13 | computing gradient
2020-09-01 13:48:15 | [drl] epoch #13 | gradient computed
2020-09-01 13:48:15 | [drl] epoch #13 | computing descent direction
2020-09-01 13:48:16 | [drl] epoch #13 | descent direction computed
2020-09-01 13:48:16 | [drl] epoch #13 | backtrack iters: 7
2020-09-01 13:48:16 | [drl] epoch #13 | optimization finished
2020-09-01 13:48:16 | [drl] epoch #13 | Computing KL after
2020-09-01 13:48:16 | [drl] epoch #13 | Computing loss after
2020-09-01 13:48:17 | [drl] epoch #13 | Fitting baseline...
2020-09-01 13:48:17 | [drl] epoch #13 | Saving snapshot...
2020-09-01 13:48:17 | [drl] epoch #13 | Saved
2020-09-01 13:48:17 | [drl] epoch #13 | Time 116.08 s
2020-09-01 13:48:17 | [drl] epoch #13 | EpochTime 8.35 s
---------------------------------------  -------------
AverageDiscountedReturn                  -344.819
AverageReturn                            -406.279
Entropy                                     6.56478
EnvExecTime                                 1.84613
Extras/EpisodeRewardMean                 -405.918
Iteration                                  13
LinearFeatureBaseline/ExplainedVariance     0.622747
MaxReturn                                -286.011
MinReturn                                -658.447
NumTrajs                                  125
Perplexity                                709.657
PolicyExecTime                              3.9295
ProcessExecTime                             0.101664
StdReturn                                 113.904
lstm_policy/Entropy                         5.95087
lstm_policy/KL                              0.979837
lstm_policy/KLBefore                        0.887469
lstm_policy/LossAfter                      -0.033727
lstm_policy/LossBefore                     -0.00133923
lstm_policy/dLoss                           0.0323877
---------------------------------------  -------------
2020-09-01 13:48:17 | [drl] epoch #14 | Obtaining samples...
2020-09-01 13:48:17 | [drl] epoch #14 | Obtaining samples for iteration 14...
2020-09-01 13:48:23 | [drl] epoch #14 | Logging diagnostics...
2020-09-01 13:48:23 | [drl] epoch #14 | Optimizing policy...
2020-09-01 13:48:23 | [drl] epoch #14 | Computing loss before
2020-09-01 13:48:23 | [drl] epoch #14 | Computing KL before
2020-09-01 13:48:23 | [drl] epoch #14 | Optimizing
2020-09-01 13:48:23 | [drl] epoch #14 | Start CG optimization: #parameters: 19852, #inputs: 150, #subsample_inputs: 150
2020-09-01 13:48:23 | [drl] epoch #14 | computing loss before
2020-09-01 13:48:23 | [drl] epoch #14 | computing gradient
2020-09-01 13:48:23 | [drl] epoch #14 | gradient computed
2020-09-01 13:48:23 | [drl] epoch #14 | computing descent direction
2020-09-01 13:48:25 | [drl] epoch #14 | descent direction computed
2020-09-01 13:48:25 | [drl] epoch #14 | backtrack iters: 5
2020-09-01 13:48:25 | [drl] epoch #14 | optimization finished
2020-09-01 13:48:25 | [drl] epoch #14 | Computing KL after
2020-09-01 13:48:25 | [drl] epoch #14 | Computing loss after
2020-09-01 13:48:25 | [drl] epoch #14 | Fitting baseline...
2020-09-01 13:48:25 | [drl] epoch #14 | Saving snapshot...
2020-09-01 13:48:25 | [drl] epoch #14 | Saved
2020-09-01 13:48:25 | [drl] epoch #14 | Time 124.61 s
2020-09-01 13:48:25 | [drl] epoch #14 | EpochTime 8.51 s
---------------------------------------  ------------
AverageDiscountedReturn                  -307.474
AverageReturn                            -354.551
Entropy                                     6.18742
EnvExecTime                                 1.84413
Extras/EpisodeRewardMean                 -353.251
Iteration                                  14
LinearFeatureBaseline/ExplainedVariance     0.758008
MaxReturn                                -286.093
MinReturn                                -634.834
NumTrajs                                  150
Perplexity                                486.591
PolicyExecTime                              3.96405
ProcessExecTime                             0.100792
StdReturn                                  61.4128
lstm_policy/Entropy                         6.37131
lstm_policy/KL                              0.753221
lstm_policy/KLBefore                        0.386714
lstm_policy/LossAfter                       0.0377733
lstm_policy/LossBefore                      0.0626613
lstm_policy/dLoss                           0.0248879
---------------------------------------  ------------
2020-09-01 13:48:25 | [drl] epoch #15 | Obtaining samples...
2020-09-01 13:48:25 | [drl] epoch #15 | Obtaining samples for iteration 15...
2020-09-01 13:48:32 | [drl] epoch #15 | Logging diagnostics...
2020-09-01 13:48:32 | [drl] epoch #15 | Optimizing policy...
2020-09-01 13:48:32 | [drl] epoch #15 | Computing loss before
2020-09-01 13:48:32 | [drl] epoch #15 | Computing KL before
2020-09-01 13:48:32 | [drl] epoch #15 | Optimizing
2020-09-01 13:48:32 | [drl] epoch #15 | Start CG optimization: #parameters: 19852, #inputs: 136, #subsample_inputs: 136
2020-09-01 13:48:32 | [drl] epoch #15 | computing loss before
2020-09-01 13:48:32 | [drl] epoch #15 | computing gradient
2020-09-01 13:48:32 | [drl] epoch #15 | gradient computed
2020-09-01 13:48:32 | [drl] epoch #15 | computing descent direction
2020-09-01 13:48:33 | [drl] epoch #15 | descent direction computed
2020-09-01 13:48:33 | [drl] epoch #15 | backtrack iters: 8
2020-09-01 13:48:33 | [drl] epoch #15 | optimization finished
2020-09-01 13:48:33 | [drl] epoch #15 | Computing KL after
2020-09-01 13:48:33 | [drl] epoch #15 | Computing loss after
2020-09-01 13:48:33 | [drl] epoch #15 | Fitting baseline...
2020-09-01 13:48:33 | [drl] epoch #15 | Saving snapshot...
2020-09-01 13:48:33 | [drl] epoch #15 | Saved
2020-09-01 13:48:33 | [drl] epoch #15 | Time 132.94 s
2020-09-01 13:48:33 | [drl] epoch #15 | EpochTime 8.32 s
---------------------------------------  -------------
AverageDiscountedReturn                  -346.412
AverageReturn                            -405.381
Entropy                                     6.62455
EnvExecTime                                 1.81986
Extras/EpisodeRewardMean                 -411.278
Iteration                                  15
LinearFeatureBaseline/ExplainedVariance     0.638398
MaxReturn                                -307.7
MinReturn                                -664.527
NumTrajs                                  136
Perplexity                                753.364
PolicyExecTime                              3.82943
ProcessExecTime                             0.101294
StdReturn                                  98.527
lstm_policy/Entropy                         6.05694
lstm_policy/KL                              0.92084
lstm_policy/KLBefore                        0.893137
lstm_policy/LossAfter                       0.10045
lstm_policy/LossBefore                      0.103718
lstm_policy/dLoss                           0.00326765
---------------------------------------  -------------
2020-09-01 13:48:33 | [drl] epoch #16 | Obtaining samples...
2020-09-01 13:48:33 | [drl] epoch #16 | Obtaining samples for iteration 16...
2020-09-01 13:48:40 | [drl] epoch #16 | Logging diagnostics...
2020-09-01 13:48:40 | [drl] epoch #16 | Optimizing policy...
2020-09-01 13:48:40 | [drl] epoch #16 | Computing loss before
2020-09-01 13:48:40 | [drl] epoch #16 | Computing KL before
2020-09-01 13:48:40 | [drl] epoch #16 | Optimizing
2020-09-01 13:48:40 | [drl] epoch #16 | Start CG optimization: #parameters: 19852, #inputs: 129, #subsample_inputs: 129
2020-09-01 13:48:40 | [drl] epoch #16 | computing loss before
2020-09-01 13:48:40 | [drl] epoch #16 | computing gradient
2020-09-01 13:48:40 | [drl] epoch #16 | gradient computed
2020-09-01 13:48:40 | [drl] epoch #16 | computing descent direction
2020-09-01 13:48:42 | [drl] epoch #16 | descent direction computed
2020-09-01 13:48:42 | [drl] epoch #16 | backtrack iters: 9
2020-09-01 13:48:42 | [drl] epoch #16 | optimization finished
2020-09-01 13:48:42 | [drl] epoch #16 | Computing KL after
2020-09-01 13:48:42 | [drl] epoch #16 | Computing loss after
2020-09-01 13:48:42 | [drl] epoch #16 | Fitting baseline...
2020-09-01 13:48:42 | [drl] epoch #16 | Saving snapshot...
2020-09-01 13:48:42 | [drl] epoch #16 | Saved
2020-09-01 13:48:42 | [drl] epoch #16 | Time 141.31 s
2020-09-01 13:48:42 | [drl] epoch #16 | EpochTime 8.35 s
---------------------------------------  ------------
AverageDiscountedReturn                  -365.681
AverageReturn                            -434.688
Entropy                                     6.27643
EnvExecTime                                 1.81316
Extras/EpisodeRewardMean                 -434.618
Iteration                                  16
LinearFeatureBaseline/ExplainedVariance     0.608925
MaxReturn                                -331.169
MinReturn                                -670.37
NumTrajs                                  129
Perplexity                                531.888
PolicyExecTime                              3.91438
ProcessExecTime                             0.101932
StdReturn                                 112.178
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              0.850576
lstm_policy/KLBefore                        0.706854
lstm_policy/LossAfter                       0.027386
lstm_policy/LossBefore                      0.0447192
lstm_policy/dLoss                           0.0173332
---------------------------------------  ------------
2020-09-01 13:48:42 | [drl] epoch #17 | Obtaining samples...
2020-09-01 13:48:42 | [drl] epoch #17 | Obtaining samples for iteration 17...
2020-09-01 13:48:48 | [drl] epoch #17 | Logging diagnostics...
2020-09-01 13:48:48 | [drl] epoch #17 | Optimizing policy...
2020-09-01 13:48:48 | [drl] epoch #17 | Computing loss before
2020-09-01 13:48:48 | [drl] epoch #17 | Computing KL before
2020-09-01 13:48:48 | [drl] epoch #17 | Optimizing
2020-09-01 13:48:48 | [drl] epoch #17 | Start CG optimization: #parameters: 19852, #inputs: 148, #subsample_inputs: 148
2020-09-01 13:48:48 | [drl] epoch #17 | computing loss before
2020-09-01 13:48:48 | [drl] epoch #17 | computing gradient
2020-09-01 13:48:48 | [drl] epoch #17 | gradient computed
2020-09-01 13:48:48 | [drl] epoch #17 | computing descent direction
2020-09-01 13:48:50 | [drl] epoch #17 | descent direction computed
2020-09-01 13:48:50 | [drl] epoch #17 | Line search condition violated. Rejecting the step!
2020-09-01 13:48:50 | [drl] epoch #17 | Violated because loss not improving
2020-09-01 13:48:50 | [drl] epoch #17 | backtrack iters: 14
2020-09-01 13:48:50 | [drl] epoch #17 | optimization finished
2020-09-01 13:48:50 | [drl] epoch #17 | Computing KL after
2020-09-01 13:48:50 | [drl] epoch #17 | Computing loss after
2020-09-01 13:48:50 | [drl] epoch #17 | Fitting baseline...
2020-09-01 13:48:50 | [drl] epoch #17 | Saving snapshot...
2020-09-01 13:48:50 | [drl] epoch #17 | Saved
2020-09-01 13:48:50 | [drl] epoch #17 | Time 149.75 s
2020-09-01 13:48:50 | [drl] epoch #17 | EpochTime 8.43 s
---------------------------------------  ------------
AverageDiscountedReturn                  -300
AverageReturn                            -342.643
Entropy                                     6.16007
EnvExecTime                                 1.76398
Extras/EpisodeRewardMean                 -344.86
Iteration                                  17
LinearFeatureBaseline/ExplainedVariance     0.848472
MaxReturn                                -287.964
MinReturn                                -614.956
NumTrajs                                  148
Perplexity                                473.463
PolicyExecTime                              3.78453
ProcessExecTime                             0.0972672
StdReturn                                  36.9472
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              0.850394
lstm_policy/KLBefore                        0.850394
lstm_policy/LossAfter                       0.101673
lstm_policy/LossBefore                      0.101673
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:48:50 | [drl] epoch #18 | Obtaining samples...
2020-09-01 13:48:50 | [drl] epoch #18 | Obtaining samples for iteration 18...
2020-09-01 13:48:57 | [drl] epoch #18 | Logging diagnostics...
2020-09-01 13:48:57 | [drl] epoch #18 | Optimizing policy...
2020-09-01 13:48:57 | [drl] epoch #18 | Computing loss before
2020-09-01 13:48:57 | [drl] epoch #18 | Computing KL before
2020-09-01 13:48:57 | [drl] epoch #18 | Optimizing
2020-09-01 13:48:57 | [drl] epoch #18 | Start CG optimization: #parameters: 19852, #inputs: 144, #subsample_inputs: 144
2020-09-01 13:48:57 | [drl] epoch #18 | computing loss before
2020-09-01 13:48:57 | [drl] epoch #18 | computing gradient
2020-09-01 13:48:57 | [drl] epoch #18 | gradient computed
2020-09-01 13:48:57 | [drl] epoch #18 | computing descent direction
2020-09-01 13:48:58 | [drl] epoch #18 | descent direction computed
2020-09-01 13:48:59 | [drl] epoch #18 | Line search condition violated. Rejecting the step!
2020-09-01 13:48:59 | [drl] epoch #18 | Violated because loss not improving
2020-09-01 13:48:59 | [drl] epoch #18 | Violated because constraint mean_kl is violated
2020-09-01 13:48:59 | [drl] epoch #18 | backtrack iters: 14
2020-09-01 13:48:59 | [drl] epoch #18 | optimization finished
2020-09-01 13:48:59 | [drl] epoch #18 | Computing KL after
2020-09-01 13:48:59 | [drl] epoch #18 | Computing loss after
2020-09-01 13:48:59 | [drl] epoch #18 | Fitting baseline...
2020-09-01 13:48:59 | [drl] epoch #18 | Saving snapshot...
2020-09-01 13:48:59 | [drl] epoch #18 | Saved
2020-09-01 13:48:59 | [drl] epoch #18 | Time 158.32 s
2020-09-01 13:48:59 | [drl] epoch #18 | EpochTime 8.56 s
---------------------------------------  -----------
AverageDiscountedReturn                  -306.184
AverageReturn                            -350.914
Entropy                                     6.18089
EnvExecTime                                 1.81954
Extras/EpisodeRewardMean                 -350.563
Iteration                                  18
LinearFeatureBaseline/ExplainedVariance     0.893849
MaxReturn                                -276.861
MinReturn                                -630.15
NumTrajs                                  144
Perplexity                                483.42
PolicyExecTime                              3.89846
ProcessExecTime                             0.10407
StdReturn                                  42.7488
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              1.00304
lstm_policy/KLBefore                        1.00304
lstm_policy/LossAfter                       0.164727
lstm_policy/LossBefore                      0.164727
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:48:59 | [drl] epoch #19 | Obtaining samples...
2020-09-01 13:48:59 | [drl] epoch #19 | Obtaining samples for iteration 19...
2020-09-01 13:49:05 | [drl] epoch #19 | Logging diagnostics...
2020-09-01 13:49:05 | [drl] epoch #19 | Optimizing policy...
2020-09-01 13:49:05 | [drl] epoch #19 | Computing loss before
2020-09-01 13:49:05 | [drl] epoch #19 | Computing KL before
2020-09-01 13:49:05 | [drl] epoch #19 | Optimizing
2020-09-01 13:49:05 | [drl] epoch #19 | Start CG optimization: #parameters: 19852, #inputs: 147, #subsample_inputs: 147
2020-09-01 13:49:05 | [drl] epoch #19 | computing loss before
2020-09-01 13:49:05 | [drl] epoch #19 | computing gradient
2020-09-01 13:49:06 | [drl] epoch #19 | gradient computed
2020-09-01 13:49:06 | [drl] epoch #19 | computing descent direction
2020-09-01 13:49:07 | [drl] epoch #19 | descent direction computed
2020-09-01 13:49:07 | [drl] epoch #19 | backtrack iters: 12
2020-09-01 13:49:07 | [drl] epoch #19 | optimization finished
2020-09-01 13:49:07 | [drl] epoch #19 | Computing KL after
2020-09-01 13:49:07 | [drl] epoch #19 | Computing loss after
2020-09-01 13:49:07 | [drl] epoch #19 | Fitting baseline...
2020-09-01 13:49:07 | [drl] epoch #19 | Saving snapshot...
2020-09-01 13:49:07 | [drl] epoch #19 | Saved
2020-09-01 13:49:07 | [drl] epoch #19 | Time 166.88 s
2020-09-01 13:49:07 | [drl] epoch #19 | EpochTime 8.54 s
---------------------------------------  ------------
AverageDiscountedReturn                  -303.182
AverageReturn                            -347.164
Entropy                                     6.15675
EnvExecTime                                 1.83482
Extras/EpisodeRewardMean                 -348.299
Iteration                                  19
LinearFeatureBaseline/ExplainedVariance     0.856599
MaxReturn                                -292.101
MinReturn                                -634.931
NumTrajs                                  147
Perplexity                                471.89
PolicyExecTime                              3.87089
ProcessExecTime                             0.104787
StdReturn                                  49.4881
lstm_policy/Entropy                         6.01543
lstm_policy/KL                              0.995135
lstm_policy/KLBefore                        0.917631
lstm_policy/LossAfter                       0.05787
lstm_policy/LossBefore                      0.111192
lstm_policy/dLoss                           0.0533217
---------------------------------------  ------------
2020-09-01 13:49:07 | [drl] epoch #20 | Obtaining samples...
2020-09-01 13:49:07 | [drl] epoch #20 | Obtaining samples for iteration 20...
2020-09-01 13:49:14 | [drl] epoch #20 | Logging diagnostics...
2020-09-01 13:49:14 | [drl] epoch #20 | Optimizing policy...
2020-09-01 13:49:14 | [drl] epoch #20 | Computing loss before
2020-09-01 13:49:14 | [drl] epoch #20 | Computing KL before
2020-09-01 13:49:14 | [drl] epoch #20 | Optimizing
2020-09-01 13:49:14 | [drl] epoch #20 | Start CG optimization: #parameters: 19852, #inputs: 147, #subsample_inputs: 147
2020-09-01 13:49:14 | [drl] epoch #20 | computing loss before
2020-09-01 13:49:14 | [drl] epoch #20 | computing gradient
2020-09-01 13:49:14 | [drl] epoch #20 | gradient computed
2020-09-01 13:49:14 | [drl] epoch #20 | computing descent direction
2020-09-01 13:49:16 | [drl] epoch #20 | descent direction computed
2020-09-01 13:49:16 | [drl] epoch #20 | backtrack iters: 8
2020-09-01 13:49:16 | [drl] epoch #20 | optimization finished
2020-09-01 13:49:16 | [drl] epoch #20 | Computing KL after
2020-09-01 13:49:16 | [drl] epoch #20 | Computing loss after
2020-09-01 13:49:16 | [drl] epoch #20 | Fitting baseline...
2020-09-01 13:49:16 | [drl] epoch #20 | Saving snapshot...
2020-09-01 13:49:16 | [drl] epoch #20 | Saved
2020-09-01 13:49:16 | [drl] epoch #20 | Time 175.41 s
2020-09-01 13:49:16 | [drl] epoch #20 | EpochTime 8.52 s
---------------------------------------  ------------
AverageDiscountedReturn                  -310.693
AverageReturn                            -357.223
Entropy                                     6.3277
EnvExecTime                                 1.82269
Extras/EpisodeRewardMean                 -358.955
Iteration                                  20
LinearFeatureBaseline/ExplainedVariance     0.808592
MaxReturn                                -277.347
MinReturn                                -639.889
NumTrajs                                  147
Perplexity                                559.869
PolicyExecTime                              3.89768
ProcessExecTime                             0.0998645
StdReturn                                  57.3637
lstm_policy/Entropy                         5.80118
lstm_policy/KL                              0.932155
lstm_policy/KLBefore                        0.749848
lstm_policy/LossAfter                       0.0519498
lstm_policy/LossBefore                      0.0738656
lstm_policy/dLoss                           0.0219158
---------------------------------------  ------------
2020-09-01 13:49:16 | [drl] epoch #21 | Obtaining samples...
2020-09-01 13:49:16 | [drl] epoch #21 | Obtaining samples for iteration 21...
2020-09-01 13:49:22 | [drl] epoch #21 | Logging diagnostics...
2020-09-01 13:49:22 | [drl] epoch #21 | Optimizing policy...
2020-09-01 13:49:22 | [drl] epoch #21 | Computing loss before
2020-09-01 13:49:23 | [drl] epoch #21 | Computing KL before
2020-09-01 13:49:23 | [drl] epoch #21 | Optimizing
2020-09-01 13:49:23 | [drl] epoch #21 | Start CG optimization: #parameters: 19852, #inputs: 144, #subsample_inputs: 144
2020-09-01 13:49:23 | [drl] epoch #21 | computing loss before
2020-09-01 13:49:23 | [drl] epoch #21 | computing gradient
2020-09-01 13:49:23 | [drl] epoch #21 | gradient computed
2020-09-01 13:49:23 | [drl] epoch #21 | computing descent direction
2020-09-01 13:49:24 | [drl] epoch #21 | descent direction computed
2020-09-01 13:49:24 | [drl] epoch #21 | backtrack iters: 3
2020-09-01 13:49:24 | [drl] epoch #21 | optimization finished
2020-09-01 13:49:24 | [drl] epoch #21 | Computing KL after
2020-09-01 13:49:24 | [drl] epoch #21 | Computing loss after
2020-09-01 13:49:24 | [drl] epoch #21 | Fitting baseline...
2020-09-01 13:49:24 | [drl] epoch #21 | Saving snapshot...
2020-09-01 13:49:24 | [drl] epoch #21 | Saved
2020-09-01 13:49:24 | [drl] epoch #21 | Time 183.82 s
2020-09-01 13:49:24 | [drl] epoch #21 | EpochTime 8.39 s
---------------------------------------  ------------
AverageDiscountedReturn                  -336.534
AverageReturn                            -395.969
Entropy                                     5.90747
EnvExecTime                                 1.7958
Extras/EpisodeRewardMean                 -392.681
Iteration                                  21
LinearFeatureBaseline/ExplainedVariance     0.562938
MaxReturn                                -292.75
MinReturn                                -653.053
NumTrajs                                  144
Perplexity                                367.773
PolicyExecTime                              3.934
ProcessExecTime                             0.104355
StdReturn                                 100.487
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              0.967224
lstm_policy/KLBefore                        0.205504
lstm_policy/LossAfter                       0.0566996
lstm_policy/LossBefore                      0.0961712
lstm_policy/dLoss                           0.0394716
---------------------------------------  ------------
2020-09-01 13:49:24 | [drl] epoch #22 | Obtaining samples...
2020-09-01 13:49:24 | [drl] epoch #22 | Obtaining samples for iteration 22...
2020-09-01 13:49:31 | [drl] epoch #22 | Logging diagnostics...
2020-09-01 13:49:31 | [drl] epoch #22 | Optimizing policy...
2020-09-01 13:49:31 | [drl] epoch #22 | Computing loss before
2020-09-01 13:49:31 | [drl] epoch #22 | Computing KL before
2020-09-01 13:49:31 | [drl] epoch #22 | Optimizing
2020-09-01 13:49:31 | [drl] epoch #22 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:49:31 | [drl] epoch #22 | computing loss before
2020-09-01 13:49:31 | [drl] epoch #22 | computing gradient
2020-09-01 13:49:31 | [drl] epoch #22 | gradient computed
2020-09-01 13:49:31 | [drl] epoch #22 | computing descent direction
2020-09-01 13:49:32 | [drl] epoch #22 | descent direction computed
2020-09-01 13:49:33 | [drl] epoch #22 | Line search condition violated. Rejecting the step!
2020-09-01 13:49:33 | [drl] epoch #22 | Violated because constraint mean_kl is violated
2020-09-01 13:49:33 | [drl] epoch #22 | backtrack iters: 14
2020-09-01 13:49:33 | [drl] epoch #22 | optimization finished
2020-09-01 13:49:33 | [drl] epoch #22 | Computing KL after
2020-09-01 13:49:33 | [drl] epoch #22 | Computing loss after
2020-09-01 13:49:33 | [drl] epoch #22 | Fitting baseline...
2020-09-01 13:49:33 | [drl] epoch #22 | Saving snapshot...
2020-09-01 13:49:33 | [drl] epoch #22 | Saved
2020-09-01 13:49:33 | [drl] epoch #22 | Time 192.13 s
2020-09-01 13:49:33 | [drl] epoch #22 | EpochTime 8.30 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.373
AverageReturn                            -399.838
Entropy                                     5.99371
EnvExecTime                                 1.82523
Extras/EpisodeRewardMean                 -401.948
Iteration                                  22
LinearFeatureBaseline/ExplainedVariance     0.613215
MaxReturn                                -284.2
MinReturn                                -639.718
NumTrajs                                  119
Perplexity                                400.901
PolicyExecTime                              3.89205
ProcessExecTime                             0.0997298
StdReturn                                 117.927
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.90403
lstm_policy/KLBefore                        1.90403
lstm_policy/LossAfter                       0.0146143
lstm_policy/LossBefore                      0.0146143
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:49:33 | [drl] epoch #23 | Obtaining samples...
2020-09-01 13:49:33 | [drl] epoch #23 | Obtaining samples for iteration 23...
2020-09-01 13:49:39 | [drl] epoch #23 | Logging diagnostics...
2020-09-01 13:49:39 | [drl] epoch #23 | Optimizing policy...
2020-09-01 13:49:39 | [drl] epoch #23 | Computing loss before
2020-09-01 13:49:39 | [drl] epoch #23 | Computing KL before
2020-09-01 13:49:39 | [drl] epoch #23 | Optimizing
2020-09-01 13:49:39 | [drl] epoch #23 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:49:39 | [drl] epoch #23 | computing loss before
2020-09-01 13:49:39 | [drl] epoch #23 | computing gradient
2020-09-01 13:49:39 | [drl] epoch #23 | gradient computed
2020-09-01 13:49:39 | [drl] epoch #23 | computing descent direction
2020-09-01 13:49:40 | [drl] epoch #23 | descent direction computed
2020-09-01 13:49:41 | [drl] epoch #23 | Line search condition violated. Rejecting the step!
2020-09-01 13:49:41 | [drl] epoch #23 | Violated because loss not improving
2020-09-01 13:49:41 | [drl] epoch #23 | Violated because constraint mean_kl is violated
2020-09-01 13:49:41 | [drl] epoch #23 | backtrack iters: 14
2020-09-01 13:49:41 | [drl] epoch #23 | optimization finished
2020-09-01 13:49:41 | [drl] epoch #23 | Computing KL after
2020-09-01 13:49:41 | [drl] epoch #23 | Computing loss after
2020-09-01 13:49:41 | [drl] epoch #23 | Fitting baseline...
2020-09-01 13:49:41 | [drl] epoch #23 | Saving snapshot...
2020-09-01 13:49:41 | [drl] epoch #23 | Saved
2020-09-01 13:49:41 | [drl] epoch #23 | Time 200.32 s
2020-09-01 13:49:41 | [drl] epoch #23 | EpochTime 8.18 s
---------------------------------------  ------------
AverageDiscountedReturn                  -353.635
AverageReturn                            -423.306
Entropy                                     5.91365
EnvExecTime                                 1.80933
Extras/EpisodeRewardMean                 -427.785
Iteration                                  23
LinearFeatureBaseline/ExplainedVariance     0.603544
MaxReturn                                -281.028
MinReturn                                -657.342
NumTrajs                                  117
Perplexity                                370.053
PolicyExecTime                              3.84658
ProcessExecTime                             0.101135
StdReturn                                 125.534
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.62212
lstm_policy/KLBefore                        1.62212
lstm_policy/LossAfter                      -0.0266518
lstm_policy/LossBefore                     -0.0266518
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:49:41 | [drl] epoch #24 | Obtaining samples...
2020-09-01 13:49:41 | [drl] epoch #24 | Obtaining samples for iteration 24...
2020-09-01 13:49:47 | [drl] epoch #24 | Logging diagnostics...
2020-09-01 13:49:47 | [drl] epoch #24 | Optimizing policy...
2020-09-01 13:49:47 | [drl] epoch #24 | Computing loss before
2020-09-01 13:49:47 | [drl] epoch #24 | Computing KL before
2020-09-01 13:49:47 | [drl] epoch #24 | Optimizing
2020-09-01 13:49:47 | [drl] epoch #24 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:49:47 | [drl] epoch #24 | computing loss before
2020-09-01 13:49:47 | [drl] epoch #24 | computing gradient
2020-09-01 13:49:47 | [drl] epoch #24 | gradient computed
2020-09-01 13:49:47 | [drl] epoch #24 | computing descent direction
2020-09-01 13:49:49 | [drl] epoch #24 | descent direction computed
2020-09-01 13:49:49 | [drl] epoch #24 | Line search condition violated. Rejecting the step!
2020-09-01 13:49:49 | [drl] epoch #24 | Violated because loss not improving
2020-09-01 13:49:49 | [drl] epoch #24 | Violated because constraint mean_kl is violated
2020-09-01 13:49:49 | [drl] epoch #24 | backtrack iters: 14
2020-09-01 13:49:49 | [drl] epoch #24 | optimization finished
2020-09-01 13:49:49 | [drl] epoch #24 | Computing KL after
2020-09-01 13:49:49 | [drl] epoch #24 | Computing loss after
2020-09-01 13:49:49 | [drl] epoch #24 | Fitting baseline...
2020-09-01 13:49:49 | [drl] epoch #24 | Saving snapshot...
2020-09-01 13:49:49 | [drl] epoch #24 | Saved
2020-09-01 13:49:49 | [drl] epoch #24 | Time 208.56 s
2020-09-01 13:49:49 | [drl] epoch #24 | EpochTime 8.23 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.212
AverageReturn                            -413.058
Entropy                                     5.93232
EnvExecTime                                 1.81213
Extras/EpisodeRewardMean                 -414.659
Iteration                                  24
LinearFeatureBaseline/ExplainedVariance     0.602173
MaxReturn                                -280.381
MinReturn                                -638.907
NumTrajs                                  119
Perplexity                                377.027
PolicyExecTime                              3.90552
ProcessExecTime                             0.0987105
StdReturn                                 124.056
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.68548
lstm_policy/KLBefore                        1.68548
lstm_policy/LossAfter                      -0.0364258
lstm_policy/LossBefore                     -0.0364258
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:49:49 | [drl] epoch #25 | Obtaining samples...
2020-09-01 13:49:49 | [drl] epoch #25 | Obtaining samples for iteration 25...
2020-09-01 13:49:56 | [drl] epoch #25 | Logging diagnostics...
2020-09-01 13:49:56 | [drl] epoch #25 | Optimizing policy...
2020-09-01 13:49:56 | [drl] epoch #25 | Computing loss before
2020-09-01 13:49:56 | [drl] epoch #25 | Computing KL before
2020-09-01 13:49:56 | [drl] epoch #25 | Optimizing
2020-09-01 13:49:56 | [drl] epoch #25 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:49:56 | [drl] epoch #25 | computing loss before
2020-09-01 13:49:56 | [drl] epoch #25 | computing gradient
2020-09-01 13:49:56 | [drl] epoch #25 | gradient computed
2020-09-01 13:49:56 | [drl] epoch #25 | computing descent direction
2020-09-01 13:49:57 | [drl] epoch #25 | descent direction computed
2020-09-01 13:49:57 | [drl] epoch #25 | Line search condition violated. Rejecting the step!
2020-09-01 13:49:57 | [drl] epoch #25 | Violated because constraint mean_kl is violated
2020-09-01 13:49:57 | [drl] epoch #25 | backtrack iters: 14
2020-09-01 13:49:57 | [drl] epoch #25 | optimization finished
2020-09-01 13:49:57 | [drl] epoch #25 | Computing KL after
2020-09-01 13:49:57 | [drl] epoch #25 | Computing loss after
2020-09-01 13:49:57 | [drl] epoch #25 | Fitting baseline...
2020-09-01 13:49:57 | [drl] epoch #25 | Saving snapshot...
2020-09-01 13:49:57 | [drl] epoch #25 | Saved
2020-09-01 13:49:57 | [drl] epoch #25 | Time 216.95 s
2020-09-01 13:49:57 | [drl] epoch #25 | EpochTime 8.37 s
---------------------------------------  ------------
AverageDiscountedReturn                  -330.732
AverageReturn                            -389.957
Entropy                                     6.03287
EnvExecTime                                 1.82332
Extras/EpisodeRewardMean                 -395.839
Iteration                                  25
LinearFeatureBaseline/ExplainedVariance     0.633271
MaxReturn                                -260.966
MinReturn                                -633.72
NumTrajs                                  121
Perplexity                                416.909
PolicyExecTime                              3.93098
ProcessExecTime                             0.100694
StdReturn                                 110.402
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.03512
lstm_policy/KLBefore                        2.03512
lstm_policy/LossAfter                      -0.0370527
lstm_policy/LossBefore                     -0.0370527
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:49:57 | [drl] epoch #26 | Obtaining samples...
2020-09-01 13:49:57 | [drl] epoch #26 | Obtaining samples for iteration 26...
2020-09-01 13:50:04 | [drl] epoch #26 | Logging diagnostics...
2020-09-01 13:50:04 | [drl] epoch #26 | Optimizing policy...
2020-09-01 13:50:04 | [drl] epoch #26 | Computing loss before
2020-09-01 13:50:04 | [drl] epoch #26 | Computing KL before
2020-09-01 13:50:04 | [drl] epoch #26 | Optimizing
2020-09-01 13:50:04 | [drl] epoch #26 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:50:04 | [drl] epoch #26 | computing loss before
2020-09-01 13:50:04 | [drl] epoch #26 | computing gradient
2020-09-01 13:50:04 | [drl] epoch #26 | gradient computed
2020-09-01 13:50:04 | [drl] epoch #26 | computing descent direction
2020-09-01 13:50:06 | [drl] epoch #26 | descent direction computed
2020-09-01 13:50:06 | [drl] epoch #26 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:06 | [drl] epoch #26 | Violated because loss not improving
2020-09-01 13:50:06 | [drl] epoch #26 | Violated because constraint mean_kl is violated
2020-09-01 13:50:06 | [drl] epoch #26 | backtrack iters: 14
2020-09-01 13:50:06 | [drl] epoch #26 | optimization finished
2020-09-01 13:50:06 | [drl] epoch #26 | Computing KL after
2020-09-01 13:50:06 | [drl] epoch #26 | Computing loss after
2020-09-01 13:50:06 | [drl] epoch #26 | Fitting baseline...
2020-09-01 13:50:06 | [drl] epoch #26 | Saving snapshot...
2020-09-01 13:50:06 | [drl] epoch #26 | Saved
2020-09-01 13:50:06 | [drl] epoch #26 | Time 225.39 s
2020-09-01 13:50:06 | [drl] epoch #26 | EpochTime 8.43 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.729
AverageReturn                            -405.7
Entropy                                     5.95664
EnvExecTime                                 1.82987
Extras/EpisodeRewardMean                 -395.596
Iteration                                  26
LinearFeatureBaseline/ExplainedVariance     0.612885
MaxReturn                                -294.65
MinReturn                                -635.826
NumTrajs                                  120
Perplexity                                386.312
PolicyExecTime                              3.91838
ProcessExecTime                             0.111478
StdReturn                                 118.589
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.75639
lstm_policy/KLBefore                        1.75639
lstm_policy/LossAfter                      -0.0103209
lstm_policy/LossBefore                     -0.0103209
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:50:06 | [drl] epoch #27 | Obtaining samples...
2020-09-01 13:50:06 | [drl] epoch #27 | Obtaining samples for iteration 27...
2020-09-01 13:50:12 | [drl] epoch #27 | Logging diagnostics...
2020-09-01 13:50:12 | [drl] epoch #27 | Optimizing policy...
2020-09-01 13:50:12 | [drl] epoch #27 | Computing loss before
2020-09-01 13:50:12 | [drl] epoch #27 | Computing KL before
2020-09-01 13:50:12 | [drl] epoch #27 | Optimizing
2020-09-01 13:50:12 | [drl] epoch #27 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:50:12 | [drl] epoch #27 | computing loss before
2020-09-01 13:50:12 | [drl] epoch #27 | computing gradient
2020-09-01 13:50:13 | [drl] epoch #27 | gradient computed
2020-09-01 13:50:13 | [drl] epoch #27 | computing descent direction
2020-09-01 13:50:14 | [drl] epoch #27 | descent direction computed
2020-09-01 13:50:14 | [drl] epoch #27 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:14 | [drl] epoch #27 | Violated because loss not improving
2020-09-01 13:50:14 | [drl] epoch #27 | Violated because constraint mean_kl is violated
2020-09-01 13:50:14 | [drl] epoch #27 | backtrack iters: 14
2020-09-01 13:50:14 | [drl] epoch #27 | optimization finished
2020-09-01 13:50:14 | [drl] epoch #27 | Computing KL after
2020-09-01 13:50:14 | [drl] epoch #27 | Computing loss after
2020-09-01 13:50:14 | [drl] epoch #27 | Fitting baseline...
2020-09-01 13:50:14 | [drl] epoch #27 | Saving snapshot...
2020-09-01 13:50:14 | [drl] epoch #27 | Saved
2020-09-01 13:50:14 | [drl] epoch #27 | Time 233.65 s
2020-09-01 13:50:14 | [drl] epoch #27 | EpochTime 8.24 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.446
AverageReturn                            -403.899
Entropy                                     6.06686
EnvExecTime                                 1.83267
Extras/EpisodeRewardMean                 -406.537
Iteration                                  27
LinearFeatureBaseline/ExplainedVariance     0.643605
MaxReturn                                -286.519
MinReturn                                -631.526
NumTrajs                                  116
Perplexity                                431.322
PolicyExecTime                              3.91686
ProcessExecTime                             0.0986543
StdReturn                                 116.103
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.1746
lstm_policy/KLBefore                        2.1746
lstm_policy/LossAfter                      -0.0364018
lstm_policy/LossBefore                     -0.0364018
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:50:14 | [drl] epoch #28 | Obtaining samples...
2020-09-01 13:50:14 | [drl] epoch #28 | Obtaining samples for iteration 28...
2020-09-01 13:50:21 | [drl] epoch #28 | Logging diagnostics...
2020-09-01 13:50:21 | [drl] epoch #28 | Optimizing policy...
2020-09-01 13:50:21 | [drl] epoch #28 | Computing loss before
2020-09-01 13:50:21 | [drl] epoch #28 | Computing KL before
2020-09-01 13:50:21 | [drl] epoch #28 | Optimizing
2020-09-01 13:50:21 | [drl] epoch #28 | Start CG optimization: #parameters: 19852, #inputs: 123, #subsample_inputs: 123
2020-09-01 13:50:21 | [drl] epoch #28 | computing loss before
2020-09-01 13:50:21 | [drl] epoch #28 | computing gradient
2020-09-01 13:50:21 | [drl] epoch #28 | gradient computed
2020-09-01 13:50:21 | [drl] epoch #28 | computing descent direction
2020-09-01 13:50:22 | [drl] epoch #28 | descent direction computed
2020-09-01 13:50:22 | [drl] epoch #28 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:22 | [drl] epoch #28 | Violated because constraint mean_kl is violated
2020-09-01 13:50:22 | [drl] epoch #28 | backtrack iters: 14
2020-09-01 13:50:22 | [drl] epoch #28 | optimization finished
2020-09-01 13:50:22 | [drl] epoch #28 | Computing KL after
2020-09-01 13:50:22 | [drl] epoch #28 | Computing loss after
2020-09-01 13:50:23 | [drl] epoch #28 | Fitting baseline...
2020-09-01 13:50:23 | [drl] epoch #28 | Saving snapshot...
2020-09-01 13:50:23 | [drl] epoch #28 | Saved
2020-09-01 13:50:23 | [drl] epoch #28 | Time 242.05 s
2020-09-01 13:50:23 | [drl] epoch #28 | EpochTime 8.38 s
---------------------------------------  ------------
AverageDiscountedReturn                  -325.673
AverageReturn                            -383.25
Entropy                                     6.02014
EnvExecTime                                 1.84684
Extras/EpisodeRewardMean                 -390.537
Iteration                                  28
LinearFeatureBaseline/ExplainedVariance     0.641494
MaxReturn                                -278.314
MinReturn                                -647.015
NumTrajs                                  123
Perplexity                                411.638
PolicyExecTime                              3.90678
ProcessExecTime                             0.0998502
StdReturn                                 106.837
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.98062
lstm_policy/KLBefore                        1.98062
lstm_policy/LossAfter                      -0.0134612
lstm_policy/LossBefore                     -0.0134612
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:50:23 | [drl] epoch #29 | Obtaining samples...
2020-09-01 13:50:23 | [drl] epoch #29 | Obtaining samples for iteration 29...
2020-09-01 13:50:30 | [drl] epoch #29 | Logging diagnostics...
2020-09-01 13:50:30 | [drl] epoch #29 | Optimizing policy...
2020-09-01 13:50:30 | [drl] epoch #29 | Computing loss before
2020-09-01 13:50:30 | [drl] epoch #29 | Computing KL before
2020-09-01 13:50:30 | [drl] epoch #29 | Optimizing
2020-09-01 13:50:30 | [drl] epoch #29 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 13:50:30 | [drl] epoch #29 | computing loss before
2020-09-01 13:50:30 | [drl] epoch #29 | computing gradient
2020-09-01 13:50:30 | [drl] epoch #29 | gradient computed
2020-09-01 13:50:30 | [drl] epoch #29 | computing descent direction
2020-09-01 13:50:31 | [drl] epoch #29 | descent direction computed
2020-09-01 13:50:32 | [drl] epoch #29 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:32 | [drl] epoch #29 | Violated because loss not improving
2020-09-01 13:50:32 | [drl] epoch #29 | Violated because constraint mean_kl is violated
2020-09-01 13:50:32 | [drl] epoch #29 | backtrack iters: 14
2020-09-01 13:50:32 | [drl] epoch #29 | optimization finished
2020-09-01 13:50:32 | [drl] epoch #29 | Computing KL after
2020-09-01 13:50:32 | [drl] epoch #29 | Computing loss after
2020-09-01 13:50:32 | [drl] epoch #29 | Fitting baseline...
2020-09-01 13:50:32 | [drl] epoch #29 | Saving snapshot...
2020-09-01 13:50:32 | [drl] epoch #29 | Saved
2020-09-01 13:50:32 | [drl] epoch #29 | Time 251.24 s
2020-09-01 13:50:32 | [drl] epoch #29 | EpochTime 9.18 s
---------------------------------------  -------------
AverageDiscountedReturn                  -336.045
AverageReturn                            -397.777
Entropy                                     5.95452
EnvExecTime                                 2.01788
Extras/EpisodeRewardMean                 -400.304
Iteration                                  29
LinearFeatureBaseline/ExplainedVariance     0.605992
MaxReturn                                -273.609
MinReturn                                -640.52
NumTrajs                                  122
Perplexity                                385.493
PolicyExecTime                              4.38844
ProcessExecTime                             0.114706
StdReturn                                 118.98
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72373
lstm_policy/KLBefore                        1.72373
lstm_policy/LossAfter                      -0.00619431
lstm_policy/LossBefore                     -0.00619431
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:50:32 | [drl] epoch #30 | Obtaining samples...
2020-09-01 13:50:32 | [drl] epoch #30 | Obtaining samples for iteration 30...
2020-09-01 13:50:39 | [drl] epoch #30 | Logging diagnostics...
2020-09-01 13:50:39 | [drl] epoch #30 | Optimizing policy...
2020-09-01 13:50:39 | [drl] epoch #30 | Computing loss before
2020-09-01 13:50:39 | [drl] epoch #30 | Computing KL before
2020-09-01 13:50:39 | [drl] epoch #30 | Optimizing
2020-09-01 13:50:39 | [drl] epoch #30 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:50:39 | [drl] epoch #30 | computing loss before
2020-09-01 13:50:39 | [drl] epoch #30 | computing gradient
2020-09-01 13:50:39 | [drl] epoch #30 | gradient computed
2020-09-01 13:50:39 | [drl] epoch #30 | computing descent direction
2020-09-01 13:50:40 | [drl] epoch #30 | descent direction computed
2020-09-01 13:50:40 | [drl] epoch #30 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:40 | [drl] epoch #30 | Violated because loss not improving
2020-09-01 13:50:40 | [drl] epoch #30 | Violated because constraint mean_kl is violated
2020-09-01 13:50:40 | [drl] epoch #30 | backtrack iters: 14
2020-09-01 13:50:40 | [drl] epoch #30 | optimization finished
2020-09-01 13:50:40 | [drl] epoch #30 | Computing KL after
2020-09-01 13:50:40 | [drl] epoch #30 | Computing loss after
2020-09-01 13:50:40 | [drl] epoch #30 | Fitting baseline...
2020-09-01 13:50:40 | [drl] epoch #30 | Saving snapshot...
2020-09-01 13:50:40 | [drl] epoch #30 | Saved
2020-09-01 13:50:40 | [drl] epoch #30 | Time 259.83 s
2020-09-01 13:50:40 | [drl] epoch #30 | EpochTime 8.57 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.771
AverageReturn                            -396.04
Entropy                                     6.06775
EnvExecTime                                 1.94136
Extras/EpisodeRewardMean                 -400.514
Iteration                                  30
LinearFeatureBaseline/ExplainedVariance     0.62761
MaxReturn                                -290.252
MinReturn                                -652.17
NumTrajs                                  117
Perplexity                                431.709
PolicyExecTime                              4.06813
ProcessExecTime                             0.122708
StdReturn                                 117.135
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.15974
lstm_policy/KLBefore                        2.15974
lstm_policy/LossAfter                      -0.0240052
lstm_policy/LossBefore                     -0.0240052
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:50:40 | [drl] epoch #31 | Obtaining samples...
2020-09-01 13:50:40 | [drl] epoch #31 | Obtaining samples for iteration 31...
2020-09-01 13:50:47 | [drl] epoch #31 | Logging diagnostics...
2020-09-01 13:50:47 | [drl] epoch #31 | Optimizing policy...
2020-09-01 13:50:47 | [drl] epoch #31 | Computing loss before
2020-09-01 13:50:47 | [drl] epoch #31 | Computing KL before
2020-09-01 13:50:47 | [drl] epoch #31 | Optimizing
2020-09-01 13:50:47 | [drl] epoch #31 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:50:47 | [drl] epoch #31 | computing loss before
2020-09-01 13:50:47 | [drl] epoch #31 | computing gradient
2020-09-01 13:50:47 | [drl] epoch #31 | gradient computed
2020-09-01 13:50:47 | [drl] epoch #31 | computing descent direction
2020-09-01 13:50:48 | [drl] epoch #31 | descent direction computed
2020-09-01 13:50:49 | [drl] epoch #31 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:49 | [drl] epoch #31 | Violated because loss not improving
2020-09-01 13:50:49 | [drl] epoch #31 | Violated because constraint mean_kl is violated
2020-09-01 13:50:49 | [drl] epoch #31 | backtrack iters: 14
2020-09-01 13:50:49 | [drl] epoch #31 | optimization finished
2020-09-01 13:50:49 | [drl] epoch #31 | Computing KL after
2020-09-01 13:50:49 | [drl] epoch #31 | Computing loss after
2020-09-01 13:50:49 | [drl] epoch #31 | Fitting baseline...
2020-09-01 13:50:49 | [drl] epoch #31 | Saving snapshot...
2020-09-01 13:50:49 | [drl] epoch #31 | Saved
2020-09-01 13:50:49 | [drl] epoch #31 | Time 268.20 s
2020-09-01 13:50:49 | [drl] epoch #31 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.348
AverageReturn                            -414.675
Entropy                                     5.96515
EnvExecTime                                 1.83228
Extras/EpisodeRewardMean                 -413.066
Iteration                                  31
LinearFeatureBaseline/ExplainedVariance     0.605756
MaxReturn                                -287.158
MinReturn                                -632.815
NumTrajs                                  117
Perplexity                                389.611
PolicyExecTime                              3.97046
ProcessExecTime                             0.103779
StdReturn                                 125.957
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.81451
lstm_policy/KLBefore                        1.81451
lstm_policy/LossAfter                      -0.0338582
lstm_policy/LossBefore                     -0.0338582
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:50:49 | [drl] epoch #32 | Obtaining samples...
2020-09-01 13:50:49 | [drl] epoch #32 | Obtaining samples for iteration 32...
2020-09-01 13:50:55 | [drl] epoch #32 | Logging diagnostics...
2020-09-01 13:50:55 | [drl] epoch #32 | Optimizing policy...
2020-09-01 13:50:55 | [drl] epoch #32 | Computing loss before
2020-09-01 13:50:55 | [drl] epoch #32 | Computing KL before
2020-09-01 13:50:55 | [drl] epoch #32 | Optimizing
2020-09-01 13:50:55 | [drl] epoch #32 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:50:55 | [drl] epoch #32 | computing loss before
2020-09-01 13:50:55 | [drl] epoch #32 | computing gradient
2020-09-01 13:50:55 | [drl] epoch #32 | gradient computed
2020-09-01 13:50:55 | [drl] epoch #32 | computing descent direction
2020-09-01 13:50:57 | [drl] epoch #32 | descent direction computed
2020-09-01 13:50:57 | [drl] epoch #32 | Line search condition violated. Rejecting the step!
2020-09-01 13:50:57 | [drl] epoch #32 | Violated because constraint mean_kl is violated
2020-09-01 13:50:57 | [drl] epoch #32 | backtrack iters: 14
2020-09-01 13:50:57 | [drl] epoch #32 | optimization finished
2020-09-01 13:50:57 | [drl] epoch #32 | Computing KL after
2020-09-01 13:50:57 | [drl] epoch #32 | Computing loss after
2020-09-01 13:50:57 | [drl] epoch #32 | Fitting baseline...
2020-09-01 13:50:57 | [drl] epoch #32 | Saving snapshot...
2020-09-01 13:50:57 | [drl] epoch #32 | Saved
2020-09-01 13:50:57 | [drl] epoch #32 | Time 276.59 s
2020-09-01 13:50:57 | [drl] epoch #32 | EpochTime 8.36 s
---------------------------------------  -----------
AverageDiscountedReturn                  -347.217
AverageReturn                            -414.618
Entropy                                     5.99232
EnvExecTime                                 1.8727
Extras/EpisodeRewardMean                 -412.975
Iteration                                  32
LinearFeatureBaseline/ExplainedVariance     0.614426
MaxReturn                                -288.373
MinReturn                                -643.814
NumTrajs                                  116
Perplexity                                400.343
PolicyExecTime                              3.9371
ProcessExecTime                             0.100035
StdReturn                                 125.024
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.90777
lstm_policy/KLBefore                        1.90777
lstm_policy/LossAfter                      -0.047295
lstm_policy/LossBefore                     -0.047295
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:50:57 | [drl] epoch #33 | Obtaining samples...
2020-09-01 13:50:57 | [drl] epoch #33 | Obtaining samples for iteration 33...
2020-09-01 13:51:04 | [drl] epoch #33 | Logging diagnostics...
2020-09-01 13:51:04 | [drl] epoch #33 | Optimizing policy...
2020-09-01 13:51:04 | [drl] epoch #33 | Computing loss before
2020-09-01 13:51:04 | [drl] epoch #33 | Computing KL before
2020-09-01 13:51:04 | [drl] epoch #33 | Optimizing
2020-09-01 13:51:04 | [drl] epoch #33 | Start CG optimization: #parameters: 19852, #inputs: 114, #subsample_inputs: 114
2020-09-01 13:51:04 | [drl] epoch #33 | computing loss before
2020-09-01 13:51:04 | [drl] epoch #33 | computing gradient
2020-09-01 13:51:04 | [drl] epoch #33 | gradient computed
2020-09-01 13:51:04 | [drl] epoch #33 | computing descent direction
2020-09-01 13:51:05 | [drl] epoch #33 | descent direction computed
2020-09-01 13:51:05 | [drl] epoch #33 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:05 | [drl] epoch #33 | Violated because loss not improving
2020-09-01 13:51:05 | [drl] epoch #33 | Violated because constraint mean_kl is violated
2020-09-01 13:51:05 | [drl] epoch #33 | backtrack iters: 14
2020-09-01 13:51:05 | [drl] epoch #33 | optimization finished
2020-09-01 13:51:05 | [drl] epoch #33 | Computing KL after
2020-09-01 13:51:05 | [drl] epoch #33 | Computing loss after
2020-09-01 13:51:05 | [drl] epoch #33 | Fitting baseline...
2020-09-01 13:51:05 | [drl] epoch #33 | Saving snapshot...
2020-09-01 13:51:05 | [drl] epoch #33 | Saved
2020-09-01 13:51:05 | [drl] epoch #33 | Time 284.82 s
2020-09-01 13:51:05 | [drl] epoch #33 | EpochTime 8.22 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.869
AverageReturn                            -407.895
Entropy                                     6.07052
EnvExecTime                                 1.83582
Extras/EpisodeRewardMean                 -407.891
Iteration                                  33
LinearFeatureBaseline/ExplainedVariance     0.63463
MaxReturn                                -261.907
MinReturn                                -645.825
NumTrajs                                  114
Perplexity                                432.904
PolicyExecTime                              3.89122
ProcessExecTime                             0.098999
StdReturn                                 121.773
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.18665
lstm_policy/KLBefore                        2.18665
lstm_policy/LossAfter                      -0.0482302
lstm_policy/LossBefore                     -0.0482302
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:05 | [drl] epoch #34 | Obtaining samples...
2020-09-01 13:51:05 | [drl] epoch #34 | Obtaining samples for iteration 34...
2020-09-01 13:51:12 | [drl] epoch #34 | Logging diagnostics...
2020-09-01 13:51:12 | [drl] epoch #34 | Optimizing policy...
2020-09-01 13:51:12 | [drl] epoch #34 | Computing loss before
2020-09-01 13:51:12 | [drl] epoch #34 | Computing KL before
2020-09-01 13:51:12 | [drl] epoch #34 | Optimizing
2020-09-01 13:51:12 | [drl] epoch #34 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 13:51:12 | [drl] epoch #34 | computing loss before
2020-09-01 13:51:12 | [drl] epoch #34 | computing gradient
2020-09-01 13:51:12 | [drl] epoch #34 | gradient computed
2020-09-01 13:51:12 | [drl] epoch #34 | computing descent direction
2020-09-01 13:51:13 | [drl] epoch #34 | descent direction computed
2020-09-01 13:51:14 | [drl] epoch #34 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:14 | [drl] epoch #34 | Violated because constraint mean_kl is violated
2020-09-01 13:51:14 | [drl] epoch #34 | backtrack iters: 14
2020-09-01 13:51:14 | [drl] epoch #34 | optimization finished
2020-09-01 13:51:14 | [drl] epoch #34 | Computing KL after
2020-09-01 13:51:14 | [drl] epoch #34 | Computing loss after
2020-09-01 13:51:14 | [drl] epoch #34 | Fitting baseline...
2020-09-01 13:51:14 | [drl] epoch #34 | Saving snapshot...
2020-09-01 13:51:14 | [drl] epoch #34 | Saved
2020-09-01 13:51:14 | [drl] epoch #34 | Time 293.22 s
2020-09-01 13:51:14 | [drl] epoch #34 | EpochTime 8.38 s
---------------------------------------  ------------
AverageDiscountedReturn                  -355.414
AverageReturn                            -426.225
Entropy                                     5.93767
EnvExecTime                                 1.82253
Extras/EpisodeRewardMean                 -420.095
Iteration                                  34
LinearFeatureBaseline/ExplainedVariance     0.606619
MaxReturn                                -284.601
MinReturn                                -645.703
NumTrajs                                  115
Perplexity                                379.05
PolicyExecTime                              3.91493
ProcessExecTime                             0.0986059
StdReturn                                 128.889
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.73935
lstm_policy/KLBefore                        1.73935
lstm_policy/LossAfter                      -0.0390593
lstm_policy/LossBefore                     -0.0390593
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:14 | [drl] epoch #35 | Obtaining samples...
2020-09-01 13:51:14 | [drl] epoch #35 | Obtaining samples for iteration 35...
2020-09-01 13:51:20 | [drl] epoch #35 | Logging diagnostics...
2020-09-01 13:51:20 | [drl] epoch #35 | Optimizing policy...
2020-09-01 13:51:20 | [drl] epoch #35 | Computing loss before
2020-09-01 13:51:20 | [drl] epoch #35 | Computing KL before
2020-09-01 13:51:20 | [drl] epoch #35 | Optimizing
2020-09-01 13:51:20 | [drl] epoch #35 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 13:51:20 | [drl] epoch #35 | computing loss before
2020-09-01 13:51:20 | [drl] epoch #35 | computing gradient
2020-09-01 13:51:20 | [drl] epoch #35 | gradient computed
2020-09-01 13:51:20 | [drl] epoch #35 | computing descent direction
2020-09-01 13:51:22 | [drl] epoch #35 | descent direction computed
2020-09-01 13:51:22 | [drl] epoch #35 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:22 | [drl] epoch #35 | Violated because constraint mean_kl is violated
2020-09-01 13:51:22 | [drl] epoch #35 | backtrack iters: 14
2020-09-01 13:51:22 | [drl] epoch #35 | optimization finished
2020-09-01 13:51:22 | [drl] epoch #35 | Computing KL after
2020-09-01 13:51:22 | [drl] epoch #35 | Computing loss after
2020-09-01 13:51:22 | [drl] epoch #35 | Fitting baseline...
2020-09-01 13:51:22 | [drl] epoch #35 | Saving snapshot...
2020-09-01 13:51:22 | [drl] epoch #35 | Saved
2020-09-01 13:51:22 | [drl] epoch #35 | Time 301.65 s
2020-09-01 13:51:22 | [drl] epoch #35 | EpochTime 8.42 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.968
AverageReturn                            -397.225
Entropy                                     5.97212
EnvExecTime                                 1.84386
Extras/EpisodeRewardMean                 -399.215
Iteration                                  35
LinearFeatureBaseline/ExplainedVariance     0.614993
MaxReturn                                -287.809
MinReturn                                -649.763
NumTrajs                                  122
Perplexity                                392.338
PolicyExecTime                              3.91763
ProcessExecTime                             0.100387
StdReturn                                 115.779
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76744
lstm_policy/KLBefore                        1.76744
lstm_policy/LossAfter                      -0.0443908
lstm_policy/LossBefore                     -0.0443908
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:22 | [drl] epoch #36 | Obtaining samples...
2020-09-01 13:51:22 | [drl] epoch #36 | Obtaining samples for iteration 36...
2020-09-01 13:51:29 | [drl] epoch #36 | Logging diagnostics...
2020-09-01 13:51:29 | [drl] epoch #36 | Optimizing policy...
2020-09-01 13:51:29 | [drl] epoch #36 | Computing loss before
2020-09-01 13:51:29 | [drl] epoch #36 | Computing KL before
2020-09-01 13:51:29 | [drl] epoch #36 | Optimizing
2020-09-01 13:51:29 | [drl] epoch #36 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:51:29 | [drl] epoch #36 | computing loss before
2020-09-01 13:51:29 | [drl] epoch #36 | computing gradient
2020-09-01 13:51:29 | [drl] epoch #36 | gradient computed
2020-09-01 13:51:29 | [drl] epoch #36 | computing descent direction
2020-09-01 13:51:30 | [drl] epoch #36 | descent direction computed
2020-09-01 13:51:30 | [drl] epoch #36 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:30 | [drl] epoch #36 | Violated because loss not improving
2020-09-01 13:51:30 | [drl] epoch #36 | Violated because constraint mean_kl is violated
2020-09-01 13:51:30 | [drl] epoch #36 | backtrack iters: 14
2020-09-01 13:51:30 | [drl] epoch #36 | optimization finished
2020-09-01 13:51:30 | [drl] epoch #36 | Computing KL after
2020-09-01 13:51:30 | [drl] epoch #36 | Computing loss after
2020-09-01 13:51:30 | [drl] epoch #36 | Fitting baseline...
2020-09-01 13:51:30 | [drl] epoch #36 | Saving snapshot...
2020-09-01 13:51:30 | [drl] epoch #36 | Saved
2020-09-01 13:51:30 | [drl] epoch #36 | Time 309.94 s
2020-09-01 13:51:30 | [drl] epoch #36 | EpochTime 8.28 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.311
AverageReturn                            -407.514
Entropy                                     5.94615
EnvExecTime                                 1.82312
Extras/EpisodeRewardMean                 -411.711
Iteration                                  36
LinearFeatureBaseline/ExplainedVariance     0.603231
MaxReturn                                -277.786
MinReturn                                -632.774
NumTrajs                                  119
Perplexity                                382.277
PolicyExecTime                              4.10382
ProcessExecTime                             0.0989182
StdReturn                                 121.976
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72884
lstm_policy/KLBefore                        1.72884
lstm_policy/LossAfter                      -0.0174612
lstm_policy/LossBefore                     -0.0174612
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:30 | [drl] epoch #37 | Obtaining samples...
2020-09-01 13:51:30 | [drl] epoch #37 | Obtaining samples for iteration 37...
2020-09-01 13:51:37 | [drl] epoch #37 | Logging diagnostics...
2020-09-01 13:51:37 | [drl] epoch #37 | Optimizing policy...
2020-09-01 13:51:37 | [drl] epoch #37 | Computing loss before
2020-09-01 13:51:37 | [drl] epoch #37 | Computing KL before
2020-09-01 13:51:37 | [drl] epoch #37 | Optimizing
2020-09-01 13:51:37 | [drl] epoch #37 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:51:37 | [drl] epoch #37 | computing loss before
2020-09-01 13:51:37 | [drl] epoch #37 | computing gradient
2020-09-01 13:51:37 | [drl] epoch #37 | gradient computed
2020-09-01 13:51:37 | [drl] epoch #37 | computing descent direction
2020-09-01 13:51:38 | [drl] epoch #37 | descent direction computed
2020-09-01 13:51:38 | [drl] epoch #37 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:38 | [drl] epoch #37 | Violated because constraint mean_kl is violated
2020-09-01 13:51:38 | [drl] epoch #37 | backtrack iters: 14
2020-09-01 13:51:38 | [drl] epoch #37 | optimization finished
2020-09-01 13:51:38 | [drl] epoch #37 | Computing KL after
2020-09-01 13:51:38 | [drl] epoch #37 | Computing loss after
2020-09-01 13:51:38 | [drl] epoch #37 | Fitting baseline...
2020-09-01 13:51:38 | [drl] epoch #37 | Saving snapshot...
2020-09-01 13:51:38 | [drl] epoch #37 | Saved
2020-09-01 13:51:38 | [drl] epoch #37 | Time 317.78 s
2020-09-01 13:51:38 | [drl] epoch #37 | EpochTime 7.82 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.72
AverageReturn                            -404.639
Entropy                                     5.98838
EnvExecTime                                 1.78463
Extras/EpisodeRewardMean                 -404.496
Iteration                                  37
LinearFeatureBaseline/ExplainedVariance     0.616118
MaxReturn                                -282.635
MinReturn                                -656.3
NumTrajs                                  119
Perplexity                                398.768
PolicyExecTime                              3.74396
ProcessExecTime                             0.0982401
StdReturn                                 120.1
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89277
lstm_policy/KLBefore                        1.89277
lstm_policy/LossAfter                      -0.0336002
lstm_policy/LossBefore                     -0.0336002
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:38 | [drl] epoch #38 | Obtaining samples...
2020-09-01 13:51:38 | [drl] epoch #38 | Obtaining samples for iteration 38...
2020-09-01 13:51:44 | [drl] epoch #38 | Logging diagnostics...
2020-09-01 13:51:44 | [drl] epoch #38 | Optimizing policy...
2020-09-01 13:51:44 | [drl] epoch #38 | Computing loss before
2020-09-01 13:51:44 | [drl] epoch #38 | Computing KL before
2020-09-01 13:51:44 | [drl] epoch #38 | Optimizing
2020-09-01 13:51:44 | [drl] epoch #38 | Start CG optimization: #parameters: 19852, #inputs: 124, #subsample_inputs: 124
2020-09-01 13:51:44 | [drl] epoch #38 | computing loss before
2020-09-01 13:51:44 | [drl] epoch #38 | computing gradient
2020-09-01 13:51:44 | [drl] epoch #38 | gradient computed
2020-09-01 13:51:44 | [drl] epoch #38 | computing descent direction
2020-09-01 13:51:46 | [drl] epoch #38 | descent direction computed
2020-09-01 13:51:46 | [drl] epoch #38 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:46 | [drl] epoch #38 | Violated because constraint mean_kl is violated
2020-09-01 13:51:46 | [drl] epoch #38 | backtrack iters: 14
2020-09-01 13:51:46 | [drl] epoch #38 | optimization finished
2020-09-01 13:51:46 | [drl] epoch #38 | Computing KL after
2020-09-01 13:51:46 | [drl] epoch #38 | Computing loss after
2020-09-01 13:51:46 | [drl] epoch #38 | Fitting baseline...
2020-09-01 13:51:46 | [drl] epoch #38 | Saving snapshot...
2020-09-01 13:51:46 | [drl] epoch #38 | Saved
2020-09-01 13:51:46 | [drl] epoch #38 | Time 325.58 s
2020-09-01 13:51:46 | [drl] epoch #38 | EpochTime 7.79 s
---------------------------------------  ------------
AverageDiscountedReturn                  -331.847
AverageReturn                            -392.101
Entropy                                     5.95169
EnvExecTime                                 1.73114
Extras/EpisodeRewardMean                 -388.168
Iteration                                  38
LinearFeatureBaseline/ExplainedVariance     0.61581
MaxReturn                                -287.391
MinReturn                                -632.851
NumTrajs                                  124
Perplexity                                384.403
PolicyExecTime                              3.66003
ProcessExecTime                             0.0964258
StdReturn                                 113.376
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.70022
lstm_policy/KLBefore                        1.70022
lstm_policy/LossAfter                      -0.0182654
lstm_policy/LossBefore                     -0.0182654
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:51:46 | [drl] epoch #39 | Obtaining samples...
2020-09-01 13:51:46 | [drl] epoch #39 | Obtaining samples for iteration 39...
2020-09-01 13:51:52 | [drl] epoch #39 | Logging diagnostics...
2020-09-01 13:51:52 | [drl] epoch #39 | Optimizing policy...
2020-09-01 13:51:52 | [drl] epoch #39 | Computing loss before
2020-09-01 13:51:52 | [drl] epoch #39 | Computing KL before
2020-09-01 13:51:52 | [drl] epoch #39 | Optimizing
2020-09-01 13:51:52 | [drl] epoch #39 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 13:51:52 | [drl] epoch #39 | computing loss before
2020-09-01 13:51:52 | [drl] epoch #39 | computing gradient
2020-09-01 13:51:52 | [drl] epoch #39 | gradient computed
2020-09-01 13:51:52 | [drl] epoch #39 | computing descent direction
2020-09-01 13:51:54 | [drl] epoch #39 | descent direction computed
2020-09-01 13:51:54 | [drl] epoch #39 | Line search condition violated. Rejecting the step!
2020-09-01 13:51:54 | [drl] epoch #39 | Violated because constraint mean_kl is violated
2020-09-01 13:51:54 | [drl] epoch #39 | backtrack iters: 14
2020-09-01 13:51:54 | [drl] epoch #39 | optimization finished
2020-09-01 13:51:54 | [drl] epoch #39 | Computing KL after
2020-09-01 13:51:54 | [drl] epoch #39 | Computing loss after
2020-09-01 13:51:54 | [drl] epoch #39 | Fitting baseline...
2020-09-01 13:51:54 | [drl] epoch #39 | Saving snapshot...
2020-09-01 13:51:54 | [drl] epoch #39 | Saved
2020-09-01 13:51:54 | [drl] epoch #39 | Time 333.56 s
2020-09-01 13:51:54 | [drl] epoch #39 | EpochTime 7.97 s
---------------------------------------  -------------
AverageDiscountedReturn                  -322.18
AverageReturn                            -378.069
Entropy                                     6.01732
EnvExecTime                                 1.80334
Extras/EpisodeRewardMean                 -381.902
Iteration                                  39
LinearFeatureBaseline/ExplainedVariance     0.63799
MaxReturn                                -270.837
MinReturn                                -639.872
NumTrajs                                  125
Perplexity                                410.476
PolicyExecTime                              3.76481
ProcessExecTime                             0.0983667
StdReturn                                 105.817
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.92595
lstm_policy/KLBefore                        1.92595
lstm_policy/LossAfter                      -0.00808852
lstm_policy/LossBefore                     -0.00808852
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:51:54 | [drl] epoch #40 | Obtaining samples...
2020-09-01 13:51:54 | [drl] epoch #40 | Obtaining samples for iteration 40...
2020-09-01 13:52:00 | [drl] epoch #40 | Logging diagnostics...
2020-09-01 13:52:00 | [drl] epoch #40 | Optimizing policy...
2020-09-01 13:52:00 | [drl] epoch #40 | Computing loss before
2020-09-01 13:52:00 | [drl] epoch #40 | Computing KL before
2020-09-01 13:52:00 | [drl] epoch #40 | Optimizing
2020-09-01 13:52:00 | [drl] epoch #40 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:52:00 | [drl] epoch #40 | computing loss before
2020-09-01 13:52:00 | [drl] epoch #40 | computing gradient
2020-09-01 13:52:00 | [drl] epoch #40 | gradient computed
2020-09-01 13:52:00 | [drl] epoch #40 | computing descent direction
2020-09-01 13:52:02 | [drl] epoch #40 | descent direction computed
2020-09-01 13:52:02 | [drl] epoch #40 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:02 | [drl] epoch #40 | Violated because constraint mean_kl is violated
2020-09-01 13:52:02 | [drl] epoch #40 | backtrack iters: 14
2020-09-01 13:52:02 | [drl] epoch #40 | optimization finished
2020-09-01 13:52:02 | [drl] epoch #40 | Computing KL after
2020-09-01 13:52:02 | [drl] epoch #40 | Computing loss after
2020-09-01 13:52:02 | [drl] epoch #40 | Fitting baseline...
2020-09-01 13:52:02 | [drl] epoch #40 | Saving snapshot...
2020-09-01 13:52:02 | [drl] epoch #40 | Saved
2020-09-01 13:52:02 | [drl] epoch #40 | Time 341.53 s
2020-09-01 13:52:02 | [drl] epoch #40 | EpochTime 7.96 s
---------------------------------------  -------------
AverageDiscountedReturn                  -340.234
AverageReturn                            -403.233
Entropy                                     5.96547
EnvExecTime                                 1.80137
Extras/EpisodeRewardMean                 -397.799
Iteration                                  40
LinearFeatureBaseline/ExplainedVariance     0.634293
MaxReturn                                -275.647
MinReturn                                -632.617
NumTrajs                                  121
Perplexity                                389.736
PolicyExecTime                              3.78172
ProcessExecTime                             0.0978346
StdReturn                                 111.809
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80725
lstm_policy/KLBefore                        1.80725
lstm_policy/LossAfter                      -0.00563933
lstm_policy/LossBefore                     -0.00563933
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:52:02 | [drl] epoch #41 | Obtaining samples...
2020-09-01 13:52:02 | [drl] epoch #41 | Obtaining samples for iteration 41...
2020-09-01 13:52:08 | [drl] epoch #41 | Logging diagnostics...
2020-09-01 13:52:08 | [drl] epoch #41 | Optimizing policy...
2020-09-01 13:52:08 | [drl] epoch #41 | Computing loss before
2020-09-01 13:52:08 | [drl] epoch #41 | Computing KL before
2020-09-01 13:52:08 | [drl] epoch #41 | Optimizing
2020-09-01 13:52:08 | [drl] epoch #41 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:52:08 | [drl] epoch #41 | computing loss before
2020-09-01 13:52:08 | [drl] epoch #41 | computing gradient
2020-09-01 13:52:08 | [drl] epoch #41 | gradient computed
2020-09-01 13:52:08 | [drl] epoch #41 | computing descent direction
2020-09-01 13:52:10 | [drl] epoch #41 | descent direction computed
2020-09-01 13:52:10 | [drl] epoch #41 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:10 | [drl] epoch #41 | Violated because constraint mean_kl is violated
2020-09-01 13:52:10 | [drl] epoch #41 | backtrack iters: 14
2020-09-01 13:52:10 | [drl] epoch #41 | optimization finished
2020-09-01 13:52:10 | [drl] epoch #41 | Computing KL after
2020-09-01 13:52:10 | [drl] epoch #41 | Computing loss after
2020-09-01 13:52:10 | [drl] epoch #41 | Fitting baseline...
2020-09-01 13:52:10 | [drl] epoch #41 | Saving snapshot...
2020-09-01 13:52:10 | [drl] epoch #41 | Saved
2020-09-01 13:52:10 | [drl] epoch #41 | Time 349.50 s
2020-09-01 13:52:10 | [drl] epoch #41 | EpochTime 7.96 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.112
AverageReturn                            -399.359
Entropy                                     5.97869
EnvExecTime                                 1.79108
Extras/EpisodeRewardMean                 -395.599
Iteration                                  41
LinearFeatureBaseline/ExplainedVariance     0.621892
MaxReturn                                -274.328
MinReturn                                -629.941
NumTrajs                                  121
Perplexity                                394.923
PolicyExecTime                              3.78096
ProcessExecTime                             0.0996883
StdReturn                                 116.133
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80895
lstm_policy/KLBefore                        1.80895
lstm_policy/LossAfter                      -0.0154086
lstm_policy/LossBefore                     -0.0154086
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:10 | [drl] epoch #42 | Obtaining samples...
2020-09-01 13:52:10 | [drl] epoch #42 | Obtaining samples for iteration 42...
2020-09-01 13:52:16 | [drl] epoch #42 | Logging diagnostics...
2020-09-01 13:52:16 | [drl] epoch #42 | Optimizing policy...
2020-09-01 13:52:16 | [drl] epoch #42 | Computing loss before
2020-09-01 13:52:16 | [drl] epoch #42 | Computing KL before
2020-09-01 13:52:16 | [drl] epoch #42 | Optimizing
2020-09-01 13:52:16 | [drl] epoch #42 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:52:16 | [drl] epoch #42 | computing loss before
2020-09-01 13:52:16 | [drl] epoch #42 | computing gradient
2020-09-01 13:52:16 | [drl] epoch #42 | gradient computed
2020-09-01 13:52:16 | [drl] epoch #42 | computing descent direction
2020-09-01 13:52:18 | [drl] epoch #42 | descent direction computed
2020-09-01 13:52:18 | [drl] epoch #42 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:18 | [drl] epoch #42 | Violated because constraint mean_kl is violated
2020-09-01 13:52:18 | [drl] epoch #42 | backtrack iters: 14
2020-09-01 13:52:18 | [drl] epoch #42 | optimization finished
2020-09-01 13:52:18 | [drl] epoch #42 | Computing KL after
2020-09-01 13:52:18 | [drl] epoch #42 | Computing loss after
2020-09-01 13:52:18 | [drl] epoch #42 | Fitting baseline...
2020-09-01 13:52:18 | [drl] epoch #42 | Saving snapshot...
2020-09-01 13:52:18 | [drl] epoch #42 | Saved
2020-09-01 13:52:18 | [drl] epoch #42 | Time 357.36 s
2020-09-01 13:52:18 | [drl] epoch #42 | EpochTime 7.85 s
---------------------------------------  ------------
AverageDiscountedReturn                  -330.703
AverageReturn                            -390.255
Entropy                                     6.10578
EnvExecTime                                 1.77348
Extras/EpisodeRewardMean                 -393.763
Iteration                                  42
LinearFeatureBaseline/ExplainedVariance     0.654202
MaxReturn                                -286.625
MinReturn                                -631.566
NumTrajs                                  116
Perplexity                                448.441
PolicyExecTime                              3.77704
ProcessExecTime                             0.102186
StdReturn                                 109.802
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.30613
lstm_policy/KLBefore                        2.30613
lstm_policy/LossAfter                      -0.0287651
lstm_policy/LossBefore                     -0.0287651
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:18 | [drl] epoch #43 | Obtaining samples...
2020-09-01 13:52:18 | [drl] epoch #43 | Obtaining samples for iteration 43...
2020-09-01 13:52:25 | [drl] epoch #43 | Logging diagnostics...
2020-09-01 13:52:25 | [drl] epoch #43 | Optimizing policy...
2020-09-01 13:52:25 | [drl] epoch #43 | Computing loss before
2020-09-01 13:52:25 | [drl] epoch #43 | Computing KL before
2020-09-01 13:52:25 | [drl] epoch #43 | Optimizing
2020-09-01 13:52:25 | [drl] epoch #43 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:52:25 | [drl] epoch #43 | computing loss before
2020-09-01 13:52:25 | [drl] epoch #43 | computing gradient
2020-09-01 13:52:25 | [drl] epoch #43 | gradient computed
2020-09-01 13:52:25 | [drl] epoch #43 | computing descent direction
2020-09-01 13:52:27 | [drl] epoch #43 | descent direction computed
2020-09-01 13:52:27 | [drl] epoch #43 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:27 | [drl] epoch #43 | Violated because constraint mean_kl is violated
2020-09-01 13:52:27 | [drl] epoch #43 | backtrack iters: 14
2020-09-01 13:52:27 | [drl] epoch #43 | optimization finished
2020-09-01 13:52:27 | [drl] epoch #43 | Computing KL after
2020-09-01 13:52:27 | [drl] epoch #43 | Computing loss after
2020-09-01 13:52:27 | [drl] epoch #43 | Fitting baseline...
2020-09-01 13:52:27 | [drl] epoch #43 | Saving snapshot...
2020-09-01 13:52:27 | [drl] epoch #43 | Saved
2020-09-01 13:52:27 | [drl] epoch #43 | Time 366.79 s
2020-09-01 13:52:27 | [drl] epoch #43 | EpochTime 9.42 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.635
AverageReturn                            -400.443
Entropy                                     5.96095
EnvExecTime                                 1.82608
Extras/EpisodeRewardMean                 -396.854
Iteration                                  43
LinearFeatureBaseline/ExplainedVariance     0.61591
MaxReturn                                -287.586
MinReturn                                -639.309
NumTrajs                                  121
Perplexity                                387.978
PolicyExecTime                              4.00431
ProcessExecTime                             0.0990214
StdReturn                                 117.415
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.77469
lstm_policy/KLBefore                        1.77469
lstm_policy/LossAfter                      -0.0121677
lstm_policy/LossBefore                     -0.0121677
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:27 | [drl] epoch #44 | Obtaining samples...
2020-09-01 13:52:27 | [drl] epoch #44 | Obtaining samples for iteration 44...
2020-09-01 13:52:34 | [drl] epoch #44 | Logging diagnostics...
2020-09-01 13:52:34 | [drl] epoch #44 | Optimizing policy...
2020-09-01 13:52:34 | [drl] epoch #44 | Computing loss before
2020-09-01 13:52:34 | [drl] epoch #44 | Computing KL before
2020-09-01 13:52:34 | [drl] epoch #44 | Optimizing
2020-09-01 13:52:34 | [drl] epoch #44 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:52:34 | [drl] epoch #44 | computing loss before
2020-09-01 13:52:34 | [drl] epoch #44 | computing gradient
2020-09-01 13:52:34 | [drl] epoch #44 | gradient computed
2020-09-01 13:52:34 | [drl] epoch #44 | computing descent direction
2020-09-01 13:52:35 | [drl] epoch #44 | descent direction computed
2020-09-01 13:52:36 | [drl] epoch #44 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:36 | [drl] epoch #44 | Violated because constraint mean_kl is violated
2020-09-01 13:52:36 | [drl] epoch #44 | backtrack iters: 14
2020-09-01 13:52:36 | [drl] epoch #44 | optimization finished
2020-09-01 13:52:36 | [drl] epoch #44 | Computing KL after
2020-09-01 13:52:36 | [drl] epoch #44 | Computing loss after
2020-09-01 13:52:36 | [drl] epoch #44 | Fitting baseline...
2020-09-01 13:52:36 | [drl] epoch #44 | Saving snapshot...
2020-09-01 13:52:36 | [drl] epoch #44 | Saved
2020-09-01 13:52:36 | [drl] epoch #44 | Time 375.11 s
2020-09-01 13:52:36 | [drl] epoch #44 | EpochTime 8.31 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.861
AverageReturn                            -398.262
Entropy                                     6.01798
EnvExecTime                                 1.83109
Extras/EpisodeRewardMean                 -398.521
Iteration                                  44
LinearFeatureBaseline/ExplainedVariance     0.621816
MaxReturn                                -287.748
MinReturn                                -633.202
NumTrajs                                  118
Perplexity                                410.748
PolicyExecTime                              3.91068
ProcessExecTime                             0.109476
StdReturn                                 117.89
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97492
lstm_policy/KLBefore                        1.97492
lstm_policy/LossAfter                      -0.0293443
lstm_policy/LossBefore                     -0.0293443
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:36 | [drl] epoch #45 | Obtaining samples...
2020-09-01 13:52:36 | [drl] epoch #45 | Obtaining samples for iteration 45...
2020-09-01 13:52:42 | [drl] epoch #45 | Logging diagnostics...
2020-09-01 13:52:42 | [drl] epoch #45 | Optimizing policy...
2020-09-01 13:52:42 | [drl] epoch #45 | Computing loss before
2020-09-01 13:52:42 | [drl] epoch #45 | Computing KL before
2020-09-01 13:52:42 | [drl] epoch #45 | Optimizing
2020-09-01 13:52:42 | [drl] epoch #45 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:52:42 | [drl] epoch #45 | computing loss before
2020-09-01 13:52:42 | [drl] epoch #45 | computing gradient
2020-09-01 13:52:42 | [drl] epoch #45 | gradient computed
2020-09-01 13:52:42 | [drl] epoch #45 | computing descent direction
2020-09-01 13:52:44 | [drl] epoch #45 | descent direction computed
2020-09-01 13:52:44 | [drl] epoch #45 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:44 | [drl] epoch #45 | Violated because loss not improving
2020-09-01 13:52:44 | [drl] epoch #45 | Violated because constraint mean_kl is violated
2020-09-01 13:52:44 | [drl] epoch #45 | backtrack iters: 14
2020-09-01 13:52:44 | [drl] epoch #45 | optimization finished
2020-09-01 13:52:44 | [drl] epoch #45 | Computing KL after
2020-09-01 13:52:44 | [drl] epoch #45 | Computing loss after
2020-09-01 13:52:44 | [drl] epoch #45 | Fitting baseline...
2020-09-01 13:52:44 | [drl] epoch #45 | Saving snapshot...
2020-09-01 13:52:44 | [drl] epoch #45 | Saved
2020-09-01 13:52:44 | [drl] epoch #45 | Time 383.47 s
2020-09-01 13:52:44 | [drl] epoch #45 | EpochTime 8.35 s
---------------------------------------  ------------
AverageDiscountedReturn                  -354.064
AverageReturn                            -423.599
Entropy                                     5.84706
EnvExecTime                                 1.82048
Extras/EpisodeRewardMean                 -438.761
Iteration                                  45
LinearFeatureBaseline/ExplainedVariance     0.586084
MaxReturn                                -285.45
MinReturn                                -644.593
NumTrajs                                  120
Perplexity                                346.216
PolicyExecTime                              3.91007
ProcessExecTime                             0.0993812
StdReturn                                 126.111
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.38682
lstm_policy/KLBefore                        1.38682
lstm_policy/LossAfter                      -0.0164294
lstm_policy/LossBefore                     -0.0164294
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:44 | [drl] epoch #46 | Obtaining samples...
2020-09-01 13:52:44 | [drl] epoch #46 | Obtaining samples for iteration 46...
2020-09-01 13:52:50 | [drl] epoch #46 | Logging diagnostics...
2020-09-01 13:52:50 | [drl] epoch #46 | Optimizing policy...
2020-09-01 13:52:50 | [drl] epoch #46 | Computing loss before
2020-09-01 13:52:50 | [drl] epoch #46 | Computing KL before
2020-09-01 13:52:51 | [drl] epoch #46 | Optimizing
2020-09-01 13:52:51 | [drl] epoch #46 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:52:51 | [drl] epoch #46 | computing loss before
2020-09-01 13:52:51 | [drl] epoch #46 | computing gradient
2020-09-01 13:52:51 | [drl] epoch #46 | gradient computed
2020-09-01 13:52:51 | [drl] epoch #46 | computing descent direction
2020-09-01 13:52:52 | [drl] epoch #46 | descent direction computed
2020-09-01 13:52:52 | [drl] epoch #46 | Line search condition violated. Rejecting the step!
2020-09-01 13:52:52 | [drl] epoch #46 | Violated because loss not improving
2020-09-01 13:52:52 | [drl] epoch #46 | Violated because constraint mean_kl is violated
2020-09-01 13:52:52 | [drl] epoch #46 | backtrack iters: 14
2020-09-01 13:52:52 | [drl] epoch #46 | optimization finished
2020-09-01 13:52:52 | [drl] epoch #46 | Computing KL after
2020-09-01 13:52:52 | [drl] epoch #46 | Computing loss after
2020-09-01 13:52:52 | [drl] epoch #46 | Fitting baseline...
2020-09-01 13:52:52 | [drl] epoch #46 | Saving snapshot...
2020-09-01 13:52:52 | [drl] epoch #46 | Saved
2020-09-01 13:52:52 | [drl] epoch #46 | Time 391.83 s
2020-09-01 13:52:52 | [drl] epoch #46 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -357.693
AverageReturn                            -429.906
Entropy                                     5.82972
EnvExecTime                                 1.81621
Extras/EpisodeRewardMean                 -428.634
Iteration                                  46
LinearFeatureBaseline/ExplainedVariance     0.569317
MaxReturn                                -273.061
MinReturn                                -639.769
NumTrajs                                  119
Perplexity                                340.265
PolicyExecTime                              3.88204
ProcessExecTime                             0.10326
StdReturn                                 134.473
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.29126
lstm_policy/KLBefore                        1.29126
lstm_policy/LossAfter                      -0.0307318
lstm_policy/LossBefore                     -0.0307318
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:52:52 | [drl] epoch #47 | Obtaining samples...
2020-09-01 13:52:52 | [drl] epoch #47 | Obtaining samples for iteration 47...
2020-09-01 13:52:59 | [drl] epoch #47 | Logging diagnostics...
2020-09-01 13:52:59 | [drl] epoch #47 | Optimizing policy...
2020-09-01 13:52:59 | [drl] epoch #47 | Computing loss before
2020-09-01 13:52:59 | [drl] epoch #47 | Computing KL before
2020-09-01 13:52:59 | [drl] epoch #47 | Optimizing
2020-09-01 13:52:59 | [drl] epoch #47 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:52:59 | [drl] epoch #47 | computing loss before
2020-09-01 13:52:59 | [drl] epoch #47 | computing gradient
2020-09-01 13:52:59 | [drl] epoch #47 | gradient computed
2020-09-01 13:52:59 | [drl] epoch #47 | computing descent direction
2020-09-01 13:53:00 | [drl] epoch #47 | descent direction computed
2020-09-01 13:53:01 | [drl] epoch #47 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:01 | [drl] epoch #47 | Violated because constraint mean_kl is violated
2020-09-01 13:53:01 | [drl] epoch #47 | backtrack iters: 14
2020-09-01 13:53:01 | [drl] epoch #47 | optimization finished
2020-09-01 13:53:01 | [drl] epoch #47 | Computing KL after
2020-09-01 13:53:01 | [drl] epoch #47 | Computing loss after
2020-09-01 13:53:01 | [drl] epoch #47 | Fitting baseline...
2020-09-01 13:53:01 | [drl] epoch #47 | Saving snapshot...
2020-09-01 13:53:01 | [drl] epoch #47 | Saved
2020-09-01 13:53:01 | [drl] epoch #47 | Time 400.23 s
2020-09-01 13:53:01 | [drl] epoch #47 | EpochTime 8.39 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.853
AverageReturn                            -406.908
Entropy                                     5.97296
EnvExecTime                                 1.86811
Extras/EpisodeRewardMean                 -412.494
Iteration                                  47
LinearFeatureBaseline/ExplainedVariance     0.60831
MaxReturn                                -282.151
MinReturn                                -647.964
NumTrajs                                  118
Perplexity                                392.668
PolicyExecTime                              3.92085
ProcessExecTime                             0.107475
StdReturn                                 121.089
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.81739
lstm_policy/KLBefore                        1.81739
lstm_policy/LossAfter                      -0.0510041
lstm_policy/LossBefore                     -0.0510041
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:01 | [drl] epoch #48 | Obtaining samples...
2020-09-01 13:53:01 | [drl] epoch #48 | Obtaining samples for iteration 48...
2020-09-01 13:53:07 | [drl] epoch #48 | Logging diagnostics...
2020-09-01 13:53:07 | [drl] epoch #48 | Optimizing policy...
2020-09-01 13:53:07 | [drl] epoch #48 | Computing loss before
2020-09-01 13:53:07 | [drl] epoch #48 | Computing KL before
2020-09-01 13:53:07 | [drl] epoch #48 | Optimizing
2020-09-01 13:53:07 | [drl] epoch #48 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:53:07 | [drl] epoch #48 | computing loss before
2020-09-01 13:53:07 | [drl] epoch #48 | computing gradient
2020-09-01 13:53:07 | [drl] epoch #48 | gradient computed
2020-09-01 13:53:07 | [drl] epoch #48 | computing descent direction
2020-09-01 13:53:09 | [drl] epoch #48 | descent direction computed
2020-09-01 13:53:09 | [drl] epoch #48 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:09 | [drl] epoch #48 | Violated because constraint mean_kl is violated
2020-09-01 13:53:09 | [drl] epoch #48 | backtrack iters: 14
2020-09-01 13:53:09 | [drl] epoch #48 | optimization finished
2020-09-01 13:53:09 | [drl] epoch #48 | Computing KL after
2020-09-01 13:53:09 | [drl] epoch #48 | Computing loss after
2020-09-01 13:53:09 | [drl] epoch #48 | Fitting baseline...
2020-09-01 13:53:09 | [drl] epoch #48 | Saving snapshot...
2020-09-01 13:53:09 | [drl] epoch #48 | Saved
2020-09-01 13:53:09 | [drl] epoch #48 | Time 408.65 s
2020-09-01 13:53:09 | [drl] epoch #48 | EpochTime 8.40 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.112
AverageReturn                            -396.427
Entropy                                     6.10393
EnvExecTime                                 1.84348
Extras/EpisodeRewardMean                 -397.76
Iteration                                  48
LinearFeatureBaseline/ExplainedVariance     0.640432
MaxReturn                                -285.772
MinReturn                                -663.88
NumTrajs                                  116
Perplexity                                447.614
PolicyExecTime                              3.93885
ProcessExecTime                             0.105947
StdReturn                                 116.253
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.33537
lstm_policy/KLBefore                        2.33537
lstm_policy/LossAfter                      -0.0370096
lstm_policy/LossBefore                     -0.0370096
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:09 | [drl] epoch #49 | Obtaining samples...
2020-09-01 13:53:09 | [drl] epoch #49 | Obtaining samples for iteration 49...
2020-09-01 13:53:16 | [drl] epoch #49 | Logging diagnostics...
2020-09-01 13:53:16 | [drl] epoch #49 | Optimizing policy...
2020-09-01 13:53:16 | [drl] epoch #49 | Computing loss before
2020-09-01 13:53:16 | [drl] epoch #49 | Computing KL before
2020-09-01 13:53:16 | [drl] epoch #49 | Optimizing
2020-09-01 13:53:16 | [drl] epoch #49 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:53:16 | [drl] epoch #49 | computing loss before
2020-09-01 13:53:16 | [drl] epoch #49 | computing gradient
2020-09-01 13:53:16 | [drl] epoch #49 | gradient computed
2020-09-01 13:53:16 | [drl] epoch #49 | computing descent direction
2020-09-01 13:53:17 | [drl] epoch #49 | descent direction computed
2020-09-01 13:53:17 | [drl] epoch #49 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:17 | [drl] epoch #49 | Violated because loss not improving
2020-09-01 13:53:17 | [drl] epoch #49 | Violated because constraint mean_kl is violated
2020-09-01 13:53:17 | [drl] epoch #49 | backtrack iters: 14
2020-09-01 13:53:17 | [drl] epoch #49 | optimization finished
2020-09-01 13:53:17 | [drl] epoch #49 | Computing KL after
2020-09-01 13:53:17 | [drl] epoch #49 | Computing loss after
2020-09-01 13:53:17 | [drl] epoch #49 | Fitting baseline...
2020-09-01 13:53:17 | [drl] epoch #49 | Saving snapshot...
2020-09-01 13:53:17 | [drl] epoch #49 | Saved
2020-09-01 13:53:17 | [drl] epoch #49 | Time 417.01 s
2020-09-01 13:53:17 | [drl] epoch #49 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.166
AverageReturn                            -404.132
Entropy                                     6.01456
EnvExecTime                                 1.82348
Extras/EpisodeRewardMean                 -405.358
Iteration                                  49
LinearFeatureBaseline/ExplainedVariance     0.621684
MaxReturn                                -279.403
MinReturn                                -675.749
NumTrajs                                  118
Perplexity                                409.344
PolicyExecTime                              3.92408
ProcessExecTime                             0.104055
StdReturn                                 119.948
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97658
lstm_policy/KLBefore                        1.97658
lstm_policy/LossAfter                      -0.0229165
lstm_policy/LossBefore                     -0.0229165
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:18 | [drl] epoch #50 | Obtaining samples...
2020-09-01 13:53:18 | [drl] epoch #50 | Obtaining samples for iteration 50...
2020-09-01 13:53:24 | [drl] epoch #50 | Logging diagnostics...
2020-09-01 13:53:24 | [drl] epoch #50 | Optimizing policy...
2020-09-01 13:53:24 | [drl] epoch #50 | Computing loss before
2020-09-01 13:53:24 | [drl] epoch #50 | Computing KL before
2020-09-01 13:53:24 | [drl] epoch #50 | Optimizing
2020-09-01 13:53:24 | [drl] epoch #50 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 13:53:24 | [drl] epoch #50 | computing loss before
2020-09-01 13:53:24 | [drl] epoch #50 | computing gradient
2020-09-01 13:53:24 | [drl] epoch #50 | gradient computed
2020-09-01 13:53:24 | [drl] epoch #50 | computing descent direction
2020-09-01 13:53:26 | [drl] epoch #50 | descent direction computed
2020-09-01 13:53:26 | [drl] epoch #50 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:26 | [drl] epoch #50 | Violated because constraint mean_kl is violated
2020-09-01 13:53:26 | [drl] epoch #50 | backtrack iters: 14
2020-09-01 13:53:26 | [drl] epoch #50 | optimization finished
2020-09-01 13:53:26 | [drl] epoch #50 | Computing KL after
2020-09-01 13:53:26 | [drl] epoch #50 | Computing loss after
2020-09-01 13:53:26 | [drl] epoch #50 | Fitting baseline...
2020-09-01 13:53:26 | [drl] epoch #50 | Saving snapshot...
2020-09-01 13:53:26 | [drl] epoch #50 | Saved
2020-09-01 13:53:26 | [drl] epoch #50 | Time 425.40 s
2020-09-01 13:53:26 | [drl] epoch #50 | EpochTime 8.37 s
---------------------------------------  ------------
AverageDiscountedReturn                  -338.914
AverageReturn                            -402.079
Entropy                                     5.9354
EnvExecTime                                 1.83937
Extras/EpisodeRewardMean                 -398.402
Iteration                                  50
LinearFeatureBaseline/ExplainedVariance     0.611985
MaxReturn                                -284.879
MinReturn                                -648.39
NumTrajs                                  122
Perplexity                                378.19
PolicyExecTime                              3.9171
ProcessExecTime                             0.106026
StdReturn                                 118.254
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.66959
lstm_policy/KLBefore                        1.66959
lstm_policy/LossAfter                      -0.0257346
lstm_policy/LossBefore                     -0.0257346
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:26 | [drl] epoch #51 | Obtaining samples...
2020-09-01 13:53:26 | [drl] epoch #51 | Obtaining samples for iteration 51...
2020-09-01 13:53:32 | [drl] epoch #51 | Logging diagnostics...
2020-09-01 13:53:32 | [drl] epoch #51 | Optimizing policy...
2020-09-01 13:53:32 | [drl] epoch #51 | Computing loss before
2020-09-01 13:53:32 | [drl] epoch #51 | Computing KL before
2020-09-01 13:53:32 | [drl] epoch #51 | Optimizing
2020-09-01 13:53:32 | [drl] epoch #51 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:53:32 | [drl] epoch #51 | computing loss before
2020-09-01 13:53:33 | [drl] epoch #51 | computing gradient
2020-09-01 13:53:33 | [drl] epoch #51 | gradient computed
2020-09-01 13:53:33 | [drl] epoch #51 | computing descent direction
2020-09-01 13:53:34 | [drl] epoch #51 | descent direction computed
2020-09-01 13:53:34 | [drl] epoch #51 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:34 | [drl] epoch #51 | Violated because constraint mean_kl is violated
2020-09-01 13:53:34 | [drl] epoch #51 | backtrack iters: 14
2020-09-01 13:53:34 | [drl] epoch #51 | optimization finished
2020-09-01 13:53:34 | [drl] epoch #51 | Computing KL after
2020-09-01 13:53:34 | [drl] epoch #51 | Computing loss after
2020-09-01 13:53:34 | [drl] epoch #51 | Fitting baseline...
2020-09-01 13:53:34 | [drl] epoch #51 | Saving snapshot...
2020-09-01 13:53:34 | [drl] epoch #51 | Saved
2020-09-01 13:53:34 | [drl] epoch #51 | Time 433.73 s
2020-09-01 13:53:34 | [drl] epoch #51 | EpochTime 8.32 s
---------------------------------------  ------------
AverageDiscountedReturn                  -356.383
AverageReturn                            -427.935
Entropy                                     5.87564
EnvExecTime                                 1.82578
Extras/EpisodeRewardMean                 -422.755
Iteration                                  51
LinearFeatureBaseline/ExplainedVariance     0.598261
MaxReturn                                -286.193
MinReturn                                -636.763
NumTrajs                                  117
Perplexity                                356.253
PolicyExecTime                              3.90871
ProcessExecTime                             0.0994289
StdReturn                                 127.691
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.50054
lstm_policy/KLBefore                        1.50054
lstm_policy/LossAfter                      -0.01926
lstm_policy/LossBefore                     -0.01926
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:34 | [drl] epoch #52 | Obtaining samples...
2020-09-01 13:53:34 | [drl] epoch #52 | Obtaining samples for iteration 52...
2020-09-01 13:53:41 | [drl] epoch #52 | Logging diagnostics...
2020-09-01 13:53:41 | [drl] epoch #52 | Optimizing policy...
2020-09-01 13:53:41 | [drl] epoch #52 | Computing loss before
2020-09-01 13:53:41 | [drl] epoch #52 | Computing KL before
2020-09-01 13:53:41 | [drl] epoch #52 | Optimizing
2020-09-01 13:53:41 | [drl] epoch #52 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:53:41 | [drl] epoch #52 | computing loss before
2020-09-01 13:53:41 | [drl] epoch #52 | computing gradient
2020-09-01 13:53:41 | [drl] epoch #52 | gradient computed
2020-09-01 13:53:41 | [drl] epoch #52 | computing descent direction
2020-09-01 13:53:42 | [drl] epoch #52 | descent direction computed
2020-09-01 13:53:42 | [drl] epoch #52 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:42 | [drl] epoch #52 | Violated because constraint mean_kl is violated
2020-09-01 13:53:42 | [drl] epoch #52 | backtrack iters: 14
2020-09-01 13:53:42 | [drl] epoch #52 | optimization finished
2020-09-01 13:53:42 | [drl] epoch #52 | Computing KL after
2020-09-01 13:53:42 | [drl] epoch #52 | Computing loss after
2020-09-01 13:53:43 | [drl] epoch #52 | Fitting baseline...
2020-09-01 13:53:43 | [drl] epoch #52 | Saving snapshot...
2020-09-01 13:53:43 | [drl] epoch #52 | Saved
2020-09-01 13:53:43 | [drl] epoch #52 | Time 442.07 s
2020-09-01 13:53:43 | [drl] epoch #52 | EpochTime 8.33 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.57
AverageReturn                            -400.049
Entropy                                     6.01962
EnvExecTime                                 1.81779
Extras/EpisodeRewardMean                 -404.974
Iteration                                  52
LinearFeatureBaseline/ExplainedVariance     0.614321
MaxReturn                                -269.033
MinReturn                                -665.129
NumTrajs                                  119
Perplexity                                411.424
PolicyExecTime                              3.96771
ProcessExecTime                             0.106177
StdReturn                                 118.481
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.0094
lstm_policy/KLBefore                        2.0094
lstm_policy/LossAfter                      -0.0457859
lstm_policy/LossBefore                     -0.0457859
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:43 | [drl] epoch #53 | Obtaining samples...
2020-09-01 13:53:43 | [drl] epoch #53 | Obtaining samples for iteration 53...
2020-09-01 13:53:49 | [drl] epoch #53 | Logging diagnostics...
2020-09-01 13:53:49 | [drl] epoch #53 | Optimizing policy...
2020-09-01 13:53:49 | [drl] epoch #53 | Computing loss before
2020-09-01 13:53:49 | [drl] epoch #53 | Computing KL before
2020-09-01 13:53:49 | [drl] epoch #53 | Optimizing
2020-09-01 13:53:49 | [drl] epoch #53 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 13:53:49 | [drl] epoch #53 | computing loss before
2020-09-01 13:53:49 | [drl] epoch #53 | computing gradient
2020-09-01 13:53:49 | [drl] epoch #53 | gradient computed
2020-09-01 13:53:49 | [drl] epoch #53 | computing descent direction
2020-09-01 13:53:51 | [drl] epoch #53 | descent direction computed
2020-09-01 13:53:51 | [drl] epoch #53 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:51 | [drl] epoch #53 | Violated because constraint mean_kl is violated
2020-09-01 13:53:51 | [drl] epoch #53 | backtrack iters: 14
2020-09-01 13:53:51 | [drl] epoch #53 | optimization finished
2020-09-01 13:53:51 | [drl] epoch #53 | Computing KL after
2020-09-01 13:53:51 | [drl] epoch #53 | Computing loss after
2020-09-01 13:53:51 | [drl] epoch #53 | Fitting baseline...
2020-09-01 13:53:51 | [drl] epoch #53 | Saving snapshot...
2020-09-01 13:53:51 | [drl] epoch #53 | Saved
2020-09-01 13:53:51 | [drl] epoch #53 | Time 450.43 s
2020-09-01 13:53:51 | [drl] epoch #53 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.928
AverageReturn                            -410.565
Entropy                                     6.02926
EnvExecTime                                 1.8238
Extras/EpisodeRewardMean                 -417.415
Iteration                                  53
LinearFeatureBaseline/ExplainedVariance     0.617396
MaxReturn                                -283.661
MinReturn                                -636.828
NumTrajs                                  115
Perplexity                                415.406
PolicyExecTime                              3.94233
ProcessExecTime                             0.100095
StdReturn                                 125.1
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.00221
lstm_policy/KLBefore                        2.00221
lstm_policy/LossAfter                      -0.0411419
lstm_policy/LossBefore                     -0.0411419
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:51 | [drl] epoch #54 | Obtaining samples...
2020-09-01 13:53:51 | [drl] epoch #54 | Obtaining samples for iteration 54...
2020-09-01 13:53:57 | [drl] epoch #54 | Logging diagnostics...
2020-09-01 13:53:57 | [drl] epoch #54 | Optimizing policy...
2020-09-01 13:53:57 | [drl] epoch #54 | Computing loss before
2020-09-01 13:53:57 | [drl] epoch #54 | Computing KL before
2020-09-01 13:53:58 | [drl] epoch #54 | Optimizing
2020-09-01 13:53:58 | [drl] epoch #54 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:53:58 | [drl] epoch #54 | computing loss before
2020-09-01 13:53:58 | [drl] epoch #54 | computing gradient
2020-09-01 13:53:58 | [drl] epoch #54 | gradient computed
2020-09-01 13:53:58 | [drl] epoch #54 | computing descent direction
2020-09-01 13:53:59 | [drl] epoch #54 | descent direction computed
2020-09-01 13:53:59 | [drl] epoch #54 | Line search condition violated. Rejecting the step!
2020-09-01 13:53:59 | [drl] epoch #54 | Violated because loss not improving
2020-09-01 13:53:59 | [drl] epoch #54 | Violated because constraint mean_kl is violated
2020-09-01 13:53:59 | [drl] epoch #54 | backtrack iters: 14
2020-09-01 13:53:59 | [drl] epoch #54 | optimization finished
2020-09-01 13:53:59 | [drl] epoch #54 | Computing KL after
2020-09-01 13:53:59 | [drl] epoch #54 | Computing loss after
2020-09-01 13:53:59 | [drl] epoch #54 | Fitting baseline...
2020-09-01 13:53:59 | [drl] epoch #54 | Saving snapshot...
2020-09-01 13:53:59 | [drl] epoch #54 | Saved
2020-09-01 13:53:59 | [drl] epoch #54 | Time 458.82 s
2020-09-01 13:53:59 | [drl] epoch #54 | EpochTime 8.38 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.297
AverageReturn                            -406.162
Entropy                                     5.99055
EnvExecTime                                 1.85677
Extras/EpisodeRewardMean                 -403.122
Iteration                                  54
LinearFeatureBaseline/ExplainedVariance     0.638505
MaxReturn                                -291.183
MinReturn                                -635.137
NumTrajs                                  119
Perplexity                                399.633
PolicyExecTime                              3.91267
ProcessExecTime                             0.107551
StdReturn                                 113.238
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89897
lstm_policy/KLBefore                        1.89897
lstm_policy/LossAfter                      -0.0322035
lstm_policy/LossBefore                     -0.0322035
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:53:59 | [drl] epoch #55 | Obtaining samples...
2020-09-01 13:53:59 | [drl] epoch #55 | Obtaining samples for iteration 55...
2020-09-01 13:54:06 | [drl] epoch #55 | Logging diagnostics...
2020-09-01 13:54:06 | [drl] epoch #55 | Optimizing policy...
2020-09-01 13:54:06 | [drl] epoch #55 | Computing loss before
2020-09-01 13:54:06 | [drl] epoch #55 | Computing KL before
2020-09-01 13:54:06 | [drl] epoch #55 | Optimizing
2020-09-01 13:54:06 | [drl] epoch #55 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:54:06 | [drl] epoch #55 | computing loss before
2020-09-01 13:54:06 | [drl] epoch #55 | computing gradient
2020-09-01 13:54:06 | [drl] epoch #55 | gradient computed
2020-09-01 13:54:06 | [drl] epoch #55 | computing descent direction
2020-09-01 13:54:07 | [drl] epoch #55 | descent direction computed
2020-09-01 13:54:08 | [drl] epoch #55 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:08 | [drl] epoch #55 | Violated because loss not improving
2020-09-01 13:54:08 | [drl] epoch #55 | Violated because constraint mean_kl is violated
2020-09-01 13:54:08 | [drl] epoch #55 | backtrack iters: 14
2020-09-01 13:54:08 | [drl] epoch #55 | optimization finished
2020-09-01 13:54:08 | [drl] epoch #55 | Computing KL after
2020-09-01 13:54:08 | [drl] epoch #55 | Computing loss after
2020-09-01 13:54:08 | [drl] epoch #55 | Fitting baseline...
2020-09-01 13:54:08 | [drl] epoch #55 | Saving snapshot...
2020-09-01 13:54:08 | [drl] epoch #55 | Saved
2020-09-01 13:54:08 | [drl] epoch #55 | Time 467.19 s
2020-09-01 13:54:08 | [drl] epoch #55 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.366
AverageReturn                            -408.144
Entropy                                     5.95554
EnvExecTime                                 1.8424
Extras/EpisodeRewardMean                 -408.205
Iteration                                  55
LinearFeatureBaseline/ExplainedVariance     0.617153
MaxReturn                                -283.407
MinReturn                                -639.985
NumTrajs                                  119
Perplexity                                385.886
PolicyExecTime                              3.88209
ProcessExecTime                             0.106415
StdReturn                                 118.779
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76244
lstm_policy/KLBefore                        1.76244
lstm_policy/LossAfter                      -0.0198913
lstm_policy/LossBefore                     -0.0198913
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:08 | [drl] epoch #56 | Obtaining samples...
2020-09-01 13:54:08 | [drl] epoch #56 | Obtaining samples for iteration 56...
2020-09-01 13:54:15 | [drl] epoch #56 | Logging diagnostics...
2020-09-01 13:54:15 | [drl] epoch #56 | Optimizing policy...
2020-09-01 13:54:15 | [drl] epoch #56 | Computing loss before
2020-09-01 13:54:15 | [drl] epoch #56 | Computing KL before
2020-09-01 13:54:15 | [drl] epoch #56 | Optimizing
2020-09-01 13:54:15 | [drl] epoch #56 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 13:54:15 | [drl] epoch #56 | computing loss before
2020-09-01 13:54:15 | [drl] epoch #56 | computing gradient
2020-09-01 13:54:15 | [drl] epoch #56 | gradient computed
2020-09-01 13:54:15 | [drl] epoch #56 | computing descent direction
2020-09-01 13:54:16 | [drl] epoch #56 | descent direction computed
2020-09-01 13:54:17 | [drl] epoch #56 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:17 | [drl] epoch #56 | Violated because loss not improving
2020-09-01 13:54:17 | [drl] epoch #56 | Violated because constraint mean_kl is violated
2020-09-01 13:54:17 | [drl] epoch #56 | backtrack iters: 14
2020-09-01 13:54:17 | [drl] epoch #56 | optimization finished
2020-09-01 13:54:17 | [drl] epoch #56 | Computing KL after
2020-09-01 13:54:17 | [drl] epoch #56 | Computing loss after
2020-09-01 13:54:17 | [drl] epoch #56 | Fitting baseline...
2020-09-01 13:54:17 | [drl] epoch #56 | Saving snapshot...
2020-09-01 13:54:17 | [drl] epoch #56 | Saved
2020-09-01 13:54:17 | [drl] epoch #56 | Time 476.11 s
2020-09-01 13:54:17 | [drl] epoch #56 | EpochTime 8.91 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.621
AverageReturn                            -415.863
Entropy                                     6.00786
EnvExecTime                                 1.87906
Extras/EpisodeRewardMean                 -418.363
Iteration                                  56
LinearFeatureBaseline/ExplainedVariance     0.625559
MaxReturn                                -270.671
MinReturn                                -635.084
NumTrajs                                  115
Perplexity                                406.614
PolicyExecTime                              4.4154
ProcessExecTime                             0.110769
StdReturn                                 123.324
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97709
lstm_policy/KLBefore                        1.97709
lstm_policy/LossAfter                      -0.0305146
lstm_policy/LossBefore                     -0.0305146
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:17 | [drl] epoch #57 | Obtaining samples...
2020-09-01 13:54:17 | [drl] epoch #57 | Obtaining samples for iteration 57...
2020-09-01 13:54:23 | [drl] epoch #57 | Logging diagnostics...
2020-09-01 13:54:23 | [drl] epoch #57 | Optimizing policy...
2020-09-01 13:54:23 | [drl] epoch #57 | Computing loss before
2020-09-01 13:54:23 | [drl] epoch #57 | Computing KL before
2020-09-01 13:54:23 | [drl] epoch #57 | Optimizing
2020-09-01 13:54:23 | [drl] epoch #57 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:54:23 | [drl] epoch #57 | computing loss before
2020-09-01 13:54:23 | [drl] epoch #57 | computing gradient
2020-09-01 13:54:23 | [drl] epoch #57 | gradient computed
2020-09-01 13:54:23 | [drl] epoch #57 | computing descent direction
2020-09-01 13:54:25 | [drl] epoch #57 | descent direction computed
2020-09-01 13:54:25 | [drl] epoch #57 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:25 | [drl] epoch #57 | Violated because constraint mean_kl is violated
2020-09-01 13:54:25 | [drl] epoch #57 | backtrack iters: 14
2020-09-01 13:54:25 | [drl] epoch #57 | optimization finished
2020-09-01 13:54:25 | [drl] epoch #57 | Computing KL after
2020-09-01 13:54:25 | [drl] epoch #57 | Computing loss after
2020-09-01 13:54:25 | [drl] epoch #57 | Fitting baseline...
2020-09-01 13:54:25 | [drl] epoch #57 | Saving snapshot...
2020-09-01 13:54:25 | [drl] epoch #57 | Saved
2020-09-01 13:54:25 | [drl] epoch #57 | Time 484.50 s
2020-09-01 13:54:25 | [drl] epoch #57 | EpochTime 8.38 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.124
AverageReturn                            -396.977
Entropy                                     6.00132
EnvExecTime                                 1.84301
Extras/EpisodeRewardMean                 -395.537
Iteration                                  57
LinearFeatureBaseline/ExplainedVariance     0.62279
MaxReturn                                -274.159
MinReturn                                -641.949
NumTrajs                                  120
Perplexity                                403.961
PolicyExecTime                              3.9355
ProcessExecTime                             0.100184
StdReturn                                 114.966
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89486
lstm_policy/KLBefore                        1.89486
lstm_policy/LossAfter                      -0.0370952
lstm_policy/LossBefore                     -0.0370952
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:25 | [drl] epoch #58 | Obtaining samples...
2020-09-01 13:54:25 | [drl] epoch #58 | Obtaining samples for iteration 58...
2020-09-01 13:54:31 | [drl] epoch #58 | Logging diagnostics...
2020-09-01 13:54:31 | [drl] epoch #58 | Optimizing policy...
2020-09-01 13:54:31 | [drl] epoch #58 | Computing loss before
2020-09-01 13:54:31 | [drl] epoch #58 | Computing KL before
2020-09-01 13:54:31 | [drl] epoch #58 | Optimizing
2020-09-01 13:54:31 | [drl] epoch #58 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:54:31 | [drl] epoch #58 | computing loss before
2020-09-01 13:54:31 | [drl] epoch #58 | computing gradient
2020-09-01 13:54:31 | [drl] epoch #58 | gradient computed
2020-09-01 13:54:31 | [drl] epoch #58 | computing descent direction
2020-09-01 13:54:33 | [drl] epoch #58 | descent direction computed
2020-09-01 13:54:33 | [drl] epoch #58 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:33 | [drl] epoch #58 | Violated because constraint mean_kl is violated
2020-09-01 13:54:33 | [drl] epoch #58 | backtrack iters: 14
2020-09-01 13:54:33 | [drl] epoch #58 | optimization finished
2020-09-01 13:54:33 | [drl] epoch #58 | Computing KL after
2020-09-01 13:54:33 | [drl] epoch #58 | Computing loss after
2020-09-01 13:54:33 | [drl] epoch #58 | Fitting baseline...
2020-09-01 13:54:33 | [drl] epoch #58 | Saving snapshot...
2020-09-01 13:54:33 | [drl] epoch #58 | Saved
2020-09-01 13:54:33 | [drl] epoch #58 | Time 492.67 s
2020-09-01 13:54:33 | [drl] epoch #58 | EpochTime 8.15 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.732
AverageReturn                            -395.662
Entropy                                     6.03373
EnvExecTime                                 1.76419
Extras/EpisodeRewardMean                 -393.978
Iteration                                  58
LinearFeatureBaseline/ExplainedVariance     0.632414
MaxReturn                                -286.061
MinReturn                                -635.278
NumTrajs                                  120
Perplexity                                417.269
PolicyExecTime                              3.79981
ProcessExecTime                             0.107987
StdReturn                                 114.925
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.02417
lstm_policy/KLBefore                        2.02417
lstm_policy/LossAfter                      -0.0176438
lstm_policy/LossBefore                     -0.0176438
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:33 | [drl] epoch #59 | Obtaining samples...
2020-09-01 13:54:33 | [drl] epoch #59 | Obtaining samples for iteration 59...
2020-09-01 13:54:40 | [drl] epoch #59 | Logging diagnostics...
2020-09-01 13:54:40 | [drl] epoch #59 | Optimizing policy...
2020-09-01 13:54:40 | [drl] epoch #59 | Computing loss before
2020-09-01 13:54:40 | [drl] epoch #59 | Computing KL before
2020-09-01 13:54:40 | [drl] epoch #59 | Optimizing
2020-09-01 13:54:40 | [drl] epoch #59 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:54:40 | [drl] epoch #59 | computing loss before
2020-09-01 13:54:40 | [drl] epoch #59 | computing gradient
2020-09-01 13:54:40 | [drl] epoch #59 | gradient computed
2020-09-01 13:54:40 | [drl] epoch #59 | computing descent direction
2020-09-01 13:54:41 | [drl] epoch #59 | descent direction computed
2020-09-01 13:54:41 | [drl] epoch #59 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:41 | [drl] epoch #59 | Violated because loss not improving
2020-09-01 13:54:41 | [drl] epoch #59 | Violated because constraint mean_kl is violated
2020-09-01 13:54:41 | [drl] epoch #59 | backtrack iters: 14
2020-09-01 13:54:41 | [drl] epoch #59 | optimization finished
2020-09-01 13:54:41 | [drl] epoch #59 | Computing KL after
2020-09-01 13:54:41 | [drl] epoch #59 | Computing loss after
2020-09-01 13:54:41 | [drl] epoch #59 | Fitting baseline...
2020-09-01 13:54:41 | [drl] epoch #59 | Saving snapshot...
2020-09-01 13:54:41 | [drl] epoch #59 | Saved
2020-09-01 13:54:41 | [drl] epoch #59 | Time 500.99 s
2020-09-01 13:54:41 | [drl] epoch #59 | EpochTime 8.32 s
---------------------------------------  ------------
AverageDiscountedReturn                  -345.06
AverageReturn                            -410.089
Entropy                                     5.98922
EnvExecTime                                 1.83237
Extras/EpisodeRewardMean                 -409.924
Iteration                                  59
LinearFeatureBaseline/ExplainedVariance     0.623454
MaxReturn                                -282.561
MinReturn                                -639.259
NumTrajs                                  118
Perplexity                                399.105
PolicyExecTime                              3.90604
ProcessExecTime                             0.103031
StdReturn                                 119.758
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89246
lstm_policy/KLBefore                        1.89246
lstm_policy/LossAfter                      -0.0243163
lstm_policy/LossBefore                     -0.0243163
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:41 | [drl] epoch #60 | Obtaining samples...
2020-09-01 13:54:41 | [drl] epoch #60 | Obtaining samples for iteration 60...
2020-09-01 13:54:48 | [drl] epoch #60 | Logging diagnostics...
2020-09-01 13:54:48 | [drl] epoch #60 | Optimizing policy...
2020-09-01 13:54:48 | [drl] epoch #60 | Computing loss before
2020-09-01 13:54:48 | [drl] epoch #60 | Computing KL before
2020-09-01 13:54:48 | [drl] epoch #60 | Optimizing
2020-09-01 13:54:48 | [drl] epoch #60 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:54:48 | [drl] epoch #60 | computing loss before
2020-09-01 13:54:48 | [drl] epoch #60 | computing gradient
2020-09-01 13:54:48 | [drl] epoch #60 | gradient computed
2020-09-01 13:54:48 | [drl] epoch #60 | computing descent direction
2020-09-01 13:54:50 | [drl] epoch #60 | descent direction computed
2020-09-01 13:54:50 | [drl] epoch #60 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:50 | [drl] epoch #60 | Violated because loss not improving
2020-09-01 13:54:50 | [drl] epoch #60 | Violated because constraint mean_kl is violated
2020-09-01 13:54:50 | [drl] epoch #60 | backtrack iters: 14
2020-09-01 13:54:50 | [drl] epoch #60 | optimization finished
2020-09-01 13:54:50 | [drl] epoch #60 | Computing KL after
2020-09-01 13:54:50 | [drl] epoch #60 | Computing loss after
2020-09-01 13:54:50 | [drl] epoch #60 | Fitting baseline...
2020-09-01 13:54:50 | [drl] epoch #60 | Saving snapshot...
2020-09-01 13:54:50 | [drl] epoch #60 | Saved
2020-09-01 13:54:50 | [drl] epoch #60 | Time 509.39 s
2020-09-01 13:54:50 | [drl] epoch #60 | EpochTime 8.38 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.235
AverageReturn                            -405.294
Entropy                                     5.97018
EnvExecTime                                 1.85875
Extras/EpisodeRewardMean                 -410.621
Iteration                                  60
LinearFeatureBaseline/ExplainedVariance     0.613246
MaxReturn                                -273.262
MinReturn                                -638.824
NumTrajs                                  120
Perplexity                                391.578
PolicyExecTime                              3.90588
ProcessExecTime                             0.112905
StdReturn                                 120.872
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82266
lstm_policy/KLBefore                        1.82266
lstm_policy/LossAfter                      -0.0260119
lstm_policy/LossBefore                     -0.0260119
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:50 | [drl] epoch #61 | Obtaining samples...
2020-09-01 13:54:50 | [drl] epoch #61 | Obtaining samples for iteration 61...
2020-09-01 13:54:56 | [drl] epoch #61 | Logging diagnostics...
2020-09-01 13:54:56 | [drl] epoch #61 | Optimizing policy...
2020-09-01 13:54:56 | [drl] epoch #61 | Computing loss before
2020-09-01 13:54:56 | [drl] epoch #61 | Computing KL before
2020-09-01 13:54:56 | [drl] epoch #61 | Optimizing
2020-09-01 13:54:56 | [drl] epoch #61 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:54:56 | [drl] epoch #61 | computing loss before
2020-09-01 13:54:56 | [drl] epoch #61 | computing gradient
2020-09-01 13:54:57 | [drl] epoch #61 | gradient computed
2020-09-01 13:54:57 | [drl] epoch #61 | computing descent direction
2020-09-01 13:54:58 | [drl] epoch #61 | descent direction computed
2020-09-01 13:54:58 | [drl] epoch #61 | Line search condition violated. Rejecting the step!
2020-09-01 13:54:58 | [drl] epoch #61 | Violated because constraint mean_kl is violated
2020-09-01 13:54:58 | [drl] epoch #61 | backtrack iters: 14
2020-09-01 13:54:58 | [drl] epoch #61 | optimization finished
2020-09-01 13:54:58 | [drl] epoch #61 | Computing KL after
2020-09-01 13:54:58 | [drl] epoch #61 | Computing loss after
2020-09-01 13:54:58 | [drl] epoch #61 | Fitting baseline...
2020-09-01 13:54:58 | [drl] epoch #61 | Saving snapshot...
2020-09-01 13:54:58 | [drl] epoch #61 | Saved
2020-09-01 13:54:58 | [drl] epoch #61 | Time 517.77 s
2020-09-01 13:54:58 | [drl] epoch #61 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.139
AverageReturn                            -412.145
Entropy                                     5.92057
EnvExecTime                                 1.81999
Extras/EpisodeRewardMean                 -414.772
Iteration                                  61
LinearFeatureBaseline/ExplainedVariance     0.606546
MaxReturn                                -284.699
MinReturn                                -658.339
NumTrajs                                  120
Perplexity                                372.624
PolicyExecTime                              3.89568
ProcessExecTime                             0.10316
StdReturn                                 122.661
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.60589
lstm_policy/KLBefore                        1.60589
lstm_policy/LossAfter                      -0.0290075
lstm_policy/LossBefore                     -0.0290075
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:54:58 | [drl] epoch #62 | Obtaining samples...
2020-09-01 13:54:58 | [drl] epoch #62 | Obtaining samples for iteration 62...
2020-09-01 13:55:05 | [drl] epoch #62 | Logging diagnostics...
2020-09-01 13:55:05 | [drl] epoch #62 | Optimizing policy...
2020-09-01 13:55:05 | [drl] epoch #62 | Computing loss before
2020-09-01 13:55:05 | [drl] epoch #62 | Computing KL before
2020-09-01 13:55:05 | [drl] epoch #62 | Optimizing
2020-09-01 13:55:05 | [drl] epoch #62 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 13:55:05 | [drl] epoch #62 | computing loss before
2020-09-01 13:55:05 | [drl] epoch #62 | computing gradient
2020-09-01 13:55:05 | [drl] epoch #62 | gradient computed
2020-09-01 13:55:05 | [drl] epoch #62 | computing descent direction
2020-09-01 13:55:06 | [drl] epoch #62 | descent direction computed
2020-09-01 13:55:07 | [drl] epoch #62 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:07 | [drl] epoch #62 | Violated because loss not improving
2020-09-01 13:55:07 | [drl] epoch #62 | Violated because constraint mean_kl is violated
2020-09-01 13:55:07 | [drl] epoch #62 | backtrack iters: 14
2020-09-01 13:55:07 | [drl] epoch #62 | optimization finished
2020-09-01 13:55:07 | [drl] epoch #62 | Computing KL after
2020-09-01 13:55:07 | [drl] epoch #62 | Computing loss after
2020-09-01 13:55:07 | [drl] epoch #62 | Fitting baseline...
2020-09-01 13:55:07 | [drl] epoch #62 | Saving snapshot...
2020-09-01 13:55:07 | [drl] epoch #62 | Saved
2020-09-01 13:55:07 | [drl] epoch #62 | Time 526.28 s
2020-09-01 13:55:07 | [drl] epoch #62 | EpochTime 8.49 s
---------------------------------------  -----------
AverageDiscountedReturn                  -340.474
AverageReturn                            -404.559
Entropy                                     5.92823
EnvExecTime                                 1.83513
Extras/EpisodeRewardMean                 -407.778
Iteration                                  62
LinearFeatureBaseline/ExplainedVariance     0.595293
MaxReturn                                -263.398
MinReturn                                -647.978
NumTrajs                                  122
Perplexity                                375.49
PolicyExecTime                              3.97563
ProcessExecTime                             0.106755
StdReturn                                 122.265
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.62525
lstm_policy/KLBefore                        1.62525
lstm_policy/LossAfter                      -0.026887
lstm_policy/LossBefore                     -0.026887
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:55:07 | [drl] epoch #63 | Obtaining samples...
2020-09-01 13:55:07 | [drl] epoch #63 | Obtaining samples for iteration 63...
2020-09-01 13:55:13 | [drl] epoch #63 | Logging diagnostics...
2020-09-01 13:55:13 | [drl] epoch #63 | Optimizing policy...
2020-09-01 13:55:13 | [drl] epoch #63 | Computing loss before
2020-09-01 13:55:13 | [drl] epoch #63 | Computing KL before
2020-09-01 13:55:13 | [drl] epoch #63 | Optimizing
2020-09-01 13:55:13 | [drl] epoch #63 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:55:13 | [drl] epoch #63 | computing loss before
2020-09-01 13:55:13 | [drl] epoch #63 | computing gradient
2020-09-01 13:55:14 | [drl] epoch #63 | gradient computed
2020-09-01 13:55:14 | [drl] epoch #63 | computing descent direction
2020-09-01 13:55:15 | [drl] epoch #63 | descent direction computed
2020-09-01 13:55:15 | [drl] epoch #63 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:15 | [drl] epoch #63 | Violated because loss not improving
2020-09-01 13:55:15 | [drl] epoch #63 | Violated because constraint mean_kl is violated
2020-09-01 13:55:15 | [drl] epoch #63 | backtrack iters: 14
2020-09-01 13:55:15 | [drl] epoch #63 | optimization finished
2020-09-01 13:55:15 | [drl] epoch #63 | Computing KL after
2020-09-01 13:55:15 | [drl] epoch #63 | Computing loss after
2020-09-01 13:55:15 | [drl] epoch #63 | Fitting baseline...
2020-09-01 13:55:15 | [drl] epoch #63 | Saving snapshot...
2020-09-01 13:55:15 | [drl] epoch #63 | Saved
2020-09-01 13:55:15 | [drl] epoch #63 | Time 534.69 s
2020-09-01 13:55:15 | [drl] epoch #63 | EpochTime 8.39 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.307
AverageReturn                            -404.445
Entropy                                     5.98048
EnvExecTime                                 1.84021
Extras/EpisodeRewardMean                 -405.106
Iteration                                  63
LinearFeatureBaseline/ExplainedVariance     0.613682
MaxReturn                                -266.962
MinReturn                                -616.542
NumTrajs                                  119
Perplexity                                395.632
PolicyExecTime                              3.92024
ProcessExecTime                             0.0998907
StdReturn                                 119.287
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.84012
lstm_policy/KLBefore                        1.84012
lstm_policy/LossAfter                      -0.0303438
lstm_policy/LossBefore                     -0.0303438
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:55:15 | [drl] epoch #64 | Obtaining samples...
2020-09-01 13:55:15 | [drl] epoch #64 | Obtaining samples for iteration 64...
2020-09-01 13:55:22 | [drl] epoch #64 | Logging diagnostics...
2020-09-01 13:55:22 | [drl] epoch #64 | Optimizing policy...
2020-09-01 13:55:22 | [drl] epoch #64 | Computing loss before
2020-09-01 13:55:22 | [drl] epoch #64 | Computing KL before
2020-09-01 13:55:22 | [drl] epoch #64 | Optimizing
2020-09-01 13:55:22 | [drl] epoch #64 | Start CG optimization: #parameters: 19852, #inputs: 127, #subsample_inputs: 127
2020-09-01 13:55:22 | [drl] epoch #64 | computing loss before
2020-09-01 13:55:22 | [drl] epoch #64 | computing gradient
2020-09-01 13:55:22 | [drl] epoch #64 | gradient computed
2020-09-01 13:55:22 | [drl] epoch #64 | computing descent direction
2020-09-01 13:55:23 | [drl] epoch #64 | descent direction computed
2020-09-01 13:55:23 | [drl] epoch #64 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:23 | [drl] epoch #64 | Violated because constraint mean_kl is violated
2020-09-01 13:55:23 | [drl] epoch #64 | backtrack iters: 14
2020-09-01 13:55:23 | [drl] epoch #64 | optimization finished
2020-09-01 13:55:23 | [drl] epoch #64 | Computing KL after
2020-09-01 13:55:23 | [drl] epoch #64 | Computing loss after
2020-09-01 13:55:24 | [drl] epoch #64 | Fitting baseline...
2020-09-01 13:55:24 | [drl] epoch #64 | Saving snapshot...
2020-09-01 13:55:24 | [drl] epoch #64 | Saved
2020-09-01 13:55:24 | [drl] epoch #64 | Time 543.07 s
2020-09-01 13:55:24 | [drl] epoch #64 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -323.17
AverageReturn                            -378.534
Entropy                                     5.98817
EnvExecTime                                 1.83303
Extras/EpisodeRewardMean                 -382.79
Iteration                                  64
LinearFeatureBaseline/ExplainedVariance     0.644121
MaxReturn                                -286.909
MinReturn                                -659.077
NumTrajs                                  127
Perplexity                                398.685
PolicyExecTime                              3.89282
ProcessExecTime                             0.103385
StdReturn                                 103.319
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.86422
lstm_policy/KLBefore                        1.86422
lstm_policy/LossAfter                      -0.0109042
lstm_policy/LossBefore                     -0.0109042
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:55:24 | [drl] epoch #65 | Obtaining samples...
2020-09-01 13:55:24 | [drl] epoch #65 | Obtaining samples for iteration 65...
2020-09-01 13:55:30 | [drl] epoch #65 | Logging diagnostics...
2020-09-01 13:55:30 | [drl] epoch #65 | Optimizing policy...
2020-09-01 13:55:30 | [drl] epoch #65 | Computing loss before
2020-09-01 13:55:30 | [drl] epoch #65 | Computing KL before
2020-09-01 13:55:30 | [drl] epoch #65 | Optimizing
2020-09-01 13:55:30 | [drl] epoch #65 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:55:30 | [drl] epoch #65 | computing loss before
2020-09-01 13:55:30 | [drl] epoch #65 | computing gradient
2020-09-01 13:55:30 | [drl] epoch #65 | gradient computed
2020-09-01 13:55:30 | [drl] epoch #65 | computing descent direction
2020-09-01 13:55:31 | [drl] epoch #65 | descent direction computed
2020-09-01 13:55:32 | [drl] epoch #65 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:32 | [drl] epoch #65 | Violated because constraint mean_kl is violated
2020-09-01 13:55:32 | [drl] epoch #65 | backtrack iters: 14
2020-09-01 13:55:32 | [drl] epoch #65 | optimization finished
2020-09-01 13:55:32 | [drl] epoch #65 | Computing KL after
2020-09-01 13:55:32 | [drl] epoch #65 | Computing loss after
2020-09-01 13:55:32 | [drl] epoch #65 | Fitting baseline...
2020-09-01 13:55:32 | [drl] epoch #65 | Saving snapshot...
2020-09-01 13:55:32 | [drl] epoch #65 | Saved
2020-09-01 13:55:32 | [drl] epoch #65 | Time 551.36 s
2020-09-01 13:55:32 | [drl] epoch #65 | EpochTime 8.28 s
---------------------------------------  -------------
AverageDiscountedReturn                  -347.213
AverageReturn                            -413.895
Entropy                                     5.96904
EnvExecTime                                 1.82164
Extras/EpisodeRewardMean                 -410.916
Iteration                                  65
LinearFeatureBaseline/ExplainedVariance     0.609937
MaxReturn                                -285.766
MinReturn                                -641.269
NumTrajs                                  117
Perplexity                                391.13
PolicyExecTime                              3.85751
ProcessExecTime                             0.103414
StdReturn                                 123.133
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80638
lstm_policy/KLBefore                        1.80638
lstm_policy/LossAfter                      -0.00796963
lstm_policy/LossBefore                     -0.00796963
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:55:32 | [drl] epoch #66 | Obtaining samples...
2020-09-01 13:55:32 | [drl] epoch #66 | Obtaining samples for iteration 66...
2020-09-01 13:55:38 | [drl] epoch #66 | Logging diagnostics...
2020-09-01 13:55:38 | [drl] epoch #66 | Optimizing policy...
2020-09-01 13:55:38 | [drl] epoch #66 | Computing loss before
2020-09-01 13:55:38 | [drl] epoch #66 | Computing KL before
2020-09-01 13:55:38 | [drl] epoch #66 | Optimizing
2020-09-01 13:55:38 | [drl] epoch #66 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:55:38 | [drl] epoch #66 | computing loss before
2020-09-01 13:55:38 | [drl] epoch #66 | computing gradient
2020-09-01 13:55:39 | [drl] epoch #66 | gradient computed
2020-09-01 13:55:39 | [drl] epoch #66 | computing descent direction
2020-09-01 13:55:40 | [drl] epoch #66 | descent direction computed
2020-09-01 13:55:40 | [drl] epoch #66 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:40 | [drl] epoch #66 | Violated because loss not improving
2020-09-01 13:55:40 | [drl] epoch #66 | Violated because constraint mean_kl is violated
2020-09-01 13:55:40 | [drl] epoch #66 | backtrack iters: 14
2020-09-01 13:55:40 | [drl] epoch #66 | optimization finished
2020-09-01 13:55:40 | [drl] epoch #66 | Computing KL after
2020-09-01 13:55:40 | [drl] epoch #66 | Computing loss after
2020-09-01 13:55:40 | [drl] epoch #66 | Fitting baseline...
2020-09-01 13:55:40 | [drl] epoch #66 | Saving snapshot...
2020-09-01 13:55:40 | [drl] epoch #66 | Saved
2020-09-01 13:55:40 | [drl] epoch #66 | Time 559.78 s
2020-09-01 13:55:40 | [drl] epoch #66 | EpochTime 8.41 s
---------------------------------------  -----------
AverageDiscountedReturn                  -345.457
AverageReturn                            -411.077
Entropy                                     5.92
EnvExecTime                                 1.83705
Extras/EpisodeRewardMean                 -420.35
Iteration                                  66
LinearFeatureBaseline/ExplainedVariance     0.609931
MaxReturn                                -289.801
MinReturn                                -655.09
NumTrajs                                  121
Perplexity                                372.411
PolicyExecTime                              3.93644
ProcessExecTime                             0.100274
StdReturn                                 120.168
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.63139
lstm_policy/KLBefore                        1.63139
lstm_policy/LossAfter                      -0.027644
lstm_policy/LossBefore                     -0.027644
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:55:40 | [drl] epoch #67 | Obtaining samples...
2020-09-01 13:55:40 | [drl] epoch #67 | Obtaining samples for iteration 67...
2020-09-01 13:55:47 | [drl] epoch #67 | Logging diagnostics...
2020-09-01 13:55:47 | [drl] epoch #67 | Optimizing policy...
2020-09-01 13:55:47 | [drl] epoch #67 | Computing loss before
2020-09-01 13:55:47 | [drl] epoch #67 | Computing KL before
2020-09-01 13:55:47 | [drl] epoch #67 | Optimizing
2020-09-01 13:55:47 | [drl] epoch #67 | Start CG optimization: #parameters: 19852, #inputs: 124, #subsample_inputs: 124
2020-09-01 13:55:47 | [drl] epoch #67 | computing loss before
2020-09-01 13:55:47 | [drl] epoch #67 | computing gradient
2020-09-01 13:55:47 | [drl] epoch #67 | gradient computed
2020-09-01 13:55:47 | [drl] epoch #67 | computing descent direction
2020-09-01 13:55:48 | [drl] epoch #67 | descent direction computed
2020-09-01 13:55:49 | [drl] epoch #67 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:49 | [drl] epoch #67 | Violated because constraint mean_kl is violated
2020-09-01 13:55:49 | [drl] epoch #67 | backtrack iters: 14
2020-09-01 13:55:49 | [drl] epoch #67 | optimization finished
2020-09-01 13:55:49 | [drl] epoch #67 | Computing KL after
2020-09-01 13:55:49 | [drl] epoch #67 | Computing loss after
2020-09-01 13:55:49 | [drl] epoch #67 | Fitting baseline...
2020-09-01 13:55:49 | [drl] epoch #67 | Saving snapshot...
2020-09-01 13:55:49 | [drl] epoch #67 | Saved
2020-09-01 13:55:49 | [drl] epoch #67 | Time 568.25 s
2020-09-01 13:55:49 | [drl] epoch #67 | EpochTime 8.46 s
---------------------------------------  ------------
AverageDiscountedReturn                  -332.39
AverageReturn                            -392.155
Entropy                                     5.96966
EnvExecTime                                 1.84717
Extras/EpisodeRewardMean                 -391.966
Iteration                                  67
LinearFeatureBaseline/ExplainedVariance     0.623457
MaxReturn                                -279.804
MinReturn                                -638.344
NumTrajs                                  124
Perplexity                                391.371
PolicyExecTime                              3.93479
ProcessExecTime                             0.100085
StdReturn                                 111.73
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.77864
lstm_policy/KLBefore                        1.77864
lstm_policy/LossAfter                      -0.0252613
lstm_policy/LossBefore                     -0.0252613
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:55:49 | [drl] epoch #68 | Obtaining samples...
2020-09-01 13:55:49 | [drl] epoch #68 | Obtaining samples for iteration 68...
2020-09-01 13:55:55 | [drl] epoch #68 | Logging diagnostics...
2020-09-01 13:55:55 | [drl] epoch #68 | Optimizing policy...
2020-09-01 13:55:55 | [drl] epoch #68 | Computing loss before
2020-09-01 13:55:55 | [drl] epoch #68 | Computing KL before
2020-09-01 13:55:55 | [drl] epoch #68 | Optimizing
2020-09-01 13:55:55 | [drl] epoch #68 | Start CG optimization: #parameters: 19852, #inputs: 123, #subsample_inputs: 123
2020-09-01 13:55:55 | [drl] epoch #68 | computing loss before
2020-09-01 13:55:55 | [drl] epoch #68 | computing gradient
2020-09-01 13:55:55 | [drl] epoch #68 | gradient computed
2020-09-01 13:55:55 | [drl] epoch #68 | computing descent direction
2020-09-01 13:55:57 | [drl] epoch #68 | descent direction computed
2020-09-01 13:55:57 | [drl] epoch #68 | Line search condition violated. Rejecting the step!
2020-09-01 13:55:57 | [drl] epoch #68 | Violated because loss not improving
2020-09-01 13:55:57 | [drl] epoch #68 | Violated because constraint mean_kl is violated
2020-09-01 13:55:57 | [drl] epoch #68 | backtrack iters: 14
2020-09-01 13:55:57 | [drl] epoch #68 | optimization finished
2020-09-01 13:55:57 | [drl] epoch #68 | Computing KL after
2020-09-01 13:55:57 | [drl] epoch #68 | Computing loss after
2020-09-01 13:55:57 | [drl] epoch #68 | Fitting baseline...
2020-09-01 13:55:57 | [drl] epoch #68 | Saving snapshot...
2020-09-01 13:55:57 | [drl] epoch #68 | Saved
2020-09-01 13:55:57 | [drl] epoch #68 | Time 576.58 s
2020-09-01 13:55:57 | [drl] epoch #68 | EpochTime 8.31 s
---------------------------------------  -------------
AverageDiscountedReturn                  -334.008
AverageReturn                            -394.759
Entropy                                     5.9527
EnvExecTime                                 1.83418
Extras/EpisodeRewardMean                 -400.669
Iteration                                  68
LinearFeatureBaseline/ExplainedVariance     0.624613
MaxReturn                                -277.9
MinReturn                                -639.744
NumTrajs                                  123
Perplexity                                384.789
PolicyExecTime                              3.87444
ProcessExecTime                             0.102866
StdReturn                                 112.219
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.73592
lstm_policy/KLBefore                        1.73592
lstm_policy/LossAfter                      -0.00856511
lstm_policy/LossBefore                     -0.00856511
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:55:57 | [drl] epoch #69 | Obtaining samples...
2020-09-01 13:55:57 | [drl] epoch #69 | Obtaining samples for iteration 69...
2020-09-01 13:56:05 | [drl] epoch #69 | Logging diagnostics...
2020-09-01 13:56:05 | [drl] epoch #69 | Optimizing policy...
2020-09-01 13:56:05 | [drl] epoch #69 | Computing loss before
2020-09-01 13:56:05 | [drl] epoch #69 | Computing KL before
2020-09-01 13:56:05 | [drl] epoch #69 | Optimizing
2020-09-01 13:56:05 | [drl] epoch #69 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:56:05 | [drl] epoch #69 | computing loss before
2020-09-01 13:56:05 | [drl] epoch #69 | computing gradient
2020-09-01 13:56:05 | [drl] epoch #69 | gradient computed
2020-09-01 13:56:05 | [drl] epoch #69 | computing descent direction
2020-09-01 13:56:07 | [drl] epoch #69 | descent direction computed
2020-09-01 13:56:07 | [drl] epoch #69 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:07 | [drl] epoch #69 | Violated because loss not improving
2020-09-01 13:56:07 | [drl] epoch #69 | Violated because constraint mean_kl is violated
2020-09-01 13:56:07 | [drl] epoch #69 | backtrack iters: 14
2020-09-01 13:56:07 | [drl] epoch #69 | optimization finished
2020-09-01 13:56:07 | [drl] epoch #69 | Computing KL after
2020-09-01 13:56:07 | [drl] epoch #69 | Computing loss after
2020-09-01 13:56:07 | [drl] epoch #69 | Fitting baseline...
2020-09-01 13:56:07 | [drl] epoch #69 | Saving snapshot...
2020-09-01 13:56:07 | [drl] epoch #69 | Saved
2020-09-01 13:56:07 | [drl] epoch #69 | Time 586.88 s
2020-09-01 13:56:07 | [drl] epoch #69 | EpochTime 10.29 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.727
AverageReturn                            -404.356
Entropy                                     6.02096
EnvExecTime                                 1.9223
Extras/EpisodeRewardMean                 -400.572
Iteration                                  69
LinearFeatureBaseline/ExplainedVariance     0.623456
MaxReturn                                -283.684
MinReturn                                -653.055
NumTrajs                                  117
Perplexity                                411.972
PolicyExecTime                              4.67182
ProcessExecTime                             0.112909
StdReturn                                 119.429
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.98941
lstm_policy/KLBefore                        1.98941
lstm_policy/LossAfter                      -0.0251082
lstm_policy/LossBefore                     -0.0251082
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:56:07 | [drl] epoch #70 | Obtaining samples...
2020-09-01 13:56:07 | [drl] epoch #70 | Obtaining samples for iteration 70...
2020-09-01 13:56:17 | [drl] epoch #70 | Logging diagnostics...
2020-09-01 13:56:17 | [drl] epoch #70 | Optimizing policy...
2020-09-01 13:56:17 | [drl] epoch #70 | Computing loss before
2020-09-01 13:56:18 | [drl] epoch #70 | Computing KL before
2020-09-01 13:56:18 | [drl] epoch #70 | Optimizing
2020-09-01 13:56:18 | [drl] epoch #70 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:56:18 | [drl] epoch #70 | computing loss before
2020-09-01 13:56:18 | [drl] epoch #70 | computing gradient
2020-09-01 13:56:18 | [drl] epoch #70 | gradient computed
2020-09-01 13:56:18 | [drl] epoch #70 | computing descent direction
2020-09-01 13:56:19 | [drl] epoch #70 | descent direction computed
2020-09-01 13:56:19 | [drl] epoch #70 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:19 | [drl] epoch #70 | Violated because constraint mean_kl is violated
2020-09-01 13:56:19 | [drl] epoch #70 | backtrack iters: 14
2020-09-01 13:56:19 | [drl] epoch #70 | optimization finished
2020-09-01 13:56:19 | [drl] epoch #70 | Computing KL after
2020-09-01 13:56:19 | [drl] epoch #70 | Computing loss after
2020-09-01 13:56:19 | [drl] epoch #70 | Fitting baseline...
2020-09-01 13:56:19 | [drl] epoch #70 | Saving snapshot...
2020-09-01 13:56:19 | [drl] epoch #70 | Saved
2020-09-01 13:56:19 | [drl] epoch #70 | Time 598.76 s
2020-09-01 13:56:19 | [drl] epoch #70 | EpochTime 11.86 s
---------------------------------------  -----------
AverageDiscountedReturn                  -337.334
AverageReturn                            -399.295
Entropy                                     6.01638
EnvExecTime                                 2.30223
Extras/EpisodeRewardMean                 -395.128
Iteration                                  70
LinearFeatureBaseline/ExplainedVariance     0.627833
MaxReturn                                -287.615
MinReturn                                -638.567
NumTrajs                                  119
Perplexity                                410.092
PolicyExecTime                              6.89451
ProcessExecTime                             0.148084
StdReturn                                 116.24
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97045
lstm_policy/KLBefore                        1.97045
lstm_policy/LossAfter                      -0.026931
lstm_policy/LossBefore                     -0.026931
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:56:19 | [drl] epoch #71 | Obtaining samples...
2020-09-01 13:56:19 | [drl] epoch #71 | Obtaining samples for iteration 71...
2020-09-01 13:56:28 | [drl] epoch #71 | Logging diagnostics...
2020-09-01 13:56:28 | [drl] epoch #71 | Optimizing policy...
2020-09-01 13:56:28 | [drl] epoch #71 | Computing loss before
2020-09-01 13:56:28 | [drl] epoch #71 | Computing KL before
2020-09-01 13:56:28 | [drl] epoch #71 | Optimizing
2020-09-01 13:56:28 | [drl] epoch #71 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:56:28 | [drl] epoch #71 | computing loss before
2020-09-01 13:56:28 | [drl] epoch #71 | computing gradient
2020-09-01 13:56:28 | [drl] epoch #71 | gradient computed
2020-09-01 13:56:28 | [drl] epoch #71 | computing descent direction
2020-09-01 13:56:30 | [drl] epoch #71 | descent direction computed
2020-09-01 13:56:30 | [drl] epoch #71 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:30 | [drl] epoch #71 | Violated because loss not improving
2020-09-01 13:56:30 | [drl] epoch #71 | Violated because constraint mean_kl is violated
2020-09-01 13:56:30 | [drl] epoch #71 | backtrack iters: 14
2020-09-01 13:56:30 | [drl] epoch #71 | optimization finished
2020-09-01 13:56:30 | [drl] epoch #71 | Computing KL after
2020-09-01 13:56:30 | [drl] epoch #71 | Computing loss after
2020-09-01 13:56:30 | [drl] epoch #71 | Fitting baseline...
2020-09-01 13:56:30 | [drl] epoch #71 | Saving snapshot...
2020-09-01 13:56:30 | [drl] epoch #71 | Saved
2020-09-01 13:56:30 | [drl] epoch #71 | Time 609.51 s
2020-09-01 13:56:30 | [drl] epoch #71 | EpochTime 10.74 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.326
AverageReturn                            -404.131
Entropy                                     6.01786
EnvExecTime                                 2.0669
Extras/EpisodeRewardMean                 -410.075
Iteration                                  71
LinearFeatureBaseline/ExplainedVariance     0.628118
MaxReturn                                -291.393
MinReturn                                -644.148
NumTrajs                                  117
Perplexity                                410.699
PolicyExecTime                              5.39999
ProcessExecTime                             0.117332
StdReturn                                 117.784
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.99078
lstm_policy/KLBefore                        1.99078
lstm_policy/LossAfter                      -0.0287245
lstm_policy/LossBefore                     -0.0287245
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:56:30 | [drl] epoch #72 | Obtaining samples...
2020-09-01 13:56:30 | [drl] epoch #72 | Obtaining samples for iteration 72...
2020-09-01 13:56:37 | [drl] epoch #72 | Logging diagnostics...
2020-09-01 13:56:37 | [drl] epoch #72 | Optimizing policy...
2020-09-01 13:56:37 | [drl] epoch #72 | Computing loss before
2020-09-01 13:56:37 | [drl] epoch #72 | Computing KL before
2020-09-01 13:56:37 | [drl] epoch #72 | Optimizing
2020-09-01 13:56:37 | [drl] epoch #72 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:56:37 | [drl] epoch #72 | computing loss before
2020-09-01 13:56:37 | [drl] epoch #72 | computing gradient
2020-09-01 13:56:37 | [drl] epoch #72 | gradient computed
2020-09-01 13:56:37 | [drl] epoch #72 | computing descent direction
2020-09-01 13:56:38 | [drl] epoch #72 | descent direction computed
2020-09-01 13:56:38 | [drl] epoch #72 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:38 | [drl] epoch #72 | Violated because loss not improving
2020-09-01 13:56:38 | [drl] epoch #72 | Violated because constraint mean_kl is violated
2020-09-01 13:56:38 | [drl] epoch #72 | backtrack iters: 14
2020-09-01 13:56:39 | [drl] epoch #72 | optimization finished
2020-09-01 13:56:39 | [drl] epoch #72 | Computing KL after
2020-09-01 13:56:39 | [drl] epoch #72 | Computing loss after
2020-09-01 13:56:39 | [drl] epoch #72 | Fitting baseline...
2020-09-01 13:56:39 | [drl] epoch #72 | Saving snapshot...
2020-09-01 13:56:39 | [drl] epoch #72 | Saved
2020-09-01 13:56:39 | [drl] epoch #72 | Time 618.09 s
2020-09-01 13:56:39 | [drl] epoch #72 | EpochTime 8.57 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.391
AverageReturn                            -414.478
Entropy                                     5.93662
EnvExecTime                                 1.92145
Extras/EpisodeRewardMean                 -419.354
Iteration                                  72
LinearFeatureBaseline/ExplainedVariance     0.605382
MaxReturn                                -294.28
MinReturn                                -636.092
NumTrajs                                  119
Perplexity                                378.652
PolicyExecTime                              4.10222
ProcessExecTime                             0.106398
StdReturn                                 123.436
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.69376
lstm_policy/KLBefore                        1.69376
lstm_policy/LossAfter                      -0.0307721
lstm_policy/LossBefore                     -0.0307721
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:56:39 | [drl] epoch #73 | Obtaining samples...
2020-09-01 13:56:39 | [drl] epoch #73 | Obtaining samples for iteration 73...
2020-09-01 13:56:45 | [drl] epoch #73 | Logging diagnostics...
2020-09-01 13:56:45 | [drl] epoch #73 | Optimizing policy...
2020-09-01 13:56:45 | [drl] epoch #73 | Computing loss before
2020-09-01 13:56:45 | [drl] epoch #73 | Computing KL before
2020-09-01 13:56:45 | [drl] epoch #73 | Optimizing
2020-09-01 13:56:45 | [drl] epoch #73 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:56:45 | [drl] epoch #73 | computing loss before
2020-09-01 13:56:45 | [drl] epoch #73 | computing gradient
2020-09-01 13:56:45 | [drl] epoch #73 | gradient computed
2020-09-01 13:56:45 | [drl] epoch #73 | computing descent direction
2020-09-01 13:56:46 | [drl] epoch #73 | descent direction computed
2020-09-01 13:56:47 | [drl] epoch #73 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:47 | [drl] epoch #73 | Violated because loss not improving
2020-09-01 13:56:47 | [drl] epoch #73 | Violated because constraint mean_kl is violated
2020-09-01 13:56:47 | [drl] epoch #73 | backtrack iters: 14
2020-09-01 13:56:47 | [drl] epoch #73 | optimization finished
2020-09-01 13:56:47 | [drl] epoch #73 | Computing KL after
2020-09-01 13:56:47 | [drl] epoch #73 | Computing loss after
2020-09-01 13:56:47 | [drl] epoch #73 | Fitting baseline...
2020-09-01 13:56:47 | [drl] epoch #73 | Saving snapshot...
2020-09-01 13:56:47 | [drl] epoch #73 | Saved
2020-09-01 13:56:47 | [drl] epoch #73 | Time 626.34 s
2020-09-01 13:56:47 | [drl] epoch #73 | EpochTime 8.24 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.475
AverageReturn                            -408.874
Entropy                                     6.00822
EnvExecTime                                 1.81364
Extras/EpisodeRewardMean                 -410.642
Iteration                                  73
LinearFeatureBaseline/ExplainedVariance     0.62899
MaxReturn                                -275.704
MinReturn                                -639.159
NumTrajs                                  116
Perplexity                                406.758
PolicyExecTime                              3.89533
ProcessExecTime                             0.10478
StdReturn                                 118.498
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.9376
lstm_policy/KLBefore                        1.9376
lstm_policy/LossAfter                      -0.0473108
lstm_policy/LossBefore                     -0.0473108
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:56:47 | [drl] epoch #74 | Obtaining samples...
2020-09-01 13:56:47 | [drl] epoch #74 | Obtaining samples for iteration 74...
2020-09-01 13:56:53 | [drl] epoch #74 | Logging diagnostics...
2020-09-01 13:56:53 | [drl] epoch #74 | Optimizing policy...
2020-09-01 13:56:53 | [drl] epoch #74 | Computing loss before
2020-09-01 13:56:53 | [drl] epoch #74 | Computing KL before
2020-09-01 13:56:53 | [drl] epoch #74 | Optimizing
2020-09-01 13:56:53 | [drl] epoch #74 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:56:53 | [drl] epoch #74 | computing loss before
2020-09-01 13:56:53 | [drl] epoch #74 | computing gradient
2020-09-01 13:56:54 | [drl] epoch #74 | gradient computed
2020-09-01 13:56:54 | [drl] epoch #74 | computing descent direction
2020-09-01 13:56:55 | [drl] epoch #74 | descent direction computed
2020-09-01 13:56:55 | [drl] epoch #74 | Line search condition violated. Rejecting the step!
2020-09-01 13:56:55 | [drl] epoch #74 | Violated because constraint mean_kl is violated
2020-09-01 13:56:55 | [drl] epoch #74 | backtrack iters: 14
2020-09-01 13:56:55 | [drl] epoch #74 | optimization finished
2020-09-01 13:56:55 | [drl] epoch #74 | Computing KL after
2020-09-01 13:56:55 | [drl] epoch #74 | Computing loss after
2020-09-01 13:56:55 | [drl] epoch #74 | Fitting baseline...
2020-09-01 13:56:55 | [drl] epoch #74 | Saving snapshot...
2020-09-01 13:56:55 | [drl] epoch #74 | Saved
2020-09-01 13:56:55 | [drl] epoch #74 | Time 634.69 s
2020-09-01 13:56:55 | [drl] epoch #74 | EpochTime 8.33 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.529
AverageReturn                            -408.23
Entropy                                     5.96478
EnvExecTime                                 1.85645
Extras/EpisodeRewardMean                 -409.238
Iteration                                  74
LinearFeatureBaseline/ExplainedVariance     0.611582
MaxReturn                                -287.099
MinReturn                                -650.685
NumTrajs                                  120
Perplexity                                389.469
PolicyExecTime                              3.89898
ProcessExecTime                             0.10046
StdReturn                                 121.314
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78162
lstm_policy/KLBefore                        1.78162
lstm_policy/LossAfter                      -0.0262132
lstm_policy/LossBefore                     -0.0262132
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:56:55 | [drl] epoch #75 | Obtaining samples...
2020-09-01 13:56:55 | [drl] epoch #75 | Obtaining samples for iteration 75...
2020-09-01 13:57:02 | [drl] epoch #75 | Logging diagnostics...
2020-09-01 13:57:02 | [drl] epoch #75 | Optimizing policy...
2020-09-01 13:57:02 | [drl] epoch #75 | Computing loss before
2020-09-01 13:57:02 | [drl] epoch #75 | Computing KL before
2020-09-01 13:57:02 | [drl] epoch #75 | Optimizing
2020-09-01 13:57:02 | [drl] epoch #75 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:57:02 | [drl] epoch #75 | computing loss before
2020-09-01 13:57:02 | [drl] epoch #75 | computing gradient
2020-09-01 13:57:02 | [drl] epoch #75 | gradient computed
2020-09-01 13:57:02 | [drl] epoch #75 | computing descent direction
2020-09-01 13:57:03 | [drl] epoch #75 | descent direction computed
2020-09-01 13:57:03 | [drl] epoch #75 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:03 | [drl] epoch #75 | Violated because constraint mean_kl is violated
2020-09-01 13:57:03 | [drl] epoch #75 | backtrack iters: 14
2020-09-01 13:57:03 | [drl] epoch #75 | optimization finished
2020-09-01 13:57:03 | [drl] epoch #75 | Computing KL after
2020-09-01 13:57:03 | [drl] epoch #75 | Computing loss after
2020-09-01 13:57:03 | [drl] epoch #75 | Fitting baseline...
2020-09-01 13:57:03 | [drl] epoch #75 | Saving snapshot...
2020-09-01 13:57:03 | [drl] epoch #75 | Saved
2020-09-01 13:57:03 | [drl] epoch #75 | Time 642.97 s
2020-09-01 13:57:03 | [drl] epoch #75 | EpochTime 8.26 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.115
AverageReturn                            -409.911
Entropy                                     5.93078
EnvExecTime                                 1.82894
Extras/EpisodeRewardMean                 -406.283
Iteration                                  75
LinearFeatureBaseline/ExplainedVariance     0.587509
MaxReturn                                -275.172
MinReturn                                -637.018
NumTrajs                                  120
Perplexity                                376.447
PolicyExecTime                              3.88589
ProcessExecTime                             0.0994067
StdReturn                                 126.468
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.6694
lstm_policy/KLBefore                        1.6694
lstm_policy/LossAfter                      -0.0290698
lstm_policy/LossBefore                     -0.0290698
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:57:03 | [drl] epoch #76 | Obtaining samples...
2020-09-01 13:57:03 | [drl] epoch #76 | Obtaining samples for iteration 76...
2020-09-01 13:57:10 | [drl] epoch #76 | Logging diagnostics...
2020-09-01 13:57:10 | [drl] epoch #76 | Optimizing policy...
2020-09-01 13:57:10 | [drl] epoch #76 | Computing loss before
2020-09-01 13:57:10 | [drl] epoch #76 | Computing KL before
2020-09-01 13:57:10 | [drl] epoch #76 | Optimizing
2020-09-01 13:57:10 | [drl] epoch #76 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:57:10 | [drl] epoch #76 | computing loss before
2020-09-01 13:57:10 | [drl] epoch #76 | computing gradient
2020-09-01 13:57:10 | [drl] epoch #76 | gradient computed
2020-09-01 13:57:10 | [drl] epoch #76 | computing descent direction
2020-09-01 13:57:11 | [drl] epoch #76 | descent direction computed
2020-09-01 13:57:12 | [drl] epoch #76 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:12 | [drl] epoch #76 | Violated because constraint mean_kl is violated
2020-09-01 13:57:12 | [drl] epoch #76 | backtrack iters: 14
2020-09-01 13:57:12 | [drl] epoch #76 | optimization finished
2020-09-01 13:57:12 | [drl] epoch #76 | Computing KL after
2020-09-01 13:57:12 | [drl] epoch #76 | Computing loss after
2020-09-01 13:57:12 | [drl] epoch #76 | Fitting baseline...
2020-09-01 13:57:12 | [drl] epoch #76 | Saving snapshot...
2020-09-01 13:57:12 | [drl] epoch #76 | Saved
2020-09-01 13:57:12 | [drl] epoch #76 | Time 651.21 s
2020-09-01 13:57:12 | [drl] epoch #76 | EpochTime 8.23 s
---------------------------------------  -----------
AverageDiscountedReturn                  -324.03
AverageReturn                            -379.824
Entropy                                     6.11079
EnvExecTime                                 1.81448
Extras/EpisodeRewardMean                 -385.501
Iteration                                  76
LinearFeatureBaseline/ExplainedVariance     0.66164
MaxReturn                                -282.642
MinReturn                                -649.927
NumTrajs                                  120
Perplexity                                450.693
PolicyExecTime                              3.86801
ProcessExecTime                             0.104475
StdReturn                                 102.949
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.30382
lstm_policy/KLBefore                        2.30382
lstm_policy/LossAfter                      -0.030248
lstm_policy/LossBefore                     -0.030248
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:57:12 | [drl] epoch #77 | Obtaining samples...
2020-09-01 13:57:12 | [drl] epoch #77 | Obtaining samples for iteration 77...
2020-09-01 13:57:18 | [drl] epoch #77 | Logging diagnostics...
2020-09-01 13:57:18 | [drl] epoch #77 | Optimizing policy...
2020-09-01 13:57:18 | [drl] epoch #77 | Computing loss before
2020-09-01 13:57:18 | [drl] epoch #77 | Computing KL before
2020-09-01 13:57:18 | [drl] epoch #77 | Optimizing
2020-09-01 13:57:18 | [drl] epoch #77 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:57:18 | [drl] epoch #77 | computing loss before
2020-09-01 13:57:18 | [drl] epoch #77 | computing gradient
2020-09-01 13:57:18 | [drl] epoch #77 | gradient computed
2020-09-01 13:57:18 | [drl] epoch #77 | computing descent direction
2020-09-01 13:57:20 | [drl] epoch #77 | descent direction computed
2020-09-01 13:57:20 | [drl] epoch #77 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:20 | [drl] epoch #77 | Violated because loss not improving
2020-09-01 13:57:20 | [drl] epoch #77 | Violated because constraint mean_kl is violated
2020-09-01 13:57:20 | [drl] epoch #77 | backtrack iters: 14
2020-09-01 13:57:20 | [drl] epoch #77 | optimization finished
2020-09-01 13:57:20 | [drl] epoch #77 | Computing KL after
2020-09-01 13:57:20 | [drl] epoch #77 | Computing loss after
2020-09-01 13:57:20 | [drl] epoch #77 | Fitting baseline...
2020-09-01 13:57:20 | [drl] epoch #77 | Saving snapshot...
2020-09-01 13:57:20 | [drl] epoch #77 | Saved
2020-09-01 13:57:20 | [drl] epoch #77 | Time 659.58 s
2020-09-01 13:57:20 | [drl] epoch #77 | EpochTime 8.35 s
---------------------------------------  -------------
AverageDiscountedReturn                  -342.575
AverageReturn                            -407.014
Entropy                                     5.97093
EnvExecTime                                 1.83457
Extras/EpisodeRewardMean                 -402.686
Iteration                                  77
LinearFeatureBaseline/ExplainedVariance     0.605212
MaxReturn                                -275.75
MinReturn                                -648.515
NumTrajs                                  120
Perplexity                                391.87
PolicyExecTime                              3.92927
ProcessExecTime                             0.0998256
StdReturn                                 123.088
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82308
lstm_policy/KLBefore                        1.82308
lstm_policy/LossAfter                       0.00421541
lstm_policy/LossBefore                      0.00421541
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:57:20 | [drl] epoch #78 | Obtaining samples...
2020-09-01 13:57:20 | [drl] epoch #78 | Obtaining samples for iteration 78...
2020-09-01 13:57:27 | [drl] epoch #78 | Logging diagnostics...
2020-09-01 13:57:27 | [drl] epoch #78 | Optimizing policy...
2020-09-01 13:57:27 | [drl] epoch #78 | Computing loss before
2020-09-01 13:57:27 | [drl] epoch #78 | Computing KL before
2020-09-01 13:57:27 | [drl] epoch #78 | Optimizing
2020-09-01 13:57:27 | [drl] epoch #78 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 13:57:27 | [drl] epoch #78 | computing loss before
2020-09-01 13:57:27 | [drl] epoch #78 | computing gradient
2020-09-01 13:57:27 | [drl] epoch #78 | gradient computed
2020-09-01 13:57:27 | [drl] epoch #78 | computing descent direction
2020-09-01 13:57:28 | [drl] epoch #78 | descent direction computed
2020-09-01 13:57:28 | [drl] epoch #78 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:28 | [drl] epoch #78 | Violated because loss not improving
2020-09-01 13:57:28 | [drl] epoch #78 | Violated because constraint mean_kl is violated
2020-09-01 13:57:28 | [drl] epoch #78 | backtrack iters: 14
2020-09-01 13:57:28 | [drl] epoch #78 | optimization finished
2020-09-01 13:57:28 | [drl] epoch #78 | Computing KL after
2020-09-01 13:57:28 | [drl] epoch #78 | Computing loss after
2020-09-01 13:57:28 | [drl] epoch #78 | Fitting baseline...
2020-09-01 13:57:28 | [drl] epoch #78 | Saving snapshot...
2020-09-01 13:57:28 | [drl] epoch #78 | Saved
2020-09-01 13:57:28 | [drl] epoch #78 | Time 667.86 s
2020-09-01 13:57:28 | [drl] epoch #78 | EpochTime 8.26 s
---------------------------------------  -----------
AverageDiscountedReturn                  -344.561
AverageReturn                            -410.089
Entropy                                     6.01427
EnvExecTime                                 1.84503
Extras/EpisodeRewardMean                 -408.759
Iteration                                  78
LinearFeatureBaseline/ExplainedVariance     0.623275
MaxReturn                                -270.586
MinReturn                                -653.363
NumTrajs                                  116
Perplexity                                409.225
PolicyExecTime                              3.90294
ProcessExecTime                             0.108526
StdReturn                                 122.592
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.96902
lstm_policy/KLBefore                        1.96902
lstm_policy/LossAfter                      -0.037761
lstm_policy/LossBefore                     -0.037761
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 13:57:28 | [drl] epoch #79 | Obtaining samples...
2020-09-01 13:57:28 | [drl] epoch #79 | Obtaining samples for iteration 79...
2020-09-01 13:57:36 | [drl] epoch #79 | Logging diagnostics...
2020-09-01 13:57:36 | [drl] epoch #79 | Optimizing policy...
2020-09-01 13:57:36 | [drl] epoch #79 | Computing loss before
2020-09-01 13:57:36 | [drl] epoch #79 | Computing KL before
2020-09-01 13:57:36 | [drl] epoch #79 | Optimizing
2020-09-01 13:57:36 | [drl] epoch #79 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:57:36 | [drl] epoch #79 | computing loss before
2020-09-01 13:57:36 | [drl] epoch #79 | computing gradient
2020-09-01 13:57:36 | [drl] epoch #79 | gradient computed
2020-09-01 13:57:36 | [drl] epoch #79 | computing descent direction
2020-09-01 13:57:38 | [drl] epoch #79 | descent direction computed
2020-09-01 13:57:38 | [drl] epoch #79 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:38 | [drl] epoch #79 | Violated because constraint mean_kl is violated
2020-09-01 13:57:38 | [drl] epoch #79 | backtrack iters: 14
2020-09-01 13:57:38 | [drl] epoch #79 | optimization finished
2020-09-01 13:57:38 | [drl] epoch #79 | Computing KL after
2020-09-01 13:57:38 | [drl] epoch #79 | Computing loss after
2020-09-01 13:57:38 | [drl] epoch #79 | Fitting baseline...
2020-09-01 13:57:38 | [drl] epoch #79 | Saving snapshot...
2020-09-01 13:57:38 | [drl] epoch #79 | Saved
2020-09-01 13:57:38 | [drl] epoch #79 | Time 677.43 s
2020-09-01 13:57:38 | [drl] epoch #79 | EpochTime 9.55 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.594
AverageReturn                            -413.176
Entropy                                     5.97818
EnvExecTime                                 1.92205
Extras/EpisodeRewardMean                 -410.322
Iteration                                  79
LinearFeatureBaseline/ExplainedVariance     0.619055
MaxReturn                                -273.7
MinReturn                                -642.075
NumTrajs                                  117
Perplexity                                394.722
PolicyExecTime                              4.25529
ProcessExecTime                             0.101274
StdReturn                                 121.239
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.84968
lstm_policy/KLBefore                        1.84968
lstm_policy/LossAfter                      -0.0350214
lstm_policy/LossBefore                     -0.0350214
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:57:38 | [drl] epoch #80 | Obtaining samples...
2020-09-01 13:57:38 | [drl] epoch #80 | Obtaining samples for iteration 80...
2020-09-01 13:57:47 | [drl] epoch #80 | Logging diagnostics...
2020-09-01 13:57:47 | [drl] epoch #80 | Optimizing policy...
2020-09-01 13:57:47 | [drl] epoch #80 | Computing loss before
2020-09-01 13:57:47 | [drl] epoch #80 | Computing KL before
2020-09-01 13:57:47 | [drl] epoch #80 | Optimizing
2020-09-01 13:57:47 | [drl] epoch #80 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:57:47 | [drl] epoch #80 | computing loss before
2020-09-01 13:57:47 | [drl] epoch #80 | computing gradient
2020-09-01 13:57:47 | [drl] epoch #80 | gradient computed
2020-09-01 13:57:47 | [drl] epoch #80 | computing descent direction
2020-09-01 13:57:50 | [drl] epoch #80 | descent direction computed
2020-09-01 13:57:51 | [drl] epoch #80 | Line search condition violated. Rejecting the step!
2020-09-01 13:57:51 | [drl] epoch #80 | Violated because constraint mean_kl is violated
2020-09-01 13:57:51 | [drl] epoch #80 | backtrack iters: 14
2020-09-01 13:57:51 | [drl] epoch #80 | optimization finished
2020-09-01 13:57:51 | [drl] epoch #80 | Computing KL after
2020-09-01 13:57:51 | [drl] epoch #80 | Computing loss after
2020-09-01 13:57:51 | [drl] epoch #80 | Fitting baseline...
2020-09-01 13:57:51 | [drl] epoch #80 | Saving snapshot...
2020-09-01 13:57:51 | [drl] epoch #80 | Saved
2020-09-01 13:57:51 | [drl] epoch #80 | Time 690.24 s
2020-09-01 13:57:51 | [drl] epoch #80 | EpochTime 12.80 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.884
AverageReturn                            -414.64
Entropy                                     5.94084
EnvExecTime                                 2.16381
Extras/EpisodeRewardMean                 -405.412
Iteration                                  80
LinearFeatureBaseline/ExplainedVariance     0.600602
MaxReturn                                -289.668
MinReturn                                -652.925
NumTrajs                                  119
Perplexity                                380.254
PolicyExecTime                              5.5739
ProcessExecTime                             0.130861
StdReturn                                 124.772
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72765
lstm_policy/KLBefore                        1.72765
lstm_policy/LossAfter                      -0.0281509
lstm_policy/LossBefore                     -0.0281509
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:57:51 | [drl] epoch #81 | Obtaining samples...
2020-09-01 13:57:51 | [drl] epoch #81 | Obtaining samples for iteration 81...
2020-09-01 13:57:58 | [drl] epoch #81 | Logging diagnostics...
2020-09-01 13:57:58 | [drl] epoch #81 | Optimizing policy...
2020-09-01 13:57:58 | [drl] epoch #81 | Computing loss before
2020-09-01 13:57:58 | [drl] epoch #81 | Computing KL before
2020-09-01 13:57:58 | [drl] epoch #81 | Optimizing
2020-09-01 13:57:58 | [drl] epoch #81 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:57:58 | [drl] epoch #81 | computing loss before
2020-09-01 13:57:58 | [drl] epoch #81 | computing gradient
2020-09-01 13:57:58 | [drl] epoch #81 | gradient computed
2020-09-01 13:57:58 | [drl] epoch #81 | computing descent direction
2020-09-01 13:58:00 | [drl] epoch #81 | descent direction computed
2020-09-01 13:58:00 | [drl] epoch #81 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:00 | [drl] epoch #81 | Violated because loss not improving
2020-09-01 13:58:00 | [drl] epoch #81 | Violated because constraint mean_kl is violated
2020-09-01 13:58:00 | [drl] epoch #81 | backtrack iters: 14
2020-09-01 13:58:00 | [drl] epoch #81 | optimization finished
2020-09-01 13:58:00 | [drl] epoch #81 | Computing KL after
2020-09-01 13:58:00 | [drl] epoch #81 | Computing loss after
2020-09-01 13:58:00 | [drl] epoch #81 | Fitting baseline...
2020-09-01 13:58:00 | [drl] epoch #81 | Saving snapshot...
2020-09-01 13:58:00 | [drl] epoch #81 | Saved
2020-09-01 13:58:00 | [drl] epoch #81 | Time 699.62 s
2020-09-01 13:58:00 | [drl] epoch #81 | EpochTime 9.37 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.789
AverageReturn                            -404.616
Entropy                                     6.00283
EnvExecTime                                 1.96973
Extras/EpisodeRewardMean                 -405.969
Iteration                                  81
LinearFeatureBaseline/ExplainedVariance     0.619078
MaxReturn                                -277.197
MinReturn                                -634.142
NumTrajs                                  118
Perplexity                                404.573
PolicyExecTime                              4.76398
ProcessExecTime                             0.125582
StdReturn                                 119.435
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.94653
lstm_policy/KLBefore                        1.94653
lstm_policy/LossAfter                      -0.0355764
lstm_policy/LossBefore                     -0.0355764
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:58:00 | [drl] epoch #82 | Obtaining samples...
2020-09-01 13:58:00 | [drl] epoch #82 | Obtaining samples for iteration 82...
2020-09-01 13:58:07 | [drl] epoch #82 | Logging diagnostics...
2020-09-01 13:58:07 | [drl] epoch #82 | Optimizing policy...
2020-09-01 13:58:07 | [drl] epoch #82 | Computing loss before
2020-09-01 13:58:07 | [drl] epoch #82 | Computing KL before
2020-09-01 13:58:07 | [drl] epoch #82 | Optimizing
2020-09-01 13:58:07 | [drl] epoch #82 | Start CG optimization: #parameters: 19852, #inputs: 126, #subsample_inputs: 126
2020-09-01 13:58:07 | [drl] epoch #82 | computing loss before
2020-09-01 13:58:07 | [drl] epoch #82 | computing gradient
2020-09-01 13:58:07 | [drl] epoch #82 | gradient computed
2020-09-01 13:58:07 | [drl] epoch #82 | computing descent direction
2020-09-01 13:58:08 | [drl] epoch #82 | descent direction computed
2020-09-01 13:58:09 | [drl] epoch #82 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:09 | [drl] epoch #82 | Violated because constraint mean_kl is violated
2020-09-01 13:58:09 | [drl] epoch #82 | backtrack iters: 14
2020-09-01 13:58:09 | [drl] epoch #82 | optimization finished
2020-09-01 13:58:09 | [drl] epoch #82 | Computing KL after
2020-09-01 13:58:09 | [drl] epoch #82 | Computing loss after
2020-09-01 13:58:09 | [drl] epoch #82 | Fitting baseline...
2020-09-01 13:58:09 | [drl] epoch #82 | Saving snapshot...
2020-09-01 13:58:09 | [drl] epoch #82 | Saved
2020-09-01 13:58:09 | [drl] epoch #82 | Time 708.25 s
2020-09-01 13:58:09 | [drl] epoch #82 | EpochTime 8.61 s
---------------------------------------  -------------
AverageDiscountedReturn                  -324.167
AverageReturn                            -380.465
Entropy                                     5.99212
EnvExecTime                                 1.86457
Extras/EpisodeRewardMean                 -375.365
Iteration                                  82
LinearFeatureBaseline/ExplainedVariance     0.639054
MaxReturn                                -267.508
MinReturn                                -648.908
NumTrajs                                  126
Perplexity                                400.262
PolicyExecTime                              4.01023
ProcessExecTime                             0.108175
StdReturn                                 105.545
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.85618
lstm_policy/KLBefore                        1.85618
lstm_policy/LossAfter                      -0.00914888
lstm_policy/LossBefore                     -0.00914888
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:58:09 | [drl] epoch #83 | Obtaining samples...
2020-09-01 13:58:09 | [drl] epoch #83 | Obtaining samples for iteration 83...
2020-09-01 13:58:16 | [drl] epoch #83 | Logging diagnostics...
2020-09-01 13:58:16 | [drl] epoch #83 | Optimizing policy...
2020-09-01 13:58:16 | [drl] epoch #83 | Computing loss before
2020-09-01 13:58:16 | [drl] epoch #83 | Computing KL before
2020-09-01 13:58:16 | [drl] epoch #83 | Optimizing
2020-09-01 13:58:16 | [drl] epoch #83 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 13:58:16 | [drl] epoch #83 | computing loss before
2020-09-01 13:58:16 | [drl] epoch #83 | computing gradient
2020-09-01 13:58:16 | [drl] epoch #83 | gradient computed
2020-09-01 13:58:16 | [drl] epoch #83 | computing descent direction
2020-09-01 13:58:18 | [drl] epoch #83 | descent direction computed
2020-09-01 13:58:18 | [drl] epoch #83 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:18 | [drl] epoch #83 | Violated because constraint mean_kl is violated
2020-09-01 13:58:18 | [drl] epoch #83 | backtrack iters: 14
2020-09-01 13:58:18 | [drl] epoch #83 | optimization finished
2020-09-01 13:58:18 | [drl] epoch #83 | Computing KL after
2020-09-01 13:58:18 | [drl] epoch #83 | Computing loss after
2020-09-01 13:58:18 | [drl] epoch #83 | Fitting baseline...
2020-09-01 13:58:18 | [drl] epoch #83 | Saving snapshot...
2020-09-01 13:58:18 | [drl] epoch #83 | Saved
2020-09-01 13:58:18 | [drl] epoch #83 | Time 717.49 s
2020-09-01 13:58:18 | [drl] epoch #83 | EpochTime 9.22 s
---------------------------------------  -------------
AverageDiscountedReturn                  -331.402
AverageReturn                            -392.201
Entropy                                     6.02782
EnvExecTime                                 1.99922
Extras/EpisodeRewardMean                 -397.876
Iteration                                  83
LinearFeatureBaseline/ExplainedVariance     0.625419
MaxReturn                                -281.259
MinReturn                                -628.888
NumTrajs                                  120
Perplexity                                414.812
PolicyExecTime                              4.50013
ProcessExecTime                             0.115389
StdReturn                                 114.032
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.02016
lstm_policy/KLBefore                        2.02016
lstm_policy/LossAfter                      -0.00325695
lstm_policy/LossBefore                     -0.00325695
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:58:18 | [drl] epoch #84 | Obtaining samples...
2020-09-01 13:58:18 | [drl] epoch #84 | Obtaining samples for iteration 84...
2020-09-01 13:58:26 | [drl] epoch #84 | Logging diagnostics...
2020-09-01 13:58:26 | [drl] epoch #84 | Optimizing policy...
2020-09-01 13:58:26 | [drl] epoch #84 | Computing loss before
2020-09-01 13:58:26 | [drl] epoch #84 | Computing KL before
2020-09-01 13:58:26 | [drl] epoch #84 | Optimizing
2020-09-01 13:58:26 | [drl] epoch #84 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:58:26 | [drl] epoch #84 | computing loss before
2020-09-01 13:58:26 | [drl] epoch #84 | computing gradient
2020-09-01 13:58:26 | [drl] epoch #84 | gradient computed
2020-09-01 13:58:26 | [drl] epoch #84 | computing descent direction
2020-09-01 13:58:27 | [drl] epoch #84 | descent direction computed
2020-09-01 13:58:27 | [drl] epoch #84 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:27 | [drl] epoch #84 | Violated because loss not improving
2020-09-01 13:58:27 | [drl] epoch #84 | Violated because constraint mean_kl is violated
2020-09-01 13:58:27 | [drl] epoch #84 | backtrack iters: 14
2020-09-01 13:58:27 | [drl] epoch #84 | optimization finished
2020-09-01 13:58:27 | [drl] epoch #84 | Computing KL after
2020-09-01 13:58:27 | [drl] epoch #84 | Computing loss after
2020-09-01 13:58:27 | [drl] epoch #84 | Fitting baseline...
2020-09-01 13:58:27 | [drl] epoch #84 | Saving snapshot...
2020-09-01 13:58:27 | [drl] epoch #84 | Saved
2020-09-01 13:58:27 | [drl] epoch #84 | Time 726.96 s
2020-09-01 13:58:27 | [drl] epoch #84 | EpochTime 9.46 s
---------------------------------------  ------------
AverageDiscountedReturn                  -345.279
AverageReturn                            -411.356
Entropy                                     5.99451
EnvExecTime                                 1.94387
Extras/EpisodeRewardMean                 -406.595
Iteration                                  84
LinearFeatureBaseline/ExplainedVariance     0.612431
MaxReturn                                -282.137
MinReturn                                -634.719
NumTrajs                                  117
Perplexity                                401.219
PolicyExecTime                              4.84435
ProcessExecTime                             0.120327
StdReturn                                 123.911
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.93141
lstm_policy/KLBefore                        1.93141
lstm_policy/LossAfter                      -0.0285487
lstm_policy/LossBefore                     -0.0285487
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:58:27 | [drl] epoch #85 | Obtaining samples...
2020-09-01 13:58:27 | [drl] epoch #85 | Obtaining samples for iteration 85...
2020-09-01 13:58:36 | [drl] epoch #85 | Logging diagnostics...
2020-09-01 13:58:36 | [drl] epoch #85 | Optimizing policy...
2020-09-01 13:58:36 | [drl] epoch #85 | Computing loss before
2020-09-01 13:58:36 | [drl] epoch #85 | Computing KL before
2020-09-01 13:58:36 | [drl] epoch #85 | Optimizing
2020-09-01 13:58:36 | [drl] epoch #85 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 13:58:36 | [drl] epoch #85 | computing loss before
2020-09-01 13:58:36 | [drl] epoch #85 | computing gradient
2020-09-01 13:58:36 | [drl] epoch #85 | gradient computed
2020-09-01 13:58:36 | [drl] epoch #85 | computing descent direction
2020-09-01 13:58:37 | [drl] epoch #85 | descent direction computed
2020-09-01 13:58:37 | [drl] epoch #85 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:37 | [drl] epoch #85 | Violated because constraint mean_kl is violated
2020-09-01 13:58:37 | [drl] epoch #85 | backtrack iters: 14
2020-09-01 13:58:37 | [drl] epoch #85 | optimization finished
2020-09-01 13:58:37 | [drl] epoch #85 | Computing KL after
2020-09-01 13:58:37 | [drl] epoch #85 | Computing loss after
2020-09-01 13:58:38 | [drl] epoch #85 | Fitting baseline...
2020-09-01 13:58:38 | [drl] epoch #85 | Saving snapshot...
2020-09-01 13:58:38 | [drl] epoch #85 | Saved
2020-09-01 13:58:38 | [drl] epoch #85 | Time 737.07 s
2020-09-01 13:58:38 | [drl] epoch #85 | EpochTime 10.10 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.971
AverageReturn                            -404.809
Entropy                                     5.9241
EnvExecTime                                 2.04548
Extras/EpisodeRewardMean                 -409.559
Iteration                                  85
LinearFeatureBaseline/ExplainedVariance     0.603558
MaxReturn                                -288.125
MinReturn                                -641.638
NumTrajs                                  122
Perplexity                                373.941
PolicyExecTime                              5.07273
ProcessExecTime                             0.121933
StdReturn                                 120.086
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.64835
lstm_policy/KLBefore                        1.64835
lstm_policy/LossAfter                      -0.0270996
lstm_policy/LossBefore                     -0.0270996
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:58:38 | [drl] epoch #86 | Obtaining samples...
2020-09-01 13:58:38 | [drl] epoch #86 | Obtaining samples for iteration 86...
2020-09-01 13:58:45 | [drl] epoch #86 | Logging diagnostics...
2020-09-01 13:58:45 | [drl] epoch #86 | Optimizing policy...
2020-09-01 13:58:45 | [drl] epoch #86 | Computing loss before
2020-09-01 13:58:45 | [drl] epoch #86 | Computing KL before
2020-09-01 13:58:45 | [drl] epoch #86 | Optimizing
2020-09-01 13:58:45 | [drl] epoch #86 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:58:45 | [drl] epoch #86 | computing loss before
2020-09-01 13:58:45 | [drl] epoch #86 | computing gradient
2020-09-01 13:58:45 | [drl] epoch #86 | gradient computed
2020-09-01 13:58:45 | [drl] epoch #86 | computing descent direction
2020-09-01 13:58:46 | [drl] epoch #86 | descent direction computed
2020-09-01 13:58:47 | [drl] epoch #86 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:47 | [drl] epoch #86 | Violated because constraint mean_kl is violated
2020-09-01 13:58:47 | [drl] epoch #86 | backtrack iters: 14
2020-09-01 13:58:47 | [drl] epoch #86 | optimization finished
2020-09-01 13:58:47 | [drl] epoch #86 | Computing KL after
2020-09-01 13:58:47 | [drl] epoch #86 | Computing loss after
2020-09-01 13:58:47 | [drl] epoch #86 | Fitting baseline...
2020-09-01 13:58:47 | [drl] epoch #86 | Saving snapshot...
2020-09-01 13:58:47 | [drl] epoch #86 | Saved
2020-09-01 13:58:47 | [drl] epoch #86 | Time 746.52 s
2020-09-01 13:58:47 | [drl] epoch #86 | EpochTime 9.44 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.711
AverageReturn                            -396.06
Entropy                                     5.99904
EnvExecTime                                 1.89471
Extras/EpisodeRewardMean                 -396.935
Iteration                                  86
LinearFeatureBaseline/ExplainedVariance     0.619686
MaxReturn                                -273.083
MinReturn                                -643.601
NumTrajs                                  121
Perplexity                                403.043
PolicyExecTime                              4.14938
ProcessExecTime                             0.109416
StdReturn                                 116.653
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.92506
lstm_policy/KLBefore                        1.92506
lstm_policy/LossAfter                      -0.0208336
lstm_policy/LossBefore                     -0.0208336
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:58:47 | [drl] epoch #87 | Obtaining samples...
2020-09-01 13:58:47 | [drl] epoch #87 | Obtaining samples for iteration 87...
2020-09-01 13:58:55 | [drl] epoch #87 | Logging diagnostics...
2020-09-01 13:58:55 | [drl] epoch #87 | Optimizing policy...
2020-09-01 13:58:55 | [drl] epoch #87 | Computing loss before
2020-09-01 13:58:55 | [drl] epoch #87 | Computing KL before
2020-09-01 13:58:55 | [drl] epoch #87 | Optimizing
2020-09-01 13:58:55 | [drl] epoch #87 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:58:55 | [drl] epoch #87 | computing loss before
2020-09-01 13:58:55 | [drl] epoch #87 | computing gradient
2020-09-01 13:58:55 | [drl] epoch #87 | gradient computed
2020-09-01 13:58:55 | [drl] epoch #87 | computing descent direction
2020-09-01 13:58:57 | [drl] epoch #87 | descent direction computed
2020-09-01 13:58:58 | [drl] epoch #87 | Line search condition violated. Rejecting the step!
2020-09-01 13:58:58 | [drl] epoch #87 | Violated because constraint mean_kl is violated
2020-09-01 13:58:58 | [drl] epoch #87 | backtrack iters: 14
2020-09-01 13:58:58 | [drl] epoch #87 | optimization finished
2020-09-01 13:58:58 | [drl] epoch #87 | Computing KL after
2020-09-01 13:58:58 | [drl] epoch #87 | Computing loss after
2020-09-01 13:58:58 | [drl] epoch #87 | Fitting baseline...
2020-09-01 13:58:58 | [drl] epoch #87 | Saving snapshot...
2020-09-01 13:58:58 | [drl] epoch #87 | Saved
2020-09-01 13:58:58 | [drl] epoch #87 | Time 757.17 s
2020-09-01 13:58:58 | [drl] epoch #87 | EpochTime 10.64 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.003
AverageReturn                            -399.373
Entropy                                     6.01906
EnvExecTime                                 2.00178
Extras/EpisodeRewardMean                 -402.472
Iteration                                  87
LinearFeatureBaseline/ExplainedVariance     0.626708
MaxReturn                                -278.229
MinReturn                                -631.986
NumTrajs                                  119
Perplexity                                411.193
PolicyExecTime                              5.21418
ProcessExecTime                             0.118382
StdReturn                                 116.608
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97611
lstm_policy/KLBefore                        1.97611
lstm_policy/LossAfter                      -0.0258433
lstm_policy/LossBefore                     -0.0258433
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:58:58 | [drl] epoch #88 | Obtaining samples...
2020-09-01 13:58:58 | [drl] epoch #88 | Obtaining samples for iteration 88...
2020-09-01 13:59:04 | [drl] epoch #88 | Logging diagnostics...
2020-09-01 13:59:04 | [drl] epoch #88 | Optimizing policy...
2020-09-01 13:59:04 | [drl] epoch #88 | Computing loss before
2020-09-01 13:59:04 | [drl] epoch #88 | Computing KL before
2020-09-01 13:59:04 | [drl] epoch #88 | Optimizing
2020-09-01 13:59:04 | [drl] epoch #88 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 13:59:04 | [drl] epoch #88 | computing loss before
2020-09-01 13:59:04 | [drl] epoch #88 | computing gradient
2020-09-01 13:59:05 | [drl] epoch #88 | gradient computed
2020-09-01 13:59:05 | [drl] epoch #88 | computing descent direction
2020-09-01 13:59:06 | [drl] epoch #88 | descent direction computed
2020-09-01 13:59:06 | [drl] epoch #88 | Line search condition violated. Rejecting the step!
2020-09-01 13:59:06 | [drl] epoch #88 | Violated because loss not improving
2020-09-01 13:59:06 | [drl] epoch #88 | Violated because constraint mean_kl is violated
2020-09-01 13:59:06 | [drl] epoch #88 | backtrack iters: 14
2020-09-01 13:59:06 | [drl] epoch #88 | optimization finished
2020-09-01 13:59:06 | [drl] epoch #88 | Computing KL after
2020-09-01 13:59:07 | [drl] epoch #88 | Computing loss after
2020-09-01 13:59:07 | [drl] epoch #88 | Fitting baseline...
2020-09-01 13:59:07 | [drl] epoch #88 | Saving snapshot...
2020-09-01 13:59:07 | [drl] epoch #88 | Saved
2020-09-01 13:59:07 | [drl] epoch #88 | Time 766.09 s
2020-09-01 13:59:07 | [drl] epoch #88 | EpochTime 8.89 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.289
AverageReturn                            -415.27
Entropy                                     5.95444
EnvExecTime                                 1.87269
Extras/EpisodeRewardMean                 -415.815
Iteration                                  88
LinearFeatureBaseline/ExplainedVariance     0.598879
MaxReturn                                -288.095
MinReturn                                -640.028
NumTrajs                                  119
Perplexity                                385.463
PolicyExecTime                              4.09546
ProcessExecTime                             0.103359
StdReturn                                 126.183
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.8015
lstm_policy/KLBefore                        1.8015
lstm_policy/LossAfter                      -0.0133256
lstm_policy/LossBefore                     -0.0133256
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:59:07 | [drl] epoch #89 | Obtaining samples...
2020-09-01 13:59:07 | [drl] epoch #89 | Obtaining samples for iteration 89...
2020-09-01 13:59:14 | [drl] epoch #89 | Logging diagnostics...
2020-09-01 13:59:14 | [drl] epoch #89 | Optimizing policy...
2020-09-01 13:59:14 | [drl] epoch #89 | Computing loss before
2020-09-01 13:59:14 | [drl] epoch #89 | Computing KL before
2020-09-01 13:59:14 | [drl] epoch #89 | Optimizing
2020-09-01 13:59:14 | [drl] epoch #89 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:59:14 | [drl] epoch #89 | computing loss before
2020-09-01 13:59:14 | [drl] epoch #89 | computing gradient
2020-09-01 13:59:14 | [drl] epoch #89 | gradient computed
2020-09-01 13:59:14 | [drl] epoch #89 | computing descent direction
2020-09-01 13:59:16 | [drl] epoch #89 | descent direction computed
2020-09-01 13:59:16 | [drl] epoch #89 | Line search condition violated. Rejecting the step!
2020-09-01 13:59:16 | [drl] epoch #89 | Violated because loss not improving
2020-09-01 13:59:16 | [drl] epoch #89 | Violated because constraint mean_kl is violated
2020-09-01 13:59:16 | [drl] epoch #89 | backtrack iters: 14
2020-09-01 13:59:16 | [drl] epoch #89 | optimization finished
2020-09-01 13:59:16 | [drl] epoch #89 | Computing KL after
2020-09-01 13:59:16 | [drl] epoch #89 | Computing loss after
2020-09-01 13:59:16 | [drl] epoch #89 | Fitting baseline...
2020-09-01 13:59:16 | [drl] epoch #89 | Saving snapshot...
2020-09-01 13:59:16 | [drl] epoch #89 | Saved
2020-09-01 13:59:16 | [drl] epoch #89 | Time 775.68 s
2020-09-01 13:59:16 | [drl] epoch #89 | EpochTime 9.59 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.854
AverageReturn                            -413.638
Entropy                                     5.96493
EnvExecTime                                 1.89379
Extras/EpisodeRewardMean                 -415.785
Iteration                                  89
LinearFeatureBaseline/ExplainedVariance     0.597204
MaxReturn                                -275.673
MinReturn                                -649.377
NumTrajs                                  118
Perplexity                                389.526
PolicyExecTime                              4.55608
ProcessExecTime                             0.113134
StdReturn                                 129.176
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78841
lstm_policy/KLBefore                        1.78841
lstm_policy/LossAfter                      -0.0413084
lstm_policy/LossBefore                     -0.0413084
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:59:16 | [drl] epoch #90 | Obtaining samples...
2020-09-01 13:59:16 | [drl] epoch #90 | Obtaining samples for iteration 90...
2020-09-01 13:59:25 | [drl] epoch #90 | Logging diagnostics...
2020-09-01 13:59:25 | [drl] epoch #90 | Optimizing policy...
2020-09-01 13:59:25 | [drl] epoch #90 | Computing loss before
2020-09-01 13:59:25 | [drl] epoch #90 | Computing KL before
2020-09-01 13:59:25 | [drl] epoch #90 | Optimizing
2020-09-01 13:59:25 | [drl] epoch #90 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 13:59:25 | [drl] epoch #90 | computing loss before
2020-09-01 13:59:25 | [drl] epoch #90 | computing gradient
2020-09-01 13:59:25 | [drl] epoch #90 | gradient computed
2020-09-01 13:59:25 | [drl] epoch #90 | computing descent direction
2020-09-01 13:59:27 | [drl] epoch #90 | descent direction computed
2020-09-01 13:59:27 | [drl] epoch #90 | Line search condition violated. Rejecting the step!
2020-09-01 13:59:27 | [drl] epoch #90 | Violated because loss not improving
2020-09-01 13:59:27 | [drl] epoch #90 | Violated because constraint mean_kl is violated
2020-09-01 13:59:27 | [drl] epoch #90 | backtrack iters: 14
2020-09-01 13:59:27 | [drl] epoch #90 | optimization finished
2020-09-01 13:59:27 | [drl] epoch #90 | Computing KL after
2020-09-01 13:59:27 | [drl] epoch #90 | Computing loss after
2020-09-01 13:59:27 | [drl] epoch #90 | Fitting baseline...
2020-09-01 13:59:27 | [drl] epoch #90 | Saving snapshot...
2020-09-01 13:59:27 | [drl] epoch #90 | Saved
2020-09-01 13:59:27 | [drl] epoch #90 | Time 786.64 s
2020-09-01 13:59:27 | [drl] epoch #90 | EpochTime 10.93 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.222
AverageReturn                            -404.702
Entropy                                     5.95498
EnvExecTime                                 2.25098
Extras/EpisodeRewardMean                 -408.644
Iteration                                  90
LinearFeatureBaseline/ExplainedVariance     0.617471
MaxReturn                                -282.818
MinReturn                                -634.645
NumTrajs                                  121
Perplexity                                385.669
PolicyExecTime                              5.68978
ProcessExecTime                             0.12508
StdReturn                                 117.301
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76489
lstm_policy/KLBefore                        1.76489
lstm_policy/LossAfter                      -0.0394315
lstm_policy/LossBefore                     -0.0394315
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 13:59:27 | [drl] epoch #91 | Obtaining samples...
2020-09-01 13:59:27 | [drl] epoch #91 | Obtaining samples for iteration 91...
2020-09-01 13:59:35 | [drl] epoch #91 | Logging diagnostics...
2020-09-01 13:59:35 | [drl] epoch #91 | Optimizing policy...
2020-09-01 13:59:35 | [drl] epoch #91 | Computing loss before
2020-09-01 13:59:35 | [drl] epoch #91 | Computing KL before
2020-09-01 13:59:35 | [drl] epoch #91 | Optimizing
2020-09-01 13:59:35 | [drl] epoch #91 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 13:59:35 | [drl] epoch #91 | computing loss before
2020-09-01 13:59:35 | [drl] epoch #91 | computing gradient
2020-09-01 13:59:35 | [drl] epoch #91 | gradient computed
2020-09-01 13:59:35 | [drl] epoch #91 | computing descent direction
2020-09-01 13:59:37 | [drl] epoch #91 | descent direction computed
2020-09-01 13:59:38 | [drl] epoch #91 | Line search condition violated. Rejecting the step!
2020-09-01 13:59:38 | [drl] epoch #91 | Violated because constraint mean_kl is violated
2020-09-01 13:59:38 | [drl] epoch #91 | backtrack iters: 14
2020-09-01 13:59:38 | [drl] epoch #91 | optimization finished
2020-09-01 13:59:38 | [drl] epoch #91 | Computing KL after
2020-09-01 13:59:38 | [drl] epoch #91 | Computing loss after
2020-09-01 13:59:38 | [drl] epoch #91 | Fitting baseline...
2020-09-01 13:59:38 | [drl] epoch #91 | Saving snapshot...
2020-09-01 13:59:38 | [drl] epoch #91 | Saved
2020-09-01 13:59:38 | [drl] epoch #91 | Time 797.11 s
2020-09-01 13:59:38 | [drl] epoch #91 | EpochTime 10.46 s
---------------------------------------  -------------
AverageDiscountedReturn                  -319.379
AverageReturn                            -372.784
Entropy                                     6.06954
EnvExecTime                                 1.966
Extras/EpisodeRewardMean                 -374.029
Iteration                                  91
LinearFeatureBaseline/ExplainedVariance     0.680881
MaxReturn                                -276.164
MinReturn                                -642.844
NumTrajs                                  125
Perplexity                                432.482
PolicyExecTime                              4.58063
ProcessExecTime                             0.108911
StdReturn                                  94.656
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.11049
lstm_policy/KLBefore                        2.11049
lstm_policy/LossAfter                       0.00148166
lstm_policy/LossBefore                      0.00148166
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:59:38 | [drl] epoch #92 | Obtaining samples...
2020-09-01 13:59:38 | [drl] epoch #92 | Obtaining samples for iteration 92...
2020-09-01 13:59:46 | [drl] epoch #92 | Logging diagnostics...
2020-09-01 13:59:46 | [drl] epoch #92 | Optimizing policy...
2020-09-01 13:59:46 | [drl] epoch #92 | Computing loss before
2020-09-01 13:59:46 | [drl] epoch #92 | Computing KL before
2020-09-01 13:59:46 | [drl] epoch #92 | Optimizing
2020-09-01 13:59:46 | [drl] epoch #92 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 13:59:46 | [drl] epoch #92 | computing loss before
2020-09-01 13:59:46 | [drl] epoch #92 | computing gradient
2020-09-01 13:59:46 | [drl] epoch #92 | gradient computed
2020-09-01 13:59:46 | [drl] epoch #92 | computing descent direction
2020-09-01 13:59:48 | [drl] epoch #92 | descent direction computed
2020-09-01 13:59:48 | [drl] epoch #92 | Line search condition violated. Rejecting the step!
2020-09-01 13:59:48 | [drl] epoch #92 | Violated because constraint mean_kl is violated
2020-09-01 13:59:48 | [drl] epoch #92 | backtrack iters: 14
2020-09-01 13:59:48 | [drl] epoch #92 | optimization finished
2020-09-01 13:59:48 | [drl] epoch #92 | Computing KL after
2020-09-01 13:59:48 | [drl] epoch #92 | Computing loss after
2020-09-01 13:59:48 | [drl] epoch #92 | Fitting baseline...
2020-09-01 13:59:48 | [drl] epoch #92 | Saving snapshot...
2020-09-01 13:59:48 | [drl] epoch #92 | Saved
2020-09-01 13:59:48 | [drl] epoch #92 | Time 807.64 s
2020-09-01 13:59:48 | [drl] epoch #92 | EpochTime 10.52 s
---------------------------------------  -------------
AverageDiscountedReturn                  -354.879
AverageReturn                            -424.973
Entropy                                     5.91568
EnvExecTime                                 2.11783
Extras/EpisodeRewardMean                 -428.886
Iteration                                  92
LinearFeatureBaseline/ExplainedVariance     0.588627
MaxReturn                                -286.202
MinReturn                                -648.517
NumTrajs                                  117
Perplexity                                370.808
PolicyExecTime                              5.23478
ProcessExecTime                             0.134721
StdReturn                                 126.522
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.65167
lstm_policy/KLBefore                        1.65167
lstm_policy/LossAfter                       0.00892959
lstm_policy/LossBefore                      0.00892959
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 13:59:48 | [drl] epoch #93 | Obtaining samples...
2020-09-01 13:59:48 | [drl] epoch #93 | Obtaining samples for iteration 93...
2020-09-01 13:59:58 | [drl] epoch #93 | Logging diagnostics...
2020-09-01 13:59:58 | [drl] epoch #93 | Optimizing policy...
2020-09-01 13:59:58 | [drl] epoch #93 | Computing loss before
2020-09-01 13:59:58 | [drl] epoch #93 | Computing KL before
2020-09-01 13:59:58 | [drl] epoch #93 | Optimizing
2020-09-01 13:59:58 | [drl] epoch #93 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 13:59:58 | [drl] epoch #93 | computing loss before
2020-09-01 13:59:58 | [drl] epoch #93 | computing gradient
2020-09-01 13:59:58 | [drl] epoch #93 | gradient computed
2020-09-01 13:59:58 | [drl] epoch #93 | computing descent direction
2020-09-01 14:00:00 | [drl] epoch #93 | descent direction computed
2020-09-01 14:00:00 | [drl] epoch #93 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:00 | [drl] epoch #93 | Violated because loss not improving
2020-09-01 14:00:00 | [drl] epoch #93 | Violated because constraint mean_kl is violated
2020-09-01 14:00:00 | [drl] epoch #93 | backtrack iters: 14
2020-09-01 14:00:00 | [drl] epoch #93 | optimization finished
2020-09-01 14:00:00 | [drl] epoch #93 | Computing KL after
2020-09-01 14:00:00 | [drl] epoch #93 | Computing loss after
2020-09-01 14:00:00 | [drl] epoch #93 | Fitting baseline...
2020-09-01 14:00:00 | [drl] epoch #93 | Saving snapshot...
2020-09-01 14:00:00 | [drl] epoch #93 | Saved
2020-09-01 14:00:00 | [drl] epoch #93 | Time 819.79 s
2020-09-01 14:00:00 | [drl] epoch #93 | EpochTime 12.13 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.479
AverageReturn                            -410.718
Entropy                                     5.96312
EnvExecTime                                 2.41366
Extras/EpisodeRewardMean                 -409.987
Iteration                                  93
LinearFeatureBaseline/ExplainedVariance     0.60069
MaxReturn                                -284.158
MinReturn                                -637.64
NumTrajs                                  118
Perplexity                                388.822
PolicyExecTime                              6.08217
ProcessExecTime                             0.158405
StdReturn                                 123.809
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78016
lstm_policy/KLBefore                        1.78016
lstm_policy/LossAfter                      -0.0377102
lstm_policy/LossBefore                     -0.0377102
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:00 | [drl] epoch #94 | Obtaining samples...
2020-09-01 14:00:00 | [drl] epoch #94 | Obtaining samples for iteration 94...
2020-09-01 14:00:10 | [drl] epoch #94 | Logging diagnostics...
2020-09-01 14:00:10 | [drl] epoch #94 | Optimizing policy...
2020-09-01 14:00:10 | [drl] epoch #94 | Computing loss before
2020-09-01 14:00:10 | [drl] epoch #94 | Computing KL before
2020-09-01 14:00:10 | [drl] epoch #94 | Optimizing
2020-09-01 14:00:10 | [drl] epoch #94 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:00:10 | [drl] epoch #94 | computing loss before
2020-09-01 14:00:10 | [drl] epoch #94 | computing gradient
2020-09-01 14:00:10 | [drl] epoch #94 | gradient computed
2020-09-01 14:00:10 | [drl] epoch #94 | computing descent direction
2020-09-01 14:00:11 | [drl] epoch #94 | descent direction computed
2020-09-01 14:00:12 | [drl] epoch #94 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:12 | [drl] epoch #94 | Violated because loss not improving
2020-09-01 14:00:12 | [drl] epoch #94 | Violated because constraint mean_kl is violated
2020-09-01 14:00:12 | [drl] epoch #94 | backtrack iters: 14
2020-09-01 14:00:12 | [drl] epoch #94 | optimization finished
2020-09-01 14:00:12 | [drl] epoch #94 | Computing KL after
2020-09-01 14:00:12 | [drl] epoch #94 | Computing loss after
2020-09-01 14:00:12 | [drl] epoch #94 | Fitting baseline...
2020-09-01 14:00:12 | [drl] epoch #94 | Saving snapshot...
2020-09-01 14:00:12 | [drl] epoch #94 | Saved
2020-09-01 14:00:12 | [drl] epoch #94 | Time 831.11 s
2020-09-01 14:00:12 | [drl] epoch #94 | EpochTime 11.30 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.22
AverageReturn                            -403.879
Entropy                                     6.04223
EnvExecTime                                 2.25401
Extras/EpisodeRewardMean                 -404.817
Iteration                                  94
LinearFeatureBaseline/ExplainedVariance     0.623537
MaxReturn                                -282.13
MinReturn                                -646.329
NumTrajs                                  117
Perplexity                                420.832
PolicyExecTime                              6.05744
ProcessExecTime                             0.156317
StdReturn                                 119.715
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.10227
lstm_policy/KLBefore                        2.10227
lstm_policy/LossAfter                      -0.0360822
lstm_policy/LossBefore                     -0.0360822
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:12 | [drl] epoch #95 | Obtaining samples...
2020-09-01 14:00:12 | [drl] epoch #95 | Obtaining samples for iteration 95...
2020-09-01 14:00:21 | [drl] epoch #95 | Logging diagnostics...
2020-09-01 14:00:21 | [drl] epoch #95 | Optimizing policy...
2020-09-01 14:00:21 | [drl] epoch #95 | Computing loss before
2020-09-01 14:00:21 | [drl] epoch #95 | Computing KL before
2020-09-01 14:00:21 | [drl] epoch #95 | Optimizing
2020-09-01 14:00:21 | [drl] epoch #95 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:00:21 | [drl] epoch #95 | computing loss before
2020-09-01 14:00:21 | [drl] epoch #95 | computing gradient
2020-09-01 14:00:21 | [drl] epoch #95 | gradient computed
2020-09-01 14:00:21 | [drl] epoch #95 | computing descent direction
2020-09-01 14:00:22 | [drl] epoch #95 | descent direction computed
2020-09-01 14:00:22 | [drl] epoch #95 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:22 | [drl] epoch #95 | Violated because constraint mean_kl is violated
2020-09-01 14:00:22 | [drl] epoch #95 | backtrack iters: 14
2020-09-01 14:00:22 | [drl] epoch #95 | optimization finished
2020-09-01 14:00:22 | [drl] epoch #95 | Computing KL after
2020-09-01 14:00:22 | [drl] epoch #95 | Computing loss after
2020-09-01 14:00:22 | [drl] epoch #95 | Fitting baseline...
2020-09-01 14:00:22 | [drl] epoch #95 | Saving snapshot...
2020-09-01 14:00:22 | [drl] epoch #95 | Saved
2020-09-01 14:00:22 | [drl] epoch #95 | Time 841.94 s
2020-09-01 14:00:22 | [drl] epoch #95 | EpochTime 10.81 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.764
AverageReturn                            -416.455
Entropy                                     5.8965
EnvExecTime                                 2.24472
Extras/EpisodeRewardMean                 -414.974
Iteration                                  95
LinearFeatureBaseline/ExplainedVariance     0.58996
MaxReturn                                -284.116
MinReturn                                -642.874
NumTrajs                                  120
Perplexity                                363.762
PolicyExecTime                              5.49449
ProcessExecTime                             0.159666
StdReturn                                 125.692
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.55653
lstm_policy/KLBefore                        1.55653
lstm_policy/LossAfter                      -0.0242823
lstm_policy/LossBefore                     -0.0242823
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:22 | [drl] epoch #96 | Obtaining samples...
2020-09-01 14:00:22 | [drl] epoch #96 | Obtaining samples for iteration 96...
2020-09-01 14:00:29 | [drl] epoch #96 | Logging diagnostics...
2020-09-01 14:00:29 | [drl] epoch #96 | Optimizing policy...
2020-09-01 14:00:29 | [drl] epoch #96 | Computing loss before
2020-09-01 14:00:29 | [drl] epoch #96 | Computing KL before
2020-09-01 14:00:29 | [drl] epoch #96 | Optimizing
2020-09-01 14:00:29 | [drl] epoch #96 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:00:29 | [drl] epoch #96 | computing loss before
2020-09-01 14:00:29 | [drl] epoch #96 | computing gradient
2020-09-01 14:00:29 | [drl] epoch #96 | gradient computed
2020-09-01 14:00:29 | [drl] epoch #96 | computing descent direction
2020-09-01 14:00:31 | [drl] epoch #96 | descent direction computed
2020-09-01 14:00:31 | [drl] epoch #96 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:31 | [drl] epoch #96 | Violated because loss not improving
2020-09-01 14:00:31 | [drl] epoch #96 | Violated because constraint mean_kl is violated
2020-09-01 14:00:31 | [drl] epoch #96 | backtrack iters: 14
2020-09-01 14:00:31 | [drl] epoch #96 | optimization finished
2020-09-01 14:00:31 | [drl] epoch #96 | Computing KL after
2020-09-01 14:00:31 | [drl] epoch #96 | Computing loss after
2020-09-01 14:00:31 | [drl] epoch #96 | Fitting baseline...
2020-09-01 14:00:31 | [drl] epoch #96 | Saving snapshot...
2020-09-01 14:00:31 | [drl] epoch #96 | Saved
2020-09-01 14:00:31 | [drl] epoch #96 | Time 850.62 s
2020-09-01 14:00:31 | [drl] epoch #96 | EpochTime 8.67 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.036
AverageReturn                            -409.338
Entropy                                     5.92883
EnvExecTime                                 1.93248
Extras/EpisodeRewardMean                 -415.233
Iteration                                  96
LinearFeatureBaseline/ExplainedVariance     0.599645
MaxReturn                                -286.713
MinReturn                                -637.865
NumTrajs                                  121
Perplexity                                375.715
PolicyExecTime                              4.14857
ProcessExecTime                             0.102502
StdReturn                                 122.281
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.63706
lstm_policy/KLBefore                        1.63706
lstm_policy/LossAfter                      -0.0340754
lstm_policy/LossBefore                     -0.0340754
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:31 | [drl] epoch #97 | Obtaining samples...
2020-09-01 14:00:31 | [drl] epoch #97 | Obtaining samples for iteration 97...
2020-09-01 14:00:38 | [drl] epoch #97 | Logging diagnostics...
2020-09-01 14:00:38 | [drl] epoch #97 | Optimizing policy...
2020-09-01 14:00:38 | [drl] epoch #97 | Computing loss before
2020-09-01 14:00:38 | [drl] epoch #97 | Computing KL before
2020-09-01 14:00:38 | [drl] epoch #97 | Optimizing
2020-09-01 14:00:38 | [drl] epoch #97 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:00:38 | [drl] epoch #97 | computing loss before
2020-09-01 14:00:38 | [drl] epoch #97 | computing gradient
2020-09-01 14:00:38 | [drl] epoch #97 | gradient computed
2020-09-01 14:00:38 | [drl] epoch #97 | computing descent direction
2020-09-01 14:00:39 | [drl] epoch #97 | descent direction computed
2020-09-01 14:00:40 | [drl] epoch #97 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:40 | [drl] epoch #97 | Violated because loss not improving
2020-09-01 14:00:40 | [drl] epoch #97 | Violated because constraint mean_kl is violated
2020-09-01 14:00:40 | [drl] epoch #97 | backtrack iters: 14
2020-09-01 14:00:40 | [drl] epoch #97 | optimization finished
2020-09-01 14:00:40 | [drl] epoch #97 | Computing KL after
2020-09-01 14:00:40 | [drl] epoch #97 | Computing loss after
2020-09-01 14:00:40 | [drl] epoch #97 | Fitting baseline...
2020-09-01 14:00:40 | [drl] epoch #97 | Saving snapshot...
2020-09-01 14:00:40 | [drl] epoch #97 | Saved
2020-09-01 14:00:40 | [drl] epoch #97 | Time 859.28 s
2020-09-01 14:00:40 | [drl] epoch #97 | EpochTime 8.65 s
---------------------------------------  ------------
AverageDiscountedReturn                  -352.773
AverageReturn                            -421.692
Entropy                                     5.96635
EnvExecTime                                 1.88138
Extras/EpisodeRewardMean                 -421.896
Iteration                                  97
LinearFeatureBaseline/ExplainedVariance     0.605281
MaxReturn                                -282.373
MinReturn                                -638.953
NumTrajs                                  116
Perplexity                                390.08
PolicyExecTime                              4.0136
ProcessExecTime                             0.104144
StdReturn                                 128.859
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82346
lstm_policy/KLBefore                        1.82346
lstm_policy/LossAfter                      -0.0384238
lstm_policy/LossBefore                     -0.0384238
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:40 | [drl] epoch #98 | Obtaining samples...
2020-09-01 14:00:40 | [drl] epoch #98 | Obtaining samples for iteration 98...
2020-09-01 14:00:46 | [drl] epoch #98 | Logging diagnostics...
2020-09-01 14:00:46 | [drl] epoch #98 | Optimizing policy...
2020-09-01 14:00:46 | [drl] epoch #98 | Computing loss before
2020-09-01 14:00:46 | [drl] epoch #98 | Computing KL before
2020-09-01 14:00:46 | [drl] epoch #98 | Optimizing
2020-09-01 14:00:46 | [drl] epoch #98 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:00:46 | [drl] epoch #98 | computing loss before
2020-09-01 14:00:46 | [drl] epoch #98 | computing gradient
2020-09-01 14:00:46 | [drl] epoch #98 | gradient computed
2020-09-01 14:00:46 | [drl] epoch #98 | computing descent direction
2020-09-01 14:00:48 | [drl] epoch #98 | descent direction computed
2020-09-01 14:00:48 | [drl] epoch #98 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:48 | [drl] epoch #98 | Violated because constraint mean_kl is violated
2020-09-01 14:00:48 | [drl] epoch #98 | backtrack iters: 14
2020-09-01 14:00:48 | [drl] epoch #98 | optimization finished
2020-09-01 14:00:48 | [drl] epoch #98 | Computing KL after
2020-09-01 14:00:48 | [drl] epoch #98 | Computing loss after
2020-09-01 14:00:48 | [drl] epoch #98 | Fitting baseline...
2020-09-01 14:00:48 | [drl] epoch #98 | Saving snapshot...
2020-09-01 14:00:48 | [drl] epoch #98 | Saved
2020-09-01 14:00:48 | [drl] epoch #98 | Time 867.51 s
2020-09-01 14:00:48 | [drl] epoch #98 | EpochTime 8.22 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.62
AverageReturn                            -408.162
Entropy                                     6.01125
EnvExecTime                                 1.79894
Extras/EpisodeRewardMean                 -398.99
Iteration                                  98
LinearFeatureBaseline/ExplainedVariance     0.623821
MaxReturn                                -287.156
MinReturn                                -640.305
NumTrajs                                  118
Perplexity                                407.992
PolicyExecTime                              3.77235
ProcessExecTime                             0.105576
StdReturn                                 120.311
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.9538
lstm_policy/KLBefore                        1.9538
lstm_policy/LossAfter                      -0.0392751
lstm_policy/LossBefore                     -0.0392751
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:48 | [drl] epoch #99 | Obtaining samples...
2020-09-01 14:00:48 | [drl] epoch #99 | Obtaining samples for iteration 99...
2020-09-01 14:00:56 | [drl] epoch #99 | Logging diagnostics...
2020-09-01 14:00:56 | [drl] epoch #99 | Optimizing policy...
2020-09-01 14:00:56 | [drl] epoch #99 | Computing loss before
2020-09-01 14:00:56 | [drl] epoch #99 | Computing KL before
2020-09-01 14:00:56 | [drl] epoch #99 | Optimizing
2020-09-01 14:00:56 | [drl] epoch #99 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:00:56 | [drl] epoch #99 | computing loss before
2020-09-01 14:00:56 | [drl] epoch #99 | computing gradient
2020-09-01 14:00:56 | [drl] epoch #99 | gradient computed
2020-09-01 14:00:56 | [drl] epoch #99 | computing descent direction
2020-09-01 14:00:58 | [drl] epoch #99 | descent direction computed
2020-09-01 14:00:58 | [drl] epoch #99 | Line search condition violated. Rejecting the step!
2020-09-01 14:00:58 | [drl] epoch #99 | Violated because loss not improving
2020-09-01 14:00:58 | [drl] epoch #99 | Violated because constraint mean_kl is violated
2020-09-01 14:00:58 | [drl] epoch #99 | backtrack iters: 14
2020-09-01 14:00:58 | [drl] epoch #99 | optimization finished
2020-09-01 14:00:58 | [drl] epoch #99 | Computing KL after
2020-09-01 14:00:58 | [drl] epoch #99 | Computing loss after
2020-09-01 14:00:58 | [drl] epoch #99 | Fitting baseline...
2020-09-01 14:00:58 | [drl] epoch #99 | Saving snapshot...
2020-09-01 14:00:58 | [drl] epoch #99 | Saved
2020-09-01 14:00:58 | [drl] epoch #99 | Time 877.98 s
2020-09-01 14:00:58 | [drl] epoch #99 | EpochTime 10.44 s
---------------------------------------  ------------
AverageDiscountedReturn                  -350.05
AverageReturn                            -417.651
Entropy                                     5.91303
EnvExecTime                                 2.09237
Extras/EpisodeRewardMean                 -419.574
Iteration                                  99
LinearFeatureBaseline/ExplainedVariance     0.606558
MaxReturn                                -290.367
MinReturn                                -650.249
NumTrajs                                  119
Perplexity                                369.824
PolicyExecTime                              4.79827
ProcessExecTime                             0.132582
StdReturn                                 123.994
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.60679
lstm_policy/KLBefore                        1.60679
lstm_policy/LossAfter                      -0.0264729
lstm_policy/LossBefore                     -0.0264729
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:00:58 | [drl] epoch #100 | Obtaining samples...
2020-09-01 14:00:58 | [drl] epoch #100 | Obtaining samples for iteration 100...
2020-09-01 14:01:10 | [drl] epoch #100 | Logging diagnostics...
2020-09-01 14:01:10 | [drl] epoch #100 | Optimizing policy...
2020-09-01 14:01:10 | [drl] epoch #100 | Computing loss before
2020-09-01 14:01:10 | [drl] epoch #100 | Computing KL before
2020-09-01 14:01:10 | [drl] epoch #100 | Optimizing
2020-09-01 14:01:10 | [drl] epoch #100 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:01:10 | [drl] epoch #100 | computing loss before
2020-09-01 14:01:10 | [drl] epoch #100 | computing gradient
2020-09-01 14:01:10 | [drl] epoch #100 | gradient computed
2020-09-01 14:01:10 | [drl] epoch #100 | computing descent direction
2020-09-01 14:01:13 | [drl] epoch #100 | descent direction computed
2020-09-01 14:01:13 | [drl] epoch #100 | Line search condition violated. Rejecting the step!
2020-09-01 14:01:13 | [drl] epoch #100 | Violated because constraint mean_kl is violated
2020-09-01 14:01:13 | [drl] epoch #100 | backtrack iters: 14
2020-09-01 14:01:13 | [drl] epoch #100 | optimization finished
2020-09-01 14:01:13 | [drl] epoch #100 | Computing KL after
2020-09-01 14:01:13 | [drl] epoch #100 | Computing loss after
2020-09-01 14:01:13 | [drl] epoch #100 | Fitting baseline...
2020-09-01 14:01:13 | [drl] epoch #100 | Saving snapshot...
2020-09-01 14:01:13 | [drl] epoch #100 | Saved
2020-09-01 14:01:13 | [drl] epoch #100 | Time 892.53 s
2020-09-01 14:01:13 | [drl] epoch #100 | EpochTime 14.54 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.314
AverageReturn                            -407.367
Entropy                                     5.91886
EnvExecTime                                 2.48132
Extras/EpisodeRewardMean                 -409.428
Iteration                                 100
LinearFeatureBaseline/ExplainedVariance     0.596159
MaxReturn                                -275.705
MinReturn                                -656.444
NumTrajs                                  121
Perplexity                                371.989
PolicyExecTime                              8.15114
ProcessExecTime                             0.157249
StdReturn                                 122.396
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.61373
lstm_policy/KLBefore                        1.61373
lstm_policy/LossAfter                      -0.0287974
lstm_policy/LossBefore                     -0.0287974
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:05:14 | [drl] epoch #0 | Obtaining samples...
2020-09-01 14:05:14 | [drl] epoch #0 | Obtaining samples for iteration 0...
2020-09-01 14:05:21 | [drl] epoch #0 | Logging diagnostics...
2020-09-01 14:05:21 | [drl] epoch #0 | Optimizing policy...
2020-09-01 14:05:21 | [drl] epoch #0 | Computing loss before
2020-09-01 14:05:21 | [drl] epoch #0 | Computing KL before
2020-09-01 14:05:21 | [drl] epoch #0 | Optimizing
2020-09-01 14:05:21 | [drl] epoch #0 | Start CG optimization: #parameters: 19852, #inputs: 100, #subsample_inputs: 100
2020-09-01 14:05:21 | [drl] epoch #0 | computing loss before
2020-09-01 14:05:21 | [drl] epoch #0 | computing gradient
2020-09-01 14:05:22 | [drl] epoch #0 | gradient computed
2020-09-01 14:05:22 | [drl] epoch #0 | computing descent direction
2020-09-01 14:05:24 | [drl] epoch #0 | descent direction computed
2020-09-01 14:05:24 | [drl] epoch #0 | backtrack iters: 6
2020-09-01 14:05:24 | [drl] epoch #0 | optimization finished
2020-09-01 14:05:24 | [drl] epoch #0 | Computing KL after
2020-09-01 14:05:24 | [drl] epoch #0 | Computing loss after
2020-09-01 14:05:24 | [drl] epoch #0 | Fitting baseline...
2020-09-01 14:05:24 | [drl] epoch #0 | Saving snapshot...
2020-09-01 14:05:24 | [drl] epoch #0 | Saved
2020-09-01 14:05:24 | [drl] epoch #0 | Time 9.97 s
2020-09-01 14:05:24 | [drl] epoch #0 | EpochTime 9.97 s
---------------------------------------  --------------
AverageDiscountedReturn                  -622.701
AverageReturn                            -786.729
Entropy                                     8.51363
EnvExecTime                                 1.81052
Extras/EpisodeRewardMean                 -786.729
Iteration                                   0
LinearFeatureBaseline/ExplainedVariance     3.75069e-08
MaxReturn                                -538.656
MinReturn                                -842.04
NumTrajs                                  100
Perplexity                               4982.22
PolicyExecTime                              4.0922
ProcessExecTime                             0.0948727
StdReturn                                  36.4843
lstm_policy/Entropy                         8.27718
lstm_policy/KL                              0.563965
lstm_policy/KLBefore                        0.000978823
lstm_policy/LossAfter                       0.00379731
lstm_policy/LossBefore                      0.0053426
lstm_policy/dLoss                           0.00154529
---------------------------------------  --------------
2020-09-01 14:05:24 | [drl] epoch #1 | Obtaining samples...
2020-09-01 14:05:24 | [drl] epoch #1 | Obtaining samples for iteration 1...
2020-09-01 14:05:31 | [drl] epoch #1 | Logging diagnostics...
2020-09-01 14:05:31 | [drl] epoch #1 | Optimizing policy...
2020-09-01 14:05:31 | [drl] epoch #1 | Computing loss before
2020-09-01 14:05:31 | [drl] epoch #1 | Computing KL before
2020-09-01 14:05:31 | [drl] epoch #1 | Optimizing
2020-09-01 14:05:31 | [drl] epoch #1 | Start CG optimization: #parameters: 19852, #inputs: 108, #subsample_inputs: 108
2020-09-01 14:05:31 | [drl] epoch #1 | computing loss before
2020-09-01 14:05:31 | [drl] epoch #1 | computing gradient
2020-09-01 14:05:31 | [drl] epoch #1 | gradient computed
2020-09-01 14:05:31 | [drl] epoch #1 | computing descent direction
2020-09-01 14:05:33 | [drl] epoch #1 | descent direction computed
2020-09-01 14:05:33 | [drl] epoch #1 | Line search condition violated. Rejecting the step!
2020-09-01 14:05:33 | [drl] epoch #1 | Violated because loss not improving
2020-09-01 14:05:33 | [drl] epoch #1 | backtrack iters: 14
2020-09-01 14:05:33 | [drl] epoch #1 | optimization finished
2020-09-01 14:05:33 | [drl] epoch #1 | Computing KL after
2020-09-01 14:05:33 | [drl] epoch #1 | Computing loss after
2020-09-01 14:05:33 | [drl] epoch #1 | Fitting baseline...
2020-09-01 14:05:33 | [drl] epoch #1 | Saving snapshot...
2020-09-01 14:05:33 | [drl] epoch #1 | Saved
2020-09-01 14:05:33 | [drl] epoch #1 | Time 18.92 s
2020-09-01 14:05:33 | [drl] epoch #1 | EpochTime 8.93 s
---------------------------------------  -------------
AverageDiscountedReturn                  -531.163
AverageReturn                            -654.757
Entropy                                     8.29337
EnvExecTime                                 1.88777
Extras/EpisodeRewardMean                 -645.557
Iteration                                   1
LinearFeatureBaseline/ExplainedVariance     0.703877
MaxReturn                                -408.842
MinReturn                                -804.354
NumTrajs                                  108
Perplexity                               3997.29
PolicyExecTime                              4.52165
ProcessExecTime                             0.115572
StdReturn                                 132.929
lstm_policy/Entropy                         8.27718
lstm_policy/KL                              0.0135801
lstm_policy/KLBefore                        0.0135801
lstm_policy/LossAfter                      -0.00451497
lstm_policy/LossBefore                     -0.00451497
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:05:33 | [drl] epoch #2 | Obtaining samples...
2020-09-01 14:05:33 | [drl] epoch #2 | Obtaining samples for iteration 2...
2020-09-01 14:05:39 | [drl] epoch #2 | Logging diagnostics...
2020-09-01 14:05:39 | [drl] epoch #2 | Optimizing policy...
2020-09-01 14:05:39 | [drl] epoch #2 | Computing loss before
2020-09-01 14:05:39 | [drl] epoch #2 | Computing KL before
2020-09-01 14:05:39 | [drl] epoch #2 | Optimizing
2020-09-01 14:05:39 | [drl] epoch #2 | Start CG optimization: #parameters: 19852, #inputs: 105, #subsample_inputs: 105
2020-09-01 14:05:39 | [drl] epoch #2 | computing loss before
2020-09-01 14:05:39 | [drl] epoch #2 | computing gradient
2020-09-01 14:05:40 | [drl] epoch #2 | gradient computed
2020-09-01 14:05:40 | [drl] epoch #2 | computing descent direction
2020-09-01 14:05:41 | [drl] epoch #2 | descent direction computed
2020-09-01 14:05:41 | [drl] epoch #2 | backtrack iters: 6
2020-09-01 14:05:41 | [drl] epoch #2 | optimization finished
2020-09-01 14:05:41 | [drl] epoch #2 | Computing KL after
2020-09-01 14:05:41 | [drl] epoch #2 | Computing loss after
2020-09-01 14:05:41 | [drl] epoch #2 | Fitting baseline...
2020-09-01 14:05:41 | [drl] epoch #2 | Saving snapshot...
2020-09-01 14:05:41 | [drl] epoch #2 | Saved
2020-09-01 14:05:41 | [drl] epoch #2 | Time 27.01 s
2020-09-01 14:05:41 | [drl] epoch #2 | EpochTime 8.07 s
---------------------------------------  --------------
AverageDiscountedReturn                  -535.202
AverageReturn                            -661.165
Entropy                                     8.29749
EnvExecTime                                 1.80444
Extras/EpisodeRewardMean                 -659.552
Iteration                                   2
LinearFeatureBaseline/ExplainedVariance     0.768979
MaxReturn                                -399.56
MinReturn                                -801.944
NumTrajs                                  105
Perplexity                               4013.8
PolicyExecTime                              3.93587
ProcessExecTime                             0.0952187
StdReturn                                 131.334
lstm_policy/Entropy                         8.75331
lstm_policy/KL                              0.215079
lstm_policy/KLBefore                        0.0147891
lstm_policy/LossAfter                       0.0246473
lstm_policy/LossBefore                      0.0248037
lstm_policy/dLoss                           0.000156347
---------------------------------------  --------------
2020-09-01 14:05:41 | [drl] epoch #3 | Obtaining samples...
2020-09-01 14:05:41 | [drl] epoch #3 | Obtaining samples for iteration 3...
2020-09-01 14:05:48 | [drl] epoch #3 | Logging diagnostics...
2020-09-01 14:05:48 | [drl] epoch #3 | Optimizing policy...
2020-09-01 14:05:48 | [drl] epoch #3 | Computing loss before
2020-09-01 14:05:48 | [drl] epoch #3 | Computing KL before
2020-09-01 14:05:48 | [drl] epoch #3 | Optimizing
2020-09-01 14:05:48 | [drl] epoch #3 | Start CG optimization: #parameters: 19852, #inputs: 101, #subsample_inputs: 101
2020-09-01 14:05:48 | [drl] epoch #3 | computing loss before
2020-09-01 14:05:48 | [drl] epoch #3 | computing gradient
2020-09-01 14:05:48 | [drl] epoch #3 | gradient computed
2020-09-01 14:05:48 | [drl] epoch #3 | computing descent direction
2020-09-01 14:05:49 | [drl] epoch #3 | descent direction computed
2020-09-01 14:05:49 | [drl] epoch #3 | backtrack iters: 5
2020-09-01 14:05:49 | [drl] epoch #3 | optimization finished
2020-09-01 14:05:49 | [drl] epoch #3 | Computing KL after
2020-09-01 14:05:49 | [drl] epoch #3 | Computing loss after
2020-09-01 14:05:49 | [drl] epoch #3 | Fitting baseline...
2020-09-01 14:05:49 | [drl] epoch #3 | Saving snapshot...
2020-09-01 14:05:49 | [drl] epoch #3 | Saved
2020-09-01 14:05:49 | [drl] epoch #3 | Time 35.11 s
2020-09-01 14:05:49 | [drl] epoch #3 | EpochTime 8.09 s
---------------------------------------  -------------
AverageDiscountedReturn                  -599.606
AverageReturn                            -753.797
Entropy                                     8.74702
EnvExecTime                                 1.81028
Extras/EpisodeRewardMean                 -753.621
Iteration                                   3
LinearFeatureBaseline/ExplainedVariance     0.882409
MaxReturn                                -454.538
MinReturn                                -820.883
NumTrajs                                  101
Perplexity                               6291.89
PolicyExecTime                              3.94401
ProcessExecTime                             0.0972395
StdReturn                                  86.2602
lstm_policy/Entropy                         8.43744
lstm_policy/KL                              0.349481
lstm_policy/KLBefore                        0.00322501
lstm_policy/LossAfter                      -0.0102691
lstm_policy/LossBefore                      0.00401419
lstm_policy/dLoss                           0.0142833
---------------------------------------  -------------
2020-09-01 14:05:49 | [drl] epoch #4 | Obtaining samples...
2020-09-01 14:05:49 | [drl] epoch #4 | Obtaining samples for iteration 4...
2020-09-01 14:05:56 | [drl] epoch #4 | Logging diagnostics...
2020-09-01 14:05:56 | [drl] epoch #4 | Optimizing policy...
2020-09-01 14:05:56 | [drl] epoch #4 | Computing loss before
2020-09-01 14:05:56 | [drl] epoch #4 | Computing KL before
2020-09-01 14:05:56 | [drl] epoch #4 | Optimizing
2020-09-01 14:05:56 | [drl] epoch #4 | Start CG optimization: #parameters: 19852, #inputs: 101, #subsample_inputs: 101
2020-09-01 14:05:56 | [drl] epoch #4 | computing loss before
2020-09-01 14:05:56 | [drl] epoch #4 | computing gradient
2020-09-01 14:05:56 | [drl] epoch #4 | gradient computed
2020-09-01 14:05:56 | [drl] epoch #4 | computing descent direction
2020-09-01 14:05:57 | [drl] epoch #4 | descent direction computed
2020-09-01 14:05:57 | [drl] epoch #4 | backtrack iters: 1
2020-09-01 14:05:57 | [drl] epoch #4 | optimization finished
2020-09-01 14:05:57 | [drl] epoch #4 | Computing KL after
2020-09-01 14:05:57 | [drl] epoch #4 | Computing loss after
2020-09-01 14:05:57 | [drl] epoch #4 | Fitting baseline...
2020-09-01 14:05:57 | [drl] epoch #4 | Saving snapshot...
2020-09-01 14:05:57 | [drl] epoch #4 | Saved
2020-09-01 14:05:57 | [drl] epoch #4 | Time 43.07 s
2020-09-01 14:05:57 | [drl] epoch #4 | EpochTime 7.94 s
---------------------------------------  -------------
AverageDiscountedReturn                  -593.103
AverageReturn                            -746.985
Entropy                                     8.43834
EnvExecTime                                 1.79721
Extras/EpisodeRewardMean                 -746.724
Iteration                                   4
LinearFeatureBaseline/ExplainedVariance     0.945228
MaxReturn                                -437.252
MinReturn                                -806.441
NumTrajs                                  101
Perplexity                               4620.86
PolicyExecTime                              3.87328
ProcessExecTime                             0.0982509
StdReturn                                  63.8167
lstm_policy/Entropy                         7.81717
lstm_policy/KL                              0.717636
lstm_policy/KLBefore                        0.00220648
lstm_policy/LossAfter                      -0.0196774
lstm_policy/LossBefore                     -0.00116654
lstm_policy/dLoss                           0.0185109
---------------------------------------  -------------
2020-09-01 14:05:57 | [drl] epoch #5 | Obtaining samples...
2020-09-01 14:05:57 | [drl] epoch #5 | Obtaining samples for iteration 5...
2020-09-01 14:06:04 | [drl] epoch #5 | Logging diagnostics...
2020-09-01 14:06:04 | [drl] epoch #5 | Optimizing policy...
2020-09-01 14:06:04 | [drl] epoch #5 | Computing loss before
2020-09-01 14:06:04 | [drl] epoch #5 | Computing KL before
2020-09-01 14:06:04 | [drl] epoch #5 | Optimizing
2020-09-01 14:06:04 | [drl] epoch #5 | Start CG optimization: #parameters: 19852, #inputs: 104, #subsample_inputs: 104
2020-09-01 14:06:04 | [drl] epoch #5 | computing loss before
2020-09-01 14:06:04 | [drl] epoch #5 | computing gradient
2020-09-01 14:06:04 | [drl] epoch #5 | gradient computed
2020-09-01 14:06:04 | [drl] epoch #5 | computing descent direction
2020-09-01 14:06:05 | [drl] epoch #5 | descent direction computed
2020-09-01 14:06:05 | [drl] epoch #5 | Line search condition violated. Rejecting the step!
2020-09-01 14:06:05 | [drl] epoch #5 | Violated because loss not improving
2020-09-01 14:06:05 | [drl] epoch #5 | backtrack iters: 14
2020-09-01 14:06:05 | [drl] epoch #5 | optimization finished
2020-09-01 14:06:05 | [drl] epoch #5 | Computing KL after
2020-09-01 14:06:05 | [drl] epoch #5 | Computing loss after
2020-09-01 14:06:05 | [drl] epoch #5 | Fitting baseline...
2020-09-01 14:06:05 | [drl] epoch #5 | Saving snapshot...
2020-09-01 14:06:05 | [drl] epoch #5 | Saved
2020-09-01 14:06:05 | [drl] epoch #5 | Time 51.34 s
2020-09-01 14:06:05 | [drl] epoch #5 | EpochTime 8.26 s
---------------------------------------  ------------
AverageDiscountedReturn                  -504.377
AverageReturn                            -623.824
Entropy                                     7.87853
EnvExecTime                                 1.78478
Extras/EpisodeRewardMean                 -626.376
Iteration                                   5
LinearFeatureBaseline/ExplainedVariance     0.691428
MaxReturn                                -364.492
MinReturn                                -773.177
NumTrajs                                  104
Perplexity                               2639.98
PolicyExecTime                              4.00456
ProcessExecTime                             0.0995638
StdReturn                                 139.52
lstm_policy/Entropy                         7.81717
lstm_policy/KL                              0.0656477
lstm_policy/KLBefore                        0.0656477
lstm_policy/LossAfter                      -0.0103375
lstm_policy/LossBefore                     -0.0103375
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:06:05 | [drl] epoch #6 | Obtaining samples...
2020-09-01 14:06:05 | [drl] epoch #6 | Obtaining samples for iteration 6...
2020-09-01 14:06:12 | [drl] epoch #6 | Logging diagnostics...
2020-09-01 14:06:12 | [drl] epoch #6 | Optimizing policy...
2020-09-01 14:06:12 | [drl] epoch #6 | Computing loss before
2020-09-01 14:06:12 | [drl] epoch #6 | Computing KL before
2020-09-01 14:06:12 | [drl] epoch #6 | Optimizing
2020-09-01 14:06:12 | [drl] epoch #6 | Start CG optimization: #parameters: 19852, #inputs: 105, #subsample_inputs: 105
2020-09-01 14:06:12 | [drl] epoch #6 | computing loss before
2020-09-01 14:06:12 | [drl] epoch #6 | computing gradient
2020-09-01 14:06:12 | [drl] epoch #6 | gradient computed
2020-09-01 14:06:12 | [drl] epoch #6 | computing descent direction
2020-09-01 14:06:13 | [drl] epoch #6 | descent direction computed
2020-09-01 14:06:13 | [drl] epoch #6 | backtrack iters: 5
2020-09-01 14:06:13 | [drl] epoch #6 | optimization finished
2020-09-01 14:06:13 | [drl] epoch #6 | Computing KL after
2020-09-01 14:06:13 | [drl] epoch #6 | Computing loss after
2020-09-01 14:06:13 | [drl] epoch #6 | Fitting baseline...
2020-09-01 14:06:13 | [drl] epoch #6 | Saving snapshot...
2020-09-01 14:06:13 | [drl] epoch #6 | Saved
2020-09-01 14:06:13 | [drl] epoch #6 | Time 59.43 s
2020-09-01 14:06:13 | [drl] epoch #6 | EpochTime 8.07 s
---------------------------------------  -------------
AverageDiscountedReturn                  -497.4
AverageReturn                            -612.939
Entropy                                     7.88749
EnvExecTime                                 1.80333
Extras/EpisodeRewardMean                 -613.305
Iteration                                   6
LinearFeatureBaseline/ExplainedVariance     0.718966
MaxReturn                                -358.258
MinReturn                                -754.584
NumTrajs                                  105
Perplexity                               2663.74
PolicyExecTime                              3.94161
ProcessExecTime                             0.100711
StdReturn                                 143.75
lstm_policy/Entropy                         7.11604
lstm_policy/KL                              0.83808
lstm_policy/KLBefore                        0.0754555
lstm_policy/LossAfter                      -0.0200005
lstm_policy/LossBefore                      0.00531277
lstm_policy/dLoss                           0.0253133
---------------------------------------  -------------
2020-09-01 14:06:13 | [drl] epoch #7 | Obtaining samples...
2020-09-01 14:06:13 | [drl] epoch #7 | Obtaining samples for iteration 7...
2020-09-01 14:06:20 | [drl] epoch #7 | Logging diagnostics...
2020-09-01 14:06:20 | [drl] epoch #7 | Optimizing policy...
2020-09-01 14:06:20 | [drl] epoch #7 | Computing loss before
2020-09-01 14:06:20 | [drl] epoch #7 | Computing KL before
2020-09-01 14:06:20 | [drl] epoch #7 | Optimizing
2020-09-01 14:06:20 | [drl] epoch #7 | Start CG optimization: #parameters: 19852, #inputs: 104, #subsample_inputs: 104
2020-09-01 14:06:20 | [drl] epoch #7 | computing loss before
2020-09-01 14:06:20 | [drl] epoch #7 | computing gradient
2020-09-01 14:06:20 | [drl] epoch #7 | gradient computed
2020-09-01 14:06:20 | [drl] epoch #7 | computing descent direction
2020-09-01 14:06:22 | [drl] epoch #7 | descent direction computed
2020-09-01 14:06:22 | [drl] epoch #7 | backtrack iters: 4
2020-09-01 14:06:22 | [drl] epoch #7 | optimization finished
2020-09-01 14:06:22 | [drl] epoch #7 | Computing KL after
2020-09-01 14:06:22 | [drl] epoch #7 | Computing loss after
2020-09-01 14:06:22 | [drl] epoch #7 | Fitting baseline...
2020-09-01 14:06:22 | [drl] epoch #7 | Saving snapshot...
2020-09-01 14:06:22 | [drl] epoch #7 | Saved
2020-09-01 14:06:22 | [drl] epoch #7 | Time 67.87 s
2020-09-01 14:06:22 | [drl] epoch #7 | EpochTime 8.42 s
---------------------------------------  -------------
AverageDiscountedReturn                  -525.737
AverageReturn                            -659.038
Entropy                                     7.14528
EnvExecTime                                 1.83898
Extras/EpisodeRewardMean                 -660.482
Iteration                                   7
LinearFeatureBaseline/ExplainedVariance     0.823866
MaxReturn                                -382.006
MinReturn                                -748.132
NumTrajs                                  104
Perplexity                               1268.11
PolicyExecTime                              4.16811
ProcessExecTime                             0.104684
StdReturn                                 104.202
lstm_policy/Entropy                         6.60346
lstm_policy/KL                              0.658567
lstm_policy/KLBefore                        0.0451335
lstm_policy/LossAfter                      -0.030541
lstm_policy/LossBefore                     -0.0277734
lstm_policy/dLoss                           0.00276758
---------------------------------------  -------------
2020-09-01 14:06:22 | [drl] epoch #8 | Obtaining samples...
2020-09-01 14:06:22 | [drl] epoch #8 | Obtaining samples for iteration 8...
2020-09-01 14:06:28 | [drl] epoch #8 | Logging diagnostics...
2020-09-01 14:06:28 | [drl] epoch #8 | Optimizing policy...
2020-09-01 14:06:28 | [drl] epoch #8 | Computing loss before
2020-09-01 14:06:28 | [drl] epoch #8 | Computing KL before
2020-09-01 14:06:29 | [drl] epoch #8 | Optimizing
2020-09-01 14:06:29 | [drl] epoch #8 | Start CG optimization: #parameters: 19852, #inputs: 127, #subsample_inputs: 127
2020-09-01 14:06:29 | [drl] epoch #8 | computing loss before
2020-09-01 14:06:29 | [drl] epoch #8 | computing gradient
2020-09-01 14:06:29 | [drl] epoch #8 | gradient computed
2020-09-01 14:06:29 | [drl] epoch #8 | computing descent direction
2020-09-01 14:06:30 | [drl] epoch #8 | descent direction computed
2020-09-01 14:06:30 | [drl] epoch #8 | backtrack iters: 14
2020-09-01 14:06:30 | [drl] epoch #8 | optimization finished
2020-09-01 14:06:30 | [drl] epoch #8 | Computing KL after
2020-09-01 14:06:30 | [drl] epoch #8 | Computing loss after
2020-09-01 14:06:30 | [drl] epoch #8 | Fitting baseline...
2020-09-01 14:06:30 | [drl] epoch #8 | Saving snapshot...
2020-09-01 14:06:30 | [drl] epoch #8 | Saved
2020-09-01 14:06:30 | [drl] epoch #8 | Time 76.43 s
2020-09-01 14:06:30 | [drl] epoch #8 | EpochTime 8.55 s
---------------------------------------  -------------
AverageDiscountedReturn                  -361.652
AverageReturn                            -426.665
Entropy                                     6.86786
EnvExecTime                                 1.80097
Extras/EpisodeRewardMean                 -435.105
Iteration                                   8
LinearFeatureBaseline/ExplainedVariance     0.479998
MaxReturn                                -324.669
MinReturn                                -672.362
NumTrajs                                  127
Perplexity                                960.89
PolicyExecTime                              4.01804
ProcessExecTime                             0.111791
StdReturn                                  99.0101
lstm_policy/Entropy                         6.74642
lstm_policy/KL                              0.938671
lstm_policy/KLBefore                        0.885168
lstm_policy/LossAfter                      -0.0443471
lstm_policy/LossBefore                     -0.0360156
lstm_policy/dLoss                           0.00833151
---------------------------------------  -------------
2020-09-01 14:06:30 | [drl] epoch #9 | Obtaining samples...
2020-09-01 14:06:30 | [drl] epoch #9 | Obtaining samples for iteration 9...
2020-09-01 14:06:37 | [drl] epoch #9 | Logging diagnostics...
2020-09-01 14:06:37 | [drl] epoch #9 | Optimizing policy...
2020-09-01 14:06:37 | [drl] epoch #9 | Computing loss before
2020-09-01 14:06:37 | [drl] epoch #9 | Computing KL before
2020-09-01 14:06:37 | [drl] epoch #9 | Optimizing
2020-09-01 14:06:37 | [drl] epoch #9 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:06:37 | [drl] epoch #9 | computing loss before
2020-09-01 14:06:37 | [drl] epoch #9 | computing gradient
2020-09-01 14:06:37 | [drl] epoch #9 | gradient computed
2020-09-01 14:06:37 | [drl] epoch #9 | computing descent direction
2020-09-01 14:06:38 | [drl] epoch #9 | descent direction computed
2020-09-01 14:06:39 | [drl] epoch #9 | backtrack iters: 7
2020-09-01 14:06:39 | [drl] epoch #9 | optimization finished
2020-09-01 14:06:39 | [drl] epoch #9 | Computing KL after
2020-09-01 14:06:39 | [drl] epoch #9 | Computing loss after
2020-09-01 14:06:39 | [drl] epoch #9 | Fitting baseline...
2020-09-01 14:06:39 | [drl] epoch #9 | Saving snapshot...
2020-09-01 14:06:39 | [drl] epoch #9 | Saved
2020-09-01 14:06:39 | [drl] epoch #9 | Time 84.68 s
2020-09-01 14:06:39 | [drl] epoch #9 | EpochTime 8.23 s
---------------------------------------  -------------
AverageDiscountedReturn                  -425.65
AverageReturn                            -517.394
Entropy                                     6.86705
EnvExecTime                                 1.81453
Extras/EpisodeRewardMean                 -511.39
Iteration                                   9
LinearFeatureBaseline/ExplainedVariance     0.646476
MaxReturn                                -330.095
MinReturn                                -702.715
NumTrajs                                  117
Perplexity                                960.108
PolicyExecTime                              3.93898
ProcessExecTime                             0.0983677
StdReturn                                 119.317
lstm_policy/Entropy                         6.59376
lstm_policy/KL                              0.515673
lstm_policy/KLBefore                        0.412918
lstm_policy/LossAfter                      -0.00867094
lstm_policy/LossBefore                      0.00604612
lstm_policy/dLoss                           0.0147171
---------------------------------------  -------------
2020-09-01 14:06:39 | [drl] epoch #10 | Obtaining samples...
2020-09-01 14:06:39 | [drl] epoch #10 | Obtaining samples for iteration 10...
2020-09-01 14:06:45 | [drl] epoch #10 | Logging diagnostics...
2020-09-01 14:06:45 | [drl] epoch #10 | Optimizing policy...
2020-09-01 14:06:45 | [drl] epoch #10 | Computing loss before
2020-09-01 14:06:45 | [drl] epoch #10 | Computing KL before
2020-09-01 14:06:45 | [drl] epoch #10 | Optimizing
2020-09-01 14:06:45 | [drl] epoch #10 | Start CG optimization: #parameters: 19852, #inputs: 110, #subsample_inputs: 110
2020-09-01 14:06:45 | [drl] epoch #10 | computing loss before
2020-09-01 14:06:45 | [drl] epoch #10 | computing gradient
2020-09-01 14:06:45 | [drl] epoch #10 | gradient computed
2020-09-01 14:06:45 | [drl] epoch #10 | computing descent direction
2020-09-01 14:06:46 | [drl] epoch #10 | descent direction computed
2020-09-01 14:06:47 | [drl] epoch #10 | Line search condition violated. Rejecting the step!
2020-09-01 14:06:47 | [drl] epoch #10 | Violated because constraint mean_kl is violated
2020-09-01 14:06:47 | [drl] epoch #10 | backtrack iters: 14
2020-09-01 14:06:47 | [drl] epoch #10 | optimization finished
2020-09-01 14:06:47 | [drl] epoch #10 | Computing KL after
2020-09-01 14:06:47 | [drl] epoch #10 | Computing loss after
2020-09-01 14:06:47 | [drl] epoch #10 | Fitting baseline...
2020-09-01 14:06:47 | [drl] epoch #10 | Saving snapshot...
2020-09-01 14:06:47 | [drl] epoch #10 | Saved
2020-09-01 14:06:47 | [drl] epoch #10 | Time 92.77 s
2020-09-01 14:06:47 | [drl] epoch #10 | EpochTime 8.07 s
---------------------------------------  ------------
AverageDiscountedReturn                  -384.19
AverageReturn                            -459.499
Entropy                                     6.9598
EnvExecTime                                 1.78987
Extras/EpisodeRewardMean                 -462.717
Iteration                                  10
LinearFeatureBaseline/ExplainedVariance     0.687291
MaxReturn                                -308.776
MinReturn                                -666.657
NumTrajs                                  110
Perplexity                               1053.42
PolicyExecTime                              3.84569
ProcessExecTime                             0.104918
StdReturn                                 113.464
lstm_policy/Entropy                         6.59376
lstm_policy/KL                              1.2181
lstm_policy/KLBefore                        1.2181
lstm_policy/LossAfter                      -0.0570603
lstm_policy/LossBefore                     -0.0570603
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:06:47 | [drl] epoch #11 | Obtaining samples...
2020-09-01 14:06:47 | [drl] epoch #11 | Obtaining samples for iteration 11...
2020-09-01 14:06:53 | [drl] epoch #11 | Logging diagnostics...
2020-09-01 14:06:53 | [drl] epoch #11 | Optimizing policy...
2020-09-01 14:06:53 | [drl] epoch #11 | Computing loss before
2020-09-01 14:06:53 | [drl] epoch #11 | Computing KL before
2020-09-01 14:06:53 | [drl] epoch #11 | Optimizing
2020-09-01 14:06:53 | [drl] epoch #11 | Start CG optimization: #parameters: 19852, #inputs: 110, #subsample_inputs: 110
2020-09-01 14:06:53 | [drl] epoch #11 | computing loss before
2020-09-01 14:06:53 | [drl] epoch #11 | computing gradient
2020-09-01 14:06:53 | [drl] epoch #11 | gradient computed
2020-09-01 14:06:53 | [drl] epoch #11 | computing descent direction
2020-09-01 14:06:55 | [drl] epoch #11 | descent direction computed
2020-09-01 14:06:55 | [drl] epoch #11 | backtrack iters: 6
2020-09-01 14:06:55 | [drl] epoch #11 | optimization finished
2020-09-01 14:06:55 | [drl] epoch #11 | Computing KL after
2020-09-01 14:06:55 | [drl] epoch #11 | Computing loss after
2020-09-01 14:06:55 | [drl] epoch #11 | Fitting baseline...
2020-09-01 14:06:55 | [drl] epoch #11 | Saving snapshot...
2020-09-01 14:06:55 | [drl] epoch #11 | Saved
2020-09-01 14:06:55 | [drl] epoch #11 | Time 100.89 s
2020-09-01 14:06:55 | [drl] epoch #11 | EpochTime 8.10 s
---------------------------------------  ------------
AverageDiscountedReturn                  -390.384
AverageReturn                            -468.457
Entropy                                     6.94324
EnvExecTime                                 1.83616
Extras/EpisodeRewardMean                 -468.129
Iteration                                  11
LinearFeatureBaseline/ExplainedVariance     0.689816
MaxReturn                                -325.45
MinReturn                                -682.494
NumTrajs                                  110
Perplexity                               1036.13
PolicyExecTime                              3.91394
ProcessExecTime                             0.101652
StdReturn                                 120.327
lstm_policy/Entropy                         6.45151
lstm_policy/KL                              0.909338
lstm_policy/KLBefore                        1.11516
lstm_policy/LossAfter                      -0.0608097
lstm_policy/LossBefore                     -0.0426364
lstm_policy/dLoss                           0.0181732
---------------------------------------  ------------
2020-09-01 14:06:55 | [drl] epoch #12 | Obtaining samples...
2020-09-01 14:06:55 | [drl] epoch #12 | Obtaining samples for iteration 12...
2020-09-01 14:07:01 | [drl] epoch #12 | Logging diagnostics...
2020-09-01 14:07:01 | [drl] epoch #12 | Optimizing policy...
2020-09-01 14:07:01 | [drl] epoch #12 | Computing loss before
2020-09-01 14:07:01 | [drl] epoch #12 | Computing KL before
2020-09-01 14:07:02 | [drl] epoch #12 | Optimizing
2020-09-01 14:07:02 | [drl] epoch #12 | Start CG optimization: #parameters: 19852, #inputs: 128, #subsample_inputs: 128
2020-09-01 14:07:02 | [drl] epoch #12 | computing loss before
2020-09-01 14:07:02 | [drl] epoch #12 | computing gradient
2020-09-01 14:07:02 | [drl] epoch #12 | gradient computed
2020-09-01 14:07:02 | [drl] epoch #12 | computing descent direction
2020-09-01 14:07:03 | [drl] epoch #12 | descent direction computed
2020-09-01 14:07:03 | [drl] epoch #12 | backtrack iters: 7
2020-09-01 14:07:03 | [drl] epoch #12 | optimization finished
2020-09-01 14:07:03 | [drl] epoch #12 | Computing KL after
2020-09-01 14:07:03 | [drl] epoch #12 | Computing loss after
2020-09-01 14:07:03 | [drl] epoch #12 | Fitting baseline...
2020-09-01 14:07:03 | [drl] epoch #12 | Saving snapshot...
2020-09-01 14:07:03 | [drl] epoch #12 | Saved
2020-09-01 14:07:03 | [drl] epoch #12 | Time 109.27 s
2020-09-01 14:07:03 | [drl] epoch #12 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -351.307
AverageReturn                            -411.946
Entropy                                     6.805
EnvExecTime                                 1.826
Extras/EpisodeRewardMean                 -411.468
Iteration                                  12
LinearFeatureBaseline/ExplainedVariance     0.647007
MaxReturn                                -310.649
MinReturn                                -686.031
NumTrajs                                  128
Perplexity                                902.352
PolicyExecTime                              4.01747
ProcessExecTime                             0.103983
StdReturn                                 105.78
lstm_policy/Entropy                         6.1723
lstm_policy/KL                              0.977449
lstm_policy/KLBefore                        0.611002
lstm_policy/LossAfter                      -0.0504548
lstm_policy/LossBefore                     -0.0242625
lstm_policy/dLoss                           0.0261922
---------------------------------------  ------------
2020-09-01 14:07:03 | [drl] epoch #13 | Obtaining samples...
2020-09-01 14:07:03 | [drl] epoch #13 | Obtaining samples for iteration 13...
2020-09-01 14:07:10 | [drl] epoch #13 | Logging diagnostics...
2020-09-01 14:07:10 | [drl] epoch #13 | Optimizing policy...
2020-09-01 14:07:10 | [drl] epoch #13 | Computing loss before
2020-09-01 14:07:10 | [drl] epoch #13 | Computing KL before
2020-09-01 14:07:10 | [drl] epoch #13 | Optimizing
2020-09-01 14:07:10 | [drl] epoch #13 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 14:07:10 | [drl] epoch #13 | computing loss before
2020-09-01 14:07:10 | [drl] epoch #13 | computing gradient
2020-09-01 14:07:10 | [drl] epoch #13 | gradient computed
2020-09-01 14:07:10 | [drl] epoch #13 | computing descent direction
2020-09-01 14:07:11 | [drl] epoch #13 | descent direction computed
2020-09-01 14:07:11 | [drl] epoch #13 | backtrack iters: 7
2020-09-01 14:07:11 | [drl] epoch #13 | optimization finished
2020-09-01 14:07:11 | [drl] epoch #13 | Computing KL after
2020-09-01 14:07:11 | [drl] epoch #13 | Computing loss after
2020-09-01 14:07:11 | [drl] epoch #13 | Fitting baseline...
2020-09-01 14:07:11 | [drl] epoch #13 | Saving snapshot...
2020-09-01 14:07:11 | [drl] epoch #13 | Saved
2020-09-01 14:07:11 | [drl] epoch #13 | Time 117.51 s
2020-09-01 14:07:11 | [drl] epoch #13 | EpochTime 8.23 s
---------------------------------------  -------------
AverageDiscountedReturn                  -344.819
AverageReturn                            -406.279
Entropy                                     6.56478
EnvExecTime                                 1.79825
Extras/EpisodeRewardMean                 -405.918
Iteration                                  13
LinearFeatureBaseline/ExplainedVariance     0.622747
MaxReturn                                -286.011
MinReturn                                -658.447
NumTrajs                                  125
Perplexity                                709.657
PolicyExecTime                              3.95131
ProcessExecTime                             0.109068
StdReturn                                 113.904
lstm_policy/Entropy                         5.95087
lstm_policy/KL                              0.979837
lstm_policy/KLBefore                        0.887469
lstm_policy/LossAfter                      -0.033727
lstm_policy/LossBefore                     -0.00133923
lstm_policy/dLoss                           0.0323877
---------------------------------------  -------------
2020-09-01 14:07:11 | [drl] epoch #14 | Obtaining samples...
2020-09-01 14:07:11 | [drl] epoch #14 | Obtaining samples for iteration 14...
2020-09-01 14:07:18 | [drl] epoch #14 | Logging diagnostics...
2020-09-01 14:07:18 | [drl] epoch #14 | Optimizing policy...
2020-09-01 14:07:18 | [drl] epoch #14 | Computing loss before
2020-09-01 14:07:18 | [drl] epoch #14 | Computing KL before
2020-09-01 14:07:18 | [drl] epoch #14 | Optimizing
2020-09-01 14:07:18 | [drl] epoch #14 | Start CG optimization: #parameters: 19852, #inputs: 150, #subsample_inputs: 150
2020-09-01 14:07:18 | [drl] epoch #14 | computing loss before
2020-09-01 14:07:18 | [drl] epoch #14 | computing gradient
2020-09-01 14:07:18 | [drl] epoch #14 | gradient computed
2020-09-01 14:07:18 | [drl] epoch #14 | computing descent direction
2020-09-01 14:07:20 | [drl] epoch #14 | descent direction computed
2020-09-01 14:07:20 | [drl] epoch #14 | backtrack iters: 5
2020-09-01 14:07:20 | [drl] epoch #14 | optimization finished
2020-09-01 14:07:20 | [drl] epoch #14 | Computing KL after
2020-09-01 14:07:20 | [drl] epoch #14 | Computing loss after
2020-09-01 14:07:20 | [drl] epoch #14 | Fitting baseline...
2020-09-01 14:07:20 | [drl] epoch #14 | Saving snapshot...
2020-09-01 14:07:20 | [drl] epoch #14 | Saved
2020-09-01 14:07:20 | [drl] epoch #14 | Time 126.07 s
2020-09-01 14:07:20 | [drl] epoch #14 | EpochTime 8.54 s
---------------------------------------  ------------
AverageDiscountedReturn                  -307.474
AverageReturn                            -354.551
Entropy                                     6.18742
EnvExecTime                                 1.78982
Extras/EpisodeRewardMean                 -353.251
Iteration                                  14
LinearFeatureBaseline/ExplainedVariance     0.758008
MaxReturn                                -286.093
MinReturn                                -634.834
NumTrajs                                  150
Perplexity                                486.591
PolicyExecTime                              3.94709
ProcessExecTime                             0.100018
StdReturn                                  61.4128
lstm_policy/Entropy                         6.37131
lstm_policy/KL                              0.753221
lstm_policy/KLBefore                        0.386714
lstm_policy/LossAfter                       0.0377733
lstm_policy/LossBefore                      0.0626613
lstm_policy/dLoss                           0.0248879
---------------------------------------  ------------
2020-09-01 14:07:20 | [drl] epoch #15 | Obtaining samples...
2020-09-01 14:07:20 | [drl] epoch #15 | Obtaining samples for iteration 15...
2020-09-01 14:07:27 | [drl] epoch #15 | Logging diagnostics...
2020-09-01 14:07:27 | [drl] epoch #15 | Optimizing policy...
2020-09-01 14:07:27 | [drl] epoch #15 | Computing loss before
2020-09-01 14:07:27 | [drl] epoch #15 | Computing KL before
2020-09-01 14:07:27 | [drl] epoch #15 | Optimizing
2020-09-01 14:07:27 | [drl] epoch #15 | Start CG optimization: #parameters: 19852, #inputs: 136, #subsample_inputs: 136
2020-09-01 14:07:27 | [drl] epoch #15 | computing loss before
2020-09-01 14:07:27 | [drl] epoch #15 | computing gradient
2020-09-01 14:07:27 | [drl] epoch #15 | gradient computed
2020-09-01 14:07:27 | [drl] epoch #15 | computing descent direction
2020-09-01 14:07:28 | [drl] epoch #15 | descent direction computed
2020-09-01 14:07:29 | [drl] epoch #15 | backtrack iters: 8
2020-09-01 14:07:29 | [drl] epoch #15 | optimization finished
2020-09-01 14:07:29 | [drl] epoch #15 | Computing KL after
2020-09-01 14:07:29 | [drl] epoch #15 | Computing loss after
2020-09-01 14:07:29 | [drl] epoch #15 | Fitting baseline...
2020-09-01 14:07:29 | [drl] epoch #15 | Saving snapshot...
2020-09-01 14:07:29 | [drl] epoch #15 | Saved
2020-09-01 14:07:29 | [drl] epoch #15 | Time 134.71 s
2020-09-01 14:07:29 | [drl] epoch #15 | EpochTime 8.62 s
---------------------------------------  -------------
AverageDiscountedReturn                  -346.412
AverageReturn                            -405.381
Entropy                                     6.62455
EnvExecTime                                 1.81212
Extras/EpisodeRewardMean                 -411.278
Iteration                                  15
LinearFeatureBaseline/ExplainedVariance     0.638398
MaxReturn                                -307.7
MinReturn                                -664.527
NumTrajs                                  136
Perplexity                                753.364
PolicyExecTime                              3.97799
ProcessExecTime                             0.0994639
StdReturn                                  98.527
lstm_policy/Entropy                         6.05694
lstm_policy/KL                              0.92084
lstm_policy/KLBefore                        0.893137
lstm_policy/LossAfter                       0.10045
lstm_policy/LossBefore                      0.103718
lstm_policy/dLoss                           0.00326765
---------------------------------------  -------------
2020-09-01 14:07:29 | [drl] epoch #16 | Obtaining samples...
2020-09-01 14:07:29 | [drl] epoch #16 | Obtaining samples for iteration 16...
2020-09-01 14:07:35 | [drl] epoch #16 | Logging diagnostics...
2020-09-01 14:07:35 | [drl] epoch #16 | Optimizing policy...
2020-09-01 14:07:35 | [drl] epoch #16 | Computing loss before
2020-09-01 14:07:35 | [drl] epoch #16 | Computing KL before
2020-09-01 14:07:35 | [drl] epoch #16 | Optimizing
2020-09-01 14:07:35 | [drl] epoch #16 | Start CG optimization: #parameters: 19852, #inputs: 129, #subsample_inputs: 129
2020-09-01 14:07:35 | [drl] epoch #16 | computing loss before
2020-09-01 14:07:35 | [drl] epoch #16 | computing gradient
2020-09-01 14:07:35 | [drl] epoch #16 | gradient computed
2020-09-01 14:07:35 | [drl] epoch #16 | computing descent direction
2020-09-01 14:07:37 | [drl] epoch #16 | descent direction computed
2020-09-01 14:07:37 | [drl] epoch #16 | backtrack iters: 9
2020-09-01 14:07:37 | [drl] epoch #16 | optimization finished
2020-09-01 14:07:37 | [drl] epoch #16 | Computing KL after
2020-09-01 14:07:37 | [drl] epoch #16 | Computing loss after
2020-09-01 14:07:37 | [drl] epoch #16 | Fitting baseline...
2020-09-01 14:07:37 | [drl] epoch #16 | Saving snapshot...
2020-09-01 14:07:37 | [drl] epoch #16 | Saved
2020-09-01 14:07:37 | [drl] epoch #16 | Time 143.06 s
2020-09-01 14:07:37 | [drl] epoch #16 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -365.681
AverageReturn                            -434.688
Entropy                                     6.27643
EnvExecTime                                 1.80535
Extras/EpisodeRewardMean                 -434.618
Iteration                                  16
LinearFeatureBaseline/ExplainedVariance     0.608925
MaxReturn                                -331.169
MinReturn                                -670.37
NumTrajs                                  129
Perplexity                                531.888
PolicyExecTime                              3.92149
ProcessExecTime                             0.099654
StdReturn                                 112.178
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              0.850576
lstm_policy/KLBefore                        0.706854
lstm_policy/LossAfter                       0.027386
lstm_policy/LossBefore                      0.0447192
lstm_policy/dLoss                           0.0173332
---------------------------------------  ------------
2020-09-01 14:07:37 | [drl] epoch #17 | Obtaining samples...
2020-09-01 14:07:37 | [drl] epoch #17 | Obtaining samples for iteration 17...
2020-09-01 14:07:44 | [drl] epoch #17 | Logging diagnostics...
2020-09-01 14:07:44 | [drl] epoch #17 | Optimizing policy...
2020-09-01 14:07:44 | [drl] epoch #17 | Computing loss before
2020-09-01 14:07:44 | [drl] epoch #17 | Computing KL before
2020-09-01 14:07:44 | [drl] epoch #17 | Optimizing
2020-09-01 14:07:44 | [drl] epoch #17 | Start CG optimization: #parameters: 19852, #inputs: 148, #subsample_inputs: 148
2020-09-01 14:07:44 | [drl] epoch #17 | computing loss before
2020-09-01 14:07:44 | [drl] epoch #17 | computing gradient
2020-09-01 14:07:44 | [drl] epoch #17 | gradient computed
2020-09-01 14:07:44 | [drl] epoch #17 | computing descent direction
2020-09-01 14:07:45 | [drl] epoch #17 | descent direction computed
2020-09-01 14:07:45 | [drl] epoch #17 | Line search condition violated. Rejecting the step!
2020-09-01 14:07:45 | [drl] epoch #17 | Violated because loss not improving
2020-09-01 14:07:45 | [drl] epoch #17 | backtrack iters: 14
2020-09-01 14:07:45 | [drl] epoch #17 | optimization finished
2020-09-01 14:07:45 | [drl] epoch #17 | Computing KL after
2020-09-01 14:07:46 | [drl] epoch #17 | Computing loss after
2020-09-01 14:07:46 | [drl] epoch #17 | Fitting baseline...
2020-09-01 14:07:46 | [drl] epoch #17 | Saving snapshot...
2020-09-01 14:07:46 | [drl] epoch #17 | Saved
2020-09-01 14:07:46 | [drl] epoch #17 | Time 151.65 s
2020-09-01 14:07:46 | [drl] epoch #17 | EpochTime 8.57 s
---------------------------------------  ------------
AverageDiscountedReturn                  -300
AverageReturn                            -342.643
Entropy                                     6.16007
EnvExecTime                                 1.80876
Extras/EpisodeRewardMean                 -344.86
Iteration                                  17
LinearFeatureBaseline/ExplainedVariance     0.848472
MaxReturn                                -287.964
MinReturn                                -614.956
NumTrajs                                  148
Perplexity                                473.463
PolicyExecTime                              3.92827
ProcessExecTime                             0.0980227
StdReturn                                  36.9472
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              0.850394
lstm_policy/KLBefore                        0.850394
lstm_policy/LossAfter                       0.101673
lstm_policy/LossBefore                      0.101673
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:07:46 | [drl] epoch #18 | Obtaining samples...
2020-09-01 14:07:46 | [drl] epoch #18 | Obtaining samples for iteration 18...
2020-09-01 14:07:52 | [drl] epoch #18 | Logging diagnostics...
2020-09-01 14:07:52 | [drl] epoch #18 | Optimizing policy...
2020-09-01 14:07:52 | [drl] epoch #18 | Computing loss before
2020-09-01 14:07:52 | [drl] epoch #18 | Computing KL before
2020-09-01 14:07:52 | [drl] epoch #18 | Optimizing
2020-09-01 14:07:52 | [drl] epoch #18 | Start CG optimization: #parameters: 19852, #inputs: 144, #subsample_inputs: 144
2020-09-01 14:07:52 | [drl] epoch #18 | computing loss before
2020-09-01 14:07:52 | [drl] epoch #18 | computing gradient
2020-09-01 14:07:52 | [drl] epoch #18 | gradient computed
2020-09-01 14:07:52 | [drl] epoch #18 | computing descent direction
2020-09-01 14:07:54 | [drl] epoch #18 | descent direction computed
2020-09-01 14:07:54 | [drl] epoch #18 | Line search condition violated. Rejecting the step!
2020-09-01 14:07:54 | [drl] epoch #18 | Violated because loss not improving
2020-09-01 14:07:54 | [drl] epoch #18 | Violated because constraint mean_kl is violated
2020-09-01 14:07:54 | [drl] epoch #18 | backtrack iters: 14
2020-09-01 14:07:54 | [drl] epoch #18 | optimization finished
2020-09-01 14:07:54 | [drl] epoch #18 | Computing KL after
2020-09-01 14:07:54 | [drl] epoch #18 | Computing loss after
2020-09-01 14:07:54 | [drl] epoch #18 | Fitting baseline...
2020-09-01 14:07:54 | [drl] epoch #18 | Saving snapshot...
2020-09-01 14:07:54 | [drl] epoch #18 | Saved
2020-09-01 14:07:54 | [drl] epoch #18 | Time 160.19 s
2020-09-01 14:07:54 | [drl] epoch #18 | EpochTime 8.52 s
---------------------------------------  ------------
AverageDiscountedReturn                  -306.184
AverageReturn                            -350.914
Entropy                                     6.18089
EnvExecTime                                 1.81334
Extras/EpisodeRewardMean                 -350.563
Iteration                                  18
LinearFeatureBaseline/ExplainedVariance     0.893849
MaxReturn                                -276.861
MinReturn                                -630.15
NumTrajs                                  144
Perplexity                                483.42
PolicyExecTime                              3.89405
ProcessExecTime                             0.0990601
StdReturn                                  42.7488
lstm_policy/Entropy                         5.75404
lstm_policy/KL                              1.00304
lstm_policy/KLBefore                        1.00304
lstm_policy/LossAfter                       0.164727
lstm_policy/LossBefore                      0.164727
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:07:54 | [drl] epoch #19 | Obtaining samples...
2020-09-01 14:07:54 | [drl] epoch #19 | Obtaining samples for iteration 19...
2020-09-01 14:08:01 | [drl] epoch #19 | Logging diagnostics...
2020-09-01 14:08:01 | [drl] epoch #19 | Optimizing policy...
2020-09-01 14:08:01 | [drl] epoch #19 | Computing loss before
2020-09-01 14:08:01 | [drl] epoch #19 | Computing KL before
2020-09-01 14:08:01 | [drl] epoch #19 | Optimizing
2020-09-01 14:08:01 | [drl] epoch #19 | Start CG optimization: #parameters: 19852, #inputs: 147, #subsample_inputs: 147
2020-09-01 14:08:01 | [drl] epoch #19 | computing loss before
2020-09-01 14:08:01 | [drl] epoch #19 | computing gradient
2020-09-01 14:08:01 | [drl] epoch #19 | gradient computed
2020-09-01 14:08:01 | [drl] epoch #19 | computing descent direction
2020-09-01 14:08:02 | [drl] epoch #19 | descent direction computed
2020-09-01 14:08:03 | [drl] epoch #19 | backtrack iters: 12
2020-09-01 14:08:03 | [drl] epoch #19 | optimization finished
2020-09-01 14:08:03 | [drl] epoch #19 | Computing KL after
2020-09-01 14:08:03 | [drl] epoch #19 | Computing loss after
2020-09-01 14:08:03 | [drl] epoch #19 | Fitting baseline...
2020-09-01 14:08:03 | [drl] epoch #19 | Saving snapshot...
2020-09-01 14:08:03 | [drl] epoch #19 | Saved
2020-09-01 14:08:03 | [drl] epoch #19 | Time 168.71 s
2020-09-01 14:08:03 | [drl] epoch #19 | EpochTime 8.50 s
---------------------------------------  ------------
AverageDiscountedReturn                  -303.182
AverageReturn                            -347.164
Entropy                                     6.15675
EnvExecTime                                 1.78292
Extras/EpisodeRewardMean                 -348.299
Iteration                                  19
LinearFeatureBaseline/ExplainedVariance     0.856599
MaxReturn                                -292.101
MinReturn                                -634.931
NumTrajs                                  147
Perplexity                                471.89
PolicyExecTime                              3.92599
ProcessExecTime                             0.107275
StdReturn                                  49.4881
lstm_policy/Entropy                         6.01543
lstm_policy/KL                              0.995135
lstm_policy/KLBefore                        0.917631
lstm_policy/LossAfter                       0.05787
lstm_policy/LossBefore                      0.111192
lstm_policy/dLoss                           0.0533217
---------------------------------------  ------------
2020-09-01 14:08:03 | [drl] epoch #20 | Obtaining samples...
2020-09-01 14:08:03 | [drl] epoch #20 | Obtaining samples for iteration 20...
2020-09-01 14:08:09 | [drl] epoch #20 | Logging diagnostics...
2020-09-01 14:08:09 | [drl] epoch #20 | Optimizing policy...
2020-09-01 14:08:09 | [drl] epoch #20 | Computing loss before
2020-09-01 14:08:09 | [drl] epoch #20 | Computing KL before
2020-09-01 14:08:09 | [drl] epoch #20 | Optimizing
2020-09-01 14:08:09 | [drl] epoch #20 | Start CG optimization: #parameters: 19852, #inputs: 147, #subsample_inputs: 147
2020-09-01 14:08:09 | [drl] epoch #20 | computing loss before
2020-09-01 14:08:09 | [drl] epoch #20 | computing gradient
2020-09-01 14:08:09 | [drl] epoch #20 | gradient computed
2020-09-01 14:08:09 | [drl] epoch #20 | computing descent direction
2020-09-01 14:08:11 | [drl] epoch #20 | descent direction computed
2020-09-01 14:08:11 | [drl] epoch #20 | backtrack iters: 8
2020-09-01 14:08:11 | [drl] epoch #20 | optimization finished
2020-09-01 14:08:11 | [drl] epoch #20 | Computing KL after
2020-09-01 14:08:11 | [drl] epoch #20 | Computing loss after
2020-09-01 14:08:11 | [drl] epoch #20 | Fitting baseline...
2020-09-01 14:08:11 | [drl] epoch #20 | Saving snapshot...
2020-09-01 14:08:11 | [drl] epoch #20 | Saved
2020-09-01 14:08:11 | [drl] epoch #20 | Time 177.19 s
2020-09-01 14:08:11 | [drl] epoch #20 | EpochTime 8.45 s
---------------------------------------  ------------
AverageDiscountedReturn                  -310.693
AverageReturn                            -357.223
Entropy                                     6.3277
EnvExecTime                                 1.79043
Extras/EpisodeRewardMean                 -358.955
Iteration                                  20
LinearFeatureBaseline/ExplainedVariance     0.808592
MaxReturn                                -277.347
MinReturn                                -639.889
NumTrajs                                  147
Perplexity                                559.869
PolicyExecTime                              3.96003
ProcessExecTime                             0.103336
StdReturn                                  57.3637
lstm_policy/Entropy                         5.80118
lstm_policy/KL                              0.932155
lstm_policy/KLBefore                        0.749848
lstm_policy/LossAfter                       0.0519498
lstm_policy/LossBefore                      0.0738656
lstm_policy/dLoss                           0.0219158
---------------------------------------  ------------
2020-09-01 14:08:11 | [drl] epoch #21 | Obtaining samples...
2020-09-01 14:08:11 | [drl] epoch #21 | Obtaining samples for iteration 21...
2020-09-01 14:08:18 | [drl] epoch #21 | Logging diagnostics...
2020-09-01 14:08:18 | [drl] epoch #21 | Optimizing policy...
2020-09-01 14:08:18 | [drl] epoch #21 | Computing loss before
2020-09-01 14:08:18 | [drl] epoch #21 | Computing KL before
2020-09-01 14:08:18 | [drl] epoch #21 | Optimizing
2020-09-01 14:08:18 | [drl] epoch #21 | Start CG optimization: #parameters: 19852, #inputs: 144, #subsample_inputs: 144
2020-09-01 14:08:18 | [drl] epoch #21 | computing loss before
2020-09-01 14:08:18 | [drl] epoch #21 | computing gradient
2020-09-01 14:08:18 | [drl] epoch #21 | gradient computed
2020-09-01 14:08:18 | [drl] epoch #21 | computing descent direction
2020-09-01 14:08:19 | [drl] epoch #21 | descent direction computed
2020-09-01 14:08:19 | [drl] epoch #21 | backtrack iters: 3
2020-09-01 14:08:19 | [drl] epoch #21 | optimization finished
2020-09-01 14:08:19 | [drl] epoch #21 | Computing KL after
2020-09-01 14:08:19 | [drl] epoch #21 | Computing loss after
2020-09-01 14:08:19 | [drl] epoch #21 | Fitting baseline...
2020-09-01 14:08:19 | [drl] epoch #21 | Saving snapshot...
2020-09-01 14:08:19 | [drl] epoch #21 | Saved
2020-09-01 14:08:19 | [drl] epoch #21 | Time 185.54 s
2020-09-01 14:08:19 | [drl] epoch #21 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -336.534
AverageReturn                            -395.969
Entropy                                     5.90747
EnvExecTime                                 1.78865
Extras/EpisodeRewardMean                 -392.681
Iteration                                  21
LinearFeatureBaseline/ExplainedVariance     0.562938
MaxReturn                                -292.75
MinReturn                                -653.053
NumTrajs                                  144
Perplexity                                367.773
PolicyExecTime                              3.92196
ProcessExecTime                             0.101483
StdReturn                                 100.487
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              0.967224
lstm_policy/KLBefore                        0.205504
lstm_policy/LossAfter                       0.0566996
lstm_policy/LossBefore                      0.0961712
lstm_policy/dLoss                           0.0394716
---------------------------------------  ------------
2020-09-01 14:08:19 | [drl] epoch #22 | Obtaining samples...
2020-09-01 14:08:19 | [drl] epoch #22 | Obtaining samples for iteration 22...
2020-09-01 14:08:26 | [drl] epoch #22 | Logging diagnostics...
2020-09-01 14:08:26 | [drl] epoch #22 | Optimizing policy...
2020-09-01 14:08:26 | [drl] epoch #22 | Computing loss before
2020-09-01 14:08:26 | [drl] epoch #22 | Computing KL before
2020-09-01 14:08:26 | [drl] epoch #22 | Optimizing
2020-09-01 14:08:26 | [drl] epoch #22 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:08:26 | [drl] epoch #22 | computing loss before
2020-09-01 14:08:26 | [drl] epoch #22 | computing gradient
2020-09-01 14:08:26 | [drl] epoch #22 | gradient computed
2020-09-01 14:08:26 | [drl] epoch #22 | computing descent direction
2020-09-01 14:08:27 | [drl] epoch #22 | descent direction computed
2020-09-01 14:08:28 | [drl] epoch #22 | Line search condition violated. Rejecting the step!
2020-09-01 14:08:28 | [drl] epoch #22 | Violated because constraint mean_kl is violated
2020-09-01 14:08:28 | [drl] epoch #22 | backtrack iters: 14
2020-09-01 14:08:28 | [drl] epoch #22 | optimization finished
2020-09-01 14:08:28 | [drl] epoch #22 | Computing KL after
2020-09-01 14:08:28 | [drl] epoch #22 | Computing loss after
2020-09-01 14:08:28 | [drl] epoch #22 | Fitting baseline...
2020-09-01 14:08:28 | [drl] epoch #22 | Saving snapshot...
2020-09-01 14:08:28 | [drl] epoch #22 | Saved
2020-09-01 14:08:28 | [drl] epoch #22 | Time 193.82 s
2020-09-01 14:08:28 | [drl] epoch #22 | EpochTime 8.26 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.373
AverageReturn                            -399.838
Entropy                                     5.99371
EnvExecTime                                 1.80806
Extras/EpisodeRewardMean                 -401.948
Iteration                                  22
LinearFeatureBaseline/ExplainedVariance     0.613215
MaxReturn                                -284.2
MinReturn                                -639.718
NumTrajs                                  119
Perplexity                                400.901
PolicyExecTime                              3.91848
ProcessExecTime                             0.101864
StdReturn                                 117.927
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.90403
lstm_policy/KLBefore                        1.90403
lstm_policy/LossAfter                       0.0146143
lstm_policy/LossBefore                      0.0146143
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:08:28 | [drl] epoch #23 | Obtaining samples...
2020-09-01 14:08:28 | [drl] epoch #23 | Obtaining samples for iteration 23...
2020-09-01 14:08:34 | [drl] epoch #23 | Logging diagnostics...
2020-09-01 14:08:34 | [drl] epoch #23 | Optimizing policy...
2020-09-01 14:08:34 | [drl] epoch #23 | Computing loss before
2020-09-01 14:08:34 | [drl] epoch #23 | Computing KL before
2020-09-01 14:08:34 | [drl] epoch #23 | Optimizing
2020-09-01 14:08:34 | [drl] epoch #23 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:08:34 | [drl] epoch #23 | computing loss before
2020-09-01 14:08:34 | [drl] epoch #23 | computing gradient
2020-09-01 14:08:34 | [drl] epoch #23 | gradient computed
2020-09-01 14:08:34 | [drl] epoch #23 | computing descent direction
2020-09-01 14:08:36 | [drl] epoch #23 | descent direction computed
2020-09-01 14:08:36 | [drl] epoch #23 | Line search condition violated. Rejecting the step!
2020-09-01 14:08:36 | [drl] epoch #23 | Violated because loss not improving
2020-09-01 14:08:36 | [drl] epoch #23 | Violated because constraint mean_kl is violated
2020-09-01 14:08:36 | [drl] epoch #23 | backtrack iters: 14
2020-09-01 14:08:36 | [drl] epoch #23 | optimization finished
2020-09-01 14:08:36 | [drl] epoch #23 | Computing KL after
2020-09-01 14:08:36 | [drl] epoch #23 | Computing loss after
2020-09-01 14:08:36 | [drl] epoch #23 | Fitting baseline...
2020-09-01 14:08:36 | [drl] epoch #23 | Saving snapshot...
2020-09-01 14:08:36 | [drl] epoch #23 | Saved
2020-09-01 14:08:36 | [drl] epoch #23 | Time 202.10 s
2020-09-01 14:08:36 | [drl] epoch #23 | EpochTime 8.26 s
---------------------------------------  ------------
AverageDiscountedReturn                  -353.635
AverageReturn                            -423.306
Entropy                                     5.91365
EnvExecTime                                 1.81007
Extras/EpisodeRewardMean                 -427.785
Iteration                                  23
LinearFeatureBaseline/ExplainedVariance     0.603544
MaxReturn                                -281.028
MinReturn                                -657.342
NumTrajs                                  117
Perplexity                                370.053
PolicyExecTime                              3.88786
ProcessExecTime                             0.10378
StdReturn                                 125.534
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.62212
lstm_policy/KLBefore                        1.62212
lstm_policy/LossAfter                      -0.0266518
lstm_policy/LossBefore                     -0.0266518
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:08:36 | [drl] epoch #24 | Obtaining samples...
2020-09-01 14:08:36 | [drl] epoch #24 | Obtaining samples for iteration 24...
2020-09-01 14:08:43 | [drl] epoch #24 | Logging diagnostics...
2020-09-01 14:08:43 | [drl] epoch #24 | Optimizing policy...
2020-09-01 14:08:43 | [drl] epoch #24 | Computing loss before
2020-09-01 14:08:43 | [drl] epoch #24 | Computing KL before
2020-09-01 14:08:43 | [drl] epoch #24 | Optimizing
2020-09-01 14:08:43 | [drl] epoch #24 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:08:43 | [drl] epoch #24 | computing loss before
2020-09-01 14:08:43 | [drl] epoch #24 | computing gradient
2020-09-01 14:08:43 | [drl] epoch #24 | gradient computed
2020-09-01 14:08:43 | [drl] epoch #24 | computing descent direction
2020-09-01 14:08:44 | [drl] epoch #24 | descent direction computed
2020-09-01 14:08:44 | [drl] epoch #24 | Line search condition violated. Rejecting the step!
2020-09-01 14:08:44 | [drl] epoch #24 | Violated because loss not improving
2020-09-01 14:08:44 | [drl] epoch #24 | Violated because constraint mean_kl is violated
2020-09-01 14:08:44 | [drl] epoch #24 | backtrack iters: 14
2020-09-01 14:08:44 | [drl] epoch #24 | optimization finished
2020-09-01 14:08:44 | [drl] epoch #24 | Computing KL after
2020-09-01 14:08:44 | [drl] epoch #24 | Computing loss after
2020-09-01 14:08:44 | [drl] epoch #24 | Fitting baseline...
2020-09-01 14:08:44 | [drl] epoch #24 | Saving snapshot...
2020-09-01 14:08:44 | [drl] epoch #24 | Saved
2020-09-01 14:08:44 | [drl] epoch #24 | Time 210.47 s
2020-09-01 14:08:44 | [drl] epoch #24 | EpochTime 8.36 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.212
AverageReturn                            -413.058
Entropy                                     5.93232
EnvExecTime                                 1.80054
Extras/EpisodeRewardMean                 -414.659
Iteration                                  24
LinearFeatureBaseline/ExplainedVariance     0.602173
MaxReturn                                -280.381
MinReturn                                -638.907
NumTrajs                                  119
Perplexity                                377.027
PolicyExecTime                              3.99476
ProcessExecTime                             0.0983045
StdReturn                                 124.056
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.68548
lstm_policy/KLBefore                        1.68548
lstm_policy/LossAfter                      -0.0364258
lstm_policy/LossBefore                     -0.0364258
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:08:44 | [drl] epoch #25 | Obtaining samples...
2020-09-01 14:08:44 | [drl] epoch #25 | Obtaining samples for iteration 25...
2020-09-01 14:08:51 | [drl] epoch #25 | Logging diagnostics...
2020-09-01 14:08:51 | [drl] epoch #25 | Optimizing policy...
2020-09-01 14:08:51 | [drl] epoch #25 | Computing loss before
2020-09-01 14:08:51 | [drl] epoch #25 | Computing KL before
2020-09-01 14:08:51 | [drl] epoch #25 | Optimizing
2020-09-01 14:08:51 | [drl] epoch #25 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:08:51 | [drl] epoch #25 | computing loss before
2020-09-01 14:08:51 | [drl] epoch #25 | computing gradient
2020-09-01 14:08:51 | [drl] epoch #25 | gradient computed
2020-09-01 14:08:51 | [drl] epoch #25 | computing descent direction
2020-09-01 14:08:52 | [drl] epoch #25 | descent direction computed
2020-09-01 14:08:53 | [drl] epoch #25 | Line search condition violated. Rejecting the step!
2020-09-01 14:08:53 | [drl] epoch #25 | Violated because constraint mean_kl is violated
2020-09-01 14:08:53 | [drl] epoch #25 | backtrack iters: 14
2020-09-01 14:08:53 | [drl] epoch #25 | optimization finished
2020-09-01 14:08:53 | [drl] epoch #25 | Computing KL after
2020-09-01 14:08:53 | [drl] epoch #25 | Computing loss after
2020-09-01 14:08:53 | [drl] epoch #25 | Fitting baseline...
2020-09-01 14:08:53 | [drl] epoch #25 | Saving snapshot...
2020-09-01 14:08:53 | [drl] epoch #25 | Saved
2020-09-01 14:08:53 | [drl] epoch #25 | Time 218.79 s
2020-09-01 14:08:53 | [drl] epoch #25 | EpochTime 8.31 s
---------------------------------------  ------------
AverageDiscountedReturn                  -330.732
AverageReturn                            -389.957
Entropy                                     6.03287
EnvExecTime                                 1.81529
Extras/EpisodeRewardMean                 -395.839
Iteration                                  25
LinearFeatureBaseline/ExplainedVariance     0.633271
MaxReturn                                -260.966
MinReturn                                -633.72
NumTrajs                                  121
Perplexity                                416.909
PolicyExecTime                              3.92962
ProcessExecTime                             0.0995235
StdReturn                                 110.402
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.03512
lstm_policy/KLBefore                        2.03512
lstm_policy/LossAfter                      -0.0370527
lstm_policy/LossBefore                     -0.0370527
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:08:53 | [drl] epoch #26 | Obtaining samples...
2020-09-01 14:08:53 | [drl] epoch #26 | Obtaining samples for iteration 26...
2020-09-01 14:08:59 | [drl] epoch #26 | Logging diagnostics...
2020-09-01 14:08:59 | [drl] epoch #26 | Optimizing policy...
2020-09-01 14:08:59 | [drl] epoch #26 | Computing loss before
2020-09-01 14:08:59 | [drl] epoch #26 | Computing KL before
2020-09-01 14:08:59 | [drl] epoch #26 | Optimizing
2020-09-01 14:08:59 | [drl] epoch #26 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:08:59 | [drl] epoch #26 | computing loss before
2020-09-01 14:08:59 | [drl] epoch #26 | computing gradient
2020-09-01 14:08:59 | [drl] epoch #26 | gradient computed
2020-09-01 14:08:59 | [drl] epoch #26 | computing descent direction
2020-09-01 14:09:01 | [drl] epoch #26 | descent direction computed
2020-09-01 14:09:01 | [drl] epoch #26 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:01 | [drl] epoch #26 | Violated because loss not improving
2020-09-01 14:09:01 | [drl] epoch #26 | Violated because constraint mean_kl is violated
2020-09-01 14:09:01 | [drl] epoch #26 | backtrack iters: 14
2020-09-01 14:09:01 | [drl] epoch #26 | optimization finished
2020-09-01 14:09:01 | [drl] epoch #26 | Computing KL after
2020-09-01 14:09:01 | [drl] epoch #26 | Computing loss after
2020-09-01 14:09:01 | [drl] epoch #26 | Fitting baseline...
2020-09-01 14:09:01 | [drl] epoch #26 | Saving snapshot...
2020-09-01 14:09:01 | [drl] epoch #26 | Saved
2020-09-01 14:09:01 | [drl] epoch #26 | Time 227.10 s
2020-09-01 14:09:01 | [drl] epoch #26 | EpochTime 8.29 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.729
AverageReturn                            -405.7
Entropy                                     5.95664
EnvExecTime                                 1.82515
Extras/EpisodeRewardMean                 -395.596
Iteration                                  26
LinearFeatureBaseline/ExplainedVariance     0.612885
MaxReturn                                -294.65
MinReturn                                -635.826
NumTrajs                                  120
Perplexity                                386.312
PolicyExecTime                              3.91659
ProcessExecTime                             0.09828
StdReturn                                 118.589
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.75639
lstm_policy/KLBefore                        1.75639
lstm_policy/LossAfter                      -0.0103209
lstm_policy/LossBefore                     -0.0103209
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:01 | [drl] epoch #27 | Obtaining samples...
2020-09-01 14:09:01 | [drl] epoch #27 | Obtaining samples for iteration 27...
2020-09-01 14:09:08 | [drl] epoch #27 | Logging diagnostics...
2020-09-01 14:09:08 | [drl] epoch #27 | Optimizing policy...
2020-09-01 14:09:08 | [drl] epoch #27 | Computing loss before
2020-09-01 14:09:08 | [drl] epoch #27 | Computing KL before
2020-09-01 14:09:08 | [drl] epoch #27 | Optimizing
2020-09-01 14:09:08 | [drl] epoch #27 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:09:08 | [drl] epoch #27 | computing loss before
2020-09-01 14:09:08 | [drl] epoch #27 | computing gradient
2020-09-01 14:09:08 | [drl] epoch #27 | gradient computed
2020-09-01 14:09:08 | [drl] epoch #27 | computing descent direction
2020-09-01 14:09:09 | [drl] epoch #27 | descent direction computed
2020-09-01 14:09:09 | [drl] epoch #27 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:09 | [drl] epoch #27 | Violated because loss not improving
2020-09-01 14:09:09 | [drl] epoch #27 | Violated because constraint mean_kl is violated
2020-09-01 14:09:09 | [drl] epoch #27 | backtrack iters: 14
2020-09-01 14:09:09 | [drl] epoch #27 | optimization finished
2020-09-01 14:09:09 | [drl] epoch #27 | Computing KL after
2020-09-01 14:09:09 | [drl] epoch #27 | Computing loss after
2020-09-01 14:09:09 | [drl] epoch #27 | Fitting baseline...
2020-09-01 14:09:09 | [drl] epoch #27 | Saving snapshot...
2020-09-01 14:09:09 | [drl] epoch #27 | Saved
2020-09-01 14:09:09 | [drl] epoch #27 | Time 235.39 s
2020-09-01 14:09:09 | [drl] epoch #27 | EpochTime 8.27 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.446
AverageReturn                            -403.899
Entropy                                     6.06686
EnvExecTime                                 1.81613
Extras/EpisodeRewardMean                 -406.537
Iteration                                  27
LinearFeatureBaseline/ExplainedVariance     0.643605
MaxReturn                                -286.519
MinReturn                                -631.526
NumTrajs                                  116
Perplexity                                431.322
PolicyExecTime                              3.94931
ProcessExecTime                             0.100994
StdReturn                                 116.103
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.1746
lstm_policy/KLBefore                        2.1746
lstm_policy/LossAfter                      -0.0364018
lstm_policy/LossBefore                     -0.0364018
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:09 | [drl] epoch #28 | Obtaining samples...
2020-09-01 14:09:09 | [drl] epoch #28 | Obtaining samples for iteration 28...
2020-09-01 14:09:16 | [drl] epoch #28 | Logging diagnostics...
2020-09-01 14:09:16 | [drl] epoch #28 | Optimizing policy...
2020-09-01 14:09:16 | [drl] epoch #28 | Computing loss before
2020-09-01 14:09:16 | [drl] epoch #28 | Computing KL before
2020-09-01 14:09:16 | [drl] epoch #28 | Optimizing
2020-09-01 14:09:16 | [drl] epoch #28 | Start CG optimization: #parameters: 19852, #inputs: 123, #subsample_inputs: 123
2020-09-01 14:09:16 | [drl] epoch #28 | computing loss before
2020-09-01 14:09:16 | [drl] epoch #28 | computing gradient
2020-09-01 14:09:16 | [drl] epoch #28 | gradient computed
2020-09-01 14:09:16 | [drl] epoch #28 | computing descent direction
2020-09-01 14:09:17 | [drl] epoch #28 | descent direction computed
2020-09-01 14:09:18 | [drl] epoch #28 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:18 | [drl] epoch #28 | Violated because constraint mean_kl is violated
2020-09-01 14:09:18 | [drl] epoch #28 | backtrack iters: 14
2020-09-01 14:09:18 | [drl] epoch #28 | optimization finished
2020-09-01 14:09:18 | [drl] epoch #28 | Computing KL after
2020-09-01 14:09:18 | [drl] epoch #28 | Computing loss after
2020-09-01 14:09:18 | [drl] epoch #28 | Fitting baseline...
2020-09-01 14:09:18 | [drl] epoch #28 | Saving snapshot...
2020-09-01 14:09:18 | [drl] epoch #28 | Saved
2020-09-01 14:09:18 | [drl] epoch #28 | Time 243.75 s
2020-09-01 14:09:18 | [drl] epoch #28 | EpochTime 8.35 s
---------------------------------------  ------------
AverageDiscountedReturn                  -325.673
AverageReturn                            -383.25
Entropy                                     6.02014
EnvExecTime                                 1.80552
Extras/EpisodeRewardMean                 -390.537
Iteration                                  28
LinearFeatureBaseline/ExplainedVariance     0.641494
MaxReturn                                -278.314
MinReturn                                -647.015
NumTrajs                                  123
Perplexity                                411.638
PolicyExecTime                              3.96342
ProcessExecTime                             0.0986309
StdReturn                                 106.837
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.98062
lstm_policy/KLBefore                        1.98062
lstm_policy/LossAfter                      -0.0134612
lstm_policy/LossBefore                     -0.0134612
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:18 | [drl] epoch #29 | Obtaining samples...
2020-09-01 14:09:18 | [drl] epoch #29 | Obtaining samples for iteration 29...
2020-09-01 14:09:24 | [drl] epoch #29 | Logging diagnostics...
2020-09-01 14:09:24 | [drl] epoch #29 | Optimizing policy...
2020-09-01 14:09:24 | [drl] epoch #29 | Computing loss before
2020-09-01 14:09:24 | [drl] epoch #29 | Computing KL before
2020-09-01 14:09:24 | [drl] epoch #29 | Optimizing
2020-09-01 14:09:24 | [drl] epoch #29 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 14:09:24 | [drl] epoch #29 | computing loss before
2020-09-01 14:09:24 | [drl] epoch #29 | computing gradient
2020-09-01 14:09:24 | [drl] epoch #29 | gradient computed
2020-09-01 14:09:24 | [drl] epoch #29 | computing descent direction
2020-09-01 14:09:26 | [drl] epoch #29 | descent direction computed
2020-09-01 14:09:26 | [drl] epoch #29 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:26 | [drl] epoch #29 | Violated because loss not improving
2020-09-01 14:09:26 | [drl] epoch #29 | Violated because constraint mean_kl is violated
2020-09-01 14:09:26 | [drl] epoch #29 | backtrack iters: 14
2020-09-01 14:09:26 | [drl] epoch #29 | optimization finished
2020-09-01 14:09:26 | [drl] epoch #29 | Computing KL after
2020-09-01 14:09:26 | [drl] epoch #29 | Computing loss after
2020-09-01 14:09:26 | [drl] epoch #29 | Fitting baseline...
2020-09-01 14:09:26 | [drl] epoch #29 | Saving snapshot...
2020-09-01 14:09:26 | [drl] epoch #29 | Saved
2020-09-01 14:09:26 | [drl] epoch #29 | Time 252.10 s
2020-09-01 14:09:26 | [drl] epoch #29 | EpochTime 8.34 s
---------------------------------------  -------------
AverageDiscountedReturn                  -336.045
AverageReturn                            -397.777
Entropy                                     5.95452
EnvExecTime                                 1.8015
Extras/EpisodeRewardMean                 -400.304
Iteration                                  29
LinearFeatureBaseline/ExplainedVariance     0.605992
MaxReturn                                -273.609
MinReturn                                -640.52
NumTrajs                                  122
Perplexity                                385.493
PolicyExecTime                              3.94604
ProcessExecTime                             0.102781
StdReturn                                 118.98
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72373
lstm_policy/KLBefore                        1.72373
lstm_policy/LossAfter                      -0.00619431
lstm_policy/LossBefore                     -0.00619431
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:09:26 | [drl] epoch #30 | Obtaining samples...
2020-09-01 14:09:26 | [drl] epoch #30 | Obtaining samples for iteration 30...
2020-09-01 14:09:33 | [drl] epoch #30 | Logging diagnostics...
2020-09-01 14:09:33 | [drl] epoch #30 | Optimizing policy...
2020-09-01 14:09:33 | [drl] epoch #30 | Computing loss before
2020-09-01 14:09:33 | [drl] epoch #30 | Computing KL before
2020-09-01 14:09:33 | [drl] epoch #30 | Optimizing
2020-09-01 14:09:33 | [drl] epoch #30 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:09:33 | [drl] epoch #30 | computing loss before
2020-09-01 14:09:33 | [drl] epoch #30 | computing gradient
2020-09-01 14:09:33 | [drl] epoch #30 | gradient computed
2020-09-01 14:09:33 | [drl] epoch #30 | computing descent direction
2020-09-01 14:09:34 | [drl] epoch #30 | descent direction computed
2020-09-01 14:09:34 | [drl] epoch #30 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:34 | [drl] epoch #30 | Violated because loss not improving
2020-09-01 14:09:34 | [drl] epoch #30 | Violated because constraint mean_kl is violated
2020-09-01 14:09:34 | [drl] epoch #30 | backtrack iters: 14
2020-09-01 14:09:34 | [drl] epoch #30 | optimization finished
2020-09-01 14:09:34 | [drl] epoch #30 | Computing KL after
2020-09-01 14:09:34 | [drl] epoch #30 | Computing loss after
2020-09-01 14:09:34 | [drl] epoch #30 | Fitting baseline...
2020-09-01 14:09:34 | [drl] epoch #30 | Saving snapshot...
2020-09-01 14:09:34 | [drl] epoch #30 | Saved
2020-09-01 14:09:34 | [drl] epoch #30 | Time 260.43 s
2020-09-01 14:09:34 | [drl] epoch #30 | EpochTime 8.31 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.771
AverageReturn                            -396.04
Entropy                                     6.06775
EnvExecTime                                 1.81217
Extras/EpisodeRewardMean                 -400.514
Iteration                                  30
LinearFeatureBaseline/ExplainedVariance     0.62761
MaxReturn                                -290.252
MinReturn                                -652.17
NumTrajs                                  117
Perplexity                                431.709
PolicyExecTime                              3.95129
ProcessExecTime                             0.103741
StdReturn                                 117.135
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.15974
lstm_policy/KLBefore                        2.15974
lstm_policy/LossAfter                      -0.0240052
lstm_policy/LossBefore                     -0.0240052
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:34 | [drl] epoch #31 | Obtaining samples...
2020-09-01 14:09:34 | [drl] epoch #31 | Obtaining samples for iteration 31...
2020-09-01 14:09:41 | [drl] epoch #31 | Logging diagnostics...
2020-09-01 14:09:41 | [drl] epoch #31 | Optimizing policy...
2020-09-01 14:09:41 | [drl] epoch #31 | Computing loss before
2020-09-01 14:09:41 | [drl] epoch #31 | Computing KL before
2020-09-01 14:09:41 | [drl] epoch #31 | Optimizing
2020-09-01 14:09:41 | [drl] epoch #31 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:09:41 | [drl] epoch #31 | computing loss before
2020-09-01 14:09:41 | [drl] epoch #31 | computing gradient
2020-09-01 14:09:41 | [drl] epoch #31 | gradient computed
2020-09-01 14:09:41 | [drl] epoch #31 | computing descent direction
2020-09-01 14:09:42 | [drl] epoch #31 | descent direction computed
2020-09-01 14:09:43 | [drl] epoch #31 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:43 | [drl] epoch #31 | Violated because loss not improving
2020-09-01 14:09:43 | [drl] epoch #31 | Violated because constraint mean_kl is violated
2020-09-01 14:09:43 | [drl] epoch #31 | backtrack iters: 14
2020-09-01 14:09:43 | [drl] epoch #31 | optimization finished
2020-09-01 14:09:43 | [drl] epoch #31 | Computing KL after
2020-09-01 14:09:43 | [drl] epoch #31 | Computing loss after
2020-09-01 14:09:43 | [drl] epoch #31 | Fitting baseline...
2020-09-01 14:09:43 | [drl] epoch #31 | Saving snapshot...
2020-09-01 14:09:43 | [drl] epoch #31 | Saved
2020-09-01 14:09:43 | [drl] epoch #31 | Time 268.73 s
2020-09-01 14:09:43 | [drl] epoch #31 | EpochTime 8.28 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.348
AverageReturn                            -414.675
Entropy                                     5.96515
EnvExecTime                                 1.83333
Extras/EpisodeRewardMean                 -413.066
Iteration                                  31
LinearFeatureBaseline/ExplainedVariance     0.605756
MaxReturn                                -287.158
MinReturn                                -632.815
NumTrajs                                  117
Perplexity                                389.611
PolicyExecTime                              3.90581
ProcessExecTime                             0.0995119
StdReturn                                 125.957
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.81451
lstm_policy/KLBefore                        1.81451
lstm_policy/LossAfter                      -0.0338582
lstm_policy/LossBefore                     -0.0338582
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:43 | [drl] epoch #32 | Obtaining samples...
2020-09-01 14:09:43 | [drl] epoch #32 | Obtaining samples for iteration 32...
2020-09-01 14:09:49 | [drl] epoch #32 | Logging diagnostics...
2020-09-01 14:09:49 | [drl] epoch #32 | Optimizing policy...
2020-09-01 14:09:49 | [drl] epoch #32 | Computing loss before
2020-09-01 14:09:49 | [drl] epoch #32 | Computing KL before
2020-09-01 14:09:49 | [drl] epoch #32 | Optimizing
2020-09-01 14:09:49 | [drl] epoch #32 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:09:49 | [drl] epoch #32 | computing loss before
2020-09-01 14:09:49 | [drl] epoch #32 | computing gradient
2020-09-01 14:09:49 | [drl] epoch #32 | gradient computed
2020-09-01 14:09:49 | [drl] epoch #32 | computing descent direction
2020-09-01 14:09:51 | [drl] epoch #32 | descent direction computed
2020-09-01 14:09:51 | [drl] epoch #32 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:51 | [drl] epoch #32 | Violated because constraint mean_kl is violated
2020-09-01 14:09:51 | [drl] epoch #32 | backtrack iters: 14
2020-09-01 14:09:51 | [drl] epoch #32 | optimization finished
2020-09-01 14:09:51 | [drl] epoch #32 | Computing KL after
2020-09-01 14:09:51 | [drl] epoch #32 | Computing loss after
2020-09-01 14:09:51 | [drl] epoch #32 | Fitting baseline...
2020-09-01 14:09:51 | [drl] epoch #32 | Saving snapshot...
2020-09-01 14:09:51 | [drl] epoch #32 | Saved
2020-09-01 14:09:51 | [drl] epoch #32 | Time 277.01 s
2020-09-01 14:09:51 | [drl] epoch #32 | EpochTime 8.26 s
---------------------------------------  -----------
AverageDiscountedReturn                  -347.217
AverageReturn                            -414.618
Entropy                                     5.99232
EnvExecTime                                 1.82909
Extras/EpisodeRewardMean                 -412.975
Iteration                                  32
LinearFeatureBaseline/ExplainedVariance     0.614426
MaxReturn                                -288.373
MinReturn                                -643.814
NumTrajs                                  116
Perplexity                                400.343
PolicyExecTime                              3.92767
ProcessExecTime                             0.101168
StdReturn                                 125.024
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.90777
lstm_policy/KLBefore                        1.90777
lstm_policy/LossAfter                      -0.047295
lstm_policy/LossBefore                     -0.047295
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 14:09:51 | [drl] epoch #33 | Obtaining samples...
2020-09-01 14:09:51 | [drl] epoch #33 | Obtaining samples for iteration 33...
2020-09-01 14:09:57 | [drl] epoch #33 | Logging diagnostics...
2020-09-01 14:09:57 | [drl] epoch #33 | Optimizing policy...
2020-09-01 14:09:57 | [drl] epoch #33 | Computing loss before
2020-09-01 14:09:57 | [drl] epoch #33 | Computing KL before
2020-09-01 14:09:57 | [drl] epoch #33 | Optimizing
2020-09-01 14:09:57 | [drl] epoch #33 | Start CG optimization: #parameters: 19852, #inputs: 114, #subsample_inputs: 114
2020-09-01 14:09:57 | [drl] epoch #33 | computing loss before
2020-09-01 14:09:57 | [drl] epoch #33 | computing gradient
2020-09-01 14:09:58 | [drl] epoch #33 | gradient computed
2020-09-01 14:09:58 | [drl] epoch #33 | computing descent direction
2020-09-01 14:09:59 | [drl] epoch #33 | descent direction computed
2020-09-01 14:09:59 | [drl] epoch #33 | Line search condition violated. Rejecting the step!
2020-09-01 14:09:59 | [drl] epoch #33 | Violated because loss not improving
2020-09-01 14:09:59 | [drl] epoch #33 | Violated because constraint mean_kl is violated
2020-09-01 14:09:59 | [drl] epoch #33 | backtrack iters: 14
2020-09-01 14:09:59 | [drl] epoch #33 | optimization finished
2020-09-01 14:09:59 | [drl] epoch #33 | Computing KL after
2020-09-01 14:09:59 | [drl] epoch #33 | Computing loss after
2020-09-01 14:09:59 | [drl] epoch #33 | Fitting baseline...
2020-09-01 14:09:59 | [drl] epoch #33 | Saving snapshot...
2020-09-01 14:09:59 | [drl] epoch #33 | Saved
2020-09-01 14:09:59 | [drl] epoch #33 | Time 285.17 s
2020-09-01 14:09:59 | [drl] epoch #33 | EpochTime 8.15 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.869
AverageReturn                            -407.895
Entropy                                     6.07052
EnvExecTime                                 1.80704
Extras/EpisodeRewardMean                 -407.891
Iteration                                  33
LinearFeatureBaseline/ExplainedVariance     0.63463
MaxReturn                                -261.907
MinReturn                                -645.825
NumTrajs                                  114
Perplexity                                432.904
PolicyExecTime                              3.9003
ProcessExecTime                             0.101189
StdReturn                                 121.773
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.18665
lstm_policy/KLBefore                        2.18665
lstm_policy/LossAfter                      -0.0482302
lstm_policy/LossBefore                     -0.0482302
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:09:59 | [drl] epoch #34 | Obtaining samples...
2020-09-01 14:09:59 | [drl] epoch #34 | Obtaining samples for iteration 34...
2020-09-01 14:10:06 | [drl] epoch #34 | Logging diagnostics...
2020-09-01 14:10:06 | [drl] epoch #34 | Optimizing policy...
2020-09-01 14:10:06 | [drl] epoch #34 | Computing loss before
2020-09-01 14:10:06 | [drl] epoch #34 | Computing KL before
2020-09-01 14:10:06 | [drl] epoch #34 | Optimizing
2020-09-01 14:10:06 | [drl] epoch #34 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 14:10:06 | [drl] epoch #34 | computing loss before
2020-09-01 14:10:06 | [drl] epoch #34 | computing gradient
2020-09-01 14:10:06 | [drl] epoch #34 | gradient computed
2020-09-01 14:10:06 | [drl] epoch #34 | computing descent direction
2020-09-01 14:10:07 | [drl] epoch #34 | descent direction computed
2020-09-01 14:10:07 | [drl] epoch #34 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:07 | [drl] epoch #34 | Violated because constraint mean_kl is violated
2020-09-01 14:10:07 | [drl] epoch #34 | backtrack iters: 14
2020-09-01 14:10:07 | [drl] epoch #34 | optimization finished
2020-09-01 14:10:07 | [drl] epoch #34 | Computing KL after
2020-09-01 14:10:07 | [drl] epoch #34 | Computing loss after
2020-09-01 14:10:07 | [drl] epoch #34 | Fitting baseline...
2020-09-01 14:10:07 | [drl] epoch #34 | Saving snapshot...
2020-09-01 14:10:07 | [drl] epoch #34 | Saved
2020-09-01 14:10:07 | [drl] epoch #34 | Time 293.36 s
2020-09-01 14:10:07 | [drl] epoch #34 | EpochTime 8.17 s
---------------------------------------  ------------
AverageDiscountedReturn                  -355.414
AverageReturn                            -426.225
Entropy                                     5.93767
EnvExecTime                                 1.78559
Extras/EpisodeRewardMean                 -420.095
Iteration                                  34
LinearFeatureBaseline/ExplainedVariance     0.606619
MaxReturn                                -284.601
MinReturn                                -645.703
NumTrajs                                  115
Perplexity                                379.05
PolicyExecTime                              3.87335
ProcessExecTime                             0.0983632
StdReturn                                 128.889
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.73935
lstm_policy/KLBefore                        1.73935
lstm_policy/LossAfter                      -0.0390593
lstm_policy/LossBefore                     -0.0390593
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:10:07 | [drl] epoch #35 | Obtaining samples...
2020-09-01 14:10:07 | [drl] epoch #35 | Obtaining samples for iteration 35...
2020-09-01 14:10:14 | [drl] epoch #35 | Logging diagnostics...
2020-09-01 14:10:14 | [drl] epoch #35 | Optimizing policy...
2020-09-01 14:10:14 | [drl] epoch #35 | Computing loss before
2020-09-01 14:10:14 | [drl] epoch #35 | Computing KL before
2020-09-01 14:10:14 | [drl] epoch #35 | Optimizing
2020-09-01 14:10:14 | [drl] epoch #35 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 14:10:14 | [drl] epoch #35 | computing loss before
2020-09-01 14:10:14 | [drl] epoch #35 | computing gradient
2020-09-01 14:10:14 | [drl] epoch #35 | gradient computed
2020-09-01 14:10:14 | [drl] epoch #35 | computing descent direction
2020-09-01 14:10:15 | [drl] epoch #35 | descent direction computed
2020-09-01 14:10:16 | [drl] epoch #35 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:16 | [drl] epoch #35 | Violated because constraint mean_kl is violated
2020-09-01 14:10:16 | [drl] epoch #35 | backtrack iters: 14
2020-09-01 14:10:16 | [drl] epoch #35 | optimization finished
2020-09-01 14:10:16 | [drl] epoch #35 | Computing KL after
2020-09-01 14:10:16 | [drl] epoch #35 | Computing loss after
2020-09-01 14:10:16 | [drl] epoch #35 | Fitting baseline...
2020-09-01 14:10:16 | [drl] epoch #35 | Saving snapshot...
2020-09-01 14:10:16 | [drl] epoch #35 | Saved
2020-09-01 14:10:16 | [drl] epoch #35 | Time 301.71 s
2020-09-01 14:10:16 | [drl] epoch #35 | EpochTime 8.34 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.968
AverageReturn                            -397.225
Entropy                                     5.97212
EnvExecTime                                 1.82016
Extras/EpisodeRewardMean                 -399.215
Iteration                                  35
LinearFeatureBaseline/ExplainedVariance     0.614993
MaxReturn                                -287.809
MinReturn                                -649.763
NumTrajs                                  122
Perplexity                                392.338
PolicyExecTime                              3.92986
ProcessExecTime                             0.102352
StdReturn                                 115.779
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76744
lstm_policy/KLBefore                        1.76744
lstm_policy/LossAfter                      -0.0443908
lstm_policy/LossBefore                     -0.0443908
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:10:16 | [drl] epoch #36 | Obtaining samples...
2020-09-01 14:10:16 | [drl] epoch #36 | Obtaining samples for iteration 36...
2020-09-01 14:10:22 | [drl] epoch #36 | Logging diagnostics...
2020-09-01 14:10:22 | [drl] epoch #36 | Optimizing policy...
2020-09-01 14:10:22 | [drl] epoch #36 | Computing loss before
2020-09-01 14:10:22 | [drl] epoch #36 | Computing KL before
2020-09-01 14:10:22 | [drl] epoch #36 | Optimizing
2020-09-01 14:10:22 | [drl] epoch #36 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:10:22 | [drl] epoch #36 | computing loss before
2020-09-01 14:10:22 | [drl] epoch #36 | computing gradient
2020-09-01 14:10:22 | [drl] epoch #36 | gradient computed
2020-09-01 14:10:22 | [drl] epoch #36 | computing descent direction
2020-09-01 14:10:24 | [drl] epoch #36 | descent direction computed
2020-09-01 14:10:24 | [drl] epoch #36 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:24 | [drl] epoch #36 | Violated because loss not improving
2020-09-01 14:10:24 | [drl] epoch #36 | Violated because constraint mean_kl is violated
2020-09-01 14:10:24 | [drl] epoch #36 | backtrack iters: 14
2020-09-01 14:10:24 | [drl] epoch #36 | optimization finished
2020-09-01 14:10:24 | [drl] epoch #36 | Computing KL after
2020-09-01 14:10:24 | [drl] epoch #36 | Computing loss after
2020-09-01 14:10:24 | [drl] epoch #36 | Fitting baseline...
2020-09-01 14:10:24 | [drl] epoch #36 | Saving snapshot...
2020-09-01 14:10:24 | [drl] epoch #36 | Saved
2020-09-01 14:10:24 | [drl] epoch #36 | Time 310.03 s
2020-09-01 14:10:24 | [drl] epoch #36 | EpochTime 8.31 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.311
AverageReturn                            -407.514
Entropy                                     5.94615
EnvExecTime                                 1.80839
Extras/EpisodeRewardMean                 -411.711
Iteration                                  36
LinearFeatureBaseline/ExplainedVariance     0.603231
MaxReturn                                -277.786
MinReturn                                -632.774
NumTrajs                                  119
Perplexity                                382.277
PolicyExecTime                              3.93405
ProcessExecTime                             0.104831
StdReturn                                 121.976
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72884
lstm_policy/KLBefore                        1.72884
lstm_policy/LossAfter                      -0.0174612
lstm_policy/LossBefore                     -0.0174612
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:10:24 | [drl] epoch #37 | Obtaining samples...
2020-09-01 14:10:24 | [drl] epoch #37 | Obtaining samples for iteration 37...
2020-09-01 14:10:31 | [drl] epoch #37 | Logging diagnostics...
2020-09-01 14:10:31 | [drl] epoch #37 | Optimizing policy...
2020-09-01 14:10:31 | [drl] epoch #37 | Computing loss before
2020-09-01 14:10:31 | [drl] epoch #37 | Computing KL before
2020-09-01 14:10:31 | [drl] epoch #37 | Optimizing
2020-09-01 14:10:31 | [drl] epoch #37 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:10:31 | [drl] epoch #37 | computing loss before
2020-09-01 14:10:31 | [drl] epoch #37 | computing gradient
2020-09-01 14:10:31 | [drl] epoch #37 | gradient computed
2020-09-01 14:10:31 | [drl] epoch #37 | computing descent direction
2020-09-01 14:10:32 | [drl] epoch #37 | descent direction computed
2020-09-01 14:10:32 | [drl] epoch #37 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:32 | [drl] epoch #37 | Violated because constraint mean_kl is violated
2020-09-01 14:10:32 | [drl] epoch #37 | backtrack iters: 14
2020-09-01 14:10:32 | [drl] epoch #37 | optimization finished
2020-09-01 14:10:32 | [drl] epoch #37 | Computing KL after
2020-09-01 14:10:32 | [drl] epoch #37 | Computing loss after
2020-09-01 14:10:32 | [drl] epoch #37 | Fitting baseline...
2020-09-01 14:10:32 | [drl] epoch #37 | Saving snapshot...
2020-09-01 14:10:32 | [drl] epoch #37 | Saved
2020-09-01 14:10:32 | [drl] epoch #37 | Time 318.45 s
2020-09-01 14:10:32 | [drl] epoch #37 | EpochTime 8.39 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.72
AverageReturn                            -404.639
Entropy                                     5.98838
EnvExecTime                                 1.83496
Extras/EpisodeRewardMean                 -404.496
Iteration                                  37
LinearFeatureBaseline/ExplainedVariance     0.616118
MaxReturn                                -282.635
MinReturn                                -656.3
NumTrajs                                  119
Perplexity                                398.768
PolicyExecTime                              4.23655
ProcessExecTime                             0.099283
StdReturn                                 120.1
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89277
lstm_policy/KLBefore                        1.89277
lstm_policy/LossAfter                      -0.0336002
lstm_policy/LossBefore                     -0.0336002
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:10:32 | [drl] epoch #38 | Obtaining samples...
2020-09-01 14:10:32 | [drl] epoch #38 | Obtaining samples for iteration 38...
2020-09-01 14:10:39 | [drl] epoch #38 | Logging diagnostics...
2020-09-01 14:10:39 | [drl] epoch #38 | Optimizing policy...
2020-09-01 14:10:39 | [drl] epoch #38 | Computing loss before
2020-09-01 14:10:39 | [drl] epoch #38 | Computing KL before
2020-09-01 14:10:39 | [drl] epoch #38 | Optimizing
2020-09-01 14:10:39 | [drl] epoch #38 | Start CG optimization: #parameters: 19852, #inputs: 124, #subsample_inputs: 124
2020-09-01 14:10:39 | [drl] epoch #38 | computing loss before
2020-09-01 14:10:39 | [drl] epoch #38 | computing gradient
2020-09-01 14:10:39 | [drl] epoch #38 | gradient computed
2020-09-01 14:10:39 | [drl] epoch #38 | computing descent direction
2020-09-01 14:10:40 | [drl] epoch #38 | descent direction computed
2020-09-01 14:10:40 | [drl] epoch #38 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:40 | [drl] epoch #38 | Violated because constraint mean_kl is violated
2020-09-01 14:10:40 | [drl] epoch #38 | backtrack iters: 14
2020-09-01 14:10:40 | [drl] epoch #38 | optimization finished
2020-09-01 14:10:40 | [drl] epoch #38 | Computing KL after
2020-09-01 14:10:40 | [drl] epoch #38 | Computing loss after
2020-09-01 14:10:40 | [drl] epoch #38 | Fitting baseline...
2020-09-01 14:10:40 | [drl] epoch #38 | Saving snapshot...
2020-09-01 14:10:40 | [drl] epoch #38 | Saved
2020-09-01 14:10:40 | [drl] epoch #38 | Time 326.55 s
2020-09-01 14:10:40 | [drl] epoch #38 | EpochTime 8.08 s
---------------------------------------  ------------
AverageDiscountedReturn                  -331.847
AverageReturn                            -392.101
Entropy                                     5.95169
EnvExecTime                                 1.78231
Extras/EpisodeRewardMean                 -388.168
Iteration                                  38
LinearFeatureBaseline/ExplainedVariance     0.61581
MaxReturn                                -287.391
MinReturn                                -632.851
NumTrajs                                  124
Perplexity                                384.403
PolicyExecTime                              3.89075
ProcessExecTime                             0.0981681
StdReturn                                 113.376
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.70022
lstm_policy/KLBefore                        1.70022
lstm_policy/LossAfter                      -0.0182654
lstm_policy/LossBefore                     -0.0182654
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:10:40 | [drl] epoch #39 | Obtaining samples...
2020-09-01 14:10:40 | [drl] epoch #39 | Obtaining samples for iteration 39...
2020-09-01 14:10:47 | [drl] epoch #39 | Logging diagnostics...
2020-09-01 14:10:47 | [drl] epoch #39 | Optimizing policy...
2020-09-01 14:10:47 | [drl] epoch #39 | Computing loss before
2020-09-01 14:10:47 | [drl] epoch #39 | Computing KL before
2020-09-01 14:10:47 | [drl] epoch #39 | Optimizing
2020-09-01 14:10:47 | [drl] epoch #39 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 14:10:47 | [drl] epoch #39 | computing loss before
2020-09-01 14:10:47 | [drl] epoch #39 | computing gradient
2020-09-01 14:10:47 | [drl] epoch #39 | gradient computed
2020-09-01 14:10:47 | [drl] epoch #39 | computing descent direction
2020-09-01 14:10:48 | [drl] epoch #39 | descent direction computed
2020-09-01 14:10:48 | [drl] epoch #39 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:48 | [drl] epoch #39 | Violated because constraint mean_kl is violated
2020-09-01 14:10:48 | [drl] epoch #39 | backtrack iters: 14
2020-09-01 14:10:48 | [drl] epoch #39 | optimization finished
2020-09-01 14:10:48 | [drl] epoch #39 | Computing KL after
2020-09-01 14:10:48 | [drl] epoch #39 | Computing loss after
2020-09-01 14:10:49 | [drl] epoch #39 | Fitting baseline...
2020-09-01 14:10:49 | [drl] epoch #39 | Saving snapshot...
2020-09-01 14:10:49 | [drl] epoch #39 | Saved
2020-09-01 14:10:49 | [drl] epoch #39 | Time 334.60 s
2020-09-01 14:10:49 | [drl] epoch #39 | EpochTime 8.05 s
---------------------------------------  -------------
AverageDiscountedReturn                  -322.18
AverageReturn                            -378.069
Entropy                                     6.01732
EnvExecTime                                 1.78338
Extras/EpisodeRewardMean                 -381.902
Iteration                                  39
LinearFeatureBaseline/ExplainedVariance     0.63799
MaxReturn                                -270.837
MinReturn                                -639.872
NumTrajs                                  125
Perplexity                                410.476
PolicyExecTime                              3.86608
ProcessExecTime                             0.101693
StdReturn                                 105.817
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.92595
lstm_policy/KLBefore                        1.92595
lstm_policy/LossAfter                      -0.00808852
lstm_policy/LossBefore                     -0.00808852
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:10:49 | [drl] epoch #40 | Obtaining samples...
2020-09-01 14:10:49 | [drl] epoch #40 | Obtaining samples for iteration 40...
2020-09-01 14:10:55 | [drl] epoch #40 | Logging diagnostics...
2020-09-01 14:10:55 | [drl] epoch #40 | Optimizing policy...
2020-09-01 14:10:55 | [drl] epoch #40 | Computing loss before
2020-09-01 14:10:55 | [drl] epoch #40 | Computing KL before
2020-09-01 14:10:55 | [drl] epoch #40 | Optimizing
2020-09-01 14:10:55 | [drl] epoch #40 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:10:55 | [drl] epoch #40 | computing loss before
2020-09-01 14:10:55 | [drl] epoch #40 | computing gradient
2020-09-01 14:10:55 | [drl] epoch #40 | gradient computed
2020-09-01 14:10:55 | [drl] epoch #40 | computing descent direction
2020-09-01 14:10:56 | [drl] epoch #40 | descent direction computed
2020-09-01 14:10:57 | [drl] epoch #40 | Line search condition violated. Rejecting the step!
2020-09-01 14:10:57 | [drl] epoch #40 | Violated because constraint mean_kl is violated
2020-09-01 14:10:57 | [drl] epoch #40 | backtrack iters: 14
2020-09-01 14:10:57 | [drl] epoch #40 | optimization finished
2020-09-01 14:10:57 | [drl] epoch #40 | Computing KL after
2020-09-01 14:10:57 | [drl] epoch #40 | Computing loss after
2020-09-01 14:10:57 | [drl] epoch #40 | Fitting baseline...
2020-09-01 14:10:57 | [drl] epoch #40 | Saving snapshot...
2020-09-01 14:10:57 | [drl] epoch #40 | Saved
2020-09-01 14:10:57 | [drl] epoch #40 | Time 342.63 s
2020-09-01 14:10:57 | [drl] epoch #40 | EpochTime 8.01 s
---------------------------------------  -------------
AverageDiscountedReturn                  -340.234
AverageReturn                            -403.233
Entropy                                     5.96547
EnvExecTime                                 1.77211
Extras/EpisodeRewardMean                 -397.799
Iteration                                  40
LinearFeatureBaseline/ExplainedVariance     0.634293
MaxReturn                                -275.647
MinReturn                                -632.617
NumTrajs                                  121
Perplexity                                389.736
PolicyExecTime                              3.8513
ProcessExecTime                             0.0989559
StdReturn                                 111.809
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80725
lstm_policy/KLBefore                        1.80725
lstm_policy/LossAfter                      -0.00563933
lstm_policy/LossBefore                     -0.00563933
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:10:57 | [drl] epoch #41 | Obtaining samples...
2020-09-01 14:10:57 | [drl] epoch #41 | Obtaining samples for iteration 41...
2020-09-01 14:11:03 | [drl] epoch #41 | Logging diagnostics...
2020-09-01 14:11:03 | [drl] epoch #41 | Optimizing policy...
2020-09-01 14:11:03 | [drl] epoch #41 | Computing loss before
2020-09-01 14:11:03 | [drl] epoch #41 | Computing KL before
2020-09-01 14:11:03 | [drl] epoch #41 | Optimizing
2020-09-01 14:11:03 | [drl] epoch #41 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:11:03 | [drl] epoch #41 | computing loss before
2020-09-01 14:11:03 | [drl] epoch #41 | computing gradient
2020-09-01 14:11:03 | [drl] epoch #41 | gradient computed
2020-09-01 14:11:03 | [drl] epoch #41 | computing descent direction
2020-09-01 14:11:04 | [drl] epoch #41 | descent direction computed
2020-09-01 14:11:05 | [drl] epoch #41 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:05 | [drl] epoch #41 | Violated because constraint mean_kl is violated
2020-09-01 14:11:05 | [drl] epoch #41 | backtrack iters: 14
2020-09-01 14:11:05 | [drl] epoch #41 | optimization finished
2020-09-01 14:11:05 | [drl] epoch #41 | Computing KL after
2020-09-01 14:11:05 | [drl] epoch #41 | Computing loss after
2020-09-01 14:11:05 | [drl] epoch #41 | Fitting baseline...
2020-09-01 14:11:05 | [drl] epoch #41 | Saving snapshot...
2020-09-01 14:11:05 | [drl] epoch #41 | Saved
2020-09-01 14:11:05 | [drl] epoch #41 | Time 350.62 s
2020-09-01 14:11:05 | [drl] epoch #41 | EpochTime 7.99 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.112
AverageReturn                            -399.359
Entropy                                     5.97869
EnvExecTime                                 1.77227
Extras/EpisodeRewardMean                 -395.599
Iteration                                  41
LinearFeatureBaseline/ExplainedVariance     0.621892
MaxReturn                                -274.328
MinReturn                                -629.941
NumTrajs                                  121
Perplexity                                394.923
PolicyExecTime                              3.83772
ProcessExecTime                             0.0978079
StdReturn                                 116.133
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80895
lstm_policy/KLBefore                        1.80895
lstm_policy/LossAfter                      -0.0154086
lstm_policy/LossBefore                     -0.0154086
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:05 | [drl] epoch #42 | Obtaining samples...
2020-09-01 14:11:05 | [drl] epoch #42 | Obtaining samples for iteration 42...
2020-09-01 14:11:11 | [drl] epoch #42 | Logging diagnostics...
2020-09-01 14:11:11 | [drl] epoch #42 | Optimizing policy...
2020-09-01 14:11:11 | [drl] epoch #42 | Computing loss before
2020-09-01 14:11:11 | [drl] epoch #42 | Computing KL before
2020-09-01 14:11:11 | [drl] epoch #42 | Optimizing
2020-09-01 14:11:11 | [drl] epoch #42 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:11:11 | [drl] epoch #42 | computing loss before
2020-09-01 14:11:11 | [drl] epoch #42 | computing gradient
2020-09-01 14:11:11 | [drl] epoch #42 | gradient computed
2020-09-01 14:11:11 | [drl] epoch #42 | computing descent direction
2020-09-01 14:11:12 | [drl] epoch #42 | descent direction computed
2020-09-01 14:11:12 | [drl] epoch #42 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:12 | [drl] epoch #42 | Violated because constraint mean_kl is violated
2020-09-01 14:11:12 | [drl] epoch #42 | backtrack iters: 14
2020-09-01 14:11:12 | [drl] epoch #42 | optimization finished
2020-09-01 14:11:12 | [drl] epoch #42 | Computing KL after
2020-09-01 14:11:12 | [drl] epoch #42 | Computing loss after
2020-09-01 14:11:12 | [drl] epoch #42 | Fitting baseline...
2020-09-01 14:11:12 | [drl] epoch #42 | Saving snapshot...
2020-09-01 14:11:12 | [drl] epoch #42 | Saved
2020-09-01 14:11:12 | [drl] epoch #42 | Time 358.52 s
2020-09-01 14:11:12 | [drl] epoch #42 | EpochTime 7.89 s
---------------------------------------  ------------
AverageDiscountedReturn                  -330.703
AverageReturn                            -390.255
Entropy                                     6.10578
EnvExecTime                                 1.76081
Extras/EpisodeRewardMean                 -393.763
Iteration                                  42
LinearFeatureBaseline/ExplainedVariance     0.654202
MaxReturn                                -286.625
MinReturn                                -631.566
NumTrajs                                  116
Perplexity                                448.441
PolicyExecTime                              3.82885
ProcessExecTime                             0.0986993
StdReturn                                 109.802
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.30613
lstm_policy/KLBefore                        2.30613
lstm_policy/LossAfter                      -0.0287651
lstm_policy/LossBefore                     -0.0287651
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:12 | [drl] epoch #43 | Obtaining samples...
2020-09-01 14:11:12 | [drl] epoch #43 | Obtaining samples for iteration 43...
2020-09-01 14:11:19 | [drl] epoch #43 | Logging diagnostics...
2020-09-01 14:11:19 | [drl] epoch #43 | Optimizing policy...
2020-09-01 14:11:19 | [drl] epoch #43 | Computing loss before
2020-09-01 14:11:19 | [drl] epoch #43 | Computing KL before
2020-09-01 14:11:19 | [drl] epoch #43 | Optimizing
2020-09-01 14:11:19 | [drl] epoch #43 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:11:19 | [drl] epoch #43 | computing loss before
2020-09-01 14:11:19 | [drl] epoch #43 | computing gradient
2020-09-01 14:11:19 | [drl] epoch #43 | gradient computed
2020-09-01 14:11:19 | [drl] epoch #43 | computing descent direction
2020-09-01 14:11:20 | [drl] epoch #43 | descent direction computed
2020-09-01 14:11:20 | [drl] epoch #43 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:20 | [drl] epoch #43 | Violated because constraint mean_kl is violated
2020-09-01 14:11:20 | [drl] epoch #43 | backtrack iters: 14
2020-09-01 14:11:20 | [drl] epoch #43 | optimization finished
2020-09-01 14:11:20 | [drl] epoch #43 | Computing KL after
2020-09-01 14:11:20 | [drl] epoch #43 | Computing loss after
2020-09-01 14:11:20 | [drl] epoch #43 | Fitting baseline...
2020-09-01 14:11:21 | [drl] epoch #43 | Saving snapshot...
2020-09-01 14:11:21 | [drl] epoch #43 | Saved
2020-09-01 14:11:21 | [drl] epoch #43 | Time 366.59 s
2020-09-01 14:11:21 | [drl] epoch #43 | EpochTime 8.05 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.635
AverageReturn                            -400.443
Entropy                                     5.96095
EnvExecTime                                 1.77417
Extras/EpisodeRewardMean                 -396.854
Iteration                                  43
LinearFeatureBaseline/ExplainedVariance     0.61591
MaxReturn                                -287.586
MinReturn                                -639.309
NumTrajs                                  121
Perplexity                                387.978
PolicyExecTime                              3.87815
ProcessExecTime                             0.100239
StdReturn                                 117.415
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.77469
lstm_policy/KLBefore                        1.77469
lstm_policy/LossAfter                      -0.0121677
lstm_policy/LossBefore                     -0.0121677
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:21 | [drl] epoch #44 | Obtaining samples...
2020-09-01 14:11:21 | [drl] epoch #44 | Obtaining samples for iteration 44...
2020-09-01 14:11:27 | [drl] epoch #44 | Logging diagnostics...
2020-09-01 14:11:27 | [drl] epoch #44 | Optimizing policy...
2020-09-01 14:11:27 | [drl] epoch #44 | Computing loss before
2020-09-01 14:11:27 | [drl] epoch #44 | Computing KL before
2020-09-01 14:11:27 | [drl] epoch #44 | Optimizing
2020-09-01 14:11:27 | [drl] epoch #44 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:11:27 | [drl] epoch #44 | computing loss before
2020-09-01 14:11:27 | [drl] epoch #44 | computing gradient
2020-09-01 14:11:27 | [drl] epoch #44 | gradient computed
2020-09-01 14:11:27 | [drl] epoch #44 | computing descent direction
2020-09-01 14:11:28 | [drl] epoch #44 | descent direction computed
2020-09-01 14:11:28 | [drl] epoch #44 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:28 | [drl] epoch #44 | Violated because constraint mean_kl is violated
2020-09-01 14:11:28 | [drl] epoch #44 | backtrack iters: 14
2020-09-01 14:11:28 | [drl] epoch #44 | optimization finished
2020-09-01 14:11:28 | [drl] epoch #44 | Computing KL after
2020-09-01 14:11:28 | [drl] epoch #44 | Computing loss after
2020-09-01 14:11:28 | [drl] epoch #44 | Fitting baseline...
2020-09-01 14:11:28 | [drl] epoch #44 | Saving snapshot...
2020-09-01 14:11:28 | [drl] epoch #44 | Saved
2020-09-01 14:11:28 | [drl] epoch #44 | Time 374.53 s
2020-09-01 14:11:28 | [drl] epoch #44 | EpochTime 7.93 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.861
AverageReturn                            -398.262
Entropy                                     6.01798
EnvExecTime                                 1.76829
Extras/EpisodeRewardMean                 -398.521
Iteration                                  44
LinearFeatureBaseline/ExplainedVariance     0.621816
MaxReturn                                -287.748
MinReturn                                -633.202
NumTrajs                                  118
Perplexity                                410.748
PolicyExecTime                              3.81961
ProcessExecTime                             0.0973842
StdReturn                                 117.89
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97492
lstm_policy/KLBefore                        1.97492
lstm_policy/LossAfter                      -0.0293443
lstm_policy/LossBefore                     -0.0293443
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:28 | [drl] epoch #45 | Obtaining samples...
2020-09-01 14:11:28 | [drl] epoch #45 | Obtaining samples for iteration 45...
2020-09-01 14:11:35 | [drl] epoch #45 | Logging diagnostics...
2020-09-01 14:11:35 | [drl] epoch #45 | Optimizing policy...
2020-09-01 14:11:35 | [drl] epoch #45 | Computing loss before
2020-09-01 14:11:35 | [drl] epoch #45 | Computing KL before
2020-09-01 14:11:35 | [drl] epoch #45 | Optimizing
2020-09-01 14:11:35 | [drl] epoch #45 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:11:35 | [drl] epoch #45 | computing loss before
2020-09-01 14:11:35 | [drl] epoch #45 | computing gradient
2020-09-01 14:11:35 | [drl] epoch #45 | gradient computed
2020-09-01 14:11:35 | [drl] epoch #45 | computing descent direction
2020-09-01 14:11:36 | [drl] epoch #45 | descent direction computed
2020-09-01 14:11:36 | [drl] epoch #45 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:36 | [drl] epoch #45 | Violated because loss not improving
2020-09-01 14:11:36 | [drl] epoch #45 | Violated because constraint mean_kl is violated
2020-09-01 14:11:36 | [drl] epoch #45 | backtrack iters: 14
2020-09-01 14:11:36 | [drl] epoch #45 | optimization finished
2020-09-01 14:11:36 | [drl] epoch #45 | Computing KL after
2020-09-01 14:11:36 | [drl] epoch #45 | Computing loss after
2020-09-01 14:11:36 | [drl] epoch #45 | Fitting baseline...
2020-09-01 14:11:36 | [drl] epoch #45 | Saving snapshot...
2020-09-01 14:11:36 | [drl] epoch #45 | Saved
2020-09-01 14:11:36 | [drl] epoch #45 | Time 382.57 s
2020-09-01 14:11:36 | [drl] epoch #45 | EpochTime 8.03 s
---------------------------------------  ------------
AverageDiscountedReturn                  -354.064
AverageReturn                            -423.599
Entropy                                     5.84706
EnvExecTime                                 1.78659
Extras/EpisodeRewardMean                 -438.761
Iteration                                  45
LinearFeatureBaseline/ExplainedVariance     0.586084
MaxReturn                                -285.45
MinReturn                                -644.593
NumTrajs                                  120
Perplexity                                346.216
PolicyExecTime                              3.85654
ProcessExecTime                             0.10272
StdReturn                                 126.111
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.38682
lstm_policy/KLBefore                        1.38682
lstm_policy/LossAfter                      -0.0164294
lstm_policy/LossBefore                     -0.0164294
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:37 | [drl] epoch #46 | Obtaining samples...
2020-09-01 14:11:37 | [drl] epoch #46 | Obtaining samples for iteration 46...
2020-09-01 14:11:43 | [drl] epoch #46 | Logging diagnostics...
2020-09-01 14:11:43 | [drl] epoch #46 | Optimizing policy...
2020-09-01 14:11:43 | [drl] epoch #46 | Computing loss before
2020-09-01 14:11:43 | [drl] epoch #46 | Computing KL before
2020-09-01 14:11:43 | [drl] epoch #46 | Optimizing
2020-09-01 14:11:43 | [drl] epoch #46 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:11:43 | [drl] epoch #46 | computing loss before
2020-09-01 14:11:43 | [drl] epoch #46 | computing gradient
2020-09-01 14:11:43 | [drl] epoch #46 | gradient computed
2020-09-01 14:11:43 | [drl] epoch #46 | computing descent direction
2020-09-01 14:11:44 | [drl] epoch #46 | descent direction computed
2020-09-01 14:11:44 | [drl] epoch #46 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:44 | [drl] epoch #46 | Violated because loss not improving
2020-09-01 14:11:44 | [drl] epoch #46 | Violated because constraint mean_kl is violated
2020-09-01 14:11:44 | [drl] epoch #46 | backtrack iters: 14
2020-09-01 14:11:44 | [drl] epoch #46 | optimization finished
2020-09-01 14:11:44 | [drl] epoch #46 | Computing KL after
2020-09-01 14:11:44 | [drl] epoch #46 | Computing loss after
2020-09-01 14:11:44 | [drl] epoch #46 | Fitting baseline...
2020-09-01 14:11:44 | [drl] epoch #46 | Saving snapshot...
2020-09-01 14:11:44 | [drl] epoch #46 | Saved
2020-09-01 14:11:44 | [drl] epoch #46 | Time 390.55 s
2020-09-01 14:11:44 | [drl] epoch #46 | EpochTime 7.97 s
---------------------------------------  ------------
AverageDiscountedReturn                  -357.693
AverageReturn                            -429.906
Entropy                                     5.82972
EnvExecTime                                 1.75269
Extras/EpisodeRewardMean                 -428.634
Iteration                                  46
LinearFeatureBaseline/ExplainedVariance     0.569317
MaxReturn                                -273.061
MinReturn                                -639.769
NumTrajs                                  119
Perplexity                                340.265
PolicyExecTime                              3.82058
ProcessExecTime                             0.0995607
StdReturn                                 134.473
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.29126
lstm_policy/KLBefore                        1.29126
lstm_policy/LossAfter                      -0.0307318
lstm_policy/LossBefore                     -0.0307318
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:44 | [drl] epoch #47 | Obtaining samples...
2020-09-01 14:11:44 | [drl] epoch #47 | Obtaining samples for iteration 47...
2020-09-01 14:11:51 | [drl] epoch #47 | Logging diagnostics...
2020-09-01 14:11:51 | [drl] epoch #47 | Optimizing policy...
2020-09-01 14:11:51 | [drl] epoch #47 | Computing loss before
2020-09-01 14:11:51 | [drl] epoch #47 | Computing KL before
2020-09-01 14:11:51 | [drl] epoch #47 | Optimizing
2020-09-01 14:11:51 | [drl] epoch #47 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:11:51 | [drl] epoch #47 | computing loss before
2020-09-01 14:11:51 | [drl] epoch #47 | computing gradient
2020-09-01 14:11:51 | [drl] epoch #47 | gradient computed
2020-09-01 14:11:51 | [drl] epoch #47 | computing descent direction
2020-09-01 14:11:52 | [drl] epoch #47 | descent direction computed
2020-09-01 14:11:52 | [drl] epoch #47 | Line search condition violated. Rejecting the step!
2020-09-01 14:11:52 | [drl] epoch #47 | Violated because constraint mean_kl is violated
2020-09-01 14:11:52 | [drl] epoch #47 | backtrack iters: 14
2020-09-01 14:11:52 | [drl] epoch #47 | optimization finished
2020-09-01 14:11:52 | [drl] epoch #47 | Computing KL after
2020-09-01 14:11:52 | [drl] epoch #47 | Computing loss after
2020-09-01 14:11:52 | [drl] epoch #47 | Fitting baseline...
2020-09-01 14:11:52 | [drl] epoch #47 | Saving snapshot...
2020-09-01 14:11:52 | [drl] epoch #47 | Saved
2020-09-01 14:11:52 | [drl] epoch #47 | Time 398.50 s
2020-09-01 14:11:52 | [drl] epoch #47 | EpochTime 7.94 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.853
AverageReturn                            -406.908
Entropy                                     5.97296
EnvExecTime                                 1.78028
Extras/EpisodeRewardMean                 -412.494
Iteration                                  47
LinearFeatureBaseline/ExplainedVariance     0.60831
MaxReturn                                -282.151
MinReturn                                -647.964
NumTrajs                                  118
Perplexity                                392.668
PolicyExecTime                              3.82823
ProcessExecTime                             0.097487
StdReturn                                 121.089
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.81739
lstm_policy/KLBefore                        1.81739
lstm_policy/LossAfter                      -0.0510041
lstm_policy/LossBefore                     -0.0510041
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:11:52 | [drl] epoch #48 | Obtaining samples...
2020-09-01 14:11:52 | [drl] epoch #48 | Obtaining samples for iteration 48...
2020-09-01 14:11:59 | [drl] epoch #48 | Logging diagnostics...
2020-09-01 14:11:59 | [drl] epoch #48 | Optimizing policy...
2020-09-01 14:11:59 | [drl] epoch #48 | Computing loss before
2020-09-01 14:11:59 | [drl] epoch #48 | Computing KL before
2020-09-01 14:11:59 | [drl] epoch #48 | Optimizing
2020-09-01 14:11:59 | [drl] epoch #48 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:11:59 | [drl] epoch #48 | computing loss before
2020-09-01 14:11:59 | [drl] epoch #48 | computing gradient
2020-09-01 14:11:59 | [drl] epoch #48 | gradient computed
2020-09-01 14:11:59 | [drl] epoch #48 | computing descent direction
2020-09-01 14:12:00 | [drl] epoch #48 | descent direction computed
2020-09-01 14:12:00 | [drl] epoch #48 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:00 | [drl] epoch #48 | Violated because constraint mean_kl is violated
2020-09-01 14:12:00 | [drl] epoch #48 | backtrack iters: 14
2020-09-01 14:12:00 | [drl] epoch #48 | optimization finished
2020-09-01 14:12:00 | [drl] epoch #48 | Computing KL after
2020-09-01 14:12:00 | [drl] epoch #48 | Computing loss after
2020-09-01 14:12:00 | [drl] epoch #48 | Fitting baseline...
2020-09-01 14:12:00 | [drl] epoch #48 | Saving snapshot...
2020-09-01 14:12:00 | [drl] epoch #48 | Saved
2020-09-01 14:12:00 | [drl] epoch #48 | Time 406.48 s
2020-09-01 14:12:00 | [drl] epoch #48 | EpochTime 7.97 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.112
AverageReturn                            -396.427
Entropy                                     6.10393
EnvExecTime                                 1.77339
Extras/EpisodeRewardMean                 -397.76
Iteration                                  48
LinearFeatureBaseline/ExplainedVariance     0.640432
MaxReturn                                -285.772
MinReturn                                -663.88
NumTrajs                                  116
Perplexity                                447.614
PolicyExecTime                              3.88063
ProcessExecTime                             0.0979044
StdReturn                                 116.253
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.33537
lstm_policy/KLBefore                        2.33537
lstm_policy/LossAfter                      -0.0370096
lstm_policy/LossBefore                     -0.0370096
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:00 | [drl] epoch #49 | Obtaining samples...
2020-09-01 14:12:00 | [drl] epoch #49 | Obtaining samples for iteration 49...
2020-09-01 14:12:07 | [drl] epoch #49 | Logging diagnostics...
2020-09-01 14:12:07 | [drl] epoch #49 | Optimizing policy...
2020-09-01 14:12:07 | [drl] epoch #49 | Computing loss before
2020-09-01 14:12:07 | [drl] epoch #49 | Computing KL before
2020-09-01 14:12:07 | [drl] epoch #49 | Optimizing
2020-09-01 14:12:07 | [drl] epoch #49 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:12:07 | [drl] epoch #49 | computing loss before
2020-09-01 14:12:07 | [drl] epoch #49 | computing gradient
2020-09-01 14:12:07 | [drl] epoch #49 | gradient computed
2020-09-01 14:12:07 | [drl] epoch #49 | computing descent direction
2020-09-01 14:12:08 | [drl] epoch #49 | descent direction computed
2020-09-01 14:12:08 | [drl] epoch #49 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:08 | [drl] epoch #49 | Violated because loss not improving
2020-09-01 14:12:08 | [drl] epoch #49 | Violated because constraint mean_kl is violated
2020-09-01 14:12:08 | [drl] epoch #49 | backtrack iters: 14
2020-09-01 14:12:08 | [drl] epoch #49 | optimization finished
2020-09-01 14:12:08 | [drl] epoch #49 | Computing KL after
2020-09-01 14:12:08 | [drl] epoch #49 | Computing loss after
2020-09-01 14:12:08 | [drl] epoch #49 | Fitting baseline...
2020-09-01 14:12:08 | [drl] epoch #49 | Saving snapshot...
2020-09-01 14:12:08 | [drl] epoch #49 | Saved
2020-09-01 14:12:08 | [drl] epoch #49 | Time 414.47 s
2020-09-01 14:12:08 | [drl] epoch #49 | EpochTime 7.98 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.166
AverageReturn                            -404.132
Entropy                                     6.01456
EnvExecTime                                 1.78663
Extras/EpisodeRewardMean                 -405.358
Iteration                                  49
LinearFeatureBaseline/ExplainedVariance     0.621684
MaxReturn                                -279.403
MinReturn                                -675.749
NumTrajs                                  118
Perplexity                                409.344
PolicyExecTime                              3.84247
ProcessExecTime                             0.097971
StdReturn                                 119.948
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97658
lstm_policy/KLBefore                        1.97658
lstm_policy/LossAfter                      -0.0229165
lstm_policy/LossBefore                     -0.0229165
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:08 | [drl] epoch #50 | Obtaining samples...
2020-09-01 14:12:08 | [drl] epoch #50 | Obtaining samples for iteration 50...
2020-09-01 14:12:15 | [drl] epoch #50 | Logging diagnostics...
2020-09-01 14:12:15 | [drl] epoch #50 | Optimizing policy...
2020-09-01 14:12:15 | [drl] epoch #50 | Computing loss before
2020-09-01 14:12:15 | [drl] epoch #50 | Computing KL before
2020-09-01 14:12:15 | [drl] epoch #50 | Optimizing
2020-09-01 14:12:15 | [drl] epoch #50 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 14:12:15 | [drl] epoch #50 | computing loss before
2020-09-01 14:12:15 | [drl] epoch #50 | computing gradient
2020-09-01 14:12:15 | [drl] epoch #50 | gradient computed
2020-09-01 14:12:15 | [drl] epoch #50 | computing descent direction
2020-09-01 14:12:16 | [drl] epoch #50 | descent direction computed
2020-09-01 14:12:16 | [drl] epoch #50 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:16 | [drl] epoch #50 | Violated because constraint mean_kl is violated
2020-09-01 14:12:16 | [drl] epoch #50 | backtrack iters: 14
2020-09-01 14:12:16 | [drl] epoch #50 | optimization finished
2020-09-01 14:12:16 | [drl] epoch #50 | Computing KL after
2020-09-01 14:12:16 | [drl] epoch #50 | Computing loss after
2020-09-01 14:12:16 | [drl] epoch #50 | Fitting baseline...
2020-09-01 14:12:16 | [drl] epoch #50 | Saving snapshot...
2020-09-01 14:12:16 | [drl] epoch #50 | Saved
2020-09-01 14:12:16 | [drl] epoch #50 | Time 422.51 s
2020-09-01 14:12:16 | [drl] epoch #50 | EpochTime 8.04 s
---------------------------------------  ------------
AverageDiscountedReturn                  -338.914
AverageReturn                            -402.079
Entropy                                     5.9354
EnvExecTime                                 1.78726
Extras/EpisodeRewardMean                 -398.402
Iteration                                  50
LinearFeatureBaseline/ExplainedVariance     0.611985
MaxReturn                                -284.879
MinReturn                                -648.39
NumTrajs                                  122
Perplexity                                378.19
PolicyExecTime                              3.85156
ProcessExecTime                             0.099304
StdReturn                                 118.254
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.66959
lstm_policy/KLBefore                        1.66959
lstm_policy/LossAfter                      -0.0257346
lstm_policy/LossBefore                     -0.0257346
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:16 | [drl] epoch #51 | Obtaining samples...
2020-09-01 14:12:16 | [drl] epoch #51 | Obtaining samples for iteration 51...
2020-09-01 14:12:23 | [drl] epoch #51 | Logging diagnostics...
2020-09-01 14:12:23 | [drl] epoch #51 | Optimizing policy...
2020-09-01 14:12:23 | [drl] epoch #51 | Computing loss before
2020-09-01 14:12:23 | [drl] epoch #51 | Computing KL before
2020-09-01 14:12:23 | [drl] epoch #51 | Optimizing
2020-09-01 14:12:23 | [drl] epoch #51 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:12:23 | [drl] epoch #51 | computing loss before
2020-09-01 14:12:23 | [drl] epoch #51 | computing gradient
2020-09-01 14:12:23 | [drl] epoch #51 | gradient computed
2020-09-01 14:12:23 | [drl] epoch #51 | computing descent direction
2020-09-01 14:12:24 | [drl] epoch #51 | descent direction computed
2020-09-01 14:12:24 | [drl] epoch #51 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:24 | [drl] epoch #51 | Violated because constraint mean_kl is violated
2020-09-01 14:12:24 | [drl] epoch #51 | backtrack iters: 14
2020-09-01 14:12:24 | [drl] epoch #51 | optimization finished
2020-09-01 14:12:24 | [drl] epoch #51 | Computing KL after
2020-09-01 14:12:24 | [drl] epoch #51 | Computing loss after
2020-09-01 14:12:24 | [drl] epoch #51 | Fitting baseline...
2020-09-01 14:12:24 | [drl] epoch #51 | Saving snapshot...
2020-09-01 14:12:24 | [drl] epoch #51 | Saved
2020-09-01 14:12:24 | [drl] epoch #51 | Time 430.47 s
2020-09-01 14:12:24 | [drl] epoch #51 | EpochTime 7.94 s
---------------------------------------  -----------
AverageDiscountedReturn                  -356.383
AverageReturn                            -427.935
Entropy                                     5.87564
EnvExecTime                                 1.75385
Extras/EpisodeRewardMean                 -422.755
Iteration                                  51
LinearFeatureBaseline/ExplainedVariance     0.598261
MaxReturn                                -286.193
MinReturn                                -636.763
NumTrajs                                  117
Perplexity                                356.253
PolicyExecTime                              3.82684
ProcessExecTime                             0.100042
StdReturn                                 127.691
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.50054
lstm_policy/KLBefore                        1.50054
lstm_policy/LossAfter                      -0.01926
lstm_policy/LossBefore                     -0.01926
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 14:12:24 | [drl] epoch #52 | Obtaining samples...
2020-09-01 14:12:24 | [drl] epoch #52 | Obtaining samples for iteration 52...
2020-09-01 14:12:31 | [drl] epoch #52 | Logging diagnostics...
2020-09-01 14:12:31 | [drl] epoch #52 | Optimizing policy...
2020-09-01 14:12:31 | [drl] epoch #52 | Computing loss before
2020-09-01 14:12:31 | [drl] epoch #52 | Computing KL before
2020-09-01 14:12:31 | [drl] epoch #52 | Optimizing
2020-09-01 14:12:31 | [drl] epoch #52 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:12:31 | [drl] epoch #52 | computing loss before
2020-09-01 14:12:31 | [drl] epoch #52 | computing gradient
2020-09-01 14:12:31 | [drl] epoch #52 | gradient computed
2020-09-01 14:12:31 | [drl] epoch #52 | computing descent direction
2020-09-01 14:12:32 | [drl] epoch #52 | descent direction computed
2020-09-01 14:12:32 | [drl] epoch #52 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:32 | [drl] epoch #52 | Violated because constraint mean_kl is violated
2020-09-01 14:12:32 | [drl] epoch #52 | backtrack iters: 14
2020-09-01 14:12:32 | [drl] epoch #52 | optimization finished
2020-09-01 14:12:32 | [drl] epoch #52 | Computing KL after
2020-09-01 14:12:32 | [drl] epoch #52 | Computing loss after
2020-09-01 14:12:32 | [drl] epoch #52 | Fitting baseline...
2020-09-01 14:12:32 | [drl] epoch #52 | Saving snapshot...
2020-09-01 14:12:32 | [drl] epoch #52 | Saved
2020-09-01 14:12:32 | [drl] epoch #52 | Time 438.47 s
2020-09-01 14:12:32 | [drl] epoch #52 | EpochTime 7.99 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.57
AverageReturn                            -400.049
Entropy                                     6.01962
EnvExecTime                                 1.79308
Extras/EpisodeRewardMean                 -404.974
Iteration                                  52
LinearFeatureBaseline/ExplainedVariance     0.614321
MaxReturn                                -269.033
MinReturn                                -665.129
NumTrajs                                  119
Perplexity                                411.424
PolicyExecTime                              3.85968
ProcessExecTime                             0.0987277
StdReturn                                 118.481
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.0094
lstm_policy/KLBefore                        2.0094
lstm_policy/LossAfter                      -0.0457859
lstm_policy/LossBefore                     -0.0457859
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:32 | [drl] epoch #53 | Obtaining samples...
2020-09-01 14:12:32 | [drl] epoch #53 | Obtaining samples for iteration 53...
2020-09-01 14:12:39 | [drl] epoch #53 | Logging diagnostics...
2020-09-01 14:12:39 | [drl] epoch #53 | Optimizing policy...
2020-09-01 14:12:39 | [drl] epoch #53 | Computing loss before
2020-09-01 14:12:39 | [drl] epoch #53 | Computing KL before
2020-09-01 14:12:39 | [drl] epoch #53 | Optimizing
2020-09-01 14:12:39 | [drl] epoch #53 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 14:12:39 | [drl] epoch #53 | computing loss before
2020-09-01 14:12:39 | [drl] epoch #53 | computing gradient
2020-09-01 14:12:39 | [drl] epoch #53 | gradient computed
2020-09-01 14:12:39 | [drl] epoch #53 | computing descent direction
2020-09-01 14:12:40 | [drl] epoch #53 | descent direction computed
2020-09-01 14:12:40 | [drl] epoch #53 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:40 | [drl] epoch #53 | Violated because constraint mean_kl is violated
2020-09-01 14:12:40 | [drl] epoch #53 | backtrack iters: 14
2020-09-01 14:12:40 | [drl] epoch #53 | optimization finished
2020-09-01 14:12:40 | [drl] epoch #53 | Computing KL after
2020-09-01 14:12:40 | [drl] epoch #53 | Computing loss after
2020-09-01 14:12:40 | [drl] epoch #53 | Fitting baseline...
2020-09-01 14:12:40 | [drl] epoch #53 | Saving snapshot...
2020-09-01 14:12:40 | [drl] epoch #53 | Saved
2020-09-01 14:12:40 | [drl] epoch #53 | Time 446.37 s
2020-09-01 14:12:40 | [drl] epoch #53 | EpochTime 7.89 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.928
AverageReturn                            -410.565
Entropy                                     6.02926
EnvExecTime                                 1.77476
Extras/EpisodeRewardMean                 -417.415
Iteration                                  53
LinearFeatureBaseline/ExplainedVariance     0.617396
MaxReturn                                -283.661
MinReturn                                -636.828
NumTrajs                                  115
Perplexity                                415.406
PolicyExecTime                              3.80466
ProcessExecTime                             0.0983355
StdReturn                                 125.1
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.00221
lstm_policy/KLBefore                        2.00221
lstm_policy/LossAfter                      -0.0411419
lstm_policy/LossBefore                     -0.0411419
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:40 | [drl] epoch #54 | Obtaining samples...
2020-09-01 14:12:40 | [drl] epoch #54 | Obtaining samples for iteration 54...
2020-09-01 14:12:47 | [drl] epoch #54 | Logging diagnostics...
2020-09-01 14:12:47 | [drl] epoch #54 | Optimizing policy...
2020-09-01 14:12:47 | [drl] epoch #54 | Computing loss before
2020-09-01 14:12:47 | [drl] epoch #54 | Computing KL before
2020-09-01 14:12:47 | [drl] epoch #54 | Optimizing
2020-09-01 14:12:47 | [drl] epoch #54 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:12:47 | [drl] epoch #54 | computing loss before
2020-09-01 14:12:47 | [drl] epoch #54 | computing gradient
2020-09-01 14:12:47 | [drl] epoch #54 | gradient computed
2020-09-01 14:12:47 | [drl] epoch #54 | computing descent direction
2020-09-01 14:12:48 | [drl] epoch #54 | descent direction computed
2020-09-01 14:12:48 | [drl] epoch #54 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:48 | [drl] epoch #54 | Violated because loss not improving
2020-09-01 14:12:48 | [drl] epoch #54 | Violated because constraint mean_kl is violated
2020-09-01 14:12:48 | [drl] epoch #54 | backtrack iters: 14
2020-09-01 14:12:48 | [drl] epoch #54 | optimization finished
2020-09-01 14:12:48 | [drl] epoch #54 | Computing KL after
2020-09-01 14:12:48 | [drl] epoch #54 | Computing loss after
2020-09-01 14:12:48 | [drl] epoch #54 | Fitting baseline...
2020-09-01 14:12:48 | [drl] epoch #54 | Saving snapshot...
2020-09-01 14:12:48 | [drl] epoch #54 | Saved
2020-09-01 14:12:48 | [drl] epoch #54 | Time 454.36 s
2020-09-01 14:12:48 | [drl] epoch #54 | EpochTime 7.98 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.297
AverageReturn                            -406.162
Entropy                                     5.99055
EnvExecTime                                 1.7833
Extras/EpisodeRewardMean                 -403.122
Iteration                                  54
LinearFeatureBaseline/ExplainedVariance     0.638505
MaxReturn                                -291.183
MinReturn                                -635.137
NumTrajs                                  119
Perplexity                                399.633
PolicyExecTime                              3.84873
ProcessExecTime                             0.100294
StdReturn                                 113.238
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89897
lstm_policy/KLBefore                        1.89897
lstm_policy/LossAfter                      -0.0322035
lstm_policy/LossBefore                     -0.0322035
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:48 | [drl] epoch #55 | Obtaining samples...
2020-09-01 14:12:48 | [drl] epoch #55 | Obtaining samples for iteration 55...
2020-09-01 14:12:55 | [drl] epoch #55 | Logging diagnostics...
2020-09-01 14:12:55 | [drl] epoch #55 | Optimizing policy...
2020-09-01 14:12:55 | [drl] epoch #55 | Computing loss before
2020-09-01 14:12:55 | [drl] epoch #55 | Computing KL before
2020-09-01 14:12:55 | [drl] epoch #55 | Optimizing
2020-09-01 14:12:55 | [drl] epoch #55 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:12:55 | [drl] epoch #55 | computing loss before
2020-09-01 14:12:55 | [drl] epoch #55 | computing gradient
2020-09-01 14:12:55 | [drl] epoch #55 | gradient computed
2020-09-01 14:12:55 | [drl] epoch #55 | computing descent direction
2020-09-01 14:12:56 | [drl] epoch #55 | descent direction computed
2020-09-01 14:12:56 | [drl] epoch #55 | Line search condition violated. Rejecting the step!
2020-09-01 14:12:56 | [drl] epoch #55 | Violated because loss not improving
2020-09-01 14:12:56 | [drl] epoch #55 | Violated because constraint mean_kl is violated
2020-09-01 14:12:56 | [drl] epoch #55 | backtrack iters: 14
2020-09-01 14:12:56 | [drl] epoch #55 | optimization finished
2020-09-01 14:12:56 | [drl] epoch #55 | Computing KL after
2020-09-01 14:12:56 | [drl] epoch #55 | Computing loss after
2020-09-01 14:12:56 | [drl] epoch #55 | Fitting baseline...
2020-09-01 14:12:56 | [drl] epoch #55 | Saving snapshot...
2020-09-01 14:12:56 | [drl] epoch #55 | Saved
2020-09-01 14:12:56 | [drl] epoch #55 | Time 462.31 s
2020-09-01 14:12:56 | [drl] epoch #55 | EpochTime 7.94 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.366
AverageReturn                            -408.144
Entropy                                     5.95554
EnvExecTime                                 1.77656
Extras/EpisodeRewardMean                 -408.205
Iteration                                  55
LinearFeatureBaseline/ExplainedVariance     0.617153
MaxReturn                                -283.407
MinReturn                                -639.985
NumTrajs                                  119
Perplexity                                385.886
PolicyExecTime                              3.81821
ProcessExecTime                             0.0981042
StdReturn                                 118.779
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76244
lstm_policy/KLBefore                        1.76244
lstm_policy/LossAfter                      -0.0198913
lstm_policy/LossBefore                     -0.0198913
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:12:56 | [drl] epoch #56 | Obtaining samples...
2020-09-01 14:12:56 | [drl] epoch #56 | Obtaining samples for iteration 56...
2020-09-01 14:13:03 | [drl] epoch #56 | Logging diagnostics...
2020-09-01 14:13:03 | [drl] epoch #56 | Optimizing policy...
2020-09-01 14:13:03 | [drl] epoch #56 | Computing loss before
2020-09-01 14:13:03 | [drl] epoch #56 | Computing KL before
2020-09-01 14:13:03 | [drl] epoch #56 | Optimizing
2020-09-01 14:13:03 | [drl] epoch #56 | Start CG optimization: #parameters: 19852, #inputs: 115, #subsample_inputs: 115
2020-09-01 14:13:03 | [drl] epoch #56 | computing loss before
2020-09-01 14:13:03 | [drl] epoch #56 | computing gradient
2020-09-01 14:13:03 | [drl] epoch #56 | gradient computed
2020-09-01 14:13:03 | [drl] epoch #56 | computing descent direction
2020-09-01 14:13:04 | [drl] epoch #56 | descent direction computed
2020-09-01 14:13:04 | [drl] epoch #56 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:04 | [drl] epoch #56 | Violated because loss not improving
2020-09-01 14:13:04 | [drl] epoch #56 | Violated because constraint mean_kl is violated
2020-09-01 14:13:04 | [drl] epoch #56 | backtrack iters: 14
2020-09-01 14:13:04 | [drl] epoch #56 | optimization finished
2020-09-01 14:13:04 | [drl] epoch #56 | Computing KL after
2020-09-01 14:13:04 | [drl] epoch #56 | Computing loss after
2020-09-01 14:13:04 | [drl] epoch #56 | Fitting baseline...
2020-09-01 14:13:04 | [drl] epoch #56 | Saving snapshot...
2020-09-01 14:13:04 | [drl] epoch #56 | Saved
2020-09-01 14:13:04 | [drl] epoch #56 | Time 470.21 s
2020-09-01 14:13:04 | [drl] epoch #56 | EpochTime 7.89 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.621
AverageReturn                            -415.863
Entropy                                     6.00786
EnvExecTime                                 1.78222
Extras/EpisodeRewardMean                 -418.363
Iteration                                  56
LinearFeatureBaseline/ExplainedVariance     0.625559
MaxReturn                                -270.671
MinReturn                                -635.084
NumTrajs                                  115
Perplexity                                406.614
PolicyExecTime                              3.82323
ProcessExecTime                             0.0980558
StdReturn                                 123.324
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97709
lstm_policy/KLBefore                        1.97709
lstm_policy/LossAfter                      -0.0305146
lstm_policy/LossBefore                     -0.0305146
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:04 | [drl] epoch #57 | Obtaining samples...
2020-09-01 14:13:04 | [drl] epoch #57 | Obtaining samples for iteration 57...
2020-09-01 14:13:11 | [drl] epoch #57 | Logging diagnostics...
2020-09-01 14:13:11 | [drl] epoch #57 | Optimizing policy...
2020-09-01 14:13:11 | [drl] epoch #57 | Computing loss before
2020-09-01 14:13:11 | [drl] epoch #57 | Computing KL before
2020-09-01 14:13:11 | [drl] epoch #57 | Optimizing
2020-09-01 14:13:11 | [drl] epoch #57 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:13:11 | [drl] epoch #57 | computing loss before
2020-09-01 14:13:11 | [drl] epoch #57 | computing gradient
2020-09-01 14:13:11 | [drl] epoch #57 | gradient computed
2020-09-01 14:13:11 | [drl] epoch #57 | computing descent direction
2020-09-01 14:13:12 | [drl] epoch #57 | descent direction computed
2020-09-01 14:13:12 | [drl] epoch #57 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:12 | [drl] epoch #57 | Violated because constraint mean_kl is violated
2020-09-01 14:13:12 | [drl] epoch #57 | backtrack iters: 14
2020-09-01 14:13:12 | [drl] epoch #57 | optimization finished
2020-09-01 14:13:12 | [drl] epoch #57 | Computing KL after
2020-09-01 14:13:12 | [drl] epoch #57 | Computing loss after
2020-09-01 14:13:12 | [drl] epoch #57 | Fitting baseline...
2020-09-01 14:13:12 | [drl] epoch #57 | Saving snapshot...
2020-09-01 14:13:12 | [drl] epoch #57 | Saved
2020-09-01 14:13:12 | [drl] epoch #57 | Time 478.22 s
2020-09-01 14:13:12 | [drl] epoch #57 | EpochTime 8.00 s
---------------------------------------  ------------
AverageDiscountedReturn                  -335.124
AverageReturn                            -396.977
Entropy                                     6.00132
EnvExecTime                                 1.79142
Extras/EpisodeRewardMean                 -395.537
Iteration                                  57
LinearFeatureBaseline/ExplainedVariance     0.62279
MaxReturn                                -274.159
MinReturn                                -641.949
NumTrajs                                  120
Perplexity                                403.961
PolicyExecTime                              3.84318
ProcessExecTime                             0.0999286
StdReturn                                 114.966
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89486
lstm_policy/KLBefore                        1.89486
lstm_policy/LossAfter                      -0.0370952
lstm_policy/LossBefore                     -0.0370952
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:12 | [drl] epoch #58 | Obtaining samples...
2020-09-01 14:13:12 | [drl] epoch #58 | Obtaining samples for iteration 58...
2020-09-01 14:13:19 | [drl] epoch #58 | Logging diagnostics...
2020-09-01 14:13:19 | [drl] epoch #58 | Optimizing policy...
2020-09-01 14:13:19 | [drl] epoch #58 | Computing loss before
2020-09-01 14:13:19 | [drl] epoch #58 | Computing KL before
2020-09-01 14:13:19 | [drl] epoch #58 | Optimizing
2020-09-01 14:13:19 | [drl] epoch #58 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:13:19 | [drl] epoch #58 | computing loss before
2020-09-01 14:13:19 | [drl] epoch #58 | computing gradient
2020-09-01 14:13:19 | [drl] epoch #58 | gradient computed
2020-09-01 14:13:19 | [drl] epoch #58 | computing descent direction
2020-09-01 14:13:20 | [drl] epoch #58 | descent direction computed
2020-09-01 14:13:20 | [drl] epoch #58 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:20 | [drl] epoch #58 | Violated because constraint mean_kl is violated
2020-09-01 14:13:20 | [drl] epoch #58 | backtrack iters: 14
2020-09-01 14:13:20 | [drl] epoch #58 | optimization finished
2020-09-01 14:13:20 | [drl] epoch #58 | Computing KL after
2020-09-01 14:13:20 | [drl] epoch #58 | Computing loss after
2020-09-01 14:13:20 | [drl] epoch #58 | Fitting baseline...
2020-09-01 14:13:20 | [drl] epoch #58 | Saving snapshot...
2020-09-01 14:13:20 | [drl] epoch #58 | Saved
2020-09-01 14:13:20 | [drl] epoch #58 | Time 486.24 s
2020-09-01 14:13:20 | [drl] epoch #58 | EpochTime 8.01 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.732
AverageReturn                            -395.662
Entropy                                     6.03373
EnvExecTime                                 1.79754
Extras/EpisodeRewardMean                 -393.978
Iteration                                  58
LinearFeatureBaseline/ExplainedVariance     0.632414
MaxReturn                                -286.061
MinReturn                                -635.278
NumTrajs                                  120
Perplexity                                417.269
PolicyExecTime                              3.85898
ProcessExecTime                             0.0988047
StdReturn                                 114.925
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.02417
lstm_policy/KLBefore                        2.02417
lstm_policy/LossAfter                      -0.0176438
lstm_policy/LossBefore                     -0.0176438
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:20 | [drl] epoch #59 | Obtaining samples...
2020-09-01 14:13:20 | [drl] epoch #59 | Obtaining samples for iteration 59...
2020-09-01 14:13:26 | [drl] epoch #59 | Logging diagnostics...
2020-09-01 14:13:26 | [drl] epoch #59 | Optimizing policy...
2020-09-01 14:13:26 | [drl] epoch #59 | Computing loss before
2020-09-01 14:13:26 | [drl] epoch #59 | Computing KL before
2020-09-01 14:13:27 | [drl] epoch #59 | Optimizing
2020-09-01 14:13:27 | [drl] epoch #59 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:13:27 | [drl] epoch #59 | computing loss before
2020-09-01 14:13:27 | [drl] epoch #59 | computing gradient
2020-09-01 14:13:27 | [drl] epoch #59 | gradient computed
2020-09-01 14:13:27 | [drl] epoch #59 | computing descent direction
2020-09-01 14:13:29 | [drl] epoch #59 | descent direction computed
2020-09-01 14:13:29 | [drl] epoch #59 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:29 | [drl] epoch #59 | Violated because loss not improving
2020-09-01 14:13:29 | [drl] epoch #59 | Violated because constraint mean_kl is violated
2020-09-01 14:13:29 | [drl] epoch #59 | backtrack iters: 14
2020-09-01 14:13:29 | [drl] epoch #59 | optimization finished
2020-09-01 14:13:29 | [drl] epoch #59 | Computing KL after
2020-09-01 14:13:29 | [drl] epoch #59 | Computing loss after
2020-09-01 14:13:29 | [drl] epoch #59 | Fitting baseline...
2020-09-01 14:13:29 | [drl] epoch #59 | Saving snapshot...
2020-09-01 14:13:29 | [drl] epoch #59 | Saved
2020-09-01 14:13:29 | [drl] epoch #59 | Time 495.27 s
2020-09-01 14:13:29 | [drl] epoch #59 | EpochTime 9.02 s
---------------------------------------  ------------
AverageDiscountedReturn                  -345.06
AverageReturn                            -410.089
Entropy                                     5.98922
EnvExecTime                                 1.77584
Extras/EpisodeRewardMean                 -409.924
Iteration                                  59
LinearFeatureBaseline/ExplainedVariance     0.623454
MaxReturn                                -282.561
MinReturn                                -639.259
NumTrajs                                  118
Perplexity                                399.105
PolicyExecTime                              3.81448
ProcessExecTime                             0.0979865
StdReturn                                 119.758
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.89246
lstm_policy/KLBefore                        1.89246
lstm_policy/LossAfter                      -0.0243163
lstm_policy/LossBefore                     -0.0243163
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:29 | [drl] epoch #60 | Obtaining samples...
2020-09-01 14:13:29 | [drl] epoch #60 | Obtaining samples for iteration 60...
2020-09-01 14:13:36 | [drl] epoch #60 | Logging diagnostics...
2020-09-01 14:13:36 | [drl] epoch #60 | Optimizing policy...
2020-09-01 14:13:36 | [drl] epoch #60 | Computing loss before
2020-09-01 14:13:36 | [drl] epoch #60 | Computing KL before
2020-09-01 14:13:36 | [drl] epoch #60 | Optimizing
2020-09-01 14:13:36 | [drl] epoch #60 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:13:36 | [drl] epoch #60 | computing loss before
2020-09-01 14:13:36 | [drl] epoch #60 | computing gradient
2020-09-01 14:13:36 | [drl] epoch #60 | gradient computed
2020-09-01 14:13:36 | [drl] epoch #60 | computing descent direction
2020-09-01 14:13:37 | [drl] epoch #60 | descent direction computed
2020-09-01 14:13:37 | [drl] epoch #60 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:37 | [drl] epoch #60 | Violated because loss not improving
2020-09-01 14:13:37 | [drl] epoch #60 | Violated because constraint mean_kl is violated
2020-09-01 14:13:37 | [drl] epoch #60 | backtrack iters: 14
2020-09-01 14:13:37 | [drl] epoch #60 | optimization finished
2020-09-01 14:13:37 | [drl] epoch #60 | Computing KL after
2020-09-01 14:13:37 | [drl] epoch #60 | Computing loss after
2020-09-01 14:13:37 | [drl] epoch #60 | Fitting baseline...
2020-09-01 14:13:37 | [drl] epoch #60 | Saving snapshot...
2020-09-01 14:13:37 | [drl] epoch #60 | Saved
2020-09-01 14:13:37 | [drl] epoch #60 | Time 503.23 s
2020-09-01 14:13:37 | [drl] epoch #60 | EpochTime 7.94 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.235
AverageReturn                            -405.294
Entropy                                     5.97018
EnvExecTime                                 1.77054
Extras/EpisodeRewardMean                 -410.621
Iteration                                  60
LinearFeatureBaseline/ExplainedVariance     0.613246
MaxReturn                                -273.262
MinReturn                                -638.824
NumTrajs                                  120
Perplexity                                391.578
PolicyExecTime                              3.85343
ProcessExecTime                             0.0990529
StdReturn                                 120.872
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82266
lstm_policy/KLBefore                        1.82266
lstm_policy/LossAfter                      -0.0260119
lstm_policy/LossBefore                     -0.0260119
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:37 | [drl] epoch #61 | Obtaining samples...
2020-09-01 14:13:37 | [drl] epoch #61 | Obtaining samples for iteration 61...
2020-09-01 14:13:44 | [drl] epoch #61 | Logging diagnostics...
2020-09-01 14:13:44 | [drl] epoch #61 | Optimizing policy...
2020-09-01 14:13:44 | [drl] epoch #61 | Computing loss before
2020-09-01 14:13:44 | [drl] epoch #61 | Computing KL before
2020-09-01 14:13:44 | [drl] epoch #61 | Optimizing
2020-09-01 14:13:44 | [drl] epoch #61 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:13:44 | [drl] epoch #61 | computing loss before
2020-09-01 14:13:44 | [drl] epoch #61 | computing gradient
2020-09-01 14:13:44 | [drl] epoch #61 | gradient computed
2020-09-01 14:13:44 | [drl] epoch #61 | computing descent direction
2020-09-01 14:13:45 | [drl] epoch #61 | descent direction computed
2020-09-01 14:13:45 | [drl] epoch #61 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:45 | [drl] epoch #61 | Violated because constraint mean_kl is violated
2020-09-01 14:13:45 | [drl] epoch #61 | backtrack iters: 14
2020-09-01 14:13:45 | [drl] epoch #61 | optimization finished
2020-09-01 14:13:45 | [drl] epoch #61 | Computing KL after
2020-09-01 14:13:45 | [drl] epoch #61 | Computing loss after
2020-09-01 14:13:45 | [drl] epoch #61 | Fitting baseline...
2020-09-01 14:13:45 | [drl] epoch #61 | Saving snapshot...
2020-09-01 14:13:45 | [drl] epoch #61 | Saved
2020-09-01 14:13:45 | [drl] epoch #61 | Time 511.29 s
2020-09-01 14:13:45 | [drl] epoch #61 | EpochTime 8.05 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.139
AverageReturn                            -412.145
Entropy                                     5.92057
EnvExecTime                                 1.76571
Extras/EpisodeRewardMean                 -414.772
Iteration                                  61
LinearFeatureBaseline/ExplainedVariance     0.606546
MaxReturn                                -284.699
MinReturn                                -658.339
NumTrajs                                  120
Perplexity                                372.624
PolicyExecTime                              3.90002
ProcessExecTime                             0.0978992
StdReturn                                 122.661
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.60589
lstm_policy/KLBefore                        1.60589
lstm_policy/LossAfter                      -0.0290075
lstm_policy/LossBefore                     -0.0290075
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:13:45 | [drl] epoch #62 | Obtaining samples...
2020-09-01 14:13:45 | [drl] epoch #62 | Obtaining samples for iteration 62...
2020-09-01 14:13:52 | [drl] epoch #62 | Logging diagnostics...
2020-09-01 14:13:52 | [drl] epoch #62 | Optimizing policy...
2020-09-01 14:13:52 | [drl] epoch #62 | Computing loss before
2020-09-01 14:13:52 | [drl] epoch #62 | Computing KL before
2020-09-01 14:13:52 | [drl] epoch #62 | Optimizing
2020-09-01 14:13:52 | [drl] epoch #62 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 14:13:52 | [drl] epoch #62 | computing loss before
2020-09-01 14:13:52 | [drl] epoch #62 | computing gradient
2020-09-01 14:13:52 | [drl] epoch #62 | gradient computed
2020-09-01 14:13:52 | [drl] epoch #62 | computing descent direction
2020-09-01 14:13:53 | [drl] epoch #62 | descent direction computed
2020-09-01 14:13:53 | [drl] epoch #62 | Line search condition violated. Rejecting the step!
2020-09-01 14:13:53 | [drl] epoch #62 | Violated because loss not improving
2020-09-01 14:13:53 | [drl] epoch #62 | Violated because constraint mean_kl is violated
2020-09-01 14:13:53 | [drl] epoch #62 | backtrack iters: 14
2020-09-01 14:13:53 | [drl] epoch #62 | optimization finished
2020-09-01 14:13:53 | [drl] epoch #62 | Computing KL after
2020-09-01 14:13:53 | [drl] epoch #62 | Computing loss after
2020-09-01 14:13:53 | [drl] epoch #62 | Fitting baseline...
2020-09-01 14:13:53 | [drl] epoch #62 | Saving snapshot...
2020-09-01 14:13:53 | [drl] epoch #62 | Saved
2020-09-01 14:13:53 | [drl] epoch #62 | Time 519.31 s
2020-09-01 14:13:53 | [drl] epoch #62 | EpochTime 8.01 s
---------------------------------------  -----------
AverageDiscountedReturn                  -340.474
AverageReturn                            -404.559
Entropy                                     5.92823
EnvExecTime                                 1.78503
Extras/EpisodeRewardMean                 -407.778
Iteration                                  62
LinearFeatureBaseline/ExplainedVariance     0.595293
MaxReturn                                -263.398
MinReturn                                -647.978
NumTrajs                                  122
Perplexity                                375.49
PolicyExecTime                              3.85042
ProcessExecTime                             0.100813
StdReturn                                 122.265
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.62525
lstm_policy/KLBefore                        1.62525
lstm_policy/LossAfter                      -0.026887
lstm_policy/LossBefore                     -0.026887
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 14:13:53 | [drl] epoch #63 | Obtaining samples...
2020-09-01 14:13:53 | [drl] epoch #63 | Obtaining samples for iteration 63...
2020-09-01 14:14:00 | [drl] epoch #63 | Logging diagnostics...
2020-09-01 14:14:00 | [drl] epoch #63 | Optimizing policy...
2020-09-01 14:14:00 | [drl] epoch #63 | Computing loss before
2020-09-01 14:14:00 | [drl] epoch #63 | Computing KL before
2020-09-01 14:14:00 | [drl] epoch #63 | Optimizing
2020-09-01 14:14:00 | [drl] epoch #63 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:14:00 | [drl] epoch #63 | computing loss before
2020-09-01 14:14:00 | [drl] epoch #63 | computing gradient
2020-09-01 14:14:00 | [drl] epoch #63 | gradient computed
2020-09-01 14:14:00 | [drl] epoch #63 | computing descent direction
2020-09-01 14:14:01 | [drl] epoch #63 | descent direction computed
2020-09-01 14:14:01 | [drl] epoch #63 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:01 | [drl] epoch #63 | Violated because loss not improving
2020-09-01 14:14:01 | [drl] epoch #63 | Violated because constraint mean_kl is violated
2020-09-01 14:14:01 | [drl] epoch #63 | backtrack iters: 14
2020-09-01 14:14:01 | [drl] epoch #63 | optimization finished
2020-09-01 14:14:01 | [drl] epoch #63 | Computing KL after
2020-09-01 14:14:01 | [drl] epoch #63 | Computing loss after
2020-09-01 14:14:01 | [drl] epoch #63 | Fitting baseline...
2020-09-01 14:14:01 | [drl] epoch #63 | Saving snapshot...
2020-09-01 14:14:01 | [drl] epoch #63 | Saved
2020-09-01 14:14:01 | [drl] epoch #63 | Time 527.30 s
2020-09-01 14:14:01 | [drl] epoch #63 | EpochTime 7.98 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.307
AverageReturn                            -404.445
Entropy                                     5.98048
EnvExecTime                                 1.77366
Extras/EpisodeRewardMean                 -405.106
Iteration                                  63
LinearFeatureBaseline/ExplainedVariance     0.613682
MaxReturn                                -266.962
MinReturn                                -616.542
NumTrajs                                  119
Perplexity                                395.632
PolicyExecTime                              3.84228
ProcessExecTime                             0.0991547
StdReturn                                 119.287
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.84012
lstm_policy/KLBefore                        1.84012
lstm_policy/LossAfter                      -0.0303438
lstm_policy/LossBefore                     -0.0303438
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:14:01 | [drl] epoch #64 | Obtaining samples...
2020-09-01 14:14:01 | [drl] epoch #64 | Obtaining samples for iteration 64...
2020-09-01 14:14:08 | [drl] epoch #64 | Logging diagnostics...
2020-09-01 14:14:08 | [drl] epoch #64 | Optimizing policy...
2020-09-01 14:14:08 | [drl] epoch #64 | Computing loss before
2020-09-01 14:14:08 | [drl] epoch #64 | Computing KL before
2020-09-01 14:14:08 | [drl] epoch #64 | Optimizing
2020-09-01 14:14:08 | [drl] epoch #64 | Start CG optimization: #parameters: 19852, #inputs: 127, #subsample_inputs: 127
2020-09-01 14:14:08 | [drl] epoch #64 | computing loss before
2020-09-01 14:14:08 | [drl] epoch #64 | computing gradient
2020-09-01 14:14:08 | [drl] epoch #64 | gradient computed
2020-09-01 14:14:08 | [drl] epoch #64 | computing descent direction
2020-09-01 14:14:09 | [drl] epoch #64 | descent direction computed
2020-09-01 14:14:09 | [drl] epoch #64 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:09 | [drl] epoch #64 | Violated because constraint mean_kl is violated
2020-09-01 14:14:09 | [drl] epoch #64 | backtrack iters: 14
2020-09-01 14:14:09 | [drl] epoch #64 | optimization finished
2020-09-01 14:14:09 | [drl] epoch #64 | Computing KL after
2020-09-01 14:14:09 | [drl] epoch #64 | Computing loss after
2020-09-01 14:14:09 | [drl] epoch #64 | Fitting baseline...
2020-09-01 14:14:09 | [drl] epoch #64 | Saving snapshot...
2020-09-01 14:14:09 | [drl] epoch #64 | Saved
2020-09-01 14:14:09 | [drl] epoch #64 | Time 535.35 s
2020-09-01 14:14:09 | [drl] epoch #64 | EpochTime 8.03 s
---------------------------------------  ------------
AverageDiscountedReturn                  -323.17
AverageReturn                            -378.534
Entropy                                     5.98817
EnvExecTime                                 1.77118
Extras/EpisodeRewardMean                 -382.79
Iteration                                  64
LinearFeatureBaseline/ExplainedVariance     0.644121
MaxReturn                                -286.909
MinReturn                                -659.077
NumTrajs                                  127
Perplexity                                398.685
PolicyExecTime                              3.83319
ProcessExecTime                             0.10024
StdReturn                                 103.319
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.86422
lstm_policy/KLBefore                        1.86422
lstm_policy/LossAfter                      -0.0109042
lstm_policy/LossBefore                     -0.0109042
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:14:09 | [drl] epoch #65 | Obtaining samples...
2020-09-01 14:14:09 | [drl] epoch #65 | Obtaining samples for iteration 65...
2020-09-01 14:14:16 | [drl] epoch #65 | Logging diagnostics...
2020-09-01 14:14:16 | [drl] epoch #65 | Optimizing policy...
2020-09-01 14:14:16 | [drl] epoch #65 | Computing loss before
2020-09-01 14:14:16 | [drl] epoch #65 | Computing KL before
2020-09-01 14:14:16 | [drl] epoch #65 | Optimizing
2020-09-01 14:14:16 | [drl] epoch #65 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:14:16 | [drl] epoch #65 | computing loss before
2020-09-01 14:14:16 | [drl] epoch #65 | computing gradient
2020-09-01 14:14:16 | [drl] epoch #65 | gradient computed
2020-09-01 14:14:16 | [drl] epoch #65 | computing descent direction
2020-09-01 14:14:17 | [drl] epoch #65 | descent direction computed
2020-09-01 14:14:17 | [drl] epoch #65 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:17 | [drl] epoch #65 | Violated because constraint mean_kl is violated
2020-09-01 14:14:17 | [drl] epoch #65 | backtrack iters: 14
2020-09-01 14:14:17 | [drl] epoch #65 | optimization finished
2020-09-01 14:14:17 | [drl] epoch #65 | Computing KL after
2020-09-01 14:14:17 | [drl] epoch #65 | Computing loss after
2020-09-01 14:14:17 | [drl] epoch #65 | Fitting baseline...
2020-09-01 14:14:17 | [drl] epoch #65 | Saving snapshot...
2020-09-01 14:14:17 | [drl] epoch #65 | Saved
2020-09-01 14:14:17 | [drl] epoch #65 | Time 543.33 s
2020-09-01 14:14:17 | [drl] epoch #65 | EpochTime 7.97 s
---------------------------------------  -------------
AverageDiscountedReturn                  -347.213
AverageReturn                            -413.895
Entropy                                     5.96904
EnvExecTime                                 1.77379
Extras/EpisodeRewardMean                 -410.916
Iteration                                  65
LinearFeatureBaseline/ExplainedVariance     0.609937
MaxReturn                                -285.766
MinReturn                                -641.269
NumTrajs                                  117
Perplexity                                391.13
PolicyExecTime                              3.82965
ProcessExecTime                             0.103343
StdReturn                                 123.133
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.80638
lstm_policy/KLBefore                        1.80638
lstm_policy/LossAfter                      -0.00796963
lstm_policy/LossBefore                     -0.00796963
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:14:17 | [drl] epoch #66 | Obtaining samples...
2020-09-01 14:14:17 | [drl] epoch #66 | Obtaining samples for iteration 66...
2020-09-01 14:14:24 | [drl] epoch #66 | Logging diagnostics...
2020-09-01 14:14:24 | [drl] epoch #66 | Optimizing policy...
2020-09-01 14:14:24 | [drl] epoch #66 | Computing loss before
2020-09-01 14:14:24 | [drl] epoch #66 | Computing KL before
2020-09-01 14:14:24 | [drl] epoch #66 | Optimizing
2020-09-01 14:14:24 | [drl] epoch #66 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:14:24 | [drl] epoch #66 | computing loss before
2020-09-01 14:14:24 | [drl] epoch #66 | computing gradient
2020-09-01 14:14:24 | [drl] epoch #66 | gradient computed
2020-09-01 14:14:24 | [drl] epoch #66 | computing descent direction
2020-09-01 14:14:25 | [drl] epoch #66 | descent direction computed
2020-09-01 14:14:25 | [drl] epoch #66 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:25 | [drl] epoch #66 | Violated because loss not improving
2020-09-01 14:14:25 | [drl] epoch #66 | Violated because constraint mean_kl is violated
2020-09-01 14:14:25 | [drl] epoch #66 | backtrack iters: 14
2020-09-01 14:14:25 | [drl] epoch #66 | optimization finished
2020-09-01 14:14:25 | [drl] epoch #66 | Computing KL after
2020-09-01 14:14:25 | [drl] epoch #66 | Computing loss after
2020-09-01 14:14:25 | [drl] epoch #66 | Fitting baseline...
2020-09-01 14:14:25 | [drl] epoch #66 | Saving snapshot...
2020-09-01 14:14:25 | [drl] epoch #66 | Saved
2020-09-01 14:14:25 | [drl] epoch #66 | Time 551.33 s
2020-09-01 14:14:25 | [drl] epoch #66 | EpochTime 7.99 s
---------------------------------------  -----------
AverageDiscountedReturn                  -345.457
AverageReturn                            -411.077
Entropy                                     5.92
EnvExecTime                                 1.77253
Extras/EpisodeRewardMean                 -420.35
Iteration                                  66
LinearFeatureBaseline/ExplainedVariance     0.609931
MaxReturn                                -289.801
MinReturn                                -655.09
NumTrajs                                  121
Perplexity                                372.411
PolicyExecTime                              3.83205
ProcessExecTime                             0.103032
StdReturn                                 120.168
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.63139
lstm_policy/KLBefore                        1.63139
lstm_policy/LossAfter                      -0.027644
lstm_policy/LossBefore                     -0.027644
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 14:14:25 | [drl] epoch #67 | Obtaining samples...
2020-09-01 14:14:25 | [drl] epoch #67 | Obtaining samples for iteration 67...
2020-09-01 14:14:32 | [drl] epoch #67 | Logging diagnostics...
2020-09-01 14:14:32 | [drl] epoch #67 | Optimizing policy...
2020-09-01 14:14:32 | [drl] epoch #67 | Computing loss before
2020-09-01 14:14:32 | [drl] epoch #67 | Computing KL before
2020-09-01 14:14:32 | [drl] epoch #67 | Optimizing
2020-09-01 14:14:32 | [drl] epoch #67 | Start CG optimization: #parameters: 19852, #inputs: 124, #subsample_inputs: 124
2020-09-01 14:14:32 | [drl] epoch #67 | computing loss before
2020-09-01 14:14:32 | [drl] epoch #67 | computing gradient
2020-09-01 14:14:32 | [drl] epoch #67 | gradient computed
2020-09-01 14:14:32 | [drl] epoch #67 | computing descent direction
2020-09-01 14:14:33 | [drl] epoch #67 | descent direction computed
2020-09-01 14:14:33 | [drl] epoch #67 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:33 | [drl] epoch #67 | Violated because constraint mean_kl is violated
2020-09-01 14:14:33 | [drl] epoch #67 | backtrack iters: 14
2020-09-01 14:14:33 | [drl] epoch #67 | optimization finished
2020-09-01 14:14:33 | [drl] epoch #67 | Computing KL after
2020-09-01 14:14:33 | [drl] epoch #67 | Computing loss after
2020-09-01 14:14:33 | [drl] epoch #67 | Fitting baseline...
2020-09-01 14:14:33 | [drl] epoch #67 | Saving snapshot...
2020-09-01 14:14:33 | [drl] epoch #67 | Saved
2020-09-01 14:14:33 | [drl] epoch #67 | Time 559.24 s
2020-09-01 14:14:33 | [drl] epoch #67 | EpochTime 7.90 s
---------------------------------------  ------------
AverageDiscountedReturn                  -332.39
AverageReturn                            -392.155
Entropy                                     5.96966
EnvExecTime                                 1.76801
Extras/EpisodeRewardMean                 -391.966
Iteration                                  67
LinearFeatureBaseline/ExplainedVariance     0.623457
MaxReturn                                -279.804
MinReturn                                -638.344
NumTrajs                                  124
Perplexity                                391.371
PolicyExecTime                              3.78305
ProcessExecTime                             0.0992174
StdReturn                                 111.73
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.77864
lstm_policy/KLBefore                        1.77864
lstm_policy/LossAfter                      -0.0252613
lstm_policy/LossBefore                     -0.0252613
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:14:33 | [drl] epoch #68 | Obtaining samples...
2020-09-01 14:14:33 | [drl] epoch #68 | Obtaining samples for iteration 68...
2020-09-01 14:14:39 | [drl] epoch #68 | Logging diagnostics...
2020-09-01 14:14:39 | [drl] epoch #68 | Optimizing policy...
2020-09-01 14:14:39 | [drl] epoch #68 | Computing loss before
2020-09-01 14:14:39 | [drl] epoch #68 | Computing KL before
2020-09-01 14:14:39 | [drl] epoch #68 | Optimizing
2020-09-01 14:14:39 | [drl] epoch #68 | Start CG optimization: #parameters: 19852, #inputs: 123, #subsample_inputs: 123
2020-09-01 14:14:39 | [drl] epoch #68 | computing loss before
2020-09-01 14:14:39 | [drl] epoch #68 | computing gradient
2020-09-01 14:14:39 | [drl] epoch #68 | gradient computed
2020-09-01 14:14:39 | [drl] epoch #68 | computing descent direction
2020-09-01 14:14:41 | [drl] epoch #68 | descent direction computed
2020-09-01 14:14:41 | [drl] epoch #68 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:41 | [drl] epoch #68 | Violated because loss not improving
2020-09-01 14:14:41 | [drl] epoch #68 | Violated because constraint mean_kl is violated
2020-09-01 14:14:41 | [drl] epoch #68 | backtrack iters: 14
2020-09-01 14:14:41 | [drl] epoch #68 | optimization finished
2020-09-01 14:14:41 | [drl] epoch #68 | Computing KL after
2020-09-01 14:14:41 | [drl] epoch #68 | Computing loss after
2020-09-01 14:14:41 | [drl] epoch #68 | Fitting baseline...
2020-09-01 14:14:41 | [drl] epoch #68 | Saving snapshot...
2020-09-01 14:14:41 | [drl] epoch #68 | Saved
2020-09-01 14:14:41 | [drl] epoch #68 | Time 567.04 s
2020-09-01 14:14:41 | [drl] epoch #68 | EpochTime 7.79 s
---------------------------------------  -------------
AverageDiscountedReturn                  -334.008
AverageReturn                            -394.759
Entropy                                     5.9527
EnvExecTime                                 1.72788
Extras/EpisodeRewardMean                 -400.669
Iteration                                  68
LinearFeatureBaseline/ExplainedVariance     0.624613
MaxReturn                                -277.9
MinReturn                                -639.744
NumTrajs                                  123
Perplexity                                384.789
PolicyExecTime                              3.71134
ProcessExecTime                             0.0971239
StdReturn                                 112.219
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.73592
lstm_policy/KLBefore                        1.73592
lstm_policy/LossAfter                      -0.00856511
lstm_policy/LossBefore                     -0.00856511
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:14:41 | [drl] epoch #69 | Obtaining samples...
2020-09-01 14:14:41 | [drl] epoch #69 | Obtaining samples for iteration 69...
2020-09-01 14:14:47 | [drl] epoch #69 | Logging diagnostics...
2020-09-01 14:14:47 | [drl] epoch #69 | Optimizing policy...
2020-09-01 14:14:47 | [drl] epoch #69 | Computing loss before
2020-09-01 14:14:47 | [drl] epoch #69 | Computing KL before
2020-09-01 14:14:47 | [drl] epoch #69 | Optimizing
2020-09-01 14:14:47 | [drl] epoch #69 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:14:47 | [drl] epoch #69 | computing loss before
2020-09-01 14:14:47 | [drl] epoch #69 | computing gradient
2020-09-01 14:14:47 | [drl] epoch #69 | gradient computed
2020-09-01 14:14:47 | [drl] epoch #69 | computing descent direction
2020-09-01 14:14:48 | [drl] epoch #69 | descent direction computed
2020-09-01 14:14:49 | [drl] epoch #69 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:49 | [drl] epoch #69 | Violated because loss not improving
2020-09-01 14:14:49 | [drl] epoch #69 | Violated because constraint mean_kl is violated
2020-09-01 14:14:49 | [drl] epoch #69 | backtrack iters: 14
2020-09-01 14:14:49 | [drl] epoch #69 | optimization finished
2020-09-01 14:14:49 | [drl] epoch #69 | Computing KL after
2020-09-01 14:14:49 | [drl] epoch #69 | Computing loss after
2020-09-01 14:14:49 | [drl] epoch #69 | Fitting baseline...
2020-09-01 14:14:49 | [drl] epoch #69 | Saving snapshot...
2020-09-01 14:14:49 | [drl] epoch #69 | Saved
2020-09-01 14:14:49 | [drl] epoch #69 | Time 574.73 s
2020-09-01 14:14:49 | [drl] epoch #69 | EpochTime 7.69 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.727
AverageReturn                            -404.356
Entropy                                     6.02096
EnvExecTime                                 1.72238
Extras/EpisodeRewardMean                 -400.572
Iteration                                  69
LinearFeatureBaseline/ExplainedVariance     0.623456
MaxReturn                                -283.684
MinReturn                                -653.055
NumTrajs                                  117
Perplexity                                411.972
PolicyExecTime                              3.70065
ProcessExecTime                             0.0968819
StdReturn                                 119.429
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.98941
lstm_policy/KLBefore                        1.98941
lstm_policy/LossAfter                      -0.0251082
lstm_policy/LossBefore                     -0.0251082
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:14:49 | [drl] epoch #70 | Obtaining samples...
2020-09-01 14:14:49 | [drl] epoch #70 | Obtaining samples for iteration 70...
2020-09-01 14:14:55 | [drl] epoch #70 | Logging diagnostics...
2020-09-01 14:14:55 | [drl] epoch #70 | Optimizing policy...
2020-09-01 14:14:55 | [drl] epoch #70 | Computing loss before
2020-09-01 14:14:55 | [drl] epoch #70 | Computing KL before
2020-09-01 14:14:55 | [drl] epoch #70 | Optimizing
2020-09-01 14:14:55 | [drl] epoch #70 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:14:55 | [drl] epoch #70 | computing loss before
2020-09-01 14:14:55 | [drl] epoch #70 | computing gradient
2020-09-01 14:14:55 | [drl] epoch #70 | gradient computed
2020-09-01 14:14:55 | [drl] epoch #70 | computing descent direction
2020-09-01 14:14:56 | [drl] epoch #70 | descent direction computed
2020-09-01 14:14:57 | [drl] epoch #70 | Line search condition violated. Rejecting the step!
2020-09-01 14:14:57 | [drl] epoch #70 | Violated because constraint mean_kl is violated
2020-09-01 14:14:57 | [drl] epoch #70 | backtrack iters: 14
2020-09-01 14:14:57 | [drl] epoch #70 | optimization finished
2020-09-01 14:14:57 | [drl] epoch #70 | Computing KL after
2020-09-01 14:14:57 | [drl] epoch #70 | Computing loss after
2020-09-01 14:14:57 | [drl] epoch #70 | Fitting baseline...
2020-09-01 14:14:57 | [drl] epoch #70 | Saving snapshot...
2020-09-01 14:14:57 | [drl] epoch #70 | Saved
2020-09-01 14:14:57 | [drl] epoch #70 | Time 582.67 s
2020-09-01 14:14:57 | [drl] epoch #70 | EpochTime 7.92 s
---------------------------------------  -----------
AverageDiscountedReturn                  -337.334
AverageReturn                            -399.295
Entropy                                     6.01638
EnvExecTime                                 1.76303
Extras/EpisodeRewardMean                 -395.128
Iteration                                  70
LinearFeatureBaseline/ExplainedVariance     0.627833
MaxReturn                                -287.615
MinReturn                                -638.567
NumTrajs                                  119
Perplexity                                410.092
PolicyExecTime                              3.81559
ProcessExecTime                             0.101268
StdReturn                                 116.24
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97045
lstm_policy/KLBefore                        1.97045
lstm_policy/LossAfter                      -0.026931
lstm_policy/LossBefore                     -0.026931
lstm_policy/dLoss                           0
---------------------------------------  -----------
2020-09-01 14:14:57 | [drl] epoch #71 | Obtaining samples...
2020-09-01 14:14:57 | [drl] epoch #71 | Obtaining samples for iteration 71...
2020-09-01 14:15:03 | [drl] epoch #71 | Logging diagnostics...
2020-09-01 14:15:03 | [drl] epoch #71 | Optimizing policy...
2020-09-01 14:15:03 | [drl] epoch #71 | Computing loss before
2020-09-01 14:15:03 | [drl] epoch #71 | Computing KL before
2020-09-01 14:15:03 | [drl] epoch #71 | Optimizing
2020-09-01 14:15:03 | [drl] epoch #71 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:15:03 | [drl] epoch #71 | computing loss before
2020-09-01 14:15:03 | [drl] epoch #71 | computing gradient
2020-09-01 14:15:03 | [drl] epoch #71 | gradient computed
2020-09-01 14:15:03 | [drl] epoch #71 | computing descent direction
2020-09-01 14:15:04 | [drl] epoch #71 | descent direction computed
2020-09-01 14:15:04 | [drl] epoch #71 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:04 | [drl] epoch #71 | Violated because loss not improving
2020-09-01 14:15:04 | [drl] epoch #71 | Violated because constraint mean_kl is violated
2020-09-01 14:15:04 | [drl] epoch #71 | backtrack iters: 14
2020-09-01 14:15:04 | [drl] epoch #71 | optimization finished
2020-09-01 14:15:04 | [drl] epoch #71 | Computing KL after
2020-09-01 14:15:04 | [drl] epoch #71 | Computing loss after
2020-09-01 14:15:05 | [drl] epoch #71 | Fitting baseline...
2020-09-01 14:15:05 | [drl] epoch #71 | Saving snapshot...
2020-09-01 14:15:05 | [drl] epoch #71 | Saved
2020-09-01 14:15:05 | [drl] epoch #71 | Time 590.59 s
2020-09-01 14:15:05 | [drl] epoch #71 | EpochTime 7.92 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.326
AverageReturn                            -404.131
Entropy                                     6.01786
EnvExecTime                                 1.75919
Extras/EpisodeRewardMean                 -410.075
Iteration                                  71
LinearFeatureBaseline/ExplainedVariance     0.628118
MaxReturn                                -291.393
MinReturn                                -644.148
NumTrajs                                  117
Perplexity                                410.699
PolicyExecTime                              3.84406
ProcessExecTime                             0.0989051
StdReturn                                 117.784
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.99078
lstm_policy/KLBefore                        1.99078
lstm_policy/LossAfter                      -0.0287245
lstm_policy/LossBefore                     -0.0287245
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:05 | [drl] epoch #72 | Obtaining samples...
2020-09-01 14:15:05 | [drl] epoch #72 | Obtaining samples for iteration 72...
2020-09-01 14:15:11 | [drl] epoch #72 | Logging diagnostics...
2020-09-01 14:15:11 | [drl] epoch #72 | Optimizing policy...
2020-09-01 14:15:11 | [drl] epoch #72 | Computing loss before
2020-09-01 14:15:11 | [drl] epoch #72 | Computing KL before
2020-09-01 14:15:11 | [drl] epoch #72 | Optimizing
2020-09-01 14:15:11 | [drl] epoch #72 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:15:11 | [drl] epoch #72 | computing loss before
2020-09-01 14:15:11 | [drl] epoch #72 | computing gradient
2020-09-01 14:15:11 | [drl] epoch #72 | gradient computed
2020-09-01 14:15:11 | [drl] epoch #72 | computing descent direction
2020-09-01 14:15:12 | [drl] epoch #72 | descent direction computed
2020-09-01 14:15:12 | [drl] epoch #72 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:12 | [drl] epoch #72 | Violated because loss not improving
2020-09-01 14:15:12 | [drl] epoch #72 | Violated because constraint mean_kl is violated
2020-09-01 14:15:12 | [drl] epoch #72 | backtrack iters: 14
2020-09-01 14:15:12 | [drl] epoch #72 | optimization finished
2020-09-01 14:15:12 | [drl] epoch #72 | Computing KL after
2020-09-01 14:15:12 | [drl] epoch #72 | Computing loss after
2020-09-01 14:15:13 | [drl] epoch #72 | Fitting baseline...
2020-09-01 14:15:13 | [drl] epoch #72 | Saving snapshot...
2020-09-01 14:15:13 | [drl] epoch #72 | Saved
2020-09-01 14:15:13 | [drl] epoch #72 | Time 598.59 s
2020-09-01 14:15:13 | [drl] epoch #72 | EpochTime 7.99 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.391
AverageReturn                            -414.478
Entropy                                     5.93662
EnvExecTime                                 1.79273
Extras/EpisodeRewardMean                 -419.354
Iteration                                  72
LinearFeatureBaseline/ExplainedVariance     0.605382
MaxReturn                                -294.28
MinReturn                                -636.092
NumTrajs                                  119
Perplexity                                378.652
PolicyExecTime                              3.84536
ProcessExecTime                             0.0985844
StdReturn                                 123.436
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.69376
lstm_policy/KLBefore                        1.69376
lstm_policy/LossAfter                      -0.0307721
lstm_policy/LossBefore                     -0.0307721
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:13 | [drl] epoch #73 | Obtaining samples...
2020-09-01 14:15:13 | [drl] epoch #73 | Obtaining samples for iteration 73...
2020-09-01 14:15:19 | [drl] epoch #73 | Logging diagnostics...
2020-09-01 14:15:19 | [drl] epoch #73 | Optimizing policy...
2020-09-01 14:15:19 | [drl] epoch #73 | Computing loss before
2020-09-01 14:15:19 | [drl] epoch #73 | Computing KL before
2020-09-01 14:15:19 | [drl] epoch #73 | Optimizing
2020-09-01 14:15:19 | [drl] epoch #73 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:15:19 | [drl] epoch #73 | computing loss before
2020-09-01 14:15:19 | [drl] epoch #73 | computing gradient
2020-09-01 14:15:19 | [drl] epoch #73 | gradient computed
2020-09-01 14:15:19 | [drl] epoch #73 | computing descent direction
2020-09-01 14:15:20 | [drl] epoch #73 | descent direction computed
2020-09-01 14:15:20 | [drl] epoch #73 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:20 | [drl] epoch #73 | Violated because loss not improving
2020-09-01 14:15:20 | [drl] epoch #73 | Violated because constraint mean_kl is violated
2020-09-01 14:15:20 | [drl] epoch #73 | backtrack iters: 14
2020-09-01 14:15:20 | [drl] epoch #73 | optimization finished
2020-09-01 14:15:20 | [drl] epoch #73 | Computing KL after
2020-09-01 14:15:20 | [drl] epoch #73 | Computing loss after
2020-09-01 14:15:20 | [drl] epoch #73 | Fitting baseline...
2020-09-01 14:15:20 | [drl] epoch #73 | Saving snapshot...
2020-09-01 14:15:20 | [drl] epoch #73 | Saved
2020-09-01 14:15:20 | [drl] epoch #73 | Time 606.53 s
2020-09-01 14:15:20 | [drl] epoch #73 | EpochTime 7.92 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.475
AverageReturn                            -408.874
Entropy                                     6.00822
EnvExecTime                                 1.76746
Extras/EpisodeRewardMean                 -410.642
Iteration                                  73
LinearFeatureBaseline/ExplainedVariance     0.62899
MaxReturn                                -275.704
MinReturn                                -639.159
NumTrajs                                  116
Perplexity                                406.758
PolicyExecTime                              3.83978
ProcessExecTime                             0.0985181
StdReturn                                 118.498
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.9376
lstm_policy/KLBefore                        1.9376
lstm_policy/LossAfter                      -0.0473108
lstm_policy/LossBefore                     -0.0473108
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:20 | [drl] epoch #74 | Obtaining samples...
2020-09-01 14:15:20 | [drl] epoch #74 | Obtaining samples for iteration 74...
2020-09-01 14:15:27 | [drl] epoch #74 | Logging diagnostics...
2020-09-01 14:15:27 | [drl] epoch #74 | Optimizing policy...
2020-09-01 14:15:27 | [drl] epoch #74 | Computing loss before
2020-09-01 14:15:27 | [drl] epoch #74 | Computing KL before
2020-09-01 14:15:27 | [drl] epoch #74 | Optimizing
2020-09-01 14:15:27 | [drl] epoch #74 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:15:27 | [drl] epoch #74 | computing loss before
2020-09-01 14:15:27 | [drl] epoch #74 | computing gradient
2020-09-01 14:15:27 | [drl] epoch #74 | gradient computed
2020-09-01 14:15:27 | [drl] epoch #74 | computing descent direction
2020-09-01 14:15:28 | [drl] epoch #74 | descent direction computed
2020-09-01 14:15:28 | [drl] epoch #74 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:28 | [drl] epoch #74 | Violated because constraint mean_kl is violated
2020-09-01 14:15:28 | [drl] epoch #74 | backtrack iters: 14
2020-09-01 14:15:28 | [drl] epoch #74 | optimization finished
2020-09-01 14:15:28 | [drl] epoch #74 | Computing KL after
2020-09-01 14:15:28 | [drl] epoch #74 | Computing loss after
2020-09-01 14:15:28 | [drl] epoch #74 | Fitting baseline...
2020-09-01 14:15:28 | [drl] epoch #74 | Saving snapshot...
2020-09-01 14:15:28 | [drl] epoch #74 | Saved
2020-09-01 14:15:28 | [drl] epoch #74 | Time 614.54 s
2020-09-01 14:15:28 | [drl] epoch #74 | EpochTime 8.00 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.529
AverageReturn                            -408.23
Entropy                                     5.96478
EnvExecTime                                 1.7931
Extras/EpisodeRewardMean                 -409.238
Iteration                                  74
LinearFeatureBaseline/ExplainedVariance     0.611582
MaxReturn                                -287.099
MinReturn                                -650.685
NumTrajs                                  120
Perplexity                                389.469
PolicyExecTime                              3.84213
ProcessExecTime                             0.0989602
StdReturn                                 121.314
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78162
lstm_policy/KLBefore                        1.78162
lstm_policy/LossAfter                      -0.0262132
lstm_policy/LossBefore                     -0.0262132
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:28 | [drl] epoch #75 | Obtaining samples...
2020-09-01 14:15:28 | [drl] epoch #75 | Obtaining samples for iteration 75...
2020-09-01 14:15:35 | [drl] epoch #75 | Logging diagnostics...
2020-09-01 14:15:35 | [drl] epoch #75 | Optimizing policy...
2020-09-01 14:15:35 | [drl] epoch #75 | Computing loss before
2020-09-01 14:15:35 | [drl] epoch #75 | Computing KL before
2020-09-01 14:15:35 | [drl] epoch #75 | Optimizing
2020-09-01 14:15:35 | [drl] epoch #75 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:15:35 | [drl] epoch #75 | computing loss before
2020-09-01 14:15:35 | [drl] epoch #75 | computing gradient
2020-09-01 14:15:35 | [drl] epoch #75 | gradient computed
2020-09-01 14:15:35 | [drl] epoch #75 | computing descent direction
2020-09-01 14:15:36 | [drl] epoch #75 | descent direction computed
2020-09-01 14:15:36 | [drl] epoch #75 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:36 | [drl] epoch #75 | Violated because constraint mean_kl is violated
2020-09-01 14:15:36 | [drl] epoch #75 | backtrack iters: 14
2020-09-01 14:15:36 | [drl] epoch #75 | optimization finished
2020-09-01 14:15:36 | [drl] epoch #75 | Computing KL after
2020-09-01 14:15:36 | [drl] epoch #75 | Computing loss after
2020-09-01 14:15:36 | [drl] epoch #75 | Fitting baseline...
2020-09-01 14:15:36 | [drl] epoch #75 | Saving snapshot...
2020-09-01 14:15:36 | [drl] epoch #75 | Saved
2020-09-01 14:15:36 | [drl] epoch #75 | Time 622.48 s
2020-09-01 14:15:36 | [drl] epoch #75 | EpochTime 7.93 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.115
AverageReturn                            -409.911
Entropy                                     5.93078
EnvExecTime                                 1.76326
Extras/EpisodeRewardMean                 -406.283
Iteration                                  75
LinearFeatureBaseline/ExplainedVariance     0.587509
MaxReturn                                -275.172
MinReturn                                -637.018
NumTrajs                                  120
Perplexity                                376.447
PolicyExecTime                              3.80108
ProcessExecTime                             0.0997138
StdReturn                                 126.468
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.6694
lstm_policy/KLBefore                        1.6694
lstm_policy/LossAfter                      -0.0290698
lstm_policy/LossBefore                     -0.0290698
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:36 | [drl] epoch #76 | Obtaining samples...
2020-09-01 14:15:36 | [drl] epoch #76 | Obtaining samples for iteration 76...
2020-09-01 14:15:43 | [drl] epoch #76 | Logging diagnostics...
2020-09-01 14:15:43 | [drl] epoch #76 | Optimizing policy...
2020-09-01 14:15:43 | [drl] epoch #76 | Computing loss before
2020-09-01 14:15:43 | [drl] epoch #76 | Computing KL before
2020-09-01 14:15:43 | [drl] epoch #76 | Optimizing
2020-09-01 14:15:43 | [drl] epoch #76 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:15:43 | [drl] epoch #76 | computing loss before
2020-09-01 14:15:43 | [drl] epoch #76 | computing gradient
2020-09-01 14:15:43 | [drl] epoch #76 | gradient computed
2020-09-01 14:15:43 | [drl] epoch #76 | computing descent direction
2020-09-01 14:15:44 | [drl] epoch #76 | descent direction computed
2020-09-01 14:15:44 | [drl] epoch #76 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:44 | [drl] epoch #76 | Violated because constraint mean_kl is violated
2020-09-01 14:15:44 | [drl] epoch #76 | backtrack iters: 14
2020-09-01 14:15:44 | [drl] epoch #76 | optimization finished
2020-09-01 14:15:44 | [drl] epoch #76 | Computing KL after
2020-09-01 14:15:44 | [drl] epoch #76 | Computing loss after
2020-09-01 14:15:44 | [drl] epoch #76 | Fitting baseline...
2020-09-01 14:15:44 | [drl] epoch #76 | Saving snapshot...
2020-09-01 14:15:44 | [drl] epoch #76 | Saved
2020-09-01 14:15:44 | [drl] epoch #76 | Time 630.41 s
2020-09-01 14:15:44 | [drl] epoch #76 | EpochTime 7.93 s
---------------------------------------  ------------
AverageDiscountedReturn                  -324.03
AverageReturn                            -379.824
Entropy                                     6.11079
EnvExecTime                                 1.76727
Extras/EpisodeRewardMean                 -385.501
Iteration                                  76
LinearFeatureBaseline/ExplainedVariance     0.66164
MaxReturn                                -282.642
MinReturn                                -649.927
NumTrajs                                  120
Perplexity                                450.693
PolicyExecTime                              3.83696
ProcessExecTime                             0.0983238
StdReturn                                 102.949
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.30382
lstm_policy/KLBefore                        2.30382
lstm_policy/LossAfter                      -0.030248
lstm_policy/LossBefore                     -0.030248
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:15:44 | [drl] epoch #77 | Obtaining samples...
2020-09-01 14:15:44 | [drl] epoch #77 | Obtaining samples for iteration 77...
2020-09-01 14:15:51 | [drl] epoch #77 | Logging diagnostics...
2020-09-01 14:15:51 | [drl] epoch #77 | Optimizing policy...
2020-09-01 14:15:51 | [drl] epoch #77 | Computing loss before
2020-09-01 14:15:51 | [drl] epoch #77 | Computing KL before
2020-09-01 14:15:51 | [drl] epoch #77 | Optimizing
2020-09-01 14:15:51 | [drl] epoch #77 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:15:51 | [drl] epoch #77 | computing loss before
2020-09-01 14:15:51 | [drl] epoch #77 | computing gradient
2020-09-01 14:15:51 | [drl] epoch #77 | gradient computed
2020-09-01 14:15:51 | [drl] epoch #77 | computing descent direction
2020-09-01 14:15:52 | [drl] epoch #77 | descent direction computed
2020-09-01 14:15:52 | [drl] epoch #77 | Line search condition violated. Rejecting the step!
2020-09-01 14:15:52 | [drl] epoch #77 | Violated because loss not improving
2020-09-01 14:15:52 | [drl] epoch #77 | Violated because constraint mean_kl is violated
2020-09-01 14:15:52 | [drl] epoch #77 | backtrack iters: 14
2020-09-01 14:15:52 | [drl] epoch #77 | optimization finished
2020-09-01 14:15:52 | [drl] epoch #77 | Computing KL after
2020-09-01 14:15:52 | [drl] epoch #77 | Computing loss after
2020-09-01 14:15:52 | [drl] epoch #77 | Fitting baseline...
2020-09-01 14:15:52 | [drl] epoch #77 | Saving snapshot...
2020-09-01 14:15:52 | [drl] epoch #77 | Saved
2020-09-01 14:15:52 | [drl] epoch #77 | Time 638.41 s
2020-09-01 14:15:52 | [drl] epoch #77 | EpochTime 7.99 s
---------------------------------------  -------------
AverageDiscountedReturn                  -342.575
AverageReturn                            -407.014
Entropy                                     5.97093
EnvExecTime                                 1.77633
Extras/EpisodeRewardMean                 -402.686
Iteration                                  77
LinearFeatureBaseline/ExplainedVariance     0.605212
MaxReturn                                -275.75
MinReturn                                -648.515
NumTrajs                                  120
Perplexity                                391.87
PolicyExecTime                              3.84726
ProcessExecTime                             0.102599
StdReturn                                 123.088
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82308
lstm_policy/KLBefore                        1.82308
lstm_policy/LossAfter                       0.00421541
lstm_policy/LossBefore                      0.00421541
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:15:52 | [drl] epoch #78 | Obtaining samples...
2020-09-01 14:15:52 | [drl] epoch #78 | Obtaining samples for iteration 78...
2020-09-01 14:15:59 | [drl] epoch #78 | Logging diagnostics...
2020-09-01 14:15:59 | [drl] epoch #78 | Optimizing policy...
2020-09-01 14:15:59 | [drl] epoch #78 | Computing loss before
2020-09-01 14:15:59 | [drl] epoch #78 | Computing KL before
2020-09-01 14:15:59 | [drl] epoch #78 | Optimizing
2020-09-01 14:15:59 | [drl] epoch #78 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:15:59 | [drl] epoch #78 | computing loss before
2020-09-01 14:15:59 | [drl] epoch #78 | computing gradient
2020-09-01 14:15:59 | [drl] epoch #78 | gradient computed
2020-09-01 14:15:59 | [drl] epoch #78 | computing descent direction
2020-09-01 14:16:00 | [drl] epoch #78 | descent direction computed
2020-09-01 14:16:00 | [drl] epoch #78 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:00 | [drl] epoch #78 | Violated because loss not improving
2020-09-01 14:16:00 | [drl] epoch #78 | Violated because constraint mean_kl is violated
2020-09-01 14:16:00 | [drl] epoch #78 | backtrack iters: 14
2020-09-01 14:16:00 | [drl] epoch #78 | optimization finished
2020-09-01 14:16:00 | [drl] epoch #78 | Computing KL after
2020-09-01 14:16:00 | [drl] epoch #78 | Computing loss after
2020-09-01 14:16:00 | [drl] epoch #78 | Fitting baseline...
2020-09-01 14:16:00 | [drl] epoch #78 | Saving snapshot...
2020-09-01 14:16:00 | [drl] epoch #78 | Saved
2020-09-01 14:16:00 | [drl] epoch #78 | Time 646.33 s
2020-09-01 14:16:00 | [drl] epoch #78 | EpochTime 7.90 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.561
AverageReturn                            -410.089
Entropy                                     6.01427
EnvExecTime                                 1.77454
Extras/EpisodeRewardMean                 -408.759
Iteration                                  78
LinearFeatureBaseline/ExplainedVariance     0.623275
MaxReturn                                -270.586
MinReturn                                -653.363
NumTrajs                                  116
Perplexity                                409.225
PolicyExecTime                              3.80883
ProcessExecTime                             0.0987537
StdReturn                                 122.592
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.96902
lstm_policy/KLBefore                        1.96902
lstm_policy/LossAfter                      -0.037761
lstm_policy/LossBefore                     -0.037761
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:00 | [drl] epoch #79 | Obtaining samples...
2020-09-01 14:16:00 | [drl] epoch #79 | Obtaining samples for iteration 79...
2020-09-01 14:16:07 | [drl] epoch #79 | Logging diagnostics...
2020-09-01 14:16:07 | [drl] epoch #79 | Optimizing policy...
2020-09-01 14:16:07 | [drl] epoch #79 | Computing loss before
2020-09-01 14:16:07 | [drl] epoch #79 | Computing KL before
2020-09-01 14:16:07 | [drl] epoch #79 | Optimizing
2020-09-01 14:16:07 | [drl] epoch #79 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:16:07 | [drl] epoch #79 | computing loss before
2020-09-01 14:16:07 | [drl] epoch #79 | computing gradient
2020-09-01 14:16:07 | [drl] epoch #79 | gradient computed
2020-09-01 14:16:07 | [drl] epoch #79 | computing descent direction
2020-09-01 14:16:08 | [drl] epoch #79 | descent direction computed
2020-09-01 14:16:08 | [drl] epoch #79 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:08 | [drl] epoch #79 | Violated because constraint mean_kl is violated
2020-09-01 14:16:08 | [drl] epoch #79 | backtrack iters: 14
2020-09-01 14:16:08 | [drl] epoch #79 | optimization finished
2020-09-01 14:16:08 | [drl] epoch #79 | Computing KL after
2020-09-01 14:16:08 | [drl] epoch #79 | Computing loss after
2020-09-01 14:16:08 | [drl] epoch #79 | Fitting baseline...
2020-09-01 14:16:08 | [drl] epoch #79 | Saving snapshot...
2020-09-01 14:16:08 | [drl] epoch #79 | Saved
2020-09-01 14:16:08 | [drl] epoch #79 | Time 654.27 s
2020-09-01 14:16:08 | [drl] epoch #79 | EpochTime 7.93 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.594
AverageReturn                            -413.176
Entropy                                     5.97818
EnvExecTime                                 1.78032
Extras/EpisodeRewardMean                 -410.322
Iteration                                  79
LinearFeatureBaseline/ExplainedVariance     0.619055
MaxReturn                                -273.7
MinReturn                                -642.075
NumTrajs                                  117
Perplexity                                394.722
PolicyExecTime                              3.82209
ProcessExecTime                             0.0986876
StdReturn                                 121.239
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.84968
lstm_policy/KLBefore                        1.84968
lstm_policy/LossAfter                      -0.0350214
lstm_policy/LossBefore                     -0.0350214
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:08 | [drl] epoch #80 | Obtaining samples...
2020-09-01 14:16:08 | [drl] epoch #80 | Obtaining samples for iteration 80...
2020-09-01 14:16:15 | [drl] epoch #80 | Logging diagnostics...
2020-09-01 14:16:15 | [drl] epoch #80 | Optimizing policy...
2020-09-01 14:16:15 | [drl] epoch #80 | Computing loss before
2020-09-01 14:16:15 | [drl] epoch #80 | Computing KL before
2020-09-01 14:16:15 | [drl] epoch #80 | Optimizing
2020-09-01 14:16:15 | [drl] epoch #80 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:16:15 | [drl] epoch #80 | computing loss before
2020-09-01 14:16:15 | [drl] epoch #80 | computing gradient
2020-09-01 14:16:15 | [drl] epoch #80 | gradient computed
2020-09-01 14:16:15 | [drl] epoch #80 | computing descent direction
2020-09-01 14:16:16 | [drl] epoch #80 | descent direction computed
2020-09-01 14:16:16 | [drl] epoch #80 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:16 | [drl] epoch #80 | Violated because constraint mean_kl is violated
2020-09-01 14:16:16 | [drl] epoch #80 | backtrack iters: 14
2020-09-01 14:16:16 | [drl] epoch #80 | optimization finished
2020-09-01 14:16:16 | [drl] epoch #80 | Computing KL after
2020-09-01 14:16:16 | [drl] epoch #80 | Computing loss after
2020-09-01 14:16:16 | [drl] epoch #80 | Fitting baseline...
2020-09-01 14:16:16 | [drl] epoch #80 | Saving snapshot...
2020-09-01 14:16:16 | [drl] epoch #80 | Saved
2020-09-01 14:16:16 | [drl] epoch #80 | Time 662.27 s
2020-09-01 14:16:16 | [drl] epoch #80 | EpochTime 8.00 s
---------------------------------------  ------------
AverageDiscountedReturn                  -347.884
AverageReturn                            -414.64
Entropy                                     5.94084
EnvExecTime                                 1.78865
Extras/EpisodeRewardMean                 -405.412
Iteration                                  80
LinearFeatureBaseline/ExplainedVariance     0.600602
MaxReturn                                -289.668
MinReturn                                -652.925
NumTrajs                                  119
Perplexity                                380.254
PolicyExecTime                              3.8414
ProcessExecTime                             0.102473
StdReturn                                 124.772
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.72765
lstm_policy/KLBefore                        1.72765
lstm_policy/LossAfter                      -0.0281509
lstm_policy/LossBefore                     -0.0281509
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:16 | [drl] epoch #81 | Obtaining samples...
2020-09-01 14:16:16 | [drl] epoch #81 | Obtaining samples for iteration 81...
2020-09-01 14:16:23 | [drl] epoch #81 | Logging diagnostics...
2020-09-01 14:16:23 | [drl] epoch #81 | Optimizing policy...
2020-09-01 14:16:23 | [drl] epoch #81 | Computing loss before
2020-09-01 14:16:23 | [drl] epoch #81 | Computing KL before
2020-09-01 14:16:23 | [drl] epoch #81 | Optimizing
2020-09-01 14:16:23 | [drl] epoch #81 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:16:23 | [drl] epoch #81 | computing loss before
2020-09-01 14:16:23 | [drl] epoch #81 | computing gradient
2020-09-01 14:16:23 | [drl] epoch #81 | gradient computed
2020-09-01 14:16:23 | [drl] epoch #81 | computing descent direction
2020-09-01 14:16:24 | [drl] epoch #81 | descent direction computed
2020-09-01 14:16:24 | [drl] epoch #81 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:24 | [drl] epoch #81 | Violated because loss not improving
2020-09-01 14:16:24 | [drl] epoch #81 | Violated because constraint mean_kl is violated
2020-09-01 14:16:24 | [drl] epoch #81 | backtrack iters: 14
2020-09-01 14:16:24 | [drl] epoch #81 | optimization finished
2020-09-01 14:16:24 | [drl] epoch #81 | Computing KL after
2020-09-01 14:16:24 | [drl] epoch #81 | Computing loss after
2020-09-01 14:16:24 | [drl] epoch #81 | Fitting baseline...
2020-09-01 14:16:24 | [drl] epoch #81 | Saving snapshot...
2020-09-01 14:16:24 | [drl] epoch #81 | Saved
2020-09-01 14:16:24 | [drl] epoch #81 | Time 670.30 s
2020-09-01 14:16:24 | [drl] epoch #81 | EpochTime 8.01 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.789
AverageReturn                            -404.616
Entropy                                     6.00283
EnvExecTime                                 1.7837
Extras/EpisodeRewardMean                 -405.969
Iteration                                  81
LinearFeatureBaseline/ExplainedVariance     0.619078
MaxReturn                                -277.197
MinReturn                                -634.142
NumTrajs                                  118
Perplexity                                404.573
PolicyExecTime                              3.85587
ProcessExecTime                             0.103707
StdReturn                                 119.435
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.94653
lstm_policy/KLBefore                        1.94653
lstm_policy/LossAfter                      -0.0355764
lstm_policy/LossBefore                     -0.0355764
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:24 | [drl] epoch #82 | Obtaining samples...
2020-09-01 14:16:24 | [drl] epoch #82 | Obtaining samples for iteration 82...
2020-09-01 14:16:31 | [drl] epoch #82 | Logging diagnostics...
2020-09-01 14:16:31 | [drl] epoch #82 | Optimizing policy...
2020-09-01 14:16:31 | [drl] epoch #82 | Computing loss before
2020-09-01 14:16:31 | [drl] epoch #82 | Computing KL before
2020-09-01 14:16:31 | [drl] epoch #82 | Optimizing
2020-09-01 14:16:31 | [drl] epoch #82 | Start CG optimization: #parameters: 19852, #inputs: 126, #subsample_inputs: 126
2020-09-01 14:16:31 | [drl] epoch #82 | computing loss before
2020-09-01 14:16:31 | [drl] epoch #82 | computing gradient
2020-09-01 14:16:31 | [drl] epoch #82 | gradient computed
2020-09-01 14:16:31 | [drl] epoch #82 | computing descent direction
2020-09-01 14:16:32 | [drl] epoch #82 | descent direction computed
2020-09-01 14:16:32 | [drl] epoch #82 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:32 | [drl] epoch #82 | Violated because constraint mean_kl is violated
2020-09-01 14:16:32 | [drl] epoch #82 | backtrack iters: 14
2020-09-01 14:16:32 | [drl] epoch #82 | optimization finished
2020-09-01 14:16:32 | [drl] epoch #82 | Computing KL after
2020-09-01 14:16:32 | [drl] epoch #82 | Computing loss after
2020-09-01 14:16:32 | [drl] epoch #82 | Fitting baseline...
2020-09-01 14:16:32 | [drl] epoch #82 | Saving snapshot...
2020-09-01 14:16:32 | [drl] epoch #82 | Saved
2020-09-01 14:16:32 | [drl] epoch #82 | Time 678.35 s
2020-09-01 14:16:32 | [drl] epoch #82 | EpochTime 8.04 s
---------------------------------------  -------------
AverageDiscountedReturn                  -324.167
AverageReturn                            -380.465
Entropy                                     5.99212
EnvExecTime                                 1.77437
Extras/EpisodeRewardMean                 -375.365
Iteration                                  82
LinearFeatureBaseline/ExplainedVariance     0.639054
MaxReturn                                -267.508
MinReturn                                -648.908
NumTrajs                                  126
Perplexity                                400.262
PolicyExecTime                              3.84818
ProcessExecTime                             0.0995007
StdReturn                                 105.545
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.85618
lstm_policy/KLBefore                        1.85618
lstm_policy/LossAfter                      -0.00914888
lstm_policy/LossBefore                     -0.00914888
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:16:32 | [drl] epoch #83 | Obtaining samples...
2020-09-01 14:16:32 | [drl] epoch #83 | Obtaining samples for iteration 83...
2020-09-01 14:16:39 | [drl] epoch #83 | Logging diagnostics...
2020-09-01 14:16:39 | [drl] epoch #83 | Optimizing policy...
2020-09-01 14:16:39 | [drl] epoch #83 | Computing loss before
2020-09-01 14:16:39 | [drl] epoch #83 | Computing KL before
2020-09-01 14:16:39 | [drl] epoch #83 | Optimizing
2020-09-01 14:16:39 | [drl] epoch #83 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:16:39 | [drl] epoch #83 | computing loss before
2020-09-01 14:16:39 | [drl] epoch #83 | computing gradient
2020-09-01 14:16:39 | [drl] epoch #83 | gradient computed
2020-09-01 14:16:39 | [drl] epoch #83 | computing descent direction
2020-09-01 14:16:40 | [drl] epoch #83 | descent direction computed
2020-09-01 14:16:40 | [drl] epoch #83 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:40 | [drl] epoch #83 | Violated because constraint mean_kl is violated
2020-09-01 14:16:40 | [drl] epoch #83 | backtrack iters: 14
2020-09-01 14:16:40 | [drl] epoch #83 | optimization finished
2020-09-01 14:16:40 | [drl] epoch #83 | Computing KL after
2020-09-01 14:16:40 | [drl] epoch #83 | Computing loss after
2020-09-01 14:16:40 | [drl] epoch #83 | Fitting baseline...
2020-09-01 14:16:40 | [drl] epoch #83 | Saving snapshot...
2020-09-01 14:16:40 | [drl] epoch #83 | Saved
2020-09-01 14:16:40 | [drl] epoch #83 | Time 686.35 s
2020-09-01 14:16:40 | [drl] epoch #83 | EpochTime 7.98 s
---------------------------------------  -------------
AverageDiscountedReturn                  -331.402
AverageReturn                            -392.201
Entropy                                     6.02782
EnvExecTime                                 1.76364
Extras/EpisodeRewardMean                 -397.876
Iteration                                  83
LinearFeatureBaseline/ExplainedVariance     0.625419
MaxReturn                                -281.259
MinReturn                                -628.888
NumTrajs                                  120
Perplexity                                414.812
PolicyExecTime                              3.86366
ProcessExecTime                             0.101097
StdReturn                                 114.032
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.02016
lstm_policy/KLBefore                        2.02016
lstm_policy/LossAfter                      -0.00325695
lstm_policy/LossBefore                     -0.00325695
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:16:40 | [drl] epoch #84 | Obtaining samples...
2020-09-01 14:16:40 | [drl] epoch #84 | Obtaining samples for iteration 84...
2020-09-01 14:16:47 | [drl] epoch #84 | Logging diagnostics...
2020-09-01 14:16:47 | [drl] epoch #84 | Optimizing policy...
2020-09-01 14:16:47 | [drl] epoch #84 | Computing loss before
2020-09-01 14:16:47 | [drl] epoch #84 | Computing KL before
2020-09-01 14:16:47 | [drl] epoch #84 | Optimizing
2020-09-01 14:16:47 | [drl] epoch #84 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:16:47 | [drl] epoch #84 | computing loss before
2020-09-01 14:16:47 | [drl] epoch #84 | computing gradient
2020-09-01 14:16:47 | [drl] epoch #84 | gradient computed
2020-09-01 14:16:47 | [drl] epoch #84 | computing descent direction
2020-09-01 14:16:48 | [drl] epoch #84 | descent direction computed
2020-09-01 14:16:48 | [drl] epoch #84 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:48 | [drl] epoch #84 | Violated because loss not improving
2020-09-01 14:16:48 | [drl] epoch #84 | Violated because constraint mean_kl is violated
2020-09-01 14:16:48 | [drl] epoch #84 | backtrack iters: 14
2020-09-01 14:16:48 | [drl] epoch #84 | optimization finished
2020-09-01 14:16:48 | [drl] epoch #84 | Computing KL after
2020-09-01 14:16:48 | [drl] epoch #84 | Computing loss after
2020-09-01 14:16:48 | [drl] epoch #84 | Fitting baseline...
2020-09-01 14:16:48 | [drl] epoch #84 | Saving snapshot...
2020-09-01 14:16:48 | [drl] epoch #84 | Saved
2020-09-01 14:16:48 | [drl] epoch #84 | Time 694.30 s
2020-09-01 14:16:48 | [drl] epoch #84 | EpochTime 7.94 s
---------------------------------------  ------------
AverageDiscountedReturn                  -345.279
AverageReturn                            -411.356
Entropy                                     5.99451
EnvExecTime                                 1.765
Extras/EpisodeRewardMean                 -406.595
Iteration                                  84
LinearFeatureBaseline/ExplainedVariance     0.612431
MaxReturn                                -282.137
MinReturn                                -634.719
NumTrajs                                  117
Perplexity                                401.219
PolicyExecTime                              3.84956
ProcessExecTime                             0.0992148
StdReturn                                 123.911
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.93141
lstm_policy/KLBefore                        1.93141
lstm_policy/LossAfter                      -0.0285487
lstm_policy/LossBefore                     -0.0285487
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:48 | [drl] epoch #85 | Obtaining samples...
2020-09-01 14:16:48 | [drl] epoch #85 | Obtaining samples for iteration 85...
2020-09-01 14:16:55 | [drl] epoch #85 | Logging diagnostics...
2020-09-01 14:16:55 | [drl] epoch #85 | Optimizing policy...
2020-09-01 14:16:55 | [drl] epoch #85 | Computing loss before
2020-09-01 14:16:55 | [drl] epoch #85 | Computing KL before
2020-09-01 14:16:55 | [drl] epoch #85 | Optimizing
2020-09-01 14:16:55 | [drl] epoch #85 | Start CG optimization: #parameters: 19852, #inputs: 122, #subsample_inputs: 122
2020-09-01 14:16:55 | [drl] epoch #85 | computing loss before
2020-09-01 14:16:55 | [drl] epoch #85 | computing gradient
2020-09-01 14:16:55 | [drl] epoch #85 | gradient computed
2020-09-01 14:16:55 | [drl] epoch #85 | computing descent direction
2020-09-01 14:16:56 | [drl] epoch #85 | descent direction computed
2020-09-01 14:16:56 | [drl] epoch #85 | Line search condition violated. Rejecting the step!
2020-09-01 14:16:56 | [drl] epoch #85 | Violated because constraint mean_kl is violated
2020-09-01 14:16:56 | [drl] epoch #85 | backtrack iters: 14
2020-09-01 14:16:56 | [drl] epoch #85 | optimization finished
2020-09-01 14:16:56 | [drl] epoch #85 | Computing KL after
2020-09-01 14:16:56 | [drl] epoch #85 | Computing loss after
2020-09-01 14:16:56 | [drl] epoch #85 | Fitting baseline...
2020-09-01 14:16:56 | [drl] epoch #85 | Saving snapshot...
2020-09-01 14:16:56 | [drl] epoch #85 | Saved
2020-09-01 14:16:56 | [drl] epoch #85 | Time 702.32 s
2020-09-01 14:16:56 | [drl] epoch #85 | EpochTime 8.01 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.971
AverageReturn                            -404.809
Entropy                                     5.9241
EnvExecTime                                 1.77627
Extras/EpisodeRewardMean                 -409.559
Iteration                                  85
LinearFeatureBaseline/ExplainedVariance     0.603558
MaxReturn                                -288.125
MinReturn                                -641.638
NumTrajs                                  122
Perplexity                                373.941
PolicyExecTime                              3.83536
ProcessExecTime                             0.0997357
StdReturn                                 120.086
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.64835
lstm_policy/KLBefore                        1.64835
lstm_policy/LossAfter                      -0.0270996
lstm_policy/LossBefore                     -0.0270996
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:16:56 | [drl] epoch #86 | Obtaining samples...
2020-09-01 14:16:56 | [drl] epoch #86 | Obtaining samples for iteration 86...
2020-09-01 14:17:03 | [drl] epoch #86 | Logging diagnostics...
2020-09-01 14:17:03 | [drl] epoch #86 | Optimizing policy...
2020-09-01 14:17:03 | [drl] epoch #86 | Computing loss before
2020-09-01 14:17:03 | [drl] epoch #86 | Computing KL before
2020-09-01 14:17:03 | [drl] epoch #86 | Optimizing
2020-09-01 14:17:03 | [drl] epoch #86 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:17:03 | [drl] epoch #86 | computing loss before
2020-09-01 14:17:03 | [drl] epoch #86 | computing gradient
2020-09-01 14:17:03 | [drl] epoch #86 | gradient computed
2020-09-01 14:17:03 | [drl] epoch #86 | computing descent direction
2020-09-01 14:17:04 | [drl] epoch #86 | descent direction computed
2020-09-01 14:17:04 | [drl] epoch #86 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:04 | [drl] epoch #86 | Violated because constraint mean_kl is violated
2020-09-01 14:17:04 | [drl] epoch #86 | backtrack iters: 14
2020-09-01 14:17:04 | [drl] epoch #86 | optimization finished
2020-09-01 14:17:04 | [drl] epoch #86 | Computing KL after
2020-09-01 14:17:04 | [drl] epoch #86 | Computing loss after
2020-09-01 14:17:04 | [drl] epoch #86 | Fitting baseline...
2020-09-01 14:17:04 | [drl] epoch #86 | Saving snapshot...
2020-09-01 14:17:04 | [drl] epoch #86 | Saved
2020-09-01 14:17:04 | [drl] epoch #86 | Time 710.35 s
2020-09-01 14:17:04 | [drl] epoch #86 | EpochTime 8.02 s
---------------------------------------  ------------
AverageDiscountedReturn                  -334.711
AverageReturn                            -396.06
Entropy                                     5.99904
EnvExecTime                                 1.78707
Extras/EpisodeRewardMean                 -396.935
Iteration                                  86
LinearFeatureBaseline/ExplainedVariance     0.619686
MaxReturn                                -273.083
MinReturn                                -643.601
NumTrajs                                  121
Perplexity                                403.043
PolicyExecTime                              3.85866
ProcessExecTime                             0.0989702
StdReturn                                 116.653
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.92506
lstm_policy/KLBefore                        1.92506
lstm_policy/LossAfter                      -0.0208336
lstm_policy/LossBefore                     -0.0208336
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:17:04 | [drl] epoch #87 | Obtaining samples...
2020-09-01 14:17:04 | [drl] epoch #87 | Obtaining samples for iteration 87...
2020-09-01 14:17:11 | [drl] epoch #87 | Logging diagnostics...
2020-09-01 14:17:11 | [drl] epoch #87 | Optimizing policy...
2020-09-01 14:17:11 | [drl] epoch #87 | Computing loss before
2020-09-01 14:17:11 | [drl] epoch #87 | Computing KL before
2020-09-01 14:17:11 | [drl] epoch #87 | Optimizing
2020-09-01 14:17:11 | [drl] epoch #87 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:17:11 | [drl] epoch #87 | computing loss before
2020-09-01 14:17:11 | [drl] epoch #87 | computing gradient
2020-09-01 14:17:11 | [drl] epoch #87 | gradient computed
2020-09-01 14:17:11 | [drl] epoch #87 | computing descent direction
2020-09-01 14:17:12 | [drl] epoch #87 | descent direction computed
2020-09-01 14:17:12 | [drl] epoch #87 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:12 | [drl] epoch #87 | Violated because constraint mean_kl is violated
2020-09-01 14:17:12 | [drl] epoch #87 | backtrack iters: 14
2020-09-01 14:17:12 | [drl] epoch #87 | optimization finished
2020-09-01 14:17:12 | [drl] epoch #87 | Computing KL after
2020-09-01 14:17:12 | [drl] epoch #87 | Computing loss after
2020-09-01 14:17:12 | [drl] epoch #87 | Fitting baseline...
2020-09-01 14:17:12 | [drl] epoch #87 | Saving snapshot...
2020-09-01 14:17:12 | [drl] epoch #87 | Saved
2020-09-01 14:17:12 | [drl] epoch #87 | Time 718.33 s
2020-09-01 14:17:12 | [drl] epoch #87 | EpochTime 7.97 s
---------------------------------------  ------------
AverageDiscountedReturn                  -337.003
AverageReturn                            -399.373
Entropy                                     6.01906
EnvExecTime                                 1.79572
Extras/EpisodeRewardMean                 -402.472
Iteration                                  87
LinearFeatureBaseline/ExplainedVariance     0.626708
MaxReturn                                -278.229
MinReturn                                -631.986
NumTrajs                                  119
Perplexity                                411.193
PolicyExecTime                              3.83541
ProcessExecTime                             0.0995781
StdReturn                                 116.608
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.97611
lstm_policy/KLBefore                        1.97611
lstm_policy/LossAfter                      -0.0258433
lstm_policy/LossBefore                     -0.0258433
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:17:12 | [drl] epoch #88 | Obtaining samples...
2020-09-01 14:17:12 | [drl] epoch #88 | Obtaining samples for iteration 88...
2020-09-01 14:17:19 | [drl] epoch #88 | Logging diagnostics...
2020-09-01 14:17:19 | [drl] epoch #88 | Optimizing policy...
2020-09-01 14:17:19 | [drl] epoch #88 | Computing loss before
2020-09-01 14:17:19 | [drl] epoch #88 | Computing KL before
2020-09-01 14:17:19 | [drl] epoch #88 | Optimizing
2020-09-01 14:17:19 | [drl] epoch #88 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:17:19 | [drl] epoch #88 | computing loss before
2020-09-01 14:17:19 | [drl] epoch #88 | computing gradient
2020-09-01 14:17:19 | [drl] epoch #88 | gradient computed
2020-09-01 14:17:19 | [drl] epoch #88 | computing descent direction
2020-09-01 14:17:20 | [drl] epoch #88 | descent direction computed
2020-09-01 14:17:20 | [drl] epoch #88 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:20 | [drl] epoch #88 | Violated because loss not improving
2020-09-01 14:17:20 | [drl] epoch #88 | Violated because constraint mean_kl is violated
2020-09-01 14:17:20 | [drl] epoch #88 | backtrack iters: 14
2020-09-01 14:17:20 | [drl] epoch #88 | optimization finished
2020-09-01 14:17:20 | [drl] epoch #88 | Computing KL after
2020-09-01 14:17:20 | [drl] epoch #88 | Computing loss after
2020-09-01 14:17:20 | [drl] epoch #88 | Fitting baseline...
2020-09-01 14:17:20 | [drl] epoch #88 | Saving snapshot...
2020-09-01 14:17:20 | [drl] epoch #88 | Saved
2020-09-01 14:17:20 | [drl] epoch #88 | Time 726.29 s
2020-09-01 14:17:20 | [drl] epoch #88 | EpochTime 7.95 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.289
AverageReturn                            -415.27
Entropy                                     5.95444
EnvExecTime                                 1.79266
Extras/EpisodeRewardMean                 -415.815
Iteration                                  88
LinearFeatureBaseline/ExplainedVariance     0.598879
MaxReturn                                -288.095
MinReturn                                -640.028
NumTrajs                                  119
Perplexity                                385.463
PolicyExecTime                              3.85515
ProcessExecTime                             0.0999439
StdReturn                                 126.183
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.8015
lstm_policy/KLBefore                        1.8015
lstm_policy/LossAfter                      -0.0133256
lstm_policy/LossBefore                     -0.0133256
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:17:20 | [drl] epoch #89 | Obtaining samples...
2020-09-01 14:17:20 | [drl] epoch #89 | Obtaining samples for iteration 89...
2020-09-01 14:17:27 | [drl] epoch #89 | Logging diagnostics...
2020-09-01 14:17:27 | [drl] epoch #89 | Optimizing policy...
2020-09-01 14:17:27 | [drl] epoch #89 | Computing loss before
2020-09-01 14:17:27 | [drl] epoch #89 | Computing KL before
2020-09-01 14:17:27 | [drl] epoch #89 | Optimizing
2020-09-01 14:17:27 | [drl] epoch #89 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:17:27 | [drl] epoch #89 | computing loss before
2020-09-01 14:17:27 | [drl] epoch #89 | computing gradient
2020-09-01 14:17:27 | [drl] epoch #89 | gradient computed
2020-09-01 14:17:27 | [drl] epoch #89 | computing descent direction
2020-09-01 14:17:28 | [drl] epoch #89 | descent direction computed
2020-09-01 14:17:28 | [drl] epoch #89 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:28 | [drl] epoch #89 | Violated because loss not improving
2020-09-01 14:17:28 | [drl] epoch #89 | Violated because constraint mean_kl is violated
2020-09-01 14:17:28 | [drl] epoch #89 | backtrack iters: 14
2020-09-01 14:17:28 | [drl] epoch #89 | optimization finished
2020-09-01 14:17:28 | [drl] epoch #89 | Computing KL after
2020-09-01 14:17:28 | [drl] epoch #89 | Computing loss after
2020-09-01 14:17:28 | [drl] epoch #89 | Fitting baseline...
2020-09-01 14:17:28 | [drl] epoch #89 | Saving snapshot...
2020-09-01 14:17:28 | [drl] epoch #89 | Saved
2020-09-01 14:17:28 | [drl] epoch #89 | Time 734.27 s
2020-09-01 14:17:28 | [drl] epoch #89 | EpochTime 7.97 s
---------------------------------------  ------------
AverageDiscountedReturn                  -346.854
AverageReturn                            -413.638
Entropy                                     5.96493
EnvExecTime                                 1.77878
Extras/EpisodeRewardMean                 -415.785
Iteration                                  89
LinearFeatureBaseline/ExplainedVariance     0.597204
MaxReturn                                -275.673
MinReturn                                -649.377
NumTrajs                                  118
Perplexity                                389.526
PolicyExecTime                              3.84752
ProcessExecTime                             0.0998247
StdReturn                                 129.176
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78841
lstm_policy/KLBefore                        1.78841
lstm_policy/LossAfter                      -0.0413084
lstm_policy/LossBefore                     -0.0413084
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:17:28 | [drl] epoch #90 | Obtaining samples...
2020-09-01 14:17:28 | [drl] epoch #90 | Obtaining samples for iteration 90...
2020-09-01 14:17:35 | [drl] epoch #90 | Logging diagnostics...
2020-09-01 14:17:35 | [drl] epoch #90 | Optimizing policy...
2020-09-01 14:17:35 | [drl] epoch #90 | Computing loss before
2020-09-01 14:17:35 | [drl] epoch #90 | Computing KL before
2020-09-01 14:17:35 | [drl] epoch #90 | Optimizing
2020-09-01 14:17:35 | [drl] epoch #90 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:17:35 | [drl] epoch #90 | computing loss before
2020-09-01 14:17:35 | [drl] epoch #90 | computing gradient
2020-09-01 14:17:35 | [drl] epoch #90 | gradient computed
2020-09-01 14:17:35 | [drl] epoch #90 | computing descent direction
2020-09-01 14:17:36 | [drl] epoch #90 | descent direction computed
2020-09-01 14:17:36 | [drl] epoch #90 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:36 | [drl] epoch #90 | Violated because loss not improving
2020-09-01 14:17:36 | [drl] epoch #90 | Violated because constraint mean_kl is violated
2020-09-01 14:17:36 | [drl] epoch #90 | backtrack iters: 14
2020-09-01 14:17:36 | [drl] epoch #90 | optimization finished
2020-09-01 14:17:36 | [drl] epoch #90 | Computing KL after
2020-09-01 14:17:36 | [drl] epoch #90 | Computing loss after
2020-09-01 14:17:36 | [drl] epoch #90 | Fitting baseline...
2020-09-01 14:17:36 | [drl] epoch #90 | Saving snapshot...
2020-09-01 14:17:36 | [drl] epoch #90 | Saved
2020-09-01 14:17:36 | [drl] epoch #90 | Time 742.28 s
2020-09-01 14:17:36 | [drl] epoch #90 | EpochTime 8.00 s
---------------------------------------  ------------
AverageDiscountedReturn                  -341.222
AverageReturn                            -404.702
Entropy                                     5.95498
EnvExecTime                                 1.76612
Extras/EpisodeRewardMean                 -408.644
Iteration                                  90
LinearFeatureBaseline/ExplainedVariance     0.617471
MaxReturn                                -282.818
MinReturn                                -634.645
NumTrajs                                  121
Perplexity                                385.669
PolicyExecTime                              3.84781
ProcessExecTime                             0.0991516
StdReturn                                 117.301
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.76489
lstm_policy/KLBefore                        1.76489
lstm_policy/LossAfter                      -0.0394315
lstm_policy/LossBefore                     -0.0394315
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:17:36 | [drl] epoch #91 | Obtaining samples...
2020-09-01 14:17:36 | [drl] epoch #91 | Obtaining samples for iteration 91...
2020-09-01 14:17:43 | [drl] epoch #91 | Logging diagnostics...
2020-09-01 14:17:43 | [drl] epoch #91 | Optimizing policy...
2020-09-01 14:17:43 | [drl] epoch #91 | Computing loss before
2020-09-01 14:17:43 | [drl] epoch #91 | Computing KL before
2020-09-01 14:17:43 | [drl] epoch #91 | Optimizing
2020-09-01 14:17:43 | [drl] epoch #91 | Start CG optimization: #parameters: 19852, #inputs: 125, #subsample_inputs: 125
2020-09-01 14:17:43 | [drl] epoch #91 | computing loss before
2020-09-01 14:17:43 | [drl] epoch #91 | computing gradient
2020-09-01 14:17:43 | [drl] epoch #91 | gradient computed
2020-09-01 14:17:43 | [drl] epoch #91 | computing descent direction
2020-09-01 14:17:44 | [drl] epoch #91 | descent direction computed
2020-09-01 14:17:44 | [drl] epoch #91 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:44 | [drl] epoch #91 | Violated because constraint mean_kl is violated
2020-09-01 14:17:44 | [drl] epoch #91 | backtrack iters: 14
2020-09-01 14:17:44 | [drl] epoch #91 | optimization finished
2020-09-01 14:17:44 | [drl] epoch #91 | Computing KL after
2020-09-01 14:17:44 | [drl] epoch #91 | Computing loss after
2020-09-01 14:17:44 | [drl] epoch #91 | Fitting baseline...
2020-09-01 14:17:44 | [drl] epoch #91 | Saving snapshot...
2020-09-01 14:17:44 | [drl] epoch #91 | Saved
2020-09-01 14:17:44 | [drl] epoch #91 | Time 750.27 s
2020-09-01 14:17:44 | [drl] epoch #91 | EpochTime 7.98 s
---------------------------------------  -------------
AverageDiscountedReturn                  -319.379
AverageReturn                            -372.784
Entropy                                     6.06954
EnvExecTime                                 1.76566
Extras/EpisodeRewardMean                 -374.029
Iteration                                  91
LinearFeatureBaseline/ExplainedVariance     0.680881
MaxReturn                                -276.164
MinReturn                                -642.844
NumTrajs                                  125
Perplexity                                432.482
PolicyExecTime                              3.83525
ProcessExecTime                             0.0987537
StdReturn                                  94.656
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.11049
lstm_policy/KLBefore                        2.11049
lstm_policy/LossAfter                       0.00148166
lstm_policy/LossBefore                      0.00148166
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:17:44 | [drl] epoch #92 | Obtaining samples...
2020-09-01 14:17:44 | [drl] epoch #92 | Obtaining samples for iteration 92...
2020-09-01 14:17:51 | [drl] epoch #92 | Logging diagnostics...
2020-09-01 14:17:51 | [drl] epoch #92 | Optimizing policy...
2020-09-01 14:17:51 | [drl] epoch #92 | Computing loss before
2020-09-01 14:17:51 | [drl] epoch #92 | Computing KL before
2020-09-01 14:17:51 | [drl] epoch #92 | Optimizing
2020-09-01 14:17:51 | [drl] epoch #92 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:17:51 | [drl] epoch #92 | computing loss before
2020-09-01 14:17:51 | [drl] epoch #92 | computing gradient
2020-09-01 14:17:51 | [drl] epoch #92 | gradient computed
2020-09-01 14:17:51 | [drl] epoch #92 | computing descent direction
2020-09-01 14:17:52 | [drl] epoch #92 | descent direction computed
2020-09-01 14:17:52 | [drl] epoch #92 | Line search condition violated. Rejecting the step!
2020-09-01 14:17:52 | [drl] epoch #92 | Violated because constraint mean_kl is violated
2020-09-01 14:17:52 | [drl] epoch #92 | backtrack iters: 14
2020-09-01 14:17:52 | [drl] epoch #92 | optimization finished
2020-09-01 14:17:52 | [drl] epoch #92 | Computing KL after
2020-09-01 14:17:52 | [drl] epoch #92 | Computing loss after
2020-09-01 14:17:52 | [drl] epoch #92 | Fitting baseline...
2020-09-01 14:17:52 | [drl] epoch #92 | Saving snapshot...
2020-09-01 14:17:52 | [drl] epoch #92 | Saved
2020-09-01 14:17:52 | [drl] epoch #92 | Time 758.26 s
2020-09-01 14:17:52 | [drl] epoch #92 | EpochTime 7.98 s
---------------------------------------  -------------
AverageDiscountedReturn                  -354.879
AverageReturn                            -424.973
Entropy                                     5.91568
EnvExecTime                                 1.76982
Extras/EpisodeRewardMean                 -428.886
Iteration                                  92
LinearFeatureBaseline/ExplainedVariance     0.588627
MaxReturn                                -286.202
MinReturn                                -648.517
NumTrajs                                  117
Perplexity                                370.808
PolicyExecTime                              3.84821
ProcessExecTime                             0.0992029
StdReturn                                 126.522
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.65167
lstm_policy/KLBefore                        1.65167
lstm_policy/LossAfter                       0.00892959
lstm_policy/LossBefore                      0.00892959
lstm_policy/dLoss                           0
---------------------------------------  -------------
2020-09-01 14:17:52 | [drl] epoch #93 | Obtaining samples...
2020-09-01 14:17:52 | [drl] epoch #93 | Obtaining samples for iteration 93...
2020-09-01 14:17:59 | [drl] epoch #93 | Logging diagnostics...
2020-09-01 14:17:59 | [drl] epoch #93 | Optimizing policy...
2020-09-01 14:17:59 | [drl] epoch #93 | Computing loss before
2020-09-01 14:17:59 | [drl] epoch #93 | Computing KL before
2020-09-01 14:17:59 | [drl] epoch #93 | Optimizing
2020-09-01 14:17:59 | [drl] epoch #93 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:17:59 | [drl] epoch #93 | computing loss before
2020-09-01 14:17:59 | [drl] epoch #93 | computing gradient
2020-09-01 14:17:59 | [drl] epoch #93 | gradient computed
2020-09-01 14:17:59 | [drl] epoch #93 | computing descent direction
2020-09-01 14:18:00 | [drl] epoch #93 | descent direction computed
2020-09-01 14:18:00 | [drl] epoch #93 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:00 | [drl] epoch #93 | Violated because loss not improving
2020-09-01 14:18:00 | [drl] epoch #93 | Violated because constraint mean_kl is violated
2020-09-01 14:18:00 | [drl] epoch #93 | backtrack iters: 14
2020-09-01 14:18:00 | [drl] epoch #93 | optimization finished
2020-09-01 14:18:00 | [drl] epoch #93 | Computing KL after
2020-09-01 14:18:00 | [drl] epoch #93 | Computing loss after
2020-09-01 14:18:00 | [drl] epoch #93 | Fitting baseline...
2020-09-01 14:18:00 | [drl] epoch #93 | Saving snapshot...
2020-09-01 14:18:00 | [drl] epoch #93 | Saved
2020-09-01 14:18:00 | [drl] epoch #93 | Time 766.23 s
2020-09-01 14:18:00 | [drl] epoch #93 | EpochTime 7.96 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.479
AverageReturn                            -410.718
Entropy                                     5.96312
EnvExecTime                                 1.78542
Extras/EpisodeRewardMean                 -409.987
Iteration                                  93
LinearFeatureBaseline/ExplainedVariance     0.60069
MaxReturn                                -284.158
MinReturn                                -637.64
NumTrajs                                  118
Perplexity                                388.822
PolicyExecTime                              3.83209
ProcessExecTime                             0.0998721
StdReturn                                 123.809
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.78016
lstm_policy/KLBefore                        1.78016
lstm_policy/LossAfter                      -0.0377102
lstm_policy/LossBefore                     -0.0377102
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:00 | [drl] epoch #94 | Obtaining samples...
2020-09-01 14:18:00 | [drl] epoch #94 | Obtaining samples for iteration 94...
2020-09-01 14:18:06 | [drl] epoch #94 | Logging diagnostics...
2020-09-01 14:18:06 | [drl] epoch #94 | Optimizing policy...
2020-09-01 14:18:06 | [drl] epoch #94 | Computing loss before
2020-09-01 14:18:07 | [drl] epoch #94 | Computing KL before
2020-09-01 14:18:07 | [drl] epoch #94 | Optimizing
2020-09-01 14:18:07 | [drl] epoch #94 | Start CG optimization: #parameters: 19852, #inputs: 117, #subsample_inputs: 117
2020-09-01 14:18:07 | [drl] epoch #94 | computing loss before
2020-09-01 14:18:07 | [drl] epoch #94 | computing gradient
2020-09-01 14:18:07 | [drl] epoch #94 | gradient computed
2020-09-01 14:18:07 | [drl] epoch #94 | computing descent direction
2020-09-01 14:18:08 | [drl] epoch #94 | descent direction computed
2020-09-01 14:18:08 | [drl] epoch #94 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:08 | [drl] epoch #94 | Violated because loss not improving
2020-09-01 14:18:08 | [drl] epoch #94 | Violated because constraint mean_kl is violated
2020-09-01 14:18:08 | [drl] epoch #94 | backtrack iters: 14
2020-09-01 14:18:08 | [drl] epoch #94 | optimization finished
2020-09-01 14:18:08 | [drl] epoch #94 | Computing KL after
2020-09-01 14:18:08 | [drl] epoch #94 | Computing loss after
2020-09-01 14:18:08 | [drl] epoch #94 | Fitting baseline...
2020-09-01 14:18:08 | [drl] epoch #94 | Saving snapshot...
2020-09-01 14:18:08 | [drl] epoch #94 | Saved
2020-09-01 14:18:08 | [drl] epoch #94 | Time 774.16 s
2020-09-01 14:18:08 | [drl] epoch #94 | EpochTime 7.92 s
---------------------------------------  ------------
AverageDiscountedReturn                  -340.22
AverageReturn                            -403.879
Entropy                                     6.04223
EnvExecTime                                 1.77241
Extras/EpisodeRewardMean                 -404.817
Iteration                                  94
LinearFeatureBaseline/ExplainedVariance     0.623537
MaxReturn                                -282.13
MinReturn                                -646.329
NumTrajs                                  117
Perplexity                                420.832
PolicyExecTime                              3.83131
ProcessExecTime                             0.101008
StdReturn                                 119.715
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              2.10227
lstm_policy/KLBefore                        2.10227
lstm_policy/LossAfter                      -0.0360822
lstm_policy/LossBefore                     -0.0360822
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:08 | [drl] epoch #95 | Obtaining samples...
2020-09-01 14:18:08 | [drl] epoch #95 | Obtaining samples for iteration 95...
2020-09-01 14:18:14 | [drl] epoch #95 | Logging diagnostics...
2020-09-01 14:18:14 | [drl] epoch #95 | Optimizing policy...
2020-09-01 14:18:14 | [drl] epoch #95 | Computing loss before
2020-09-01 14:18:14 | [drl] epoch #95 | Computing KL before
2020-09-01 14:18:15 | [drl] epoch #95 | Optimizing
2020-09-01 14:18:15 | [drl] epoch #95 | Start CG optimization: #parameters: 19852, #inputs: 120, #subsample_inputs: 120
2020-09-01 14:18:15 | [drl] epoch #95 | computing loss before
2020-09-01 14:18:15 | [drl] epoch #95 | computing gradient
2020-09-01 14:18:15 | [drl] epoch #95 | gradient computed
2020-09-01 14:18:15 | [drl] epoch #95 | computing descent direction
2020-09-01 14:18:16 | [drl] epoch #95 | descent direction computed
2020-09-01 14:18:16 | [drl] epoch #95 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:16 | [drl] epoch #95 | Violated because constraint mean_kl is violated
2020-09-01 14:18:16 | [drl] epoch #95 | backtrack iters: 14
2020-09-01 14:18:16 | [drl] epoch #95 | optimization finished
2020-09-01 14:18:16 | [drl] epoch #95 | Computing KL after
2020-09-01 14:18:16 | [drl] epoch #95 | Computing loss after
2020-09-01 14:18:16 | [drl] epoch #95 | Fitting baseline...
2020-09-01 14:18:16 | [drl] epoch #95 | Saving snapshot...
2020-09-01 14:18:16 | [drl] epoch #95 | Saved
2020-09-01 14:18:16 | [drl] epoch #95 | Time 782.18 s
2020-09-01 14:18:16 | [drl] epoch #95 | EpochTime 8.01 s
---------------------------------------  ------------
AverageDiscountedReturn                  -348.764
AverageReturn                            -416.455
Entropy                                     5.8965
EnvExecTime                                 1.77232
Extras/EpisodeRewardMean                 -414.974
Iteration                                  95
LinearFeatureBaseline/ExplainedVariance     0.58996
MaxReturn                                -284.116
MinReturn                                -642.874
NumTrajs                                  120
Perplexity                                363.762
PolicyExecTime                              3.86053
ProcessExecTime                             0.0994642
StdReturn                                 125.692
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.55653
lstm_policy/KLBefore                        1.55653
lstm_policy/LossAfter                      -0.0242823
lstm_policy/LossBefore                     -0.0242823
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:16 | [drl] epoch #96 | Obtaining samples...
2020-09-01 14:18:16 | [drl] epoch #96 | Obtaining samples for iteration 96...
2020-09-01 14:18:22 | [drl] epoch #96 | Logging diagnostics...
2020-09-01 14:18:22 | [drl] epoch #96 | Optimizing policy...
2020-09-01 14:18:22 | [drl] epoch #96 | Computing loss before
2020-09-01 14:18:23 | [drl] epoch #96 | Computing KL before
2020-09-01 14:18:23 | [drl] epoch #96 | Optimizing
2020-09-01 14:18:23 | [drl] epoch #96 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:18:23 | [drl] epoch #96 | computing loss before
2020-09-01 14:18:23 | [drl] epoch #96 | computing gradient
2020-09-01 14:18:23 | [drl] epoch #96 | gradient computed
2020-09-01 14:18:23 | [drl] epoch #96 | computing descent direction
2020-09-01 14:18:24 | [drl] epoch #96 | descent direction computed
2020-09-01 14:18:24 | [drl] epoch #96 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:24 | [drl] epoch #96 | Violated because loss not improving
2020-09-01 14:18:24 | [drl] epoch #96 | Violated because constraint mean_kl is violated
2020-09-01 14:18:24 | [drl] epoch #96 | backtrack iters: 14
2020-09-01 14:18:24 | [drl] epoch #96 | optimization finished
2020-09-01 14:18:24 | [drl] epoch #96 | Computing KL after
2020-09-01 14:18:24 | [drl] epoch #96 | Computing loss after
2020-09-01 14:18:24 | [drl] epoch #96 | Fitting baseline...
2020-09-01 14:18:24 | [drl] epoch #96 | Saving snapshot...
2020-09-01 14:18:24 | [drl] epoch #96 | Saved
2020-09-01 14:18:24 | [drl] epoch #96 | Time 790.20 s
2020-09-01 14:18:24 | [drl] epoch #96 | EpochTime 8.01 s
---------------------------------------  ------------
AverageDiscountedReturn                  -344.036
AverageReturn                            -409.338
Entropy                                     5.92883
EnvExecTime                                 1.78046
Extras/EpisodeRewardMean                 -415.233
Iteration                                  96
LinearFeatureBaseline/ExplainedVariance     0.599645
MaxReturn                                -286.713
MinReturn                                -637.865
NumTrajs                                  121
Perplexity                                375.715
PolicyExecTime                              3.85627
ProcessExecTime                             0.100556
StdReturn                                 122.281
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.63706
lstm_policy/KLBefore                        1.63706
lstm_policy/LossAfter                      -0.0340754
lstm_policy/LossBefore                     -0.0340754
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:24 | [drl] epoch #97 | Obtaining samples...
2020-09-01 14:18:24 | [drl] epoch #97 | Obtaining samples for iteration 97...
2020-09-01 14:18:31 | [drl] epoch #97 | Logging diagnostics...
2020-09-01 14:18:31 | [drl] epoch #97 | Optimizing policy...
2020-09-01 14:18:31 | [drl] epoch #97 | Computing loss before
2020-09-01 14:18:31 | [drl] epoch #97 | Computing KL before
2020-09-01 14:18:31 | [drl] epoch #97 | Optimizing
2020-09-01 14:18:31 | [drl] epoch #97 | Start CG optimization: #parameters: 19852, #inputs: 116, #subsample_inputs: 116
2020-09-01 14:18:31 | [drl] epoch #97 | computing loss before
2020-09-01 14:18:31 | [drl] epoch #97 | computing gradient
2020-09-01 14:18:31 | [drl] epoch #97 | gradient computed
2020-09-01 14:18:31 | [drl] epoch #97 | computing descent direction
2020-09-01 14:18:32 | [drl] epoch #97 | descent direction computed
2020-09-01 14:18:32 | [drl] epoch #97 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:32 | [drl] epoch #97 | Violated because loss not improving
2020-09-01 14:18:32 | [drl] epoch #97 | Violated because constraint mean_kl is violated
2020-09-01 14:18:32 | [drl] epoch #97 | backtrack iters: 14
2020-09-01 14:18:32 | [drl] epoch #97 | optimization finished
2020-09-01 14:18:32 | [drl] epoch #97 | Computing KL after
2020-09-01 14:18:32 | [drl] epoch #97 | Computing loss after
2020-09-01 14:18:32 | [drl] epoch #97 | Fitting baseline...
2020-09-01 14:18:32 | [drl] epoch #97 | Saving snapshot...
2020-09-01 14:18:32 | [drl] epoch #97 | Saved
2020-09-01 14:18:32 | [drl] epoch #97 | Time 798.30 s
2020-09-01 14:18:32 | [drl] epoch #97 | EpochTime 8.09 s
---------------------------------------  ------------
AverageDiscountedReturn                  -352.773
AverageReturn                            -421.692
Entropy                                     5.96635
EnvExecTime                                 1.79383
Extras/EpisodeRewardMean                 -421.896
Iteration                                  97
LinearFeatureBaseline/ExplainedVariance     0.605281
MaxReturn                                -282.373
MinReturn                                -638.953
NumTrajs                                  116
Perplexity                                390.08
PolicyExecTime                              3.96051
ProcessExecTime                             0.10324
StdReturn                                 128.859
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.82346
lstm_policy/KLBefore                        1.82346
lstm_policy/LossAfter                      -0.0384238
lstm_policy/LossBefore                     -0.0384238
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:32 | [drl] epoch #98 | Obtaining samples...
2020-09-01 14:18:32 | [drl] epoch #98 | Obtaining samples for iteration 98...
2020-09-01 14:18:39 | [drl] epoch #98 | Logging diagnostics...
2020-09-01 14:18:39 | [drl] epoch #98 | Optimizing policy...
2020-09-01 14:18:39 | [drl] epoch #98 | Computing loss before
2020-09-01 14:18:39 | [drl] epoch #98 | Computing KL before
2020-09-01 14:18:39 | [drl] epoch #98 | Optimizing
2020-09-01 14:18:39 | [drl] epoch #98 | Start CG optimization: #parameters: 19852, #inputs: 118, #subsample_inputs: 118
2020-09-01 14:18:39 | [drl] epoch #98 | computing loss before
2020-09-01 14:18:39 | [drl] epoch #98 | computing gradient
2020-09-01 14:18:39 | [drl] epoch #98 | gradient computed
2020-09-01 14:18:39 | [drl] epoch #98 | computing descent direction
2020-09-01 14:18:40 | [drl] epoch #98 | descent direction computed
2020-09-01 14:18:40 | [drl] epoch #98 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:40 | [drl] epoch #98 | Violated because constraint mean_kl is violated
2020-09-01 14:18:40 | [drl] epoch #98 | backtrack iters: 14
2020-09-01 14:18:40 | [drl] epoch #98 | optimization finished
2020-09-01 14:18:40 | [drl] epoch #98 | Computing KL after
2020-09-01 14:18:40 | [drl] epoch #98 | Computing loss after
2020-09-01 14:18:40 | [drl] epoch #98 | Fitting baseline...
2020-09-01 14:18:40 | [drl] epoch #98 | Saving snapshot...
2020-09-01 14:18:40 | [drl] epoch #98 | Saved
2020-09-01 14:18:40 | [drl] epoch #98 | Time 806.35 s
2020-09-01 14:18:40 | [drl] epoch #98 | EpochTime 8.04 s
---------------------------------------  ------------
AverageDiscountedReturn                  -343.62
AverageReturn                            -408.162
Entropy                                     6.01125
EnvExecTime                                 1.77295
Extras/EpisodeRewardMean                 -398.99
Iteration                                  98
LinearFeatureBaseline/ExplainedVariance     0.623821
MaxReturn                                -287.156
MinReturn                                -640.305
NumTrajs                                  118
Perplexity                                407.992
PolicyExecTime                              3.87051
ProcessExecTime                             0.0993423
StdReturn                                 120.311
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.9538
lstm_policy/KLBefore                        1.9538
lstm_policy/LossAfter                      -0.0392751
lstm_policy/LossBefore                     -0.0392751
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:40 | [drl] epoch #99 | Obtaining samples...
2020-09-01 14:18:40 | [drl] epoch #99 | Obtaining samples for iteration 99...
2020-09-01 14:18:47 | [drl] epoch #99 | Logging diagnostics...
2020-09-01 14:18:47 | [drl] epoch #99 | Optimizing policy...
2020-09-01 14:18:47 | [drl] epoch #99 | Computing loss before
2020-09-01 14:18:47 | [drl] epoch #99 | Computing KL before
2020-09-01 14:18:47 | [drl] epoch #99 | Optimizing
2020-09-01 14:18:47 | [drl] epoch #99 | Start CG optimization: #parameters: 19852, #inputs: 119, #subsample_inputs: 119
2020-09-01 14:18:47 | [drl] epoch #99 | computing loss before
2020-09-01 14:18:47 | [drl] epoch #99 | computing gradient
2020-09-01 14:18:47 | [drl] epoch #99 | gradient computed
2020-09-01 14:18:47 | [drl] epoch #99 | computing descent direction
2020-09-01 14:18:48 | [drl] epoch #99 | descent direction computed
2020-09-01 14:18:48 | [drl] epoch #99 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:48 | [drl] epoch #99 | Violated because loss not improving
2020-09-01 14:18:48 | [drl] epoch #99 | Violated because constraint mean_kl is violated
2020-09-01 14:18:48 | [drl] epoch #99 | backtrack iters: 14
2020-09-01 14:18:48 | [drl] epoch #99 | optimization finished
2020-09-01 14:18:48 | [drl] epoch #99 | Computing KL after
2020-09-01 14:18:48 | [drl] epoch #99 | Computing loss after
2020-09-01 14:18:48 | [drl] epoch #99 | Fitting baseline...
2020-09-01 14:18:48 | [drl] epoch #99 | Saving snapshot...
2020-09-01 14:18:48 | [drl] epoch #99 | Saved
2020-09-01 14:18:48 | [drl] epoch #99 | Time 814.32 s
2020-09-01 14:18:48 | [drl] epoch #99 | EpochTime 7.95 s
---------------------------------------  ------------
AverageDiscountedReturn                  -350.05
AverageReturn                            -417.651
Entropy                                     5.91303
EnvExecTime                                 1.7771
Extras/EpisodeRewardMean                 -419.574
Iteration                                  99
LinearFeatureBaseline/ExplainedVariance     0.606558
MaxReturn                                -290.367
MinReturn                                -650.249
NumTrajs                                  119
Perplexity                                369.824
PolicyExecTime                              3.82831
ProcessExecTime                             0.0995874
StdReturn                                 123.994
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.60679
lstm_policy/KLBefore                        1.60679
lstm_policy/LossAfter                      -0.0264729
lstm_policy/LossBefore                     -0.0264729
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-01 14:18:48 | [drl] epoch #100 | Obtaining samples...
2020-09-01 14:18:48 | [drl] epoch #100 | Obtaining samples for iteration 100...
2020-09-01 14:18:55 | [drl] epoch #100 | Logging diagnostics...
2020-09-01 14:18:55 | [drl] epoch #100 | Optimizing policy...
2020-09-01 14:18:55 | [drl] epoch #100 | Computing loss before
2020-09-01 14:18:55 | [drl] epoch #100 | Computing KL before
2020-09-01 14:18:55 | [drl] epoch #100 | Optimizing
2020-09-01 14:18:55 | [drl] epoch #100 | Start CG optimization: #parameters: 19852, #inputs: 121, #subsample_inputs: 121
2020-09-01 14:18:55 | [drl] epoch #100 | computing loss before
2020-09-01 14:18:55 | [drl] epoch #100 | computing gradient
2020-09-01 14:18:55 | [drl] epoch #100 | gradient computed
2020-09-01 14:18:55 | [drl] epoch #100 | computing descent direction
2020-09-01 14:18:56 | [drl] epoch #100 | descent direction computed
2020-09-01 14:18:56 | [drl] epoch #100 | Line search condition violated. Rejecting the step!
2020-09-01 14:18:56 | [drl] epoch #100 | Violated because constraint mean_kl is violated
2020-09-01 14:18:56 | [drl] epoch #100 | backtrack iters: 14
2020-09-01 14:18:56 | [drl] epoch #100 | optimization finished
2020-09-01 14:18:56 | [drl] epoch #100 | Computing KL after
2020-09-01 14:18:56 | [drl] epoch #100 | Computing loss after
2020-09-01 14:18:56 | [drl] epoch #100 | Fitting baseline...
2020-09-01 14:18:56 | [drl] epoch #100 | Saving snapshot...
2020-09-01 14:18:56 | [drl] epoch #100 | Saved
2020-09-01 14:18:56 | [drl] epoch #100 | Time 822.35 s
2020-09-01 14:18:56 | [drl] epoch #100 | EpochTime 8.02 s
---------------------------------------  ------------
AverageDiscountedReturn                  -342.314
AverageReturn                            -407.367
Entropy                                     5.91886
EnvExecTime                                 1.76851
Extras/EpisodeRewardMean                 -409.428
Iteration                                 100
LinearFeatureBaseline/ExplainedVariance     0.596159
MaxReturn                                -275.705
MinReturn                                -656.444
NumTrajs                                  121
Perplexity                                371.989
PolicyExecTime                              3.85445
ProcessExecTime                             0.0989974
StdReturn                                 122.396
lstm_policy/Entropy                         5.41667
lstm_policy/KL                              1.61373
lstm_policy/KLBefore                        1.61373
lstm_policy/LossAfter                      -0.0287974
lstm_policy/LossBefore                     -0.0287974
lstm_policy/dLoss                           0
---------------------------------------  ------------
2020-09-03 14:58:55 | [drl] epoch #0 | Obtaining samples...
2020-09-03 14:58:55 | [drl] epoch #0 | Obtaining samples for iteration 0...
2020-09-03 14:58:56 | [drl] epoch #0 | Logging diagnostics...
2020-09-03 14:58:56 | [drl] epoch #0 | Optimizing policy...
2020-09-03 14:58:56 | [drl] epoch #0 | Computing loss before
2020-09-03 14:58:56 | [drl] epoch #0 | Computing KL before
2020-09-03 14:58:56 | [drl] epoch #0 | Optimizing
2020-09-03 14:58:56 | [drl] epoch #0 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:58:56 | [drl] epoch #0 | computing loss before
2020-09-03 14:58:56 | [drl] epoch #0 | computing gradient
2020-09-03 14:58:56 | [drl] epoch #0 | gradient computed
2020-09-03 14:58:56 | [drl] epoch #0 | computing descent direction
2020-09-03 14:58:57 | [drl] epoch #0 | descent direction computed
2020-09-03 14:58:57 | [drl] epoch #0 | Line search condition violated. Rejecting the step!
2020-09-03 14:58:57 | [drl] epoch #0 | Violated because loss is NaN
2020-09-03 14:58:57 | [drl] epoch #0 | Violated because constraint mean_kl is NaN
2020-09-03 14:58:57 | [drl] epoch #0 | backtrack iters: 14
2020-09-03 14:58:57 | [drl] epoch #0 | optimization finished
2020-09-03 14:58:57 | [drl] epoch #0 | Computing KL after
2020-09-03 14:58:57 | [drl] epoch #0 | Computing loss after
2020-09-03 14:58:57 | [drl] epoch #0 | Fitting baseline...
2020-09-03 14:58:57 | [drl] epoch #0 | Saving snapshot...
2020-09-03 14:58:57 | [drl] epoch #0 | Saved
2020-09-03 14:58:57 | [drl] epoch #0 | Time 1.92 s
2020-09-03 14:58:57 | [drl] epoch #0 | EpochTime 1.92 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -120282
AverageReturn                            -196586
Entropy                                        8.51363
EnvExecTime                                    0.0355582
Extras/EpisodeRewardMean                 -196586
Iteration                                      0
LinearFeatureBaseline/ExplainedVariance        7.22073e-08
MaxReturn                                -196586
MinReturn                                -196586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.335925
ProcessExecTime                                0.000996113
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:58:57 | [drl] epoch #1 | Obtaining samples...
2020-09-03 14:58:57 | [drl] epoch #1 | Obtaining samples for iteration 1...
2020-09-03 14:58:58 | [drl] epoch #1 | Logging diagnostics...
2020-09-03 14:58:58 | [drl] epoch #1 | Optimizing policy...
2020-09-03 14:58:58 | [drl] epoch #1 | Computing loss before
2020-09-03 14:58:58 | [drl] epoch #1 | Computing KL before
2020-09-03 14:58:58 | [drl] epoch #1 | Optimizing
2020-09-03 14:58:58 | [drl] epoch #1 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:58:58 | [drl] epoch #1 | computing loss before
2020-09-03 14:58:58 | [drl] epoch #1 | computing gradient
2020-09-03 14:58:58 | [drl] epoch #1 | gradient computed
2020-09-03 14:58:58 | [drl] epoch #1 | computing descent direction
2020-09-03 14:58:58 | [drl] epoch #1 | descent direction computed
2020-09-03 14:58:58 | [drl] epoch #1 | Line search condition violated. Rejecting the step!
2020-09-03 14:58:58 | [drl] epoch #1 | Violated because loss is NaN
2020-09-03 14:58:58 | [drl] epoch #1 | Violated because constraint mean_kl is NaN
2020-09-03 14:58:58 | [drl] epoch #1 | backtrack iters: 14
2020-09-03 14:58:58 | [drl] epoch #1 | optimization finished
2020-09-03 14:58:58 | [drl] epoch #1 | Computing KL after
2020-09-03 14:58:58 | [drl] epoch #1 | Computing loss after
2020-09-03 14:58:58 | [drl] epoch #1 | Fitting baseline...
2020-09-03 14:58:58 | [drl] epoch #1 | Saving snapshot...
2020-09-03 14:58:58 | [drl] epoch #1 | Saved
2020-09-03 14:58:58 | [drl] epoch #1 | Time 2.62 s
2020-09-03 14:58:58 | [drl] epoch #1 | EpochTime 0.69 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -185827
AverageReturn                            -303842
Entropy                                        8.51363
EnvExecTime                                    0.0352473
Extras/EpisodeRewardMean                 -250214
Iteration                                      1
LinearFeatureBaseline/ExplainedVariance        0.873328
MaxReturn                                -303842
MinReturn                                -303842
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0408287
ProcessExecTime                                0.000977516
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:58:58 | [drl] epoch #2 | Obtaining samples...
2020-09-03 14:58:58 | [drl] epoch #2 | Obtaining samples for iteration 2...
2020-09-03 14:58:58 | [drl] epoch #2 | Logging diagnostics...
2020-09-03 14:58:58 | [drl] epoch #2 | Optimizing policy...
2020-09-03 14:58:58 | [drl] epoch #2 | Computing loss before
2020-09-03 14:58:58 | [drl] epoch #2 | Computing KL before
2020-09-03 14:58:58 | [drl] epoch #2 | Optimizing
2020-09-03 14:58:58 | [drl] epoch #2 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:58:58 | [drl] epoch #2 | computing loss before
2020-09-03 14:58:58 | [drl] epoch #2 | computing gradient
2020-09-03 14:58:58 | [drl] epoch #2 | gradient computed
2020-09-03 14:58:58 | [drl] epoch #2 | computing descent direction
2020-09-03 14:58:59 | [drl] epoch #2 | descent direction computed
2020-09-03 14:58:59 | [drl] epoch #2 | Line search condition violated. Rejecting the step!
2020-09-03 14:58:59 | [drl] epoch #2 | Violated because loss is NaN
2020-09-03 14:58:59 | [drl] epoch #2 | Violated because constraint mean_kl is NaN
2020-09-03 14:58:59 | [drl] epoch #2 | backtrack iters: 14
2020-09-03 14:58:59 | [drl] epoch #2 | optimization finished
2020-09-03 14:58:59 | [drl] epoch #2 | Computing KL after
2020-09-03 14:58:59 | [drl] epoch #2 | Computing loss after
2020-09-03 14:58:59 | [drl] epoch #2 | Fitting baseline...
2020-09-03 14:58:59 | [drl] epoch #2 | Saving snapshot...
2020-09-03 14:58:59 | [drl] epoch #2 | Saved
2020-09-03 14:58:59 | [drl] epoch #2 | Time 3.33 s
2020-09-03 14:58:59 | [drl] epoch #2 | EpochTime 0.69 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -137108
AverageReturn                            -224135
Entropy                                        8.51363
EnvExecTime                                    0.039252
Extras/EpisodeRewardMean                 -241521
Iteration                                      2
LinearFeatureBaseline/ExplainedVariance        0.871718
MaxReturn                                -224135
MinReturn                                -224135
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.038281
ProcessExecTime                                0.000966072
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:58:59 | [drl] epoch #3 | Obtaining samples...
2020-09-03 14:58:59 | [drl] epoch #3 | Obtaining samples for iteration 3...
2020-09-03 14:58:59 | [drl] epoch #3 | Logging diagnostics...
2020-09-03 14:58:59 | [drl] epoch #3 | Optimizing policy...
2020-09-03 14:58:59 | [drl] epoch #3 | Computing loss before
2020-09-03 14:58:59 | [drl] epoch #3 | Computing KL before
2020-09-03 14:58:59 | [drl] epoch #3 | Optimizing
2020-09-03 14:58:59 | [drl] epoch #3 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:58:59 | [drl] epoch #3 | computing loss before
2020-09-03 14:58:59 | [drl] epoch #3 | computing gradient
2020-09-03 14:58:59 | [drl] epoch #3 | gradient computed
2020-09-03 14:58:59 | [drl] epoch #3 | computing descent direction
2020-09-03 14:58:59 | [drl] epoch #3 | descent direction computed
2020-09-03 14:59:00 | [drl] epoch #3 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:00 | [drl] epoch #3 | Violated because loss is NaN
2020-09-03 14:59:00 | [drl] epoch #3 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:00 | [drl] epoch #3 | backtrack iters: 14
2020-09-03 14:59:00 | [drl] epoch #3 | optimization finished
2020-09-03 14:59:00 | [drl] epoch #3 | Computing KL after
2020-09-03 14:59:00 | [drl] epoch #3 | Computing loss after
2020-09-03 14:59:00 | [drl] epoch #3 | Fitting baseline...
2020-09-03 14:59:00 | [drl] epoch #3 | Saving snapshot...
2020-09-03 14:59:00 | [drl] epoch #3 | Saved
2020-09-03 14:59:00 | [drl] epoch #3 | Time 4.08 s
2020-09-03 14:59:00 | [drl] epoch #3 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -84596.1
AverageReturn                            -138193
Entropy                                        8.51363
EnvExecTime                                    0.0443826
Extras/EpisodeRewardMean                 -215689
Iteration                                      3
LinearFeatureBaseline/ExplainedVariance        0.597185
MaxReturn                                -138193
MinReturn                                -138193
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0390809
ProcessExecTime                                0.000974655
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:00 | [drl] epoch #4 | Obtaining samples...
2020-09-03 14:59:00 | [drl] epoch #4 | Obtaining samples for iteration 4...
2020-09-03 14:59:00 | [drl] epoch #4 | Logging diagnostics...
2020-09-03 14:59:00 | [drl] epoch #4 | Optimizing policy...
2020-09-03 14:59:00 | [drl] epoch #4 | Computing loss before
2020-09-03 14:59:00 | [drl] epoch #4 | Computing KL before
2020-09-03 14:59:00 | [drl] epoch #4 | Optimizing
2020-09-03 14:59:00 | [drl] epoch #4 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:00 | [drl] epoch #4 | computing loss before
2020-09-03 14:59:00 | [drl] epoch #4 | computing gradient
2020-09-03 14:59:00 | [drl] epoch #4 | gradient computed
2020-09-03 14:59:00 | [drl] epoch #4 | computing descent direction
2020-09-03 14:59:00 | [drl] epoch #4 | descent direction computed
2020-09-03 14:59:00 | [drl] epoch #4 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:00 | [drl] epoch #4 | Violated because loss is NaN
2020-09-03 14:59:00 | [drl] epoch #4 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:00 | [drl] epoch #4 | backtrack iters: 14
2020-09-03 14:59:00 | [drl] epoch #4 | optimization finished
2020-09-03 14:59:00 | [drl] epoch #4 | Computing KL after
2020-09-03 14:59:00 | [drl] epoch #4 | Computing loss after
2020-09-03 14:59:00 | [drl] epoch #4 | Fitting baseline...
2020-09-03 14:59:00 | [drl] epoch #4 | Saving snapshot...
2020-09-03 14:59:00 | [drl] epoch #4 | Saved
2020-09-03 14:59:00 | [drl] epoch #4 | Time 4.83 s
2020-09-03 14:59:00 | [drl] epoch #4 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -166430
AverageReturn                            -272108
Entropy                                        8.51363
EnvExecTime                                    0.0363894
Extras/EpisodeRewardMean                 -226973
Iteration                                      4
LinearFeatureBaseline/ExplainedVariance        0.753183
MaxReturn                                -272108
MinReturn                                -272108
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0467875
ProcessExecTime                                0.00102282
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:00 | [drl] epoch #5 | Obtaining samples...
2020-09-03 14:59:00 | [drl] epoch #5 | Obtaining samples for iteration 5...
2020-09-03 14:59:00 | [drl] epoch #5 | Logging diagnostics...
2020-09-03 14:59:00 | [drl] epoch #5 | Optimizing policy...
2020-09-03 14:59:00 | [drl] epoch #5 | Computing loss before
2020-09-03 14:59:00 | [drl] epoch #5 | Computing KL before
2020-09-03 14:59:00 | [drl] epoch #5 | Optimizing
2020-09-03 14:59:00 | [drl] epoch #5 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:00 | [drl] epoch #5 | computing loss before
2020-09-03 14:59:00 | [drl] epoch #5 | computing gradient
2020-09-03 14:59:00 | [drl] epoch #5 | gradient computed
2020-09-03 14:59:00 | [drl] epoch #5 | computing descent direction
2020-09-03 14:59:01 | [drl] epoch #5 | descent direction computed
2020-09-03 14:59:01 | [drl] epoch #5 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:01 | [drl] epoch #5 | Violated because loss is NaN
2020-09-03 14:59:01 | [drl] epoch #5 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:01 | [drl] epoch #5 | backtrack iters: 14
2020-09-03 14:59:01 | [drl] epoch #5 | optimization finished
2020-09-03 14:59:01 | [drl] epoch #5 | Computing KL after
2020-09-03 14:59:01 | [drl] epoch #5 | Computing loss after
2020-09-03 14:59:01 | [drl] epoch #5 | Fitting baseline...
2020-09-03 14:59:01 | [drl] epoch #5 | Saving snapshot...
2020-09-03 14:59:01 | [drl] epoch #5 | Saved
2020-09-03 14:59:01 | [drl] epoch #5 | Time 5.61 s
2020-09-03 14:59:01 | [drl] epoch #5 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -131569
AverageReturn                            -215054
Entropy                                        8.51363
EnvExecTime                                    0.0390949
Extras/EpisodeRewardMean                 -224986
Iteration                                      5
LinearFeatureBaseline/ExplainedVariance        0.927991
MaxReturn                                -215054
MinReturn                                -215054
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0470319
ProcessExecTime                                0.000973701
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:01 | [drl] epoch #6 | Obtaining samples...
2020-09-03 14:59:01 | [drl] epoch #6 | Obtaining samples for iteration 6...
2020-09-03 14:59:01 | [drl] epoch #6 | Logging diagnostics...
2020-09-03 14:59:01 | [drl] epoch #6 | Optimizing policy...
2020-09-03 14:59:01 | [drl] epoch #6 | Computing loss before
2020-09-03 14:59:01 | [drl] epoch #6 | Computing KL before
2020-09-03 14:59:01 | [drl] epoch #6 | Optimizing
2020-09-03 14:59:01 | [drl] epoch #6 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:01 | [drl] epoch #6 | computing loss before
2020-09-03 14:59:01 | [drl] epoch #6 | computing gradient
2020-09-03 14:59:01 | [drl] epoch #6 | gradient computed
2020-09-03 14:59:01 | [drl] epoch #6 | computing descent direction
2020-09-03 14:59:02 | [drl] epoch #6 | descent direction computed
2020-09-03 14:59:02 | [drl] epoch #6 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:02 | [drl] epoch #6 | Violated because loss is NaN
2020-09-03 14:59:02 | [drl] epoch #6 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:02 | [drl] epoch #6 | backtrack iters: 14
2020-09-03 14:59:02 | [drl] epoch #6 | optimization finished
2020-09-03 14:59:02 | [drl] epoch #6 | Computing KL after
2020-09-03 14:59:02 | [drl] epoch #6 | Computing loss after
2020-09-03 14:59:02 | [drl] epoch #6 | Fitting baseline...
2020-09-03 14:59:02 | [drl] epoch #6 | Saving snapshot...
2020-09-03 14:59:02 | [drl] epoch #6 | Saved
2020-09-03 14:59:02 | [drl] epoch #6 | Time 6.43 s
2020-09-03 14:59:02 | [drl] epoch #6 | EpochTime 0.81 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -100550
AverageReturn                            -164312
Entropy                                        8.51363
EnvExecTime                                    0.0406573
Extras/EpisodeRewardMean                 -216319
Iteration                                      6
LinearFeatureBaseline/ExplainedVariance        0.901804
MaxReturn                                -164312
MinReturn                                -164312
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0469944
ProcessExecTime                                0.00102234
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:02 | [drl] epoch #7 | Obtaining samples...
2020-09-03 14:59:02 | [drl] epoch #7 | Obtaining samples for iteration 7...
2020-09-03 14:59:02 | [drl] epoch #7 | Logging diagnostics...
2020-09-03 14:59:02 | [drl] epoch #7 | Optimizing policy...
2020-09-03 14:59:02 | [drl] epoch #7 | Computing loss before
2020-09-03 14:59:02 | [drl] epoch #7 | Computing KL before
2020-09-03 14:59:02 | [drl] epoch #7 | Optimizing
2020-09-03 14:59:02 | [drl] epoch #7 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:02 | [drl] epoch #7 | computing loss before
2020-09-03 14:59:02 | [drl] epoch #7 | computing gradient
2020-09-03 14:59:02 | [drl] epoch #7 | gradient computed
2020-09-03 14:59:02 | [drl] epoch #7 | computing descent direction
2020-09-03 14:59:03 | [drl] epoch #7 | descent direction computed
2020-09-03 14:59:03 | [drl] epoch #7 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:03 | [drl] epoch #7 | Violated because loss is NaN
2020-09-03 14:59:03 | [drl] epoch #7 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:03 | [drl] epoch #7 | backtrack iters: 14
2020-09-03 14:59:03 | [drl] epoch #7 | optimization finished
2020-09-03 14:59:03 | [drl] epoch #7 | Computing KL after
2020-09-03 14:59:03 | [drl] epoch #7 | Computing loss after
2020-09-03 14:59:03 | [drl] epoch #7 | Fitting baseline...
2020-09-03 14:59:03 | [drl] epoch #7 | Saving snapshot...
2020-09-03 14:59:03 | [drl] epoch #7 | Saved
2020-09-03 14:59:03 | [drl] epoch #7 | Time 7.17 s
2020-09-03 14:59:03 | [drl] epoch #7 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -200005
AverageReturn                            -327052
Entropy                                        8.51363
EnvExecTime                                    0.0390537
Extras/EpisodeRewardMean                 -230160
Iteration                                      7
LinearFeatureBaseline/ExplainedVariance        0.748626
MaxReturn                                -327052
MinReturn                                -327052
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0522718
ProcessExecTime                                0.000994921
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:03 | [drl] epoch #8 | Obtaining samples...
2020-09-03 14:59:03 | [drl] epoch #8 | Obtaining samples for iteration 8...
2020-09-03 14:59:03 | [drl] epoch #8 | Logging diagnostics...
2020-09-03 14:59:03 | [drl] epoch #8 | Optimizing policy...
2020-09-03 14:59:03 | [drl] epoch #8 | Computing loss before
2020-09-03 14:59:03 | [drl] epoch #8 | Computing KL before
2020-09-03 14:59:03 | [drl] epoch #8 | Optimizing
2020-09-03 14:59:03 | [drl] epoch #8 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:03 | [drl] epoch #8 | computing loss before
2020-09-03 14:59:03 | [drl] epoch #8 | computing gradient
2020-09-03 14:59:03 | [drl] epoch #8 | gradient computed
2020-09-03 14:59:03 | [drl] epoch #8 | computing descent direction
2020-09-03 14:59:03 | [drl] epoch #8 | descent direction computed
2020-09-03 14:59:04 | [drl] epoch #8 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:04 | [drl] epoch #8 | Violated because loss is NaN
2020-09-03 14:59:04 | [drl] epoch #8 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:04 | [drl] epoch #8 | backtrack iters: 14
2020-09-03 14:59:04 | [drl] epoch #8 | optimization finished
2020-09-03 14:59:04 | [drl] epoch #8 | Computing KL after
2020-09-03 14:59:04 | [drl] epoch #8 | Computing loss after
2020-09-03 14:59:04 | [drl] epoch #8 | Fitting baseline...
2020-09-03 14:59:04 | [drl] epoch #8 | Saving snapshot...
2020-09-03 14:59:04 | [drl] epoch #8 | Saved
2020-09-03 14:59:04 | [drl] epoch #8 | Time 8.11 s
2020-09-03 14:59:04 | [drl] epoch #8 | EpochTime 0.93 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -144031
AverageReturn                            -235441
Entropy                                        8.51363
EnvExecTime                                    0.0391173
Extras/EpisodeRewardMean                 -230747
Iteration                                      8
LinearFeatureBaseline/ExplainedVariance        0.844583
MaxReturn                                -235441
MinReturn                                -235441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0413997
ProcessExecTime                                0.000952721
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:04 | [drl] epoch #9 | Obtaining samples...
2020-09-03 14:59:04 | [drl] epoch #9 | Obtaining samples for iteration 9...
2020-09-03 14:59:04 | [drl] epoch #9 | Logging diagnostics...
2020-09-03 14:59:04 | [drl] epoch #9 | Optimizing policy...
2020-09-03 14:59:04 | [drl] epoch #9 | Computing loss before
2020-09-03 14:59:04 | [drl] epoch #9 | Computing KL before
2020-09-03 14:59:04 | [drl] epoch #9 | Optimizing
2020-09-03 14:59:04 | [drl] epoch #9 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:04 | [drl] epoch #9 | computing loss before
2020-09-03 14:59:04 | [drl] epoch #9 | computing gradient
2020-09-03 14:59:04 | [drl] epoch #9 | gradient computed
2020-09-03 14:59:04 | [drl] epoch #9 | computing descent direction
2020-09-03 14:59:04 | [drl] epoch #9 | descent direction computed
2020-09-03 14:59:04 | [drl] epoch #9 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:04 | [drl] epoch #9 | Violated because loss is NaN
2020-09-03 14:59:04 | [drl] epoch #9 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:04 | [drl] epoch #9 | backtrack iters: 14
2020-09-03 14:59:04 | [drl] epoch #9 | optimization finished
2020-09-03 14:59:04 | [drl] epoch #9 | Computing KL after
2020-09-03 14:59:04 | [drl] epoch #9 | Computing loss after
2020-09-03 14:59:04 | [drl] epoch #9 | Fitting baseline...
2020-09-03 14:59:04 | [drl] epoch #9 | Saving snapshot...
2020-09-03 14:59:04 | [drl] epoch #9 | Saved
2020-09-03 14:59:04 | [drl] epoch #9 | Time 8.89 s
2020-09-03 14:59:04 | [drl] epoch #9 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -171067
AverageReturn                            -279688
Entropy                                        8.51363
EnvExecTime                                    0.0346217
Extras/EpisodeRewardMean                 -235641
Iteration                                      9
LinearFeatureBaseline/ExplainedVariance        0.974453
MaxReturn                                -279688
MinReturn                                -279688
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0493617
ProcessExecTime                                0.00219178
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:04 | [drl] epoch #10 | Obtaining samples...
2020-09-03 14:59:04 | [drl] epoch #10 | Obtaining samples for iteration 10...
2020-09-03 14:59:05 | [drl] epoch #10 | Logging diagnostics...
2020-09-03 14:59:05 | [drl] epoch #10 | Optimizing policy...
2020-09-03 14:59:05 | [drl] epoch #10 | Computing loss before
2020-09-03 14:59:05 | [drl] epoch #10 | Computing KL before
2020-09-03 14:59:05 | [drl] epoch #10 | Optimizing
2020-09-03 14:59:05 | [drl] epoch #10 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:05 | [drl] epoch #10 | computing loss before
2020-09-03 14:59:05 | [drl] epoch #10 | computing gradient
2020-09-03 14:59:05 | [drl] epoch #10 | gradient computed
2020-09-03 14:59:05 | [drl] epoch #10 | computing descent direction
2020-09-03 14:59:05 | [drl] epoch #10 | descent direction computed
2020-09-03 14:59:05 | [drl] epoch #10 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:05 | [drl] epoch #10 | Violated because loss is NaN
2020-09-03 14:59:05 | [drl] epoch #10 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:05 | [drl] epoch #10 | backtrack iters: 14
2020-09-03 14:59:05 | [drl] epoch #10 | optimization finished
2020-09-03 14:59:05 | [drl] epoch #10 | Computing KL after
2020-09-03 14:59:05 | [drl] epoch #10 | Computing loss after
2020-09-03 14:59:05 | [drl] epoch #10 | Fitting baseline...
2020-09-03 14:59:05 | [drl] epoch #10 | Saving snapshot...
2020-09-03 14:59:05 | [drl] epoch #10 | Saved
2020-09-03 14:59:05 | [drl] epoch #10 | Time 9.64 s
2020-09-03 14:59:05 | [drl] epoch #10 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -77695
AverageReturn                            -126915
Entropy                                        8.51363
EnvExecTime                                    0.036629
Extras/EpisodeRewardMean                 -225757
Iteration                                     10
LinearFeatureBaseline/ExplainedVariance       -0.499061
MaxReturn                                -126915
MinReturn                                -126915
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0491011
ProcessExecTime                                0.00109053
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:05 | [drl] epoch #11 | Obtaining samples...
2020-09-03 14:59:05 | [drl] epoch #11 | Obtaining samples for iteration 11...
2020-09-03 14:59:05 | [drl] epoch #11 | Logging diagnostics...
2020-09-03 14:59:05 | [drl] epoch #11 | Optimizing policy...
2020-09-03 14:59:05 | [drl] epoch #11 | Computing loss before
2020-09-03 14:59:05 | [drl] epoch #11 | Computing KL before
2020-09-03 14:59:05 | [drl] epoch #11 | Optimizing
2020-09-03 14:59:05 | [drl] epoch #11 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:05 | [drl] epoch #11 | computing loss before
2020-09-03 14:59:05 | [drl] epoch #11 | computing gradient
2020-09-03 14:59:05 | [drl] epoch #11 | gradient computed
2020-09-03 14:59:05 | [drl] epoch #11 | computing descent direction
2020-09-03 14:59:06 | [drl] epoch #11 | descent direction computed
2020-09-03 14:59:06 | [drl] epoch #11 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:06 | [drl] epoch #11 | Violated because loss is NaN
2020-09-03 14:59:06 | [drl] epoch #11 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:06 | [drl] epoch #11 | backtrack iters: 14
2020-09-03 14:59:06 | [drl] epoch #11 | optimization finished
2020-09-03 14:59:06 | [drl] epoch #11 | Computing KL after
2020-09-03 14:59:06 | [drl] epoch #11 | Computing loss after
2020-09-03 14:59:06 | [drl] epoch #11 | Fitting baseline...
2020-09-03 14:59:06 | [drl] epoch #11 | Saving snapshot...
2020-09-03 14:59:06 | [drl] epoch #11 | Saved
2020-09-03 14:59:06 | [drl] epoch #11 | Time 10.38 s
2020-09-03 14:59:06 | [drl] epoch #11 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -97539.2
AverageReturn                            -159379
Entropy                                        8.51363
EnvExecTime                                    0.0376108
Extras/EpisodeRewardMean                 -220225
Iteration                                     11
LinearFeatureBaseline/ExplainedVariance        0.957473
MaxReturn                                -159379
MinReturn                                -159379
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.044528
ProcessExecTime                                0.00104284
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:06 | [drl] epoch #12 | Obtaining samples...
2020-09-03 14:59:06 | [drl] epoch #12 | Obtaining samples for iteration 12...
2020-09-03 14:59:06 | [drl] epoch #12 | Logging diagnostics...
2020-09-03 14:59:06 | [drl] epoch #12 | Optimizing policy...
2020-09-03 14:59:06 | [drl] epoch #12 | Computing loss before
2020-09-03 14:59:06 | [drl] epoch #12 | Computing KL before
2020-09-03 14:59:06 | [drl] epoch #12 | Optimizing
2020-09-03 14:59:06 | [drl] epoch #12 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:06 | [drl] epoch #12 | computing loss before
2020-09-03 14:59:06 | [drl] epoch #12 | computing gradient
2020-09-03 14:59:06 | [drl] epoch #12 | gradient computed
2020-09-03 14:59:06 | [drl] epoch #12 | computing descent direction
2020-09-03 14:59:07 | [drl] epoch #12 | descent direction computed
2020-09-03 14:59:07 | [drl] epoch #12 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:07 | [drl] epoch #12 | Violated because loss is NaN
2020-09-03 14:59:07 | [drl] epoch #12 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:07 | [drl] epoch #12 | backtrack iters: 14
2020-09-03 14:59:07 | [drl] epoch #12 | optimization finished
2020-09-03 14:59:07 | [drl] epoch #12 | Computing KL after
2020-09-03 14:59:07 | [drl] epoch #12 | Computing loss after
2020-09-03 14:59:07 | [drl] epoch #12 | Fitting baseline...
2020-09-03 14:59:07 | [drl] epoch #12 | Saving snapshot...
2020-09-03 14:59:07 | [drl] epoch #12 | Saved
2020-09-03 14:59:07 | [drl] epoch #12 | Time 11.26 s
2020-09-03 14:59:07 | [drl] epoch #12 | EpochTime 0.87 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -171353
AverageReturn                            -280168
Entropy                                        8.51363
EnvExecTime                                    0.0674074
Extras/EpisodeRewardMean                 -224836
Iteration                                     12
LinearFeatureBaseline/ExplainedVariance        0.810962
MaxReturn                                -280168
MinReturn                                -280168
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0778756
ProcessExecTime                                0.0121038
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-03 14:59:07 | [drl] epoch #13 | Obtaining samples...
2020-09-03 14:59:07 | [drl] epoch #13 | Obtaining samples for iteration 13...
2020-09-03 14:59:07 | [drl] epoch #13 | Logging diagnostics...
2020-09-03 14:59:07 | [drl] epoch #13 | Optimizing policy...
2020-09-03 14:59:07 | [drl] epoch #13 | Computing loss before
2020-09-03 14:59:07 | [drl] epoch #13 | Computing KL before
2020-09-03 14:59:07 | [drl] epoch #13 | Optimizing
2020-09-03 14:59:07 | [drl] epoch #13 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:07 | [drl] epoch #13 | computing loss before
2020-09-03 14:59:07 | [drl] epoch #13 | computing gradient
2020-09-03 14:59:07 | [drl] epoch #13 | gradient computed
2020-09-03 14:59:07 | [drl] epoch #13 | computing descent direction
2020-09-03 14:59:07 | [drl] epoch #13 | descent direction computed
2020-09-03 14:59:08 | [drl] epoch #13 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:08 | [drl] epoch #13 | Violated because loss is NaN
2020-09-03 14:59:08 | [drl] epoch #13 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:08 | [drl] epoch #13 | backtrack iters: 14
2020-09-03 14:59:08 | [drl] epoch #13 | optimization finished
2020-09-03 14:59:08 | [drl] epoch #13 | Computing KL after
2020-09-03 14:59:08 | [drl] epoch #13 | Computing loss after
2020-09-03 14:59:08 | [drl] epoch #13 | Fitting baseline...
2020-09-03 14:59:08 | [drl] epoch #13 | Saving snapshot...
2020-09-03 14:59:08 | [drl] epoch #13 | Saved
2020-09-03 14:59:08 | [drl] epoch #13 | Time 12.08 s
2020-09-03 14:59:08 | [drl] epoch #13 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -135676
AverageReturn                            -221781
Entropy                                        8.51363
EnvExecTime                                    0.0379393
Extras/EpisodeRewardMean                 -224618
Iteration                                     13
LinearFeatureBaseline/ExplainedVariance        0.929095
MaxReturn                                -221781
MinReturn                                -221781
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0620952
ProcessExecTime                                0.000944376
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:08 | [drl] epoch #14 | Obtaining samples...
2020-09-03 14:59:08 | [drl] epoch #14 | Obtaining samples for iteration 14...
2020-09-03 14:59:08 | [drl] epoch #14 | Logging diagnostics...
2020-09-03 14:59:08 | [drl] epoch #14 | Optimizing policy...
2020-09-03 14:59:08 | [drl] epoch #14 | Computing loss before
2020-09-03 14:59:08 | [drl] epoch #14 | Computing KL before
2020-09-03 14:59:08 | [drl] epoch #14 | Optimizing
2020-09-03 14:59:08 | [drl] epoch #14 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:08 | [drl] epoch #14 | computing loss before
2020-09-03 14:59:08 | [drl] epoch #14 | computing gradient
2020-09-03 14:59:08 | [drl] epoch #14 | gradient computed
2020-09-03 14:59:08 | [drl] epoch #14 | computing descent direction
2020-09-03 14:59:08 | [drl] epoch #14 | descent direction computed
2020-09-03 14:59:08 | [drl] epoch #14 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:08 | [drl] epoch #14 | Violated because loss is NaN
2020-09-03 14:59:08 | [drl] epoch #14 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:08 | [drl] epoch #14 | backtrack iters: 14
2020-09-03 14:59:08 | [drl] epoch #14 | optimization finished
2020-09-03 14:59:08 | [drl] epoch #14 | Computing KL after
2020-09-03 14:59:08 | [drl] epoch #14 | Computing loss after
2020-09-03 14:59:08 | [drl] epoch #14 | Fitting baseline...
2020-09-03 14:59:08 | [drl] epoch #14 | Saving snapshot...
2020-09-03 14:59:08 | [drl] epoch #14 | Saved
2020-09-03 14:59:08 | [drl] epoch #14 | Time 12.82 s
2020-09-03 14:59:08 | [drl] epoch #14 | EpochTime 0.72 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93079.6
AverageReturn                            -152079
Entropy                                        8.51363
EnvExecTime                                    0.034405
Extras/EpisodeRewardMean                 -219782
Iteration                                     14
LinearFeatureBaseline/ExplainedVariance        0.783378
MaxReturn                                -152079
MinReturn                                -152079
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.03882
ProcessExecTime                                0.000923395
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:08 | [drl] epoch #15 | Obtaining samples...
2020-09-03 14:59:08 | [drl] epoch #15 | Obtaining samples for iteration 15...
2020-09-03 14:59:08 | [drl] epoch #15 | Logging diagnostics...
2020-09-03 14:59:08 | [drl] epoch #15 | Optimizing policy...
2020-09-03 14:59:08 | [drl] epoch #15 | Computing loss before
2020-09-03 14:59:08 | [drl] epoch #15 | Computing KL before
2020-09-03 14:59:08 | [drl] epoch #15 | Optimizing
2020-09-03 14:59:08 | [drl] epoch #15 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:08 | [drl] epoch #15 | computing loss before
2020-09-03 14:59:08 | [drl] epoch #15 | computing gradient
2020-09-03 14:59:08 | [drl] epoch #15 | gradient computed
2020-09-03 14:59:08 | [drl] epoch #15 | computing descent direction
2020-09-03 14:59:09 | [drl] epoch #15 | descent direction computed
2020-09-03 14:59:09 | [drl] epoch #15 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:09 | [drl] epoch #15 | Violated because loss is NaN
2020-09-03 14:59:09 | [drl] epoch #15 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:09 | [drl] epoch #15 | backtrack iters: 14
2020-09-03 14:59:09 | [drl] epoch #15 | optimization finished
2020-09-03 14:59:09 | [drl] epoch #15 | Computing KL after
2020-09-03 14:59:09 | [drl] epoch #15 | Computing loss after
2020-09-03 14:59:09 | [drl] epoch #15 | Fitting baseline...
2020-09-03 14:59:09 | [drl] epoch #15 | Saving snapshot...
2020-09-03 14:59:09 | [drl] epoch #15 | Saved
2020-09-03 14:59:09 | [drl] epoch #15 | Time 13.56 s
2020-09-03 14:59:09 | [drl] epoch #15 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -86820.4
AverageReturn                            -141831
Entropy                                        8.51363
EnvExecTime                                    0.0409794
Extras/EpisodeRewardMean                 -214910
Iteration                                     15
LinearFeatureBaseline/ExplainedVariance        0.994511
MaxReturn                                -141831
MinReturn                                -141831
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0459452
ProcessExecTime                                0.00092721
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:09 | [drl] epoch #16 | Obtaining samples...
2020-09-03 14:59:09 | [drl] epoch #16 | Obtaining samples for iteration 16...
2020-09-03 14:59:09 | [drl] epoch #16 | Logging diagnostics...
2020-09-03 14:59:09 | [drl] epoch #16 | Optimizing policy...
2020-09-03 14:59:09 | [drl] epoch #16 | Computing loss before
2020-09-03 14:59:09 | [drl] epoch #16 | Computing KL before
2020-09-03 14:59:09 | [drl] epoch #16 | Optimizing
2020-09-03 14:59:09 | [drl] epoch #16 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:09 | [drl] epoch #16 | computing loss before
2020-09-03 14:59:09 | [drl] epoch #16 | computing gradient
2020-09-03 14:59:09 | [drl] epoch #16 | gradient computed
2020-09-03 14:59:09 | [drl] epoch #16 | computing descent direction
2020-09-03 14:59:10 | [drl] epoch #16 | descent direction computed
2020-09-03 14:59:10 | [drl] epoch #16 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:10 | [drl] epoch #16 | Violated because loss is NaN
2020-09-03 14:59:10 | [drl] epoch #16 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:10 | [drl] epoch #16 | backtrack iters: 14
2020-09-03 14:59:10 | [drl] epoch #16 | optimization finished
2020-09-03 14:59:10 | [drl] epoch #16 | Computing KL after
2020-09-03 14:59:10 | [drl] epoch #16 | Computing loss after
2020-09-03 14:59:10 | [drl] epoch #16 | Fitting baseline...
2020-09-03 14:59:10 | [drl] epoch #16 | Saving snapshot...
2020-09-03 14:59:10 | [drl] epoch #16 | Saved
2020-09-03 14:59:10 | [drl] epoch #16 | Time 14.68 s
2020-09-03 14:59:10 | [drl] epoch #16 | EpochTime 1.10 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -89177.5
AverageReturn                            -145687
Entropy                                        8.51363
EnvExecTime                                    0.0892918
Extras/EpisodeRewardMean                 -210838
Iteration                                     16
LinearFeatureBaseline/ExplainedVariance        0.999301
MaxReturn                                -145687
MinReturn                                -145687
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0800779
ProcessExecTime                                0.00161076
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:10 | [drl] epoch #17 | Obtaining samples...
2020-09-03 14:59:10 | [drl] epoch #17 | Obtaining samples for iteration 17...
2020-09-03 14:59:10 | [drl] epoch #17 | Logging diagnostics...
2020-09-03 14:59:10 | [drl] epoch #17 | Optimizing policy...
2020-09-03 14:59:10 | [drl] epoch #17 | Computing loss before
2020-09-03 14:59:10 | [drl] epoch #17 | Computing KL before
2020-09-03 14:59:10 | [drl] epoch #17 | Optimizing
2020-09-03 14:59:10 | [drl] epoch #17 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:10 | [drl] epoch #17 | computing loss before
2020-09-03 14:59:10 | [drl] epoch #17 | computing gradient
2020-09-03 14:59:10 | [drl] epoch #17 | gradient computed
2020-09-03 14:59:10 | [drl] epoch #17 | computing descent direction
2020-09-03 14:59:11 | [drl] epoch #17 | descent direction computed
2020-09-03 14:59:11 | [drl] epoch #17 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:11 | [drl] epoch #17 | Violated because loss is NaN
2020-09-03 14:59:11 | [drl] epoch #17 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:11 | [drl] epoch #17 | backtrack iters: 14
2020-09-03 14:59:11 | [drl] epoch #17 | optimization finished
2020-09-03 14:59:11 | [drl] epoch #17 | Computing KL after
2020-09-03 14:59:11 | [drl] epoch #17 | Computing loss after
2020-09-03 14:59:11 | [drl] epoch #17 | Fitting baseline...
2020-09-03 14:59:11 | [drl] epoch #17 | Saving snapshot...
2020-09-03 14:59:11 | [drl] epoch #17 | Saved
2020-09-03 14:59:11 | [drl] epoch #17 | Time 15.50 s
2020-09-03 14:59:11 | [drl] epoch #17 | EpochTime 0.81 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173471
AverageReturn                            -283627
Entropy                                        8.51363
EnvExecTime                                    0.0320568
Extras/EpisodeRewardMean                 -214882
Iteration                                     17
LinearFeatureBaseline/ExplainedVariance        0.758987
MaxReturn                                -283627
MinReturn                                -283627
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0565214
ProcessExecTime                                0.000980377
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:11 | [drl] epoch #18 | Obtaining samples...
2020-09-03 14:59:11 | [drl] epoch #18 | Obtaining samples for iteration 18...
2020-09-03 14:59:11 | [drl] epoch #18 | Logging diagnostics...
2020-09-03 14:59:11 | [drl] epoch #18 | Optimizing policy...
2020-09-03 14:59:11 | [drl] epoch #18 | Computing loss before
2020-09-03 14:59:11 | [drl] epoch #18 | Computing KL before
2020-09-03 14:59:11 | [drl] epoch #18 | Optimizing
2020-09-03 14:59:11 | [drl] epoch #18 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:11 | [drl] epoch #18 | computing loss before
2020-09-03 14:59:11 | [drl] epoch #18 | computing gradient
2020-09-03 14:59:11 | [drl] epoch #18 | gradient computed
2020-09-03 14:59:11 | [drl] epoch #18 | computing descent direction
2020-09-03 14:59:12 | [drl] epoch #18 | descent direction computed
2020-09-03 14:59:12 | [drl] epoch #18 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:12 | [drl] epoch #18 | Violated because loss is NaN
2020-09-03 14:59:12 | [drl] epoch #18 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:12 | [drl] epoch #18 | backtrack iters: 14
2020-09-03 14:59:12 | [drl] epoch #18 | optimization finished
2020-09-03 14:59:12 | [drl] epoch #18 | Computing KL after
2020-09-03 14:59:12 | [drl] epoch #18 | Computing loss after
2020-09-03 14:59:12 | [drl] epoch #18 | Fitting baseline...
2020-09-03 14:59:12 | [drl] epoch #18 | Saving snapshot...
2020-09-03 14:59:12 | [drl] epoch #18 | Saved
2020-09-03 14:59:12 | [drl] epoch #18 | Time 16.28 s
2020-09-03 14:59:12 | [drl] epoch #18 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -90334.2
AverageReturn                            -147591
Entropy                                        8.51363
EnvExecTime                                    0.0508475
Extras/EpisodeRewardMean                 -211341
Iteration                                     18
LinearFeatureBaseline/ExplainedVariance        0.123617
MaxReturn                                -147591
MinReturn                                -147591
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.056803
ProcessExecTime                                0.000966549
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:12 | [drl] epoch #19 | Obtaining samples...
2020-09-03 14:59:12 | [drl] epoch #19 | Obtaining samples for iteration 19...
2020-09-03 14:59:12 | [drl] epoch #19 | Logging diagnostics...
2020-09-03 14:59:12 | [drl] epoch #19 | Optimizing policy...
2020-09-03 14:59:12 | [drl] epoch #19 | Computing loss before
2020-09-03 14:59:12 | [drl] epoch #19 | Computing KL before
2020-09-03 14:59:12 | [drl] epoch #19 | Optimizing
2020-09-03 14:59:12 | [drl] epoch #19 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:12 | [drl] epoch #19 | computing loss before
2020-09-03 14:59:12 | [drl] epoch #19 | computing gradient
2020-09-03 14:59:12 | [drl] epoch #19 | gradient computed
2020-09-03 14:59:12 | [drl] epoch #19 | computing descent direction
2020-09-03 14:59:12 | [drl] epoch #19 | descent direction computed
2020-09-03 14:59:13 | [drl] epoch #19 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:13 | [drl] epoch #19 | Violated because loss is NaN
2020-09-03 14:59:13 | [drl] epoch #19 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:13 | [drl] epoch #19 | backtrack iters: 14
2020-09-03 14:59:13 | [drl] epoch #19 | optimization finished
2020-09-03 14:59:13 | [drl] epoch #19 | Computing KL after
2020-09-03 14:59:13 | [drl] epoch #19 | Computing loss after
2020-09-03 14:59:13 | [drl] epoch #19 | Fitting baseline...
2020-09-03 14:59:13 | [drl] epoch #19 | Saving snapshot...
2020-09-03 14:59:13 | [drl] epoch #19 | Saved
2020-09-03 14:59:13 | [drl] epoch #19 | Time 17.04 s
2020-09-03 14:59:13 | [drl] epoch #19 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106449
AverageReturn                            -173957
Entropy                                        8.51363
EnvExecTime                                    0.0451677
Extras/EpisodeRewardMean                 -209471
Iteration                                     19
LinearFeatureBaseline/ExplainedVariance        0.976486
MaxReturn                                -173957
MinReturn                                -173957
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0478165
ProcessExecTime                                0.000989199
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:13 | [drl] epoch #20 | Obtaining samples...
2020-09-03 14:59:13 | [drl] epoch #20 | Obtaining samples for iteration 20...
2020-09-03 14:59:13 | [drl] epoch #20 | Logging diagnostics...
2020-09-03 14:59:13 | [drl] epoch #20 | Optimizing policy...
2020-09-03 14:59:13 | [drl] epoch #20 | Computing loss before
2020-09-03 14:59:13 | [drl] epoch #20 | Computing KL before
2020-09-03 14:59:13 | [drl] epoch #20 | Optimizing
2020-09-03 14:59:13 | [drl] epoch #20 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:13 | [drl] epoch #20 | computing loss before
2020-09-03 14:59:13 | [drl] epoch #20 | computing gradient
2020-09-03 14:59:13 | [drl] epoch #20 | gradient computed
2020-09-03 14:59:13 | [drl] epoch #20 | computing descent direction
2020-09-03 14:59:13 | [drl] epoch #20 | descent direction computed
2020-09-03 14:59:13 | [drl] epoch #20 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:13 | [drl] epoch #20 | Violated because loss is NaN
2020-09-03 14:59:13 | [drl] epoch #20 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:13 | [drl] epoch #20 | backtrack iters: 14
2020-09-03 14:59:13 | [drl] epoch #20 | optimization finished
2020-09-03 14:59:13 | [drl] epoch #20 | Computing KL after
2020-09-03 14:59:13 | [drl] epoch #20 | Computing loss after
2020-09-03 14:59:13 | [drl] epoch #20 | Fitting baseline...
2020-09-03 14:59:13 | [drl] epoch #20 | Saving snapshot...
2020-09-03 14:59:13 | [drl] epoch #20 | Saved
2020-09-03 14:59:13 | [drl] epoch #20 | Time 17.81 s
2020-09-03 14:59:13 | [drl] epoch #20 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -96632.3
AverageReturn                            -157899
Entropy                                        8.51363
EnvExecTime                                    0.0453548
Extras/EpisodeRewardMean                 -207015
Iteration                                     20
LinearFeatureBaseline/ExplainedVariance        0.989373
MaxReturn                                -157899
MinReturn                                -157899
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0514288
ProcessExecTime                                0.00111175
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:13 | [drl] epoch #21 | Obtaining samples...
2020-09-03 14:59:13 | [drl] epoch #21 | Obtaining samples for iteration 21...
2020-09-03 14:59:13 | [drl] epoch #21 | Logging diagnostics...
2020-09-03 14:59:13 | [drl] epoch #21 | Optimizing policy...
2020-09-03 14:59:13 | [drl] epoch #21 | Computing loss before
2020-09-03 14:59:13 | [drl] epoch #21 | Computing KL before
2020-09-03 14:59:13 | [drl] epoch #21 | Optimizing
2020-09-03 14:59:13 | [drl] epoch #21 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:13 | [drl] epoch #21 | computing loss before
2020-09-03 14:59:13 | [drl] epoch #21 | computing gradient
2020-09-03 14:59:13 | [drl] epoch #21 | gradient computed
2020-09-03 14:59:13 | [drl] epoch #21 | computing descent direction
2020-09-03 14:59:14 | [drl] epoch #21 | descent direction computed
2020-09-03 14:59:14 | [drl] epoch #21 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:14 | [drl] epoch #21 | Violated because loss is NaN
2020-09-03 14:59:14 | [drl] epoch #21 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:14 | [drl] epoch #21 | backtrack iters: 14
2020-09-03 14:59:14 | [drl] epoch #21 | optimization finished
2020-09-03 14:59:14 | [drl] epoch #21 | Computing KL after
2020-09-03 14:59:14 | [drl] epoch #21 | Computing loss after
2020-09-03 14:59:14 | [drl] epoch #21 | Fitting baseline...
2020-09-03 14:59:14 | [drl] epoch #21 | Saving snapshot...
2020-09-03 14:59:14 | [drl] epoch #21 | Saved
2020-09-03 14:59:14 | [drl] epoch #21 | Time 18.57 s
2020-09-03 14:59:14 | [drl] epoch #21 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -170612
AverageReturn                            -278935
Entropy                                        8.51363
EnvExecTime                                    0.0439689
Extras/EpisodeRewardMean                 -210285
Iteration                                     21
LinearFeatureBaseline/ExplainedVariance        0.808798
MaxReturn                                -278935
MinReturn                                -278935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0591571
ProcessExecTime                                0.00100183
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:14 | [drl] epoch #22 | Obtaining samples...
2020-09-03 14:59:14 | [drl] epoch #22 | Obtaining samples for iteration 22...
2020-09-03 14:59:14 | [drl] epoch #22 | Logging diagnostics...
2020-09-03 14:59:14 | [drl] epoch #22 | Optimizing policy...
2020-09-03 14:59:14 | [drl] epoch #22 | Computing loss before
2020-09-03 14:59:14 | [drl] epoch #22 | Computing KL before
2020-09-03 14:59:14 | [drl] epoch #22 | Optimizing
2020-09-03 14:59:14 | [drl] epoch #22 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:14 | [drl] epoch #22 | computing loss before
2020-09-03 14:59:14 | [drl] epoch #22 | computing gradient
2020-09-03 14:59:14 | [drl] epoch #22 | gradient computed
2020-09-03 14:59:14 | [drl] epoch #22 | computing descent direction
2020-09-03 14:59:15 | [drl] epoch #22 | descent direction computed
2020-09-03 14:59:15 | [drl] epoch #22 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:15 | [drl] epoch #22 | Violated because loss is NaN
2020-09-03 14:59:15 | [drl] epoch #22 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:15 | [drl] epoch #22 | backtrack iters: 14
2020-09-03 14:59:15 | [drl] epoch #22 | optimization finished
2020-09-03 14:59:15 | [drl] epoch #22 | Computing KL after
2020-09-03 14:59:15 | [drl] epoch #22 | Computing loss after
2020-09-03 14:59:15 | [drl] epoch #22 | Fitting baseline...
2020-09-03 14:59:15 | [drl] epoch #22 | Saving snapshot...
2020-09-03 14:59:15 | [drl] epoch #22 | Saved
2020-09-03 14:59:15 | [drl] epoch #22 | Time 19.34 s
2020-09-03 14:59:15 | [drl] epoch #22 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -142558
AverageReturn                            -233040
Entropy                                        8.51363
EnvExecTime                                    0.0338864
Extras/EpisodeRewardMean                 -211274
Iteration                                     22
LinearFeatureBaseline/ExplainedVariance        0.960675
MaxReturn                                -233040
MinReturn                                -233040
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0617855
ProcessExecTime                                0.000950575
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:15 | [drl] epoch #23 | Obtaining samples...
2020-09-03 14:59:15 | [drl] epoch #23 | Obtaining samples for iteration 23...
2020-09-03 14:59:15 | [drl] epoch #23 | Logging diagnostics...
2020-09-03 14:59:15 | [drl] epoch #23 | Optimizing policy...
2020-09-03 14:59:15 | [drl] epoch #23 | Computing loss before
2020-09-03 14:59:15 | [drl] epoch #23 | Computing KL before
2020-09-03 14:59:15 | [drl] epoch #23 | Optimizing
2020-09-03 14:59:15 | [drl] epoch #23 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:15 | [drl] epoch #23 | computing loss before
2020-09-03 14:59:15 | [drl] epoch #23 | computing gradient
2020-09-03 14:59:15 | [drl] epoch #23 | gradient computed
2020-09-03 14:59:15 | [drl] epoch #23 | computing descent direction
2020-09-03 14:59:15 | [drl] epoch #23 | descent direction computed
2020-09-03 14:59:16 | [drl] epoch #23 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:16 | [drl] epoch #23 | Violated because loss is NaN
2020-09-03 14:59:16 | [drl] epoch #23 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:16 | [drl] epoch #23 | backtrack iters: 14
2020-09-03 14:59:16 | [drl] epoch #23 | optimization finished
2020-09-03 14:59:16 | [drl] epoch #23 | Computing KL after
2020-09-03 14:59:16 | [drl] epoch #23 | Computing loss after
2020-09-03 14:59:16 | [drl] epoch #23 | Fitting baseline...
2020-09-03 14:59:16 | [drl] epoch #23 | Saving snapshot...
2020-09-03 14:59:16 | [drl] epoch #23 | Saved
2020-09-03 14:59:16 | [drl] epoch #23 | Time 20.11 s
2020-09-03 14:59:16 | [drl] epoch #23 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -176606
AverageReturn                            -288756
Entropy                                        8.51363
EnvExecTime                                    0.034826
Extras/EpisodeRewardMean                 -214502
Iteration                                     23
LinearFeatureBaseline/ExplainedVariance        0.962094
MaxReturn                                -288756
MinReturn                                -288756
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0420964
ProcessExecTime                                0.00101399
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:16 | [drl] epoch #24 | Obtaining samples...
2020-09-03 14:59:16 | [drl] epoch #24 | Obtaining samples for iteration 24...
2020-09-03 14:59:16 | [drl] epoch #24 | Logging diagnostics...
2020-09-03 14:59:16 | [drl] epoch #24 | Optimizing policy...
2020-09-03 14:59:16 | [drl] epoch #24 | Computing loss before
2020-09-03 14:59:16 | [drl] epoch #24 | Computing KL before
2020-09-03 14:59:16 | [drl] epoch #24 | Optimizing
2020-09-03 14:59:16 | [drl] epoch #24 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:16 | [drl] epoch #24 | computing loss before
2020-09-03 14:59:16 | [drl] epoch #24 | computing gradient
2020-09-03 14:59:16 | [drl] epoch #24 | gradient computed
2020-09-03 14:59:16 | [drl] epoch #24 | computing descent direction
2020-09-03 14:59:16 | [drl] epoch #24 | descent direction computed
2020-09-03 14:59:16 | [drl] epoch #24 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:16 | [drl] epoch #24 | Violated because loss is NaN
2020-09-03 14:59:16 | [drl] epoch #24 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:16 | [drl] epoch #24 | backtrack iters: 14
2020-09-03 14:59:16 | [drl] epoch #24 | optimization finished
2020-09-03 14:59:16 | [drl] epoch #24 | Computing KL after
2020-09-03 14:59:16 | [drl] epoch #24 | Computing loss after
2020-09-03 14:59:16 | [drl] epoch #24 | Fitting baseline...
2020-09-03 14:59:16 | [drl] epoch #24 | Saving snapshot...
2020-09-03 14:59:16 | [drl] epoch #24 | Saved
2020-09-03 14:59:16 | [drl] epoch #24 | Time 20.90 s
2020-09-03 14:59:16 | [drl] epoch #24 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -109849
AverageReturn                            -179519
Entropy                                        8.51363
EnvExecTime                                    0.0339234
Extras/EpisodeRewardMean                 -213103
Iteration                                     24
LinearFeatureBaseline/ExplainedVariance        0.619529
MaxReturn                                -179519
MinReturn                                -179519
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.063411
ProcessExecTime                                0.00094986
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:16 | [drl] epoch #25 | Obtaining samples...
2020-09-03 14:59:16 | [drl] epoch #25 | Obtaining samples for iteration 25...
2020-09-03 14:59:17 | [drl] epoch #25 | Logging diagnostics...
2020-09-03 14:59:17 | [drl] epoch #25 | Optimizing policy...
2020-09-03 14:59:17 | [drl] epoch #25 | Computing loss before
2020-09-03 14:59:17 | [drl] epoch #25 | Computing KL before
2020-09-03 14:59:17 | [drl] epoch #25 | Optimizing
2020-09-03 14:59:17 | [drl] epoch #25 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:17 | [drl] epoch #25 | computing loss before
2020-09-03 14:59:17 | [drl] epoch #25 | computing gradient
2020-09-03 14:59:17 | [drl] epoch #25 | gradient computed
2020-09-03 14:59:17 | [drl] epoch #25 | computing descent direction
2020-09-03 14:59:17 | [drl] epoch #25 | descent direction computed
2020-09-03 14:59:17 | [drl] epoch #25 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:17 | [drl] epoch #25 | Violated because loss is NaN
2020-09-03 14:59:17 | [drl] epoch #25 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:17 | [drl] epoch #25 | backtrack iters: 14
2020-09-03 14:59:17 | [drl] epoch #25 | optimization finished
2020-09-03 14:59:17 | [drl] epoch #25 | Computing KL after
2020-09-03 14:59:17 | [drl] epoch #25 | Computing loss after
2020-09-03 14:59:17 | [drl] epoch #25 | Fitting baseline...
2020-09-03 14:59:17 | [drl] epoch #25 | Saving snapshot...
2020-09-03 14:59:17 | [drl] epoch #25 | Saved
2020-09-03 14:59:17 | [drl] epoch #25 | Time 21.67 s
2020-09-03 14:59:17 | [drl] epoch #25 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -105961
AverageReturn                            -173154
Entropy                                        8.51363
EnvExecTime                                    0.0331011
Extras/EpisodeRewardMean                 -211567
Iteration                                     25
LinearFeatureBaseline/ExplainedVariance        0.998613
MaxReturn                                -173154
MinReturn                                -173154
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0449197
ProcessExecTime                                0.00266576
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:17 | [drl] epoch #26 | Obtaining samples...
2020-09-03 14:59:17 | [drl] epoch #26 | Obtaining samples for iteration 26...
2020-09-03 14:59:17 | [drl] epoch #26 | Logging diagnostics...
2020-09-03 14:59:17 | [drl] epoch #26 | Optimizing policy...
2020-09-03 14:59:17 | [drl] epoch #26 | Computing loss before
2020-09-03 14:59:17 | [drl] epoch #26 | Computing KL before
2020-09-03 14:59:17 | [drl] epoch #26 | Optimizing
2020-09-03 14:59:17 | [drl] epoch #26 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:17 | [drl] epoch #26 | computing loss before
2020-09-03 14:59:17 | [drl] epoch #26 | computing gradient
2020-09-03 14:59:17 | [drl] epoch #26 | gradient computed
2020-09-03 14:59:17 | [drl] epoch #26 | computing descent direction
2020-09-03 14:59:18 | [drl] epoch #26 | descent direction computed
2020-09-03 14:59:18 | [drl] epoch #26 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:18 | [drl] epoch #26 | Violated because loss is NaN
2020-09-03 14:59:18 | [drl] epoch #26 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:18 | [drl] epoch #26 | backtrack iters: 14
2020-09-03 14:59:18 | [drl] epoch #26 | optimization finished
2020-09-03 14:59:18 | [drl] epoch #26 | Computing KL after
2020-09-03 14:59:18 | [drl] epoch #26 | Computing loss after
2020-09-03 14:59:18 | [drl] epoch #26 | Fitting baseline...
2020-09-03 14:59:18 | [drl] epoch #26 | Saving snapshot...
2020-09-03 14:59:18 | [drl] epoch #26 | Saved
2020-09-03 14:59:18 | [drl] epoch #26 | Time 22.44 s
2020-09-03 14:59:18 | [drl] epoch #26 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -123080
AverageReturn                            -201169
Entropy                                        8.51363
EnvExecTime                                    0.0384023
Extras/EpisodeRewardMean                 -211181
Iteration                                     26
LinearFeatureBaseline/ExplainedVariance        0.980211
MaxReturn                                -201169
MinReturn                                -201169
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0481102
ProcessExecTime                                0.00104523
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:18 | [drl] epoch #27 | Obtaining samples...
2020-09-03 14:59:18 | [drl] epoch #27 | Obtaining samples for iteration 27...
2020-09-03 14:59:18 | [drl] epoch #27 | Logging diagnostics...
2020-09-03 14:59:18 | [drl] epoch #27 | Optimizing policy...
2020-09-03 14:59:18 | [drl] epoch #27 | Computing loss before
2020-09-03 14:59:18 | [drl] epoch #27 | Computing KL before
2020-09-03 14:59:18 | [drl] epoch #27 | Optimizing
2020-09-03 14:59:18 | [drl] epoch #27 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:18 | [drl] epoch #27 | computing loss before
2020-09-03 14:59:18 | [drl] epoch #27 | computing gradient
2020-09-03 14:59:18 | [drl] epoch #27 | gradient computed
2020-09-03 14:59:18 | [drl] epoch #27 | computing descent direction
2020-09-03 14:59:19 | [drl] epoch #27 | descent direction computed
2020-09-03 14:59:19 | [drl] epoch #27 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:19 | [drl] epoch #27 | Violated because loss is NaN
2020-09-03 14:59:19 | [drl] epoch #27 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:19 | [drl] epoch #27 | backtrack iters: 14
2020-09-03 14:59:19 | [drl] epoch #27 | optimization finished
2020-09-03 14:59:19 | [drl] epoch #27 | Computing KL after
2020-09-03 14:59:19 | [drl] epoch #27 | Computing loss after
2020-09-03 14:59:19 | [drl] epoch #27 | Fitting baseline...
2020-09-03 14:59:19 | [drl] epoch #27 | Saving snapshot...
2020-09-03 14:59:19 | [drl] epoch #27 | Saved
2020-09-03 14:59:19 | [drl] epoch #27 | Time 23.21 s
2020-09-03 14:59:19 | [drl] epoch #27 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -98838.3
AverageReturn                            -161501
Entropy                                        8.51363
EnvExecTime                                    0.03193
Extras/EpisodeRewardMean                 -209407
Iteration                                     27
LinearFeatureBaseline/ExplainedVariance        0.937946
MaxReturn                                -161501
MinReturn                                -161501
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0604324
ProcessExecTime                                0.000941515
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:19 | [drl] epoch #28 | Obtaining samples...
2020-09-03 14:59:19 | [drl] epoch #28 | Obtaining samples for iteration 28...
2020-09-03 14:59:19 | [drl] epoch #28 | Logging diagnostics...
2020-09-03 14:59:19 | [drl] epoch #28 | Optimizing policy...
2020-09-03 14:59:19 | [drl] epoch #28 | Computing loss before
2020-09-03 14:59:19 | [drl] epoch #28 | Computing KL before
2020-09-03 14:59:19 | [drl] epoch #28 | Optimizing
2020-09-03 14:59:19 | [drl] epoch #28 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:19 | [drl] epoch #28 | computing loss before
2020-09-03 14:59:19 | [drl] epoch #28 | computing gradient
2020-09-03 14:59:19 | [drl] epoch #28 | gradient computed
2020-09-03 14:59:19 | [drl] epoch #28 | computing descent direction
2020-09-03 14:59:19 | [drl] epoch #28 | descent direction computed
2020-09-03 14:59:19 | [drl] epoch #28 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:19 | [drl] epoch #28 | Violated because loss is NaN
2020-09-03 14:59:19 | [drl] epoch #28 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:19 | [drl] epoch #28 | backtrack iters: 14
2020-09-03 14:59:19 | [drl] epoch #28 | optimization finished
2020-09-03 14:59:19 | [drl] epoch #28 | Computing KL after
2020-09-03 14:59:19 | [drl] epoch #28 | Computing loss after
2020-09-03 14:59:19 | [drl] epoch #28 | Fitting baseline...
2020-09-03 14:59:19 | [drl] epoch #28 | Saving snapshot...
2020-09-03 14:59:19 | [drl] epoch #28 | Saved
2020-09-03 14:59:19 | [drl] epoch #28 | Time 23.99 s
2020-09-03 14:59:19 | [drl] epoch #28 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -76607.3
AverageReturn                            -125122
Entropy                                        8.51363
EnvExecTime                                    0.043185
Extras/EpisodeRewardMean                 -206501
Iteration                                     28
LinearFeatureBaseline/ExplainedVariance        0.912185
MaxReturn                                -125122
MinReturn                                -125122
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0508461
ProcessExecTime                                0.00093627
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:19 | [drl] epoch #29 | Obtaining samples...
2020-09-03 14:59:19 | [drl] epoch #29 | Obtaining samples for iteration 29...
2020-09-03 14:59:20 | [drl] epoch #29 | Logging diagnostics...
2020-09-03 14:59:20 | [drl] epoch #29 | Optimizing policy...
2020-09-03 14:59:20 | [drl] epoch #29 | Computing loss before
2020-09-03 14:59:20 | [drl] epoch #29 | Computing KL before
2020-09-03 14:59:20 | [drl] epoch #29 | Optimizing
2020-09-03 14:59:20 | [drl] epoch #29 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:20 | [drl] epoch #29 | computing loss before
2020-09-03 14:59:20 | [drl] epoch #29 | computing gradient
2020-09-03 14:59:20 | [drl] epoch #29 | gradient computed
2020-09-03 14:59:20 | [drl] epoch #29 | computing descent direction
2020-09-03 14:59:20 | [drl] epoch #29 | descent direction computed
2020-09-03 14:59:20 | [drl] epoch #29 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:20 | [drl] epoch #29 | Violated because loss is NaN
2020-09-03 14:59:20 | [drl] epoch #29 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:20 | [drl] epoch #29 | backtrack iters: 14
2020-09-03 14:59:20 | [drl] epoch #29 | optimization finished
2020-09-03 14:59:20 | [drl] epoch #29 | Computing KL after
2020-09-03 14:59:20 | [drl] epoch #29 | Computing loss after
2020-09-03 14:59:20 | [drl] epoch #29 | Fitting baseline...
2020-09-03 14:59:20 | [drl] epoch #29 | Saving snapshot...
2020-09-03 14:59:20 | [drl] epoch #29 | Saved
2020-09-03 14:59:20 | [drl] epoch #29 | Time 24.75 s
2020-09-03 14:59:20 | [drl] epoch #29 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101247
AverageReturn                            -165454
Entropy                                        8.51363
EnvExecTime                                    0.0323312
Extras/EpisodeRewardMean                 -205133
Iteration                                     29
LinearFeatureBaseline/ExplainedVariance        0.938442
MaxReturn                                -165454
MinReturn                                -165454
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.054003
ProcessExecTime                                0.000965834
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:20 | [drl] epoch #30 | Obtaining samples...
2020-09-03 14:59:20 | [drl] epoch #30 | Obtaining samples for iteration 30...
2020-09-03 14:59:20 | [drl] epoch #30 | Logging diagnostics...
2020-09-03 14:59:20 | [drl] epoch #30 | Optimizing policy...
2020-09-03 14:59:20 | [drl] epoch #30 | Computing loss before
2020-09-03 14:59:20 | [drl] epoch #30 | Computing KL before
2020-09-03 14:59:20 | [drl] epoch #30 | Optimizing
2020-09-03 14:59:20 | [drl] epoch #30 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:20 | [drl] epoch #30 | computing loss before
2020-09-03 14:59:20 | [drl] epoch #30 | computing gradient
2020-09-03 14:59:20 | [drl] epoch #30 | gradient computed
2020-09-03 14:59:20 | [drl] epoch #30 | computing descent direction
2020-09-03 14:59:21 | [drl] epoch #30 | descent direction computed
2020-09-03 14:59:21 | [drl] epoch #30 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:21 | [drl] epoch #30 | Violated because loss is NaN
2020-09-03 14:59:21 | [drl] epoch #30 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:21 | [drl] epoch #30 | backtrack iters: 14
2020-09-03 14:59:21 | [drl] epoch #30 | optimization finished
2020-09-03 14:59:21 | [drl] epoch #30 | Computing KL after
2020-09-03 14:59:21 | [drl] epoch #30 | Computing loss after
2020-09-03 14:59:21 | [drl] epoch #30 | Fitting baseline...
2020-09-03 14:59:21 | [drl] epoch #30 | Saving snapshot...
2020-09-03 14:59:21 | [drl] epoch #30 | Saved
2020-09-03 14:59:21 | [drl] epoch #30 | Time 25.52 s
2020-09-03 14:59:21 | [drl] epoch #30 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -122695
AverageReturn                            -200540
Entropy                                        8.51363
EnvExecTime                                    0.0403419
Extras/EpisodeRewardMean                 -204984
Iteration                                     30
LinearFeatureBaseline/ExplainedVariance        0.968962
MaxReturn                                -200540
MinReturn                                -200540
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0520227
ProcessExecTime                                0.000930548
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:21 | [drl] epoch #31 | Obtaining samples...
2020-09-03 14:59:21 | [drl] epoch #31 | Obtaining samples for iteration 31...
2020-09-03 14:59:21 | [drl] epoch #31 | Logging diagnostics...
2020-09-03 14:59:21 | [drl] epoch #31 | Optimizing policy...
2020-09-03 14:59:21 | [drl] epoch #31 | Computing loss before
2020-09-03 14:59:21 | [drl] epoch #31 | Computing KL before
2020-09-03 14:59:21 | [drl] epoch #31 | Optimizing
2020-09-03 14:59:21 | [drl] epoch #31 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:21 | [drl] epoch #31 | computing loss before
2020-09-03 14:59:21 | [drl] epoch #31 | computing gradient
2020-09-03 14:59:21 | [drl] epoch #31 | gradient computed
2020-09-03 14:59:21 | [drl] epoch #31 | computing descent direction
2020-09-03 14:59:22 | [drl] epoch #31 | descent direction computed
2020-09-03 14:59:22 | [drl] epoch #31 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:22 | [drl] epoch #31 | Violated because loss is NaN
2020-09-03 14:59:22 | [drl] epoch #31 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:22 | [drl] epoch #31 | backtrack iters: 14
2020-09-03 14:59:22 | [drl] epoch #31 | optimization finished
2020-09-03 14:59:22 | [drl] epoch #31 | Computing KL after
2020-09-03 14:59:22 | [drl] epoch #31 | Computing loss after
2020-09-03 14:59:22 | [drl] epoch #31 | Fitting baseline...
2020-09-03 14:59:22 | [drl] epoch #31 | Saving snapshot...
2020-09-03 14:59:22 | [drl] epoch #31 | Saved
2020-09-03 14:59:22 | [drl] epoch #31 | Time 26.27 s
2020-09-03 14:59:22 | [drl] epoch #31 | EpochTime 0.74 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -81070.4
AverageReturn                            -132436
Entropy                                        8.51363
EnvExecTime                                    0.0436196
Extras/EpisodeRewardMean                 -202717
Iteration                                     31
LinearFeatureBaseline/ExplainedVariance        0.727661
MaxReturn                                -132436
MinReturn                                -132436
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0547523
ProcessExecTime                                0.0014267
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-03 14:59:22 | [drl] epoch #32 | Obtaining samples...
2020-09-03 14:59:22 | [drl] epoch #32 | Obtaining samples for iteration 32...
2020-09-03 14:59:22 | [drl] epoch #32 | Logging diagnostics...
2020-09-03 14:59:22 | [drl] epoch #32 | Optimizing policy...
2020-09-03 14:59:22 | [drl] epoch #32 | Computing loss before
2020-09-03 14:59:22 | [drl] epoch #32 | Computing KL before
2020-09-03 14:59:22 | [drl] epoch #32 | Optimizing
2020-09-03 14:59:22 | [drl] epoch #32 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:22 | [drl] epoch #32 | computing loss before
2020-09-03 14:59:22 | [drl] epoch #32 | computing gradient
2020-09-03 14:59:22 | [drl] epoch #32 | gradient computed
2020-09-03 14:59:22 | [drl] epoch #32 | computing descent direction
2020-09-03 14:59:22 | [drl] epoch #32 | descent direction computed
2020-09-03 14:59:23 | [drl] epoch #32 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:23 | [drl] epoch #32 | Violated because loss is NaN
2020-09-03 14:59:23 | [drl] epoch #32 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:23 | [drl] epoch #32 | backtrack iters: 14
2020-09-03 14:59:23 | [drl] epoch #32 | optimization finished
2020-09-03 14:59:23 | [drl] epoch #32 | Computing KL after
2020-09-03 14:59:23 | [drl] epoch #32 | Computing loss after
2020-09-03 14:59:23 | [drl] epoch #32 | Fitting baseline...
2020-09-03 14:59:23 | [drl] epoch #32 | Saving snapshot...
2020-09-03 14:59:23 | [drl] epoch #32 | Saved
2020-09-03 14:59:23 | [drl] epoch #32 | Time 27.04 s
2020-09-03 14:59:23 | [drl] epoch #32 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -152810
AverageReturn                            -249823
Entropy                                        8.51363
EnvExecTime                                    0.0316429
Extras/EpisodeRewardMean                 -204145
Iteration                                     32
LinearFeatureBaseline/ExplainedVariance        0.77543
MaxReturn                                -249823
MinReturn                                -249823
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0584729
ProcessExecTime                                0.000942469
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:23 | [drl] epoch #33 | Obtaining samples...
2020-09-03 14:59:23 | [drl] epoch #33 | Obtaining samples for iteration 33...
2020-09-03 14:59:23 | [drl] epoch #33 | Logging diagnostics...
2020-09-03 14:59:23 | [drl] epoch #33 | Optimizing policy...
2020-09-03 14:59:23 | [drl] epoch #33 | Computing loss before
2020-09-03 14:59:23 | [drl] epoch #33 | Computing KL before
2020-09-03 14:59:23 | [drl] epoch #33 | Optimizing
2020-09-03 14:59:23 | [drl] epoch #33 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:23 | [drl] epoch #33 | computing loss before
2020-09-03 14:59:23 | [drl] epoch #33 | computing gradient
2020-09-03 14:59:23 | [drl] epoch #33 | gradient computed
2020-09-03 14:59:23 | [drl] epoch #33 | computing descent direction
2020-09-03 14:59:23 | [drl] epoch #33 | descent direction computed
2020-09-03 14:59:23 | [drl] epoch #33 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:23 | [drl] epoch #33 | Violated because loss is NaN
2020-09-03 14:59:23 | [drl] epoch #33 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:23 | [drl] epoch #33 | backtrack iters: 14
2020-09-03 14:59:23 | [drl] epoch #33 | optimization finished
2020-09-03 14:59:23 | [drl] epoch #33 | Computing KL after
2020-09-03 14:59:23 | [drl] epoch #33 | Computing loss after
2020-09-03 14:59:23 | [drl] epoch #33 | Fitting baseline...
2020-09-03 14:59:23 | [drl] epoch #33 | Saving snapshot...
2020-09-03 14:59:23 | [drl] epoch #33 | Saved
2020-09-03 14:59:23 | [drl] epoch #33 | Time 27.82 s
2020-09-03 14:59:23 | [drl] epoch #33 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -149549
AverageReturn                            -244485
Entropy                                        8.51363
EnvExecTime                                    0.0413802
Extras/EpisodeRewardMean                 -205331
Iteration                                     33
LinearFeatureBaseline/ExplainedVariance        0.999521
MaxReturn                                -244485
MinReturn                                -244485
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0454857
ProcessExecTime                                0.000953913
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:23 | [drl] epoch #34 | Obtaining samples...
2020-09-03 14:59:23 | [drl] epoch #34 | Obtaining samples for iteration 34...
2020-09-03 14:59:23 | [drl] epoch #34 | Logging diagnostics...
2020-09-03 14:59:23 | [drl] epoch #34 | Optimizing policy...
2020-09-03 14:59:23 | [drl] epoch #34 | Computing loss before
2020-09-03 14:59:23 | [drl] epoch #34 | Computing KL before
2020-09-03 14:59:23 | [drl] epoch #34 | Optimizing
2020-09-03 14:59:23 | [drl] epoch #34 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:23 | [drl] epoch #34 | computing loss before
2020-09-03 14:59:23 | [drl] epoch #34 | computing gradient
2020-09-03 14:59:24 | [drl] epoch #34 | gradient computed
2020-09-03 14:59:24 | [drl] epoch #34 | computing descent direction
2020-09-03 14:59:24 | [drl] epoch #34 | descent direction computed
2020-09-03 14:59:24 | [drl] epoch #34 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:24 | [drl] epoch #34 | Violated because loss is NaN
2020-09-03 14:59:24 | [drl] epoch #34 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:24 | [drl] epoch #34 | backtrack iters: 14
2020-09-03 14:59:24 | [drl] epoch #34 | optimization finished
2020-09-03 14:59:24 | [drl] epoch #34 | Computing KL after
2020-09-03 14:59:24 | [drl] epoch #34 | Computing loss after
2020-09-03 14:59:24 | [drl] epoch #34 | Fitting baseline...
2020-09-03 14:59:24 | [drl] epoch #34 | Saving snapshot...
2020-09-03 14:59:24 | [drl] epoch #34 | Saved
2020-09-03 14:59:24 | [drl] epoch #34 | Time 28.59 s
2020-09-03 14:59:24 | [drl] epoch #34 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -105282
AverageReturn                            -172041
Entropy                                        8.51363
EnvExecTime                                    0.0380096
Extras/EpisodeRewardMean                 -204380
Iteration                                     34
LinearFeatureBaseline/ExplainedVariance        0.8175
MaxReturn                                -172041
MinReturn                                -172041
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0548122
ProcessExecTime                                0.000948191
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:24 | [drl] epoch #35 | Obtaining samples...
2020-09-03 14:59:24 | [drl] epoch #35 | Obtaining samples for iteration 35...
2020-09-03 14:59:24 | [drl] epoch #35 | Logging diagnostics...
2020-09-03 14:59:24 | [drl] epoch #35 | Optimizing policy...
2020-09-03 14:59:24 | [drl] epoch #35 | Computing loss before
2020-09-03 14:59:24 | [drl] epoch #35 | Computing KL before
2020-09-03 14:59:24 | [drl] epoch #35 | Optimizing
2020-09-03 14:59:24 | [drl] epoch #35 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:24 | [drl] epoch #35 | computing loss before
2020-09-03 14:59:24 | [drl] epoch #35 | computing gradient
2020-09-03 14:59:24 | [drl] epoch #35 | gradient computed
2020-09-03 14:59:24 | [drl] epoch #35 | computing descent direction
2020-09-03 14:59:25 | [drl] epoch #35 | descent direction computed
2020-09-03 14:59:25 | [drl] epoch #35 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:25 | [drl] epoch #35 | Violated because loss is NaN
2020-09-03 14:59:25 | [drl] epoch #35 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:25 | [drl] epoch #35 | backtrack iters: 14
2020-09-03 14:59:25 | [drl] epoch #35 | optimization finished
2020-09-03 14:59:25 | [drl] epoch #35 | Computing KL after
2020-09-03 14:59:25 | [drl] epoch #35 | Computing loss after
2020-09-03 14:59:25 | [drl] epoch #35 | Fitting baseline...
2020-09-03 14:59:25 | [drl] epoch #35 | Saving snapshot...
2020-09-03 14:59:25 | [drl] epoch #35 | Saved
2020-09-03 14:59:25 | [drl] epoch #35 | Time 29.35 s
2020-09-03 14:59:25 | [drl] epoch #35 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -83754.4
AverageReturn                            -136818
Entropy                                        8.51363
EnvExecTime                                    0.0325027
Extras/EpisodeRewardMean                 -202503
Iteration                                     35
LinearFeatureBaseline/ExplainedVariance        0.931261
MaxReturn                                -136818
MinReturn                                -136818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0543239
ProcessExecTime                                0.000985146
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:25 | [drl] epoch #36 | Obtaining samples...
2020-09-03 14:59:25 | [drl] epoch #36 | Obtaining samples for iteration 36...
2020-09-03 14:59:25 | [drl] epoch #36 | Logging diagnostics...
2020-09-03 14:59:25 | [drl] epoch #36 | Optimizing policy...
2020-09-03 14:59:25 | [drl] epoch #36 | Computing loss before
2020-09-03 14:59:25 | [drl] epoch #36 | Computing KL before
2020-09-03 14:59:25 | [drl] epoch #36 | Optimizing
2020-09-03 14:59:25 | [drl] epoch #36 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:25 | [drl] epoch #36 | computing loss before
2020-09-03 14:59:25 | [drl] epoch #36 | computing gradient
2020-09-03 14:59:25 | [drl] epoch #36 | gradient computed
2020-09-03 14:59:25 | [drl] epoch #36 | computing descent direction
2020-09-03 14:59:25 | [drl] epoch #36 | descent direction computed
2020-09-03 14:59:26 | [drl] epoch #36 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:26 | [drl] epoch #36 | Violated because loss is NaN
2020-09-03 14:59:26 | [drl] epoch #36 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:26 | [drl] epoch #36 | backtrack iters: 14
2020-09-03 14:59:26 | [drl] epoch #36 | optimization finished
2020-09-03 14:59:26 | [drl] epoch #36 | Computing KL after
2020-09-03 14:59:26 | [drl] epoch #36 | Computing loss after
2020-09-03 14:59:26 | [drl] epoch #36 | Fitting baseline...
2020-09-03 14:59:26 | [drl] epoch #36 | Saving snapshot...
2020-09-03 14:59:26 | [drl] epoch #36 | Saved
2020-09-03 14:59:26 | [drl] epoch #36 | Time 30.12 s
2020-09-03 14:59:26 | [drl] epoch #36 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -95636
AverageReturn                            -156260
Entropy                                        8.51363
EnvExecTime                                    0.0425053
Extras/EpisodeRewardMean                 -201253
Iteration                                     36
LinearFeatureBaseline/ExplainedVariance        0.983943
MaxReturn                                -156260
MinReturn                                -156260
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0512366
ProcessExecTime                                0.000929594
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:26 | [drl] epoch #37 | Obtaining samples...
2020-09-03 14:59:26 | [drl] epoch #37 | Obtaining samples for iteration 37...
2020-09-03 14:59:26 | [drl] epoch #37 | Logging diagnostics...
2020-09-03 14:59:26 | [drl] epoch #37 | Optimizing policy...
2020-09-03 14:59:26 | [drl] epoch #37 | Computing loss before
2020-09-03 14:59:26 | [drl] epoch #37 | Computing KL before
2020-09-03 14:59:26 | [drl] epoch #37 | Optimizing
2020-09-03 14:59:26 | [drl] epoch #37 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:26 | [drl] epoch #37 | computing loss before
2020-09-03 14:59:26 | [drl] epoch #37 | computing gradient
2020-09-03 14:59:26 | [drl] epoch #37 | gradient computed
2020-09-03 14:59:26 | [drl] epoch #37 | computing descent direction
2020-09-03 14:59:26 | [drl] epoch #37 | descent direction computed
2020-09-03 14:59:26 | [drl] epoch #37 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:26 | [drl] epoch #37 | Violated because loss is NaN
2020-09-03 14:59:26 | [drl] epoch #37 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:26 | [drl] epoch #37 | backtrack iters: 14
2020-09-03 14:59:26 | [drl] epoch #37 | optimization finished
2020-09-03 14:59:26 | [drl] epoch #37 | Computing KL after
2020-09-03 14:59:26 | [drl] epoch #37 | Computing loss after
2020-09-03 14:59:26 | [drl] epoch #37 | Fitting baseline...
2020-09-03 14:59:26 | [drl] epoch #37 | Saving snapshot...
2020-09-03 14:59:26 | [drl] epoch #37 | Saved
2020-09-03 14:59:26 | [drl] epoch #37 | Time 30.90 s
2020-09-03 14:59:26 | [drl] epoch #37 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -127458
AverageReturn                            -208340
Entropy                                        8.51363
EnvExecTime                                    0.042942
Extras/EpisodeRewardMean                 -201440
Iteration                                     37
LinearFeatureBaseline/ExplainedVariance        0.936051
MaxReturn                                -208340
MinReturn                                -208340
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0501647
ProcessExecTime                                0.00095892
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:26 | [drl] epoch #38 | Obtaining samples...
2020-09-03 14:59:26 | [drl] epoch #38 | Obtaining samples for iteration 38...
2020-09-03 14:59:27 | [drl] epoch #38 | Logging diagnostics...
2020-09-03 14:59:27 | [drl] epoch #38 | Optimizing policy...
2020-09-03 14:59:27 | [drl] epoch #38 | Computing loss before
2020-09-03 14:59:27 | [drl] epoch #38 | Computing KL before
2020-09-03 14:59:27 | [drl] epoch #38 | Optimizing
2020-09-03 14:59:27 | [drl] epoch #38 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:27 | [drl] epoch #38 | computing loss before
2020-09-03 14:59:27 | [drl] epoch #38 | computing gradient
2020-09-03 14:59:27 | [drl] epoch #38 | gradient computed
2020-09-03 14:59:27 | [drl] epoch #38 | computing descent direction
2020-09-03 14:59:27 | [drl] epoch #38 | descent direction computed
2020-09-03 14:59:27 | [drl] epoch #38 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:27 | [drl] epoch #38 | Violated because loss is NaN
2020-09-03 14:59:27 | [drl] epoch #38 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:27 | [drl] epoch #38 | backtrack iters: 14
2020-09-03 14:59:27 | [drl] epoch #38 | optimization finished
2020-09-03 14:59:27 | [drl] epoch #38 | Computing KL after
2020-09-03 14:59:27 | [drl] epoch #38 | Computing loss after
2020-09-03 14:59:27 | [drl] epoch #38 | Fitting baseline...
2020-09-03 14:59:27 | [drl] epoch #38 | Saving snapshot...
2020-09-03 14:59:27 | [drl] epoch #38 | Saved
2020-09-03 14:59:27 | [drl] epoch #38 | Time 31.67 s
2020-09-03 14:59:27 | [drl] epoch #38 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -182617
AverageReturn                            -298590
Entropy                                        8.51363
EnvExecTime                                    0.0329394
Extras/EpisodeRewardMean                 -203931
Iteration                                     38
LinearFeatureBaseline/ExplainedVariance        0.907401
MaxReturn                                -298590
MinReturn                                -298590
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0517352
ProcessExecTime                                0.00226212
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:27 | [drl] epoch #39 | Obtaining samples...
2020-09-03 14:59:27 | [drl] epoch #39 | Obtaining samples for iteration 39...
2020-09-03 14:59:27 | [drl] epoch #39 | Logging diagnostics...
2020-09-03 14:59:27 | [drl] epoch #39 | Optimizing policy...
2020-09-03 14:59:27 | [drl] epoch #39 | Computing loss before
2020-09-03 14:59:27 | [drl] epoch #39 | Computing KL before
2020-09-03 14:59:27 | [drl] epoch #39 | Optimizing
2020-09-03 14:59:27 | [drl] epoch #39 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:27 | [drl] epoch #39 | computing loss before
2020-09-03 14:59:27 | [drl] epoch #39 | computing gradient
2020-09-03 14:59:27 | [drl] epoch #39 | gradient computed
2020-09-03 14:59:27 | [drl] epoch #39 | computing descent direction
2020-09-03 14:59:28 | [drl] epoch #39 | descent direction computed
2020-09-03 14:59:28 | [drl] epoch #39 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:28 | [drl] epoch #39 | Violated because loss is NaN
2020-09-03 14:59:28 | [drl] epoch #39 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:28 | [drl] epoch #39 | backtrack iters: 14
2020-09-03 14:59:28 | [drl] epoch #39 | optimization finished
2020-09-03 14:59:28 | [drl] epoch #39 | Computing KL after
2020-09-03 14:59:28 | [drl] epoch #39 | Computing loss after
2020-09-03 14:59:28 | [drl] epoch #39 | Fitting baseline...
2020-09-03 14:59:28 | [drl] epoch #39 | Saving snapshot...
2020-09-03 14:59:28 | [drl] epoch #39 | Saved
2020-09-03 14:59:28 | [drl] epoch #39 | Time 32.45 s
2020-09-03 14:59:28 | [drl] epoch #39 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -94049.3
AverageReturn                            -153662
Entropy                                        8.51363
EnvExecTime                                    0.0323532
Extras/EpisodeRewardMean                 -202674
Iteration                                     39
LinearFeatureBaseline/ExplainedVariance        0.0829904
MaxReturn                                -153662
MinReturn                                -153662
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0480287
ProcessExecTime                                0.00101423
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:28 | [drl] epoch #40 | Obtaining samples...
2020-09-03 14:59:28 | [drl] epoch #40 | Obtaining samples for iteration 40...
2020-09-03 14:59:28 | [drl] epoch #40 | Logging diagnostics...
2020-09-03 14:59:28 | [drl] epoch #40 | Optimizing policy...
2020-09-03 14:59:28 | [drl] epoch #40 | Computing loss before
2020-09-03 14:59:28 | [drl] epoch #40 | Computing KL before
2020-09-03 14:59:28 | [drl] epoch #40 | Optimizing
2020-09-03 14:59:28 | [drl] epoch #40 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:28 | [drl] epoch #40 | computing loss before
2020-09-03 14:59:28 | [drl] epoch #40 | computing gradient
2020-09-03 14:59:28 | [drl] epoch #40 | gradient computed
2020-09-03 14:59:28 | [drl] epoch #40 | computing descent direction
2020-09-03 14:59:29 | [drl] epoch #40 | descent direction computed
2020-09-03 14:59:29 | [drl] epoch #40 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:29 | [drl] epoch #40 | Violated because loss is NaN
2020-09-03 14:59:29 | [drl] epoch #40 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:29 | [drl] epoch #40 | backtrack iters: 14
2020-09-03 14:59:29 | [drl] epoch #40 | optimization finished
2020-09-03 14:59:29 | [drl] epoch #40 | Computing KL after
2020-09-03 14:59:29 | [drl] epoch #40 | Computing loss after
2020-09-03 14:59:29 | [drl] epoch #40 | Fitting baseline...
2020-09-03 14:59:29 | [drl] epoch #40 | Saving snapshot...
2020-09-03 14:59:29 | [drl] epoch #40 | Saved
2020-09-03 14:59:29 | [drl] epoch #40 | Time 33.22 s
2020-09-03 14:59:29 | [drl] epoch #40 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -175642
AverageReturn                            -287175
Entropy                                        8.51363
EnvExecTime                                    0.0340331
Extras/EpisodeRewardMean                 -204735
Iteration                                     40
LinearFeatureBaseline/ExplainedVariance        0.780284
MaxReturn                                -287175
MinReturn                                -287175
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0654237
ProcessExecTime                                0.000972748
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:29 | [drl] epoch #41 | Obtaining samples...
2020-09-03 14:59:29 | [drl] epoch #41 | Obtaining samples for iteration 41...
2020-09-03 14:59:29 | [drl] epoch #41 | Logging diagnostics...
2020-09-03 14:59:29 | [drl] epoch #41 | Optimizing policy...
2020-09-03 14:59:29 | [drl] epoch #41 | Computing loss before
2020-09-03 14:59:29 | [drl] epoch #41 | Computing KL before
2020-09-03 14:59:29 | [drl] epoch #41 | Optimizing
2020-09-03 14:59:29 | [drl] epoch #41 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:29 | [drl] epoch #41 | computing loss before
2020-09-03 14:59:29 | [drl] epoch #41 | computing gradient
2020-09-03 14:59:29 | [drl] epoch #41 | gradient computed
2020-09-03 14:59:29 | [drl] epoch #41 | computing descent direction
2020-09-03 14:59:29 | [drl] epoch #41 | descent direction computed
2020-09-03 14:59:29 | [drl] epoch #41 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:29 | [drl] epoch #41 | Violated because loss is NaN
2020-09-03 14:59:29 | [drl] epoch #41 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:29 | [drl] epoch #41 | backtrack iters: 14
2020-09-03 14:59:29 | [drl] epoch #41 | optimization finished
2020-09-03 14:59:29 | [drl] epoch #41 | Computing KL after
2020-09-03 14:59:29 | [drl] epoch #41 | Computing loss after
2020-09-03 14:59:29 | [drl] epoch #41 | Fitting baseline...
2020-09-03 14:59:29 | [drl] epoch #41 | Saving snapshot...
2020-09-03 14:59:29 | [drl] epoch #41 | Saved
2020-09-03 14:59:29 | [drl] epoch #41 | Time 34.00 s
2020-09-03 14:59:29 | [drl] epoch #41 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -157949
AverageReturn                            -258225
Entropy                                        8.51363
EnvExecTime                                    0.0457845
Extras/EpisodeRewardMean                 -206009
Iteration                                     41
LinearFeatureBaseline/ExplainedVariance        0.987174
MaxReturn                                -258225
MinReturn                                -258225
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0460665
ProcessExecTime                                0.000941277
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:30 | [drl] epoch #42 | Obtaining samples...
2020-09-03 14:59:30 | [drl] epoch #42 | Obtaining samples for iteration 42...
2020-09-03 14:59:30 | [drl] epoch #42 | Logging diagnostics...
2020-09-03 14:59:30 | [drl] epoch #42 | Optimizing policy...
2020-09-03 14:59:30 | [drl] epoch #42 | Computing loss before
2020-09-03 14:59:30 | [drl] epoch #42 | Computing KL before
2020-09-03 14:59:30 | [drl] epoch #42 | Optimizing
2020-09-03 14:59:30 | [drl] epoch #42 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:30 | [drl] epoch #42 | computing loss before
2020-09-03 14:59:30 | [drl] epoch #42 | computing gradient
2020-09-03 14:59:30 | [drl] epoch #42 | gradient computed
2020-09-03 14:59:30 | [drl] epoch #42 | computing descent direction
2020-09-03 14:59:30 | [drl] epoch #42 | descent direction computed
2020-09-03 14:59:30 | [drl] epoch #42 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:30 | [drl] epoch #42 | Violated because loss is NaN
2020-09-03 14:59:30 | [drl] epoch #42 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:30 | [drl] epoch #42 | backtrack iters: 14
2020-09-03 14:59:30 | [drl] epoch #42 | optimization finished
2020-09-03 14:59:30 | [drl] epoch #42 | Computing KL after
2020-09-03 14:59:30 | [drl] epoch #42 | Computing loss after
2020-09-03 14:59:30 | [drl] epoch #42 | Fitting baseline...
2020-09-03 14:59:30 | [drl] epoch #42 | Saving snapshot...
2020-09-03 14:59:30 | [drl] epoch #42 | Saved
2020-09-03 14:59:30 | [drl] epoch #42 | Time 34.77 s
2020-09-03 14:59:30 | [drl] epoch #42 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93356.8
AverageReturn                            -152530
Entropy                                        8.51363
EnvExecTime                                    0.0342393
Extras/EpisodeRewardMean                 -204765
Iteration                                     42
LinearFeatureBaseline/ExplainedVariance        0.50533
MaxReturn                                -152530
MinReturn                                -152530
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0557432
ProcessExecTime                                0.000927687
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:30 | [drl] epoch #43 | Obtaining samples...
2020-09-03 14:59:30 | [drl] epoch #43 | Obtaining samples for iteration 43...
2020-09-03 14:59:30 | [drl] epoch #43 | Logging diagnostics...
2020-09-03 14:59:30 | [drl] epoch #43 | Optimizing policy...
2020-09-03 14:59:30 | [drl] epoch #43 | Computing loss before
2020-09-03 14:59:30 | [drl] epoch #43 | Computing KL before
2020-09-03 14:59:30 | [drl] epoch #43 | Optimizing
2020-09-03 14:59:30 | [drl] epoch #43 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:30 | [drl] epoch #43 | computing loss before
2020-09-03 14:59:30 | [drl] epoch #43 | computing gradient
2020-09-03 14:59:30 | [drl] epoch #43 | gradient computed
2020-09-03 14:59:30 | [drl] epoch #43 | computing descent direction
2020-09-03 14:59:31 | [drl] epoch #43 | descent direction computed
2020-09-03 14:59:31 | [drl] epoch #43 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:31 | [drl] epoch #43 | Violated because loss is NaN
2020-09-03 14:59:31 | [drl] epoch #43 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:31 | [drl] epoch #43 | backtrack iters: 14
2020-09-03 14:59:31 | [drl] epoch #43 | optimization finished
2020-09-03 14:59:31 | [drl] epoch #43 | Computing KL after
2020-09-03 14:59:31 | [drl] epoch #43 | Computing loss after
2020-09-03 14:59:31 | [drl] epoch #43 | Fitting baseline...
2020-09-03 14:59:31 | [drl] epoch #43 | Saving snapshot...
2020-09-03 14:59:31 | [drl] epoch #43 | Saved
2020-09-03 14:59:31 | [drl] epoch #43 | Time 35.56 s
2020-09-03 14:59:31 | [drl] epoch #43 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -174311
AverageReturn                            -285009
Entropy                                        8.51363
EnvExecTime                                    0.0381851
Extras/EpisodeRewardMean                 -206589
Iteration                                     43
LinearFeatureBaseline/ExplainedVariance        0.780239
MaxReturn                                -285009
MinReturn                                -285009
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.057322
ProcessExecTime                                0.000938892
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:31 | [drl] epoch #44 | Obtaining samples...
2020-09-03 14:59:31 | [drl] epoch #44 | Obtaining samples for iteration 44...
2020-09-03 14:59:31 | [drl] epoch #44 | Logging diagnostics...
2020-09-03 14:59:31 | [drl] epoch #44 | Optimizing policy...
2020-09-03 14:59:31 | [drl] epoch #44 | Computing loss before
2020-09-03 14:59:31 | [drl] epoch #44 | Computing KL before
2020-09-03 14:59:31 | [drl] epoch #44 | Optimizing
2020-09-03 14:59:31 | [drl] epoch #44 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:31 | [drl] epoch #44 | computing loss before
2020-09-03 14:59:31 | [drl] epoch #44 | computing gradient
2020-09-03 14:59:31 | [drl] epoch #44 | gradient computed
2020-09-03 14:59:31 | [drl] epoch #44 | computing descent direction
2020-09-03 14:59:32 | [drl] epoch #44 | descent direction computed
2020-09-03 14:59:32 | [drl] epoch #44 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:32 | [drl] epoch #44 | Violated because loss is NaN
2020-09-03 14:59:32 | [drl] epoch #44 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:32 | [drl] epoch #44 | backtrack iters: 14
2020-09-03 14:59:32 | [drl] epoch #44 | optimization finished
2020-09-03 14:59:32 | [drl] epoch #44 | Computing KL after
2020-09-03 14:59:32 | [drl] epoch #44 | Computing loss after
2020-09-03 14:59:32 | [drl] epoch #44 | Fitting baseline...
2020-09-03 14:59:32 | [drl] epoch #44 | Saving snapshot...
2020-09-03 14:59:32 | [drl] epoch #44 | Saved
2020-09-03 14:59:32 | [drl] epoch #44 | Time 36.32 s
2020-09-03 14:59:32 | [drl] epoch #44 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -174310
AverageReturn                            -284997
Entropy                                        8.51363
EnvExecTime                                    0.0359833
Extras/EpisodeRewardMean                 -208331
Iteration                                     44
LinearFeatureBaseline/ExplainedVariance        1
MaxReturn                                -284997
MinReturn                                -284997
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0487518
ProcessExecTime                                0.000953913
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:32 | [drl] epoch #45 | Obtaining samples...
2020-09-03 14:59:32 | [drl] epoch #45 | Obtaining samples for iteration 45...
2020-09-03 14:59:32 | [drl] epoch #45 | Logging diagnostics...
2020-09-03 14:59:32 | [drl] epoch #45 | Optimizing policy...
2020-09-03 14:59:32 | [drl] epoch #45 | Computing loss before
2020-09-03 14:59:32 | [drl] epoch #45 | Computing KL before
2020-09-03 14:59:32 | [drl] epoch #45 | Optimizing
2020-09-03 14:59:32 | [drl] epoch #45 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:32 | [drl] epoch #45 | computing loss before
2020-09-03 14:59:32 | [drl] epoch #45 | computing gradient
2020-09-03 14:59:32 | [drl] epoch #45 | gradient computed
2020-09-03 14:59:32 | [drl] epoch #45 | computing descent direction
2020-09-03 14:59:32 | [drl] epoch #45 | descent direction computed
2020-09-03 14:59:33 | [drl] epoch #45 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:33 | [drl] epoch #45 | Violated because loss is NaN
2020-09-03 14:59:33 | [drl] epoch #45 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:33 | [drl] epoch #45 | backtrack iters: 14
2020-09-03 14:59:33 | [drl] epoch #45 | optimization finished
2020-09-03 14:59:33 | [drl] epoch #45 | Computing KL after
2020-09-03 14:59:33 | [drl] epoch #45 | Computing loss after
2020-09-03 14:59:33 | [drl] epoch #45 | Fitting baseline...
2020-09-03 14:59:33 | [drl] epoch #45 | Saving snapshot...
2020-09-03 14:59:33 | [drl] epoch #45 | Saved
2020-09-03 14:59:33 | [drl] epoch #45 | Time 37.10 s
2020-09-03 14:59:33 | [drl] epoch #45 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -77151.7
AverageReturn                            -126014
Entropy                                        8.51363
EnvExecTime                                    0.0324478
Extras/EpisodeRewardMean                 -206542
Iteration                                     45
LinearFeatureBaseline/ExplainedVariance       -0.651504
MaxReturn                                -126014
MinReturn                                -126014
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.055686
ProcessExecTime                                0.000959635
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:33 | [drl] epoch #46 | Obtaining samples...
2020-09-03 14:59:33 | [drl] epoch #46 | Obtaining samples for iteration 46...
2020-09-03 14:59:33 | [drl] epoch #46 | Logging diagnostics...
2020-09-03 14:59:33 | [drl] epoch #46 | Optimizing policy...
2020-09-03 14:59:33 | [drl] epoch #46 | Computing loss before
2020-09-03 14:59:33 | [drl] epoch #46 | Computing KL before
2020-09-03 14:59:33 | [drl] epoch #46 | Optimizing
2020-09-03 14:59:33 | [drl] epoch #46 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:33 | [drl] epoch #46 | computing loss before
2020-09-03 14:59:33 | [drl] epoch #46 | computing gradient
2020-09-03 14:59:33 | [drl] epoch #46 | gradient computed
2020-09-03 14:59:33 | [drl] epoch #46 | computing descent direction
2020-09-03 14:59:33 | [drl] epoch #46 | descent direction computed
2020-09-03 14:59:33 | [drl] epoch #46 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:33 | [drl] epoch #46 | Violated because loss is NaN
2020-09-03 14:59:33 | [drl] epoch #46 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:33 | [drl] epoch #46 | backtrack iters: 14
2020-09-03 14:59:33 | [drl] epoch #46 | optimization finished
2020-09-03 14:59:33 | [drl] epoch #46 | Computing KL after
2020-09-03 14:59:33 | [drl] epoch #46 | Computing loss after
2020-09-03 14:59:33 | [drl] epoch #46 | Fitting baseline...
2020-09-03 14:59:33 | [drl] epoch #46 | Saving snapshot...
2020-09-03 14:59:33 | [drl] epoch #46 | Saved
2020-09-03 14:59:33 | [drl] epoch #46 | Time 37.87 s
2020-09-03 14:59:33 | [drl] epoch #46 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -165927
AverageReturn                            -271277
Entropy                                        8.51363
EnvExecTime                                    0.0502019
Extras/EpisodeRewardMean                 -207919
Iteration                                     46
LinearFeatureBaseline/ExplainedVariance        0.708287
MaxReturn                                -271277
MinReturn                                -271277
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0456855
ProcessExecTime                                0.00099349
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:33 | [drl] epoch #47 | Obtaining samples...
2020-09-03 14:59:33 | [drl] epoch #47 | Obtaining samples for iteration 47...
2020-09-03 14:59:33 | [drl] epoch #47 | Logging diagnostics...
2020-09-03 14:59:33 | [drl] epoch #47 | Optimizing policy...
2020-09-03 14:59:33 | [drl] epoch #47 | Computing loss before
2020-09-03 14:59:33 | [drl] epoch #47 | Computing KL before
2020-09-03 14:59:34 | [drl] epoch #47 | Optimizing
2020-09-03 14:59:34 | [drl] epoch #47 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:34 | [drl] epoch #47 | computing loss before
2020-09-03 14:59:34 | [drl] epoch #47 | computing gradient
2020-09-03 14:59:34 | [drl] epoch #47 | gradient computed
2020-09-03 14:59:34 | [drl] epoch #47 | computing descent direction
2020-09-03 14:59:34 | [drl] epoch #47 | descent direction computed
2020-09-03 14:59:34 | [drl] epoch #47 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:34 | [drl] epoch #47 | Violated because loss is NaN
2020-09-03 14:59:34 | [drl] epoch #47 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:34 | [drl] epoch #47 | backtrack iters: 14
2020-09-03 14:59:34 | [drl] epoch #47 | optimization finished
2020-09-03 14:59:34 | [drl] epoch #47 | Computing KL after
2020-09-03 14:59:34 | [drl] epoch #47 | Computing loss after
2020-09-03 14:59:34 | [drl] epoch #47 | Fitting baseline...
2020-09-03 14:59:34 | [drl] epoch #47 | Saving snapshot...
2020-09-03 14:59:34 | [drl] epoch #47 | Saved
2020-09-03 14:59:34 | [drl] epoch #47 | Time 38.62 s
2020-09-03 14:59:34 | [drl] epoch #47 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -85876.8
AverageReturn                            -140289
Entropy                                        8.51363
EnvExecTime                                    0.0410619
Extras/EpisodeRewardMean                 -206510
Iteration                                     47
LinearFeatureBaseline/ExplainedVariance        0.097853
MaxReturn                                -140289
MinReturn                                -140289
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.047477
ProcessExecTime                                0.000997305
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:34 | [drl] epoch #48 | Obtaining samples...
2020-09-03 14:59:34 | [drl] epoch #48 | Obtaining samples for iteration 48...
2020-09-03 14:59:34 | [drl] epoch #48 | Logging diagnostics...
2020-09-03 14:59:34 | [drl] epoch #48 | Optimizing policy...
2020-09-03 14:59:34 | [drl] epoch #48 | Computing loss before
2020-09-03 14:59:34 | [drl] epoch #48 | Computing KL before
2020-09-03 14:59:34 | [drl] epoch #48 | Optimizing
2020-09-03 14:59:34 | [drl] epoch #48 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:34 | [drl] epoch #48 | computing loss before
2020-09-03 14:59:34 | [drl] epoch #48 | computing gradient
2020-09-03 14:59:34 | [drl] epoch #48 | gradient computed
2020-09-03 14:59:34 | [drl] epoch #48 | computing descent direction
2020-09-03 14:59:35 | [drl] epoch #48 | descent direction computed
2020-09-03 14:59:35 | [drl] epoch #48 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:35 | [drl] epoch #48 | Violated because loss is NaN
2020-09-03 14:59:35 | [drl] epoch #48 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:35 | [drl] epoch #48 | backtrack iters: 14
2020-09-03 14:59:35 | [drl] epoch #48 | optimization finished
2020-09-03 14:59:35 | [drl] epoch #48 | Computing KL after
2020-09-03 14:59:35 | [drl] epoch #48 | Computing loss after
2020-09-03 14:59:35 | [drl] epoch #48 | Fitting baseline...
2020-09-03 14:59:35 | [drl] epoch #48 | Saving snapshot...
2020-09-03 14:59:35 | [drl] epoch #48 | Saved
2020-09-03 14:59:35 | [drl] epoch #48 | Time 39.36 s
2020-09-03 14:59:35 | [drl] epoch #48 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -177630
AverageReturn                            -290441
Entropy                                        8.51363
EnvExecTime                                    0.0322058
Extras/EpisodeRewardMean                 -208223
Iteration                                     48
LinearFeatureBaseline/ExplainedVariance        0.72819
MaxReturn                                -290441
MinReturn                                -290441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0531001
ProcessExecTime                                0.000996828
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:35 | [drl] epoch #49 | Obtaining samples...
2020-09-03 14:59:35 | [drl] epoch #49 | Obtaining samples for iteration 49...
2020-09-03 14:59:35 | [drl] epoch #49 | Logging diagnostics...
2020-09-03 14:59:35 | [drl] epoch #49 | Optimizing policy...
2020-09-03 14:59:35 | [drl] epoch #49 | Computing loss before
2020-09-03 14:59:35 | [drl] epoch #49 | Computing KL before
2020-09-03 14:59:35 | [drl] epoch #49 | Optimizing
2020-09-03 14:59:35 | [drl] epoch #49 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:35 | [drl] epoch #49 | computing loss before
2020-09-03 14:59:35 | [drl] epoch #49 | computing gradient
2020-09-03 14:59:35 | [drl] epoch #49 | gradient computed
2020-09-03 14:59:35 | [drl] epoch #49 | computing descent direction
2020-09-03 14:59:35 | [drl] epoch #49 | descent direction computed
2020-09-03 14:59:36 | [drl] epoch #49 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:36 | [drl] epoch #49 | Violated because loss is NaN
2020-09-03 14:59:36 | [drl] epoch #49 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:36 | [drl] epoch #49 | backtrack iters: 14
2020-09-03 14:59:36 | [drl] epoch #49 | optimization finished
2020-09-03 14:59:36 | [drl] epoch #49 | Computing KL after
2020-09-03 14:59:36 | [drl] epoch #49 | Computing loss after
2020-09-03 14:59:36 | [drl] epoch #49 | Fitting baseline...
2020-09-03 14:59:36 | [drl] epoch #49 | Saving snapshot...
2020-09-03 14:59:36 | [drl] epoch #49 | Saved
2020-09-03 14:59:36 | [drl] epoch #49 | Time 40.12 s
2020-09-03 14:59:36 | [drl] epoch #49 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93604.7
AverageReturn                            -152935
Entropy                                        8.51363
EnvExecTime                                    0.0372477
Extras/EpisodeRewardMean                 -207117
Iteration                                     49
LinearFeatureBaseline/ExplainedVariance        0.165185
MaxReturn                                -152935
MinReturn                                -152935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0647004
ProcessExecTime                                0.000933409
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:36 | [drl] epoch #50 | Obtaining samples...
2020-09-03 14:59:36 | [drl] epoch #50 | Obtaining samples for iteration 50...
2020-09-03 14:59:36 | [drl] epoch #50 | Logging diagnostics...
2020-09-03 14:59:36 | [drl] epoch #50 | Optimizing policy...
2020-09-03 14:59:36 | [drl] epoch #50 | Computing loss before
2020-09-03 14:59:36 | [drl] epoch #50 | Computing KL before
2020-09-03 14:59:36 | [drl] epoch #50 | Optimizing
2020-09-03 14:59:36 | [drl] epoch #50 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:36 | [drl] epoch #50 | computing loss before
2020-09-03 14:59:36 | [drl] epoch #50 | computing gradient
2020-09-03 14:59:36 | [drl] epoch #50 | gradient computed
2020-09-03 14:59:36 | [drl] epoch #50 | computing descent direction
2020-09-03 14:59:36 | [drl] epoch #50 | descent direction computed
2020-09-03 14:59:36 | [drl] epoch #50 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:36 | [drl] epoch #50 | Violated because loss is NaN
2020-09-03 14:59:36 | [drl] epoch #50 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:36 | [drl] epoch #50 | backtrack iters: 14
2020-09-03 14:59:36 | [drl] epoch #50 | optimization finished
2020-09-03 14:59:36 | [drl] epoch #50 | Computing KL after
2020-09-03 14:59:36 | [drl] epoch #50 | Computing loss after
2020-09-03 14:59:36 | [drl] epoch #50 | Fitting baseline...
2020-09-03 14:59:36 | [drl] epoch #50 | Saving snapshot...
2020-09-03 14:59:36 | [drl] epoch #50 | Saved
2020-09-03 14:59:36 | [drl] epoch #50 | Time 40.90 s
2020-09-03 14:59:36 | [drl] epoch #50 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -128502
AverageReturn                            -210039
Entropy                                        8.51363
EnvExecTime                                    0.0356874
Extras/EpisodeRewardMean                 -207175
Iteration                                     50
LinearFeatureBaseline/ExplainedVariance        0.924474
MaxReturn                                -210039
MinReturn                                -210039
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0461442
ProcessExecTime                                0.00135946
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:36 | [drl] epoch #51 | Obtaining samples...
2020-09-03 14:59:36 | [drl] epoch #51 | Obtaining samples for iteration 51...
2020-09-03 14:59:37 | [drl] epoch #51 | Logging diagnostics...
2020-09-03 14:59:37 | [drl] epoch #51 | Optimizing policy...
2020-09-03 14:59:37 | [drl] epoch #51 | Computing loss before
2020-09-03 14:59:37 | [drl] epoch #51 | Computing KL before
2020-09-03 14:59:37 | [drl] epoch #51 | Optimizing
2020-09-03 14:59:37 | [drl] epoch #51 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:37 | [drl] epoch #51 | computing loss before
2020-09-03 14:59:37 | [drl] epoch #51 | computing gradient
2020-09-03 14:59:37 | [drl] epoch #51 | gradient computed
2020-09-03 14:59:37 | [drl] epoch #51 | computing descent direction
2020-09-03 14:59:37 | [drl] epoch #51 | descent direction computed
2020-09-03 14:59:37 | [drl] epoch #51 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:37 | [drl] epoch #51 | Violated because loss is NaN
2020-09-03 14:59:37 | [drl] epoch #51 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:37 | [drl] epoch #51 | backtrack iters: 14
2020-09-03 14:59:37 | [drl] epoch #51 | optimization finished
2020-09-03 14:59:37 | [drl] epoch #51 | Computing KL after
2020-09-03 14:59:37 | [drl] epoch #51 | Computing loss after
2020-09-03 14:59:37 | [drl] epoch #51 | Fitting baseline...
2020-09-03 14:59:37 | [drl] epoch #51 | Saving snapshot...
2020-09-03 14:59:37 | [drl] epoch #51 | Saved
2020-09-03 14:59:37 | [drl] epoch #51 | Time 41.68 s
2020-09-03 14:59:37 | [drl] epoch #51 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -137705
AverageReturn                            -225111
Entropy                                        8.51363
EnvExecTime                                    0.032712
Extras/EpisodeRewardMean                 -207519
Iteration                                     51
LinearFeatureBaseline/ExplainedVariance        0.995334
MaxReturn                                -225111
MinReturn                                -225111
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0611267
ProcessExecTime                                0.000961065
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:37 | [drl] epoch #52 | Obtaining samples...
2020-09-03 14:59:37 | [drl] epoch #52 | Obtaining samples for iteration 52...
2020-09-03 14:59:37 | [drl] epoch #52 | Logging diagnostics...
2020-09-03 14:59:37 | [drl] epoch #52 | Optimizing policy...
2020-09-03 14:59:37 | [drl] epoch #52 | Computing loss before
2020-09-03 14:59:37 | [drl] epoch #52 | Computing KL before
2020-09-03 14:59:37 | [drl] epoch #52 | Optimizing
2020-09-03 14:59:37 | [drl] epoch #52 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:37 | [drl] epoch #52 | computing loss before
2020-09-03 14:59:37 | [drl] epoch #52 | computing gradient
2020-09-03 14:59:37 | [drl] epoch #52 | gradient computed
2020-09-03 14:59:37 | [drl] epoch #52 | computing descent direction
2020-09-03 14:59:38 | [drl] epoch #52 | descent direction computed
2020-09-03 14:59:38 | [drl] epoch #52 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:38 | [drl] epoch #52 | Violated because loss is NaN
2020-09-03 14:59:38 | [drl] epoch #52 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:38 | [drl] epoch #52 | backtrack iters: 14
2020-09-03 14:59:38 | [drl] epoch #52 | optimization finished
2020-09-03 14:59:38 | [drl] epoch #52 | Computing KL after
2020-09-03 14:59:38 | [drl] epoch #52 | Computing loss after
2020-09-03 14:59:38 | [drl] epoch #52 | Fitting baseline...
2020-09-03 14:59:38 | [drl] epoch #52 | Saving snapshot...
2020-09-03 14:59:38 | [drl] epoch #52 | Saved
2020-09-03 14:59:38 | [drl] epoch #52 | Time 42.45 s
2020-09-03 14:59:38 | [drl] epoch #52 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -94635.8
AverageReturn                            -154637
Entropy                                        8.51363
EnvExecTime                                    0.0344348
Extras/EpisodeRewardMean                 -206522
Iteration                                     52
LinearFeatureBaseline/ExplainedVariance        0.785821
MaxReturn                                -154637
MinReturn                                -154637
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0559986
ProcessExecTime                                0.00104952
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:38 | [drl] epoch #53 | Obtaining samples...
2020-09-03 14:59:38 | [drl] epoch #53 | Obtaining samples for iteration 53...
2020-09-03 14:59:38 | [drl] epoch #53 | Logging diagnostics...
2020-09-03 14:59:38 | [drl] epoch #53 | Optimizing policy...
2020-09-03 14:59:38 | [drl] epoch #53 | Computing loss before
2020-09-03 14:59:38 | [drl] epoch #53 | Computing KL before
2020-09-03 14:59:38 | [drl] epoch #53 | Optimizing
2020-09-03 14:59:38 | [drl] epoch #53 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:38 | [drl] epoch #53 | computing loss before
2020-09-03 14:59:38 | [drl] epoch #53 | computing gradient
2020-09-03 14:59:38 | [drl] epoch #53 | gradient computed
2020-09-03 14:59:38 | [drl] epoch #53 | computing descent direction
2020-09-03 14:59:39 | [drl] epoch #53 | descent direction computed
2020-09-03 14:59:39 | [drl] epoch #53 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:39 | [drl] epoch #53 | Violated because loss is NaN
2020-09-03 14:59:39 | [drl] epoch #53 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:39 | [drl] epoch #53 | backtrack iters: 14
2020-09-03 14:59:39 | [drl] epoch #53 | optimization finished
2020-09-03 14:59:39 | [drl] epoch #53 | Computing KL after
2020-09-03 14:59:39 | [drl] epoch #53 | Computing loss after
2020-09-03 14:59:39 | [drl] epoch #53 | Fitting baseline...
2020-09-03 14:59:39 | [drl] epoch #53 | Saving snapshot...
2020-09-03 14:59:39 | [drl] epoch #53 | Saved
2020-09-03 14:59:39 | [drl] epoch #53 | Time 43.24 s
2020-09-03 14:59:39 | [drl] epoch #53 | EpochTime 0.78 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -96025.6
AverageReturn                            -156887
Entropy                                        8.51363
EnvExecTime                                    0.0398407
Extras/EpisodeRewardMean                 -205603
Iteration                                     53
LinearFeatureBaseline/ExplainedVariance        0.999817
MaxReturn                                -156887
MinReturn                                -156887
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0454571
ProcessExecTime                                0.00733495
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:39 | [drl] epoch #54 | Obtaining samples...
2020-09-03 14:59:39 | [drl] epoch #54 | Obtaining samples for iteration 54...
2020-09-03 14:59:39 | [drl] epoch #54 | Logging diagnostics...
2020-09-03 14:59:39 | [drl] epoch #54 | Optimizing policy...
2020-09-03 14:59:39 | [drl] epoch #54 | Computing loss before
2020-09-03 14:59:39 | [drl] epoch #54 | Computing KL before
2020-09-03 14:59:39 | [drl] epoch #54 | Optimizing
2020-09-03 14:59:39 | [drl] epoch #54 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:39 | [drl] epoch #54 | computing loss before
2020-09-03 14:59:39 | [drl] epoch #54 | computing gradient
2020-09-03 14:59:39 | [drl] epoch #54 | gradient computed
2020-09-03 14:59:39 | [drl] epoch #54 | computing descent direction
2020-09-03 14:59:39 | [drl] epoch #54 | descent direction computed
2020-09-03 14:59:39 | [drl] epoch #54 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:39 | [drl] epoch #54 | Violated because loss is NaN
2020-09-03 14:59:39 | [drl] epoch #54 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:39 | [drl] epoch #54 | backtrack iters: 14
2020-09-03 14:59:39 | [drl] epoch #54 | optimization finished
2020-09-03 14:59:39 | [drl] epoch #54 | Computing KL after
2020-09-03 14:59:39 | [drl] epoch #54 | Computing loss after
2020-09-03 14:59:39 | [drl] epoch #54 | Fitting baseline...
2020-09-03 14:59:39 | [drl] epoch #54 | Saving snapshot...
2020-09-03 14:59:39 | [drl] epoch #54 | Saved
2020-09-03 14:59:39 | [drl] epoch #54 | Time 44.01 s
2020-09-03 14:59:39 | [drl] epoch #54 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -94380.9
AverageReturn                            -154213
Entropy                                        8.51363
EnvExecTime                                    0.0366988
Extras/EpisodeRewardMean                 -204668
Iteration                                     54
LinearFeatureBaseline/ExplainedVariance        0.999722
MaxReturn                                -154213
MinReturn                                -154213
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0501812
ProcessExecTime                                0.000958443
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:40 | [drl] epoch #55 | Obtaining samples...
2020-09-03 14:59:40 | [drl] epoch #55 | Obtaining samples for iteration 55...
2020-09-03 14:59:40 | [drl] epoch #55 | Logging diagnostics...
2020-09-03 14:59:40 | [drl] epoch #55 | Optimizing policy...
2020-09-03 14:59:40 | [drl] epoch #55 | Computing loss before
2020-09-03 14:59:40 | [drl] epoch #55 | Computing KL before
2020-09-03 14:59:40 | [drl] epoch #55 | Optimizing
2020-09-03 14:59:40 | [drl] epoch #55 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:40 | [drl] epoch #55 | computing loss before
2020-09-03 14:59:40 | [drl] epoch #55 | computing gradient
2020-09-03 14:59:40 | [drl] epoch #55 | gradient computed
2020-09-03 14:59:40 | [drl] epoch #55 | computing descent direction
2020-09-03 14:59:40 | [drl] epoch #55 | descent direction computed
2020-09-03 14:59:40 | [drl] epoch #55 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:40 | [drl] epoch #55 | Violated because loss is NaN
2020-09-03 14:59:40 | [drl] epoch #55 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:40 | [drl] epoch #55 | backtrack iters: 14
2020-09-03 14:59:40 | [drl] epoch #55 | optimization finished
2020-09-03 14:59:40 | [drl] epoch #55 | Computing KL after
2020-09-03 14:59:40 | [drl] epoch #55 | Computing loss after
2020-09-03 14:59:40 | [drl] epoch #55 | Fitting baseline...
2020-09-03 14:59:40 | [drl] epoch #55 | Saving snapshot...
2020-09-03 14:59:40 | [drl] epoch #55 | Saved
2020-09-03 14:59:40 | [drl] epoch #55 | Time 44.78 s
2020-09-03 14:59:40 | [drl] epoch #55 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -102312
AverageReturn                            -167192
Entropy                                        8.51363
EnvExecTime                                    0.0316386
Extras/EpisodeRewardMean                 -203999
Iteration                                     55
LinearFeatureBaseline/ExplainedVariance        0.99385
MaxReturn                                -167192
MinReturn                                -167192
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0539968
ProcessExecTime                                0.00100493
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:40 | [drl] epoch #56 | Obtaining samples...
2020-09-03 14:59:40 | [drl] epoch #56 | Obtaining samples for iteration 56...
2020-09-03 14:59:40 | [drl] epoch #56 | Logging diagnostics...
2020-09-03 14:59:40 | [drl] epoch #56 | Optimizing policy...
2020-09-03 14:59:40 | [drl] epoch #56 | Computing loss before
2020-09-03 14:59:40 | [drl] epoch #56 | Computing KL before
2020-09-03 14:59:40 | [drl] epoch #56 | Optimizing
2020-09-03 14:59:40 | [drl] epoch #56 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:40 | [drl] epoch #56 | computing loss before
2020-09-03 14:59:40 | [drl] epoch #56 | computing gradient
2020-09-03 14:59:40 | [drl] epoch #56 | gradient computed
2020-09-03 14:59:40 | [drl] epoch #56 | computing descent direction
2020-09-03 14:59:41 | [drl] epoch #56 | descent direction computed
2020-09-03 14:59:41 | [drl] epoch #56 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:41 | [drl] epoch #56 | Violated because loss is NaN
2020-09-03 14:59:41 | [drl] epoch #56 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:41 | [drl] epoch #56 | backtrack iters: 14
2020-09-03 14:59:41 | [drl] epoch #56 | optimization finished
2020-09-03 14:59:41 | [drl] epoch #56 | Computing KL after
2020-09-03 14:59:41 | [drl] epoch #56 | Computing loss after
2020-09-03 14:59:41 | [drl] epoch #56 | Fitting baseline...
2020-09-03 14:59:41 | [drl] epoch #56 | Saving snapshot...
2020-09-03 14:59:41 | [drl] epoch #56 | Saved
2020-09-03 14:59:41 | [drl] epoch #56 | Time 45.55 s
2020-09-03 14:59:41 | [drl] epoch #56 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -98891.9
AverageReturn                            -161580
Entropy                                        8.51363
EnvExecTime                                    0.0354688
Extras/EpisodeRewardMean                 -203255
Iteration                                     56
LinearFeatureBaseline/ExplainedVariance        0.998727
MaxReturn                                -161580
MinReturn                                -161580
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0585108
ProcessExecTime                                0.000973225
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:41 | [drl] epoch #57 | Obtaining samples...
2020-09-03 14:59:41 | [drl] epoch #57 | Obtaining samples for iteration 57...
2020-09-03 14:59:41 | [drl] epoch #57 | Logging diagnostics...
2020-09-03 14:59:41 | [drl] epoch #57 | Optimizing policy...
2020-09-03 14:59:41 | [drl] epoch #57 | Computing loss before
2020-09-03 14:59:41 | [drl] epoch #57 | Computing KL before
2020-09-03 14:59:41 | [drl] epoch #57 | Optimizing
2020-09-03 14:59:41 | [drl] epoch #57 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:41 | [drl] epoch #57 | computing loss before
2020-09-03 14:59:41 | [drl] epoch #57 | computing gradient
2020-09-03 14:59:41 | [drl] epoch #57 | gradient computed
2020-09-03 14:59:41 | [drl] epoch #57 | computing descent direction
2020-09-03 14:59:42 | [drl] epoch #57 | descent direction computed
2020-09-03 14:59:42 | [drl] epoch #57 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:42 | [drl] epoch #57 | Violated because loss is NaN
2020-09-03 14:59:42 | [drl] epoch #57 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:42 | [drl] epoch #57 | backtrack iters: 14
2020-09-03 14:59:42 | [drl] epoch #57 | optimization finished
2020-09-03 14:59:42 | [drl] epoch #57 | Computing KL after
2020-09-03 14:59:42 | [drl] epoch #57 | Computing loss after
2020-09-03 14:59:42 | [drl] epoch #57 | Fitting baseline...
2020-09-03 14:59:42 | [drl] epoch #57 | Saving snapshot...
2020-09-03 14:59:42 | [drl] epoch #57 | Saved
2020-09-03 14:59:42 | [drl] epoch #57 | Time 46.32 s
2020-09-03 14:59:42 | [drl] epoch #57 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173259
AverageReturn                            -283275
Entropy                                        8.51363
EnvExecTime                                    0.0366607
Extras/EpisodeRewardMean                 -204634
Iteration                                     57
LinearFeatureBaseline/ExplainedVariance        0.812135
MaxReturn                                -283275
MinReturn                                -283275
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.046535
ProcessExecTime                                0.000941277
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:42 | [drl] epoch #58 | Obtaining samples...
2020-09-03 14:59:42 | [drl] epoch #58 | Obtaining samples for iteration 58...
2020-09-03 14:59:42 | [drl] epoch #58 | Logging diagnostics...
2020-09-03 14:59:42 | [drl] epoch #58 | Optimizing policy...
2020-09-03 14:59:42 | [drl] epoch #58 | Computing loss before
2020-09-03 14:59:42 | [drl] epoch #58 | Computing KL before
2020-09-03 14:59:42 | [drl] epoch #58 | Optimizing
2020-09-03 14:59:42 | [drl] epoch #58 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:42 | [drl] epoch #58 | computing loss before
2020-09-03 14:59:42 | [drl] epoch #58 | computing gradient
2020-09-03 14:59:42 | [drl] epoch #58 | gradient computed
2020-09-03 14:59:42 | [drl] epoch #58 | computing descent direction
2020-09-03 14:59:42 | [drl] epoch #58 | descent direction computed
2020-09-03 14:59:43 | [drl] epoch #58 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:43 | [drl] epoch #58 | Violated because loss is NaN
2020-09-03 14:59:43 | [drl] epoch #58 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:43 | [drl] epoch #58 | backtrack iters: 14
2020-09-03 14:59:43 | [drl] epoch #58 | optimization finished
2020-09-03 14:59:43 | [drl] epoch #58 | Computing KL after
2020-09-03 14:59:43 | [drl] epoch #58 | Computing loss after
2020-09-03 14:59:43 | [drl] epoch #58 | Fitting baseline...
2020-09-03 14:59:43 | [drl] epoch #58 | Saving snapshot...
2020-09-03 14:59:43 | [drl] epoch #58 | Saved
2020-09-03 14:59:43 | [drl] epoch #58 | Time 47.10 s
2020-09-03 14:59:43 | [drl] epoch #58 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106860
AverageReturn                            -174630
Entropy                                        8.51363
EnvExecTime                                    0.0318415
Extras/EpisodeRewardMean                 -204126
Iteration                                     58
LinearFeatureBaseline/ExplainedVariance        0.602093
MaxReturn                                -174630
MinReturn                                -174630
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.051966
ProcessExecTime                                0.000988483
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:43 | [drl] epoch #59 | Obtaining samples...
2020-09-03 14:59:43 | [drl] epoch #59 | Obtaining samples for iteration 59...
2020-09-03 14:59:43 | [drl] epoch #59 | Logging diagnostics...
2020-09-03 14:59:43 | [drl] epoch #59 | Optimizing policy...
2020-09-03 14:59:43 | [drl] epoch #59 | Computing loss before
2020-09-03 14:59:43 | [drl] epoch #59 | Computing KL before
2020-09-03 14:59:43 | [drl] epoch #59 | Optimizing
2020-09-03 14:59:43 | [drl] epoch #59 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:43 | [drl] epoch #59 | computing loss before
2020-09-03 14:59:43 | [drl] epoch #59 | computing gradient
2020-09-03 14:59:43 | [drl] epoch #59 | gradient computed
2020-09-03 14:59:43 | [drl] epoch #59 | computing descent direction
2020-09-03 14:59:43 | [drl] epoch #59 | descent direction computed
2020-09-03 14:59:43 | [drl] epoch #59 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:43 | [drl] epoch #59 | Violated because loss is NaN
2020-09-03 14:59:43 | [drl] epoch #59 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:43 | [drl] epoch #59 | backtrack iters: 14
2020-09-03 14:59:43 | [drl] epoch #59 | optimization finished
2020-09-03 14:59:43 | [drl] epoch #59 | Computing KL after
2020-09-03 14:59:43 | [drl] epoch #59 | Computing loss after
2020-09-03 14:59:43 | [drl] epoch #59 | Fitting baseline...
2020-09-03 14:59:43 | [drl] epoch #59 | Saving snapshot...
2020-09-03 14:59:43 | [drl] epoch #59 | Saved
2020-09-03 14:59:43 | [drl] epoch #59 | Time 47.87 s
2020-09-03 14:59:43 | [drl] epoch #59 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -85407.1
AverageReturn                            -139527
Entropy                                        8.51363
EnvExecTime                                    0.0356905
Extras/EpisodeRewardMean                 -203049
Iteration                                     59
LinearFeatureBaseline/ExplainedVariance        0.93504
MaxReturn                                -139527
MinReturn                                -139527
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0454421
ProcessExecTime                                0.000956774
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:43 | [drl] epoch #60 | Obtaining samples...
2020-09-03 14:59:43 | [drl] epoch #60 | Obtaining samples for iteration 60...
2020-09-03 14:59:43 | [drl] epoch #60 | Logging diagnostics...
2020-09-03 14:59:43 | [drl] epoch #60 | Optimizing policy...
2020-09-03 14:59:43 | [drl] epoch #60 | Computing loss before
2020-09-03 14:59:44 | [drl] epoch #60 | Computing KL before
2020-09-03 14:59:44 | [drl] epoch #60 | Optimizing
2020-09-03 14:59:44 | [drl] epoch #60 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:44 | [drl] epoch #60 | computing loss before
2020-09-03 14:59:44 | [drl] epoch #60 | computing gradient
2020-09-03 14:59:44 | [drl] epoch #60 | gradient computed
2020-09-03 14:59:44 | [drl] epoch #60 | computing descent direction
2020-09-03 14:59:44 | [drl] epoch #60 | descent direction computed
2020-09-03 14:59:44 | [drl] epoch #60 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:44 | [drl] epoch #60 | Violated because loss is NaN
2020-09-03 14:59:44 | [drl] epoch #60 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:44 | [drl] epoch #60 | backtrack iters: 14
2020-09-03 14:59:44 | [drl] epoch #60 | optimization finished
2020-09-03 14:59:44 | [drl] epoch #60 | Computing KL after
2020-09-03 14:59:44 | [drl] epoch #60 | Computing loss after
2020-09-03 14:59:44 | [drl] epoch #60 | Fitting baseline...
2020-09-03 14:59:44 | [drl] epoch #60 | Saving snapshot...
2020-09-03 14:59:44 | [drl] epoch #60 | Saved
2020-09-03 14:59:44 | [drl] epoch #60 | Time 48.66 s
2020-09-03 14:59:44 | [drl] epoch #60 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -181040
AverageReturn                            -296004
Entropy                                        8.51363
EnvExecTime                                    0.0314913
Extras/EpisodeRewardMean                 -204573
Iteration                                     60
LinearFeatureBaseline/ExplainedVariance        0.716422
MaxReturn                                -296004
MinReturn                                -296004
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0557208
ProcessExecTime                                0.000957966
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:44 | [drl] epoch #61 | Obtaining samples...
2020-09-03 14:59:44 | [drl] epoch #61 | Obtaining samples for iteration 61...
2020-09-03 14:59:44 | [drl] epoch #61 | Logging diagnostics...
2020-09-03 14:59:44 | [drl] epoch #61 | Optimizing policy...
2020-09-03 14:59:44 | [drl] epoch #61 | Computing loss before
2020-09-03 14:59:44 | [drl] epoch #61 | Computing KL before
2020-09-03 14:59:44 | [drl] epoch #61 | Optimizing
2020-09-03 14:59:44 | [drl] epoch #61 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:44 | [drl] epoch #61 | computing loss before
2020-09-03 14:59:44 | [drl] epoch #61 | computing gradient
2020-09-03 14:59:44 | [drl] epoch #61 | gradient computed
2020-09-03 14:59:44 | [drl] epoch #61 | computing descent direction
2020-09-03 14:59:45 | [drl] epoch #61 | descent direction computed
2020-09-03 14:59:45 | [drl] epoch #61 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:45 | [drl] epoch #61 | Violated because loss is NaN
2020-09-03 14:59:45 | [drl] epoch #61 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:45 | [drl] epoch #61 | backtrack iters: 14
2020-09-03 14:59:45 | [drl] epoch #61 | optimization finished
2020-09-03 14:59:45 | [drl] epoch #61 | Computing KL after
2020-09-03 14:59:45 | [drl] epoch #61 | Computing loss after
2020-09-03 14:59:45 | [drl] epoch #61 | Fitting baseline...
2020-09-03 14:59:45 | [drl] epoch #61 | Saving snapshot...
2020-09-03 14:59:45 | [drl] epoch #61 | Saved
2020-09-03 14:59:45 | [drl] epoch #61 | Time 49.43 s
2020-09-03 14:59:45 | [drl] epoch #61 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -163842
AverageReturn                            -267869
Entropy                                        8.51363
EnvExecTime                                    0.0379148
Extras/EpisodeRewardMean                 -205594
Iteration                                     61
LinearFeatureBaseline/ExplainedVariance        0.988761
MaxReturn                                -267869
MinReturn                                -267869
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.056499
ProcessExecTime                                0.000953674
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:45 | [drl] epoch #62 | Obtaining samples...
2020-09-03 14:59:45 | [drl] epoch #62 | Obtaining samples for iteration 62...
2020-09-03 14:59:45 | [drl] epoch #62 | Logging diagnostics...
2020-09-03 14:59:45 | [drl] epoch #62 | Optimizing policy...
2020-09-03 14:59:45 | [drl] epoch #62 | Computing loss before
2020-09-03 14:59:45 | [drl] epoch #62 | Computing KL before
2020-09-03 14:59:45 | [drl] epoch #62 | Optimizing
2020-09-03 14:59:45 | [drl] epoch #62 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:45 | [drl] epoch #62 | computing loss before
2020-09-03 14:59:45 | [drl] epoch #62 | computing gradient
2020-09-03 14:59:45 | [drl] epoch #62 | gradient computed
2020-09-03 14:59:45 | [drl] epoch #62 | computing descent direction
2020-09-03 14:59:46 | [drl] epoch #62 | descent direction computed
2020-09-03 14:59:46 | [drl] epoch #62 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:46 | [drl] epoch #62 | Violated because loss is NaN
2020-09-03 14:59:46 | [drl] epoch #62 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:46 | [drl] epoch #62 | backtrack iters: 14
2020-09-03 14:59:46 | [drl] epoch #62 | optimization finished
2020-09-03 14:59:46 | [drl] epoch #62 | Computing KL after
2020-09-03 14:59:46 | [drl] epoch #62 | Computing loss after
2020-09-03 14:59:46 | [drl] epoch #62 | Fitting baseline...
2020-09-03 14:59:46 | [drl] epoch #62 | Saving snapshot...
2020-09-03 14:59:46 | [drl] epoch #62 | Saved
2020-09-03 14:59:46 | [drl] epoch #62 | Time 50.20 s
2020-09-03 14:59:46 | [drl] epoch #62 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -97578.5
AverageReturn                            -159450
Entropy                                        8.51363
EnvExecTime                                    0.0335228
Extras/EpisodeRewardMean                 -204862
Iteration                                     62
LinearFeatureBaseline/ExplainedVariance        0.524721
MaxReturn                                -159450
MinReturn                                -159450
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0558114
ProcessExecTime                                0.000940561
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:46 | [drl] epoch #63 | Obtaining samples...
2020-09-03 14:59:46 | [drl] epoch #63 | Obtaining samples for iteration 63...
2020-09-03 14:59:46 | [drl] epoch #63 | Logging diagnostics...
2020-09-03 14:59:46 | [drl] epoch #63 | Optimizing policy...
2020-09-03 14:59:46 | [drl] epoch #63 | Computing loss before
2020-09-03 14:59:46 | [drl] epoch #63 | Computing KL before
2020-09-03 14:59:46 | [drl] epoch #63 | Optimizing
2020-09-03 14:59:46 | [drl] epoch #63 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:46 | [drl] epoch #63 | computing loss before
2020-09-03 14:59:46 | [drl] epoch #63 | computing gradient
2020-09-03 14:59:46 | [drl] epoch #63 | gradient computed
2020-09-03 14:59:46 | [drl] epoch #63 | computing descent direction
2020-09-03 14:59:46 | [drl] epoch #63 | descent direction computed
2020-09-03 14:59:46 | [drl] epoch #63 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:46 | [drl] epoch #63 | Violated because loss is NaN
2020-09-03 14:59:46 | [drl] epoch #63 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:46 | [drl] epoch #63 | backtrack iters: 14
2020-09-03 14:59:46 | [drl] epoch #63 | optimization finished
2020-09-03 14:59:46 | [drl] epoch #63 | Computing KL after
2020-09-03 14:59:46 | [drl] epoch #63 | Computing loss after
2020-09-03 14:59:46 | [drl] epoch #63 | Fitting baseline...
2020-09-03 14:59:46 | [drl] epoch #63 | Saving snapshot...
2020-09-03 14:59:46 | [drl] epoch #63 | Saved
2020-09-03 14:59:46 | [drl] epoch #63 | Time 50.97 s
2020-09-03 14:59:46 | [drl] epoch #63 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -88079
AverageReturn                            -143903
Entropy                                        8.51363
EnvExecTime                                    0.0343523
Extras/EpisodeRewardMean                 -203909
Iteration                                     63
LinearFeatureBaseline/ExplainedVariance        0.988021
MaxReturn                                -143903
MinReturn                                -143903
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0517919
ProcessExecTime                                0.000939846
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:46 | [drl] epoch #64 | Obtaining samples...
2020-09-03 14:59:46 | [drl] epoch #64 | Obtaining samples for iteration 64...
2020-09-03 14:59:47 | [drl] epoch #64 | Logging diagnostics...
2020-09-03 14:59:47 | [drl] epoch #64 | Optimizing policy...
2020-09-03 14:59:47 | [drl] epoch #64 | Computing loss before
2020-09-03 14:59:47 | [drl] epoch #64 | Computing KL before
2020-09-03 14:59:47 | [drl] epoch #64 | Optimizing
2020-09-03 14:59:47 | [drl] epoch #64 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:47 | [drl] epoch #64 | computing loss before
2020-09-03 14:59:47 | [drl] epoch #64 | computing gradient
2020-09-03 14:59:47 | [drl] epoch #64 | gradient computed
2020-09-03 14:59:47 | [drl] epoch #64 | computing descent direction
2020-09-03 14:59:47 | [drl] epoch #64 | descent direction computed
2020-09-03 14:59:47 | [drl] epoch #64 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:47 | [drl] epoch #64 | Violated because loss is NaN
2020-09-03 14:59:47 | [drl] epoch #64 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:47 | [drl] epoch #64 | backtrack iters: 14
2020-09-03 14:59:47 | [drl] epoch #64 | optimization finished
2020-09-03 14:59:47 | [drl] epoch #64 | Computing KL after
2020-09-03 14:59:47 | [drl] epoch #64 | Computing loss after
2020-09-03 14:59:47 | [drl] epoch #64 | Fitting baseline...
2020-09-03 14:59:47 | [drl] epoch #64 | Saving snapshot...
2020-09-03 14:59:47 | [drl] epoch #64 | Saved
2020-09-03 14:59:47 | [drl] epoch #64 | Time 51.74 s
2020-09-03 14:59:47 | [drl] epoch #64 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -87203.5
AverageReturn                            -142464
Entropy                                        8.51363
EnvExecTime                                    0.0392408
Extras/EpisodeRewardMean                 -202964
Iteration                                     64
LinearFeatureBaseline/ExplainedVariance        0.999881
MaxReturn                                -142464
MinReturn                                -142464
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0491309
ProcessExecTime                                0.00101209
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:47 | [drl] epoch #65 | Obtaining samples...
2020-09-03 14:59:47 | [drl] epoch #65 | Obtaining samples for iteration 65...
2020-09-03 14:59:47 | [drl] epoch #65 | Logging diagnostics...
2020-09-03 14:59:47 | [drl] epoch #65 | Optimizing policy...
2020-09-03 14:59:47 | [drl] epoch #65 | Computing loss before
2020-09-03 14:59:47 | [drl] epoch #65 | Computing KL before
2020-09-03 14:59:47 | [drl] epoch #65 | Optimizing
2020-09-03 14:59:47 | [drl] epoch #65 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:47 | [drl] epoch #65 | computing loss before
2020-09-03 14:59:47 | [drl] epoch #65 | computing gradient
2020-09-03 14:59:47 | [drl] epoch #65 | gradient computed
2020-09-03 14:59:47 | [drl] epoch #65 | computing descent direction
2020-09-03 14:59:48 | [drl] epoch #65 | descent direction computed
2020-09-03 14:59:48 | [drl] epoch #65 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:48 | [drl] epoch #65 | Violated because loss is NaN
2020-09-03 14:59:48 | [drl] epoch #65 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:48 | [drl] epoch #65 | backtrack iters: 14
2020-09-03 14:59:48 | [drl] epoch #65 | optimization finished
2020-09-03 14:59:48 | [drl] epoch #65 | Computing KL after
2020-09-03 14:59:48 | [drl] epoch #65 | Computing loss after
2020-09-03 14:59:48 | [drl] epoch #65 | Fitting baseline...
2020-09-03 14:59:48 | [drl] epoch #65 | Saving snapshot...
2020-09-03 14:59:48 | [drl] epoch #65 | Saved
2020-09-03 14:59:48 | [drl] epoch #65 | Time 52.51 s
2020-09-03 14:59:48 | [drl] epoch #65 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -164100
AverageReturn                            -268298
Entropy                                        8.51363
EnvExecTime                                    0.0381284
Extras/EpisodeRewardMean                 -203954
Iteration                                     65
LinearFeatureBaseline/ExplainedVariance        0.776063
MaxReturn                                -268298
MinReturn                                -268298
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0490499
ProcessExecTime                                0.000993729
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:48 | [drl] epoch #66 | Obtaining samples...
2020-09-03 14:59:48 | [drl] epoch #66 | Obtaining samples for iteration 66...
2020-09-03 14:59:48 | [drl] epoch #66 | Logging diagnostics...
2020-09-03 14:59:48 | [drl] epoch #66 | Optimizing policy...
2020-09-03 14:59:48 | [drl] epoch #66 | Computing loss before
2020-09-03 14:59:48 | [drl] epoch #66 | Computing KL before
2020-09-03 14:59:48 | [drl] epoch #66 | Optimizing
2020-09-03 14:59:48 | [drl] epoch #66 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:48 | [drl] epoch #66 | computing loss before
2020-09-03 14:59:48 | [drl] epoch #66 | computing gradient
2020-09-03 14:59:48 | [drl] epoch #66 | gradient computed
2020-09-03 14:59:48 | [drl] epoch #66 | computing descent direction
2020-09-03 14:59:49 | [drl] epoch #66 | descent direction computed
2020-09-03 14:59:49 | [drl] epoch #66 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:49 | [drl] epoch #66 | Violated because loss is NaN
2020-09-03 14:59:49 | [drl] epoch #66 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:49 | [drl] epoch #66 | backtrack iters: 14
2020-09-03 14:59:49 | [drl] epoch #66 | optimization finished
2020-09-03 14:59:49 | [drl] epoch #66 | Computing KL after
2020-09-03 14:59:49 | [drl] epoch #66 | Computing loss after
2020-09-03 14:59:49 | [drl] epoch #66 | Fitting baseline...
2020-09-03 14:59:49 | [drl] epoch #66 | Saving snapshot...
2020-09-03 14:59:49 | [drl] epoch #66 | Saved
2020-09-03 14:59:49 | [drl] epoch #66 | Time 53.28 s
2020-09-03 14:59:49 | [drl] epoch #66 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -92386
AverageReturn                            -150933
Entropy                                        8.51363
EnvExecTime                                    0.0313151
Extras/EpisodeRewardMean                 -203162
Iteration                                     66
LinearFeatureBaseline/ExplainedVariance        0.374969
MaxReturn                                -150933
MinReturn                                -150933
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0589631
ProcessExecTime                                0.00102258
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:49 | [drl] epoch #67 | Obtaining samples...
2020-09-03 14:59:49 | [drl] epoch #67 | Obtaining samples for iteration 67...
2020-09-03 14:59:49 | [drl] epoch #67 | Logging diagnostics...
2020-09-03 14:59:49 | [drl] epoch #67 | Optimizing policy...
2020-09-03 14:59:49 | [drl] epoch #67 | Computing loss before
2020-09-03 14:59:49 | [drl] epoch #67 | Computing KL before
2020-09-03 14:59:49 | [drl] epoch #67 | Optimizing
2020-09-03 14:59:49 | [drl] epoch #67 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:49 | [drl] epoch #67 | computing loss before
2020-09-03 14:59:49 | [drl] epoch #67 | computing gradient
2020-09-03 14:59:49 | [drl] epoch #67 | gradient computed
2020-09-03 14:59:49 | [drl] epoch #67 | computing descent direction
2020-09-03 14:59:49 | [drl] epoch #67 | descent direction computed
2020-09-03 14:59:50 | [drl] epoch #67 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:50 | [drl] epoch #67 | Violated because loss is NaN
2020-09-03 14:59:50 | [drl] epoch #67 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:50 | [drl] epoch #67 | backtrack iters: 14
2020-09-03 14:59:50 | [drl] epoch #67 | optimization finished
2020-09-03 14:59:50 | [drl] epoch #67 | Computing KL after
2020-09-03 14:59:50 | [drl] epoch #67 | Computing loss after
2020-09-03 14:59:50 | [drl] epoch #67 | Fitting baseline...
2020-09-03 14:59:50 | [drl] epoch #67 | Saving snapshot...
2020-09-03 14:59:50 | [drl] epoch #67 | Saved
2020-09-03 14:59:50 | [drl] epoch #67 | Time 54.04 s
2020-09-03 14:59:50 | [drl] epoch #67 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -99646.6
AverageReturn                            -162818
Entropy                                        8.51363
EnvExecTime                                    0.0347061
Extras/EpisodeRewardMean                 -202569
Iteration                                     67
LinearFeatureBaseline/ExplainedVariance        0.994453
MaxReturn                                -162818
MinReturn                                -162818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0466869
ProcessExecTime                                0.000933886
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:50 | [drl] epoch #68 | Obtaining samples...
2020-09-03 14:59:50 | [drl] epoch #68 | Obtaining samples for iteration 68...
2020-09-03 14:59:50 | [drl] epoch #68 | Logging diagnostics...
2020-09-03 14:59:50 | [drl] epoch #68 | Optimizing policy...
2020-09-03 14:59:50 | [drl] epoch #68 | Computing loss before
2020-09-03 14:59:50 | [drl] epoch #68 | Computing KL before
2020-09-03 14:59:50 | [drl] epoch #68 | Optimizing
2020-09-03 14:59:50 | [drl] epoch #68 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:50 | [drl] epoch #68 | computing loss before
2020-09-03 14:59:50 | [drl] epoch #68 | computing gradient
2020-09-03 14:59:50 | [drl] epoch #68 | gradient computed
2020-09-03 14:59:50 | [drl] epoch #68 | computing descent direction
2020-09-03 14:59:50 | [drl] epoch #68 | descent direction computed
2020-09-03 14:59:50 | [drl] epoch #68 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:50 | [drl] epoch #68 | Violated because loss is NaN
2020-09-03 14:59:50 | [drl] epoch #68 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:50 | [drl] epoch #68 | backtrack iters: 14
2020-09-03 14:59:50 | [drl] epoch #68 | optimization finished
2020-09-03 14:59:50 | [drl] epoch #68 | Computing KL after
2020-09-03 14:59:50 | [drl] epoch #68 | Computing loss after
2020-09-03 14:59:50 | [drl] epoch #68 | Fitting baseline...
2020-09-03 14:59:50 | [drl] epoch #68 | Saving snapshot...
2020-09-03 14:59:50 | [drl] epoch #68 | Saved
2020-09-03 14:59:50 | [drl] epoch #68 | Time 54.82 s
2020-09-03 14:59:50 | [drl] epoch #68 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114481
AverageReturn                            -187102
Entropy                                        8.51363
EnvExecTime                                    0.0374832
Extras/EpisodeRewardMean                 -202345
Iteration                                     68
LinearFeatureBaseline/ExplainedVariance        0.982752
MaxReturn                                -187102
MinReturn                                -187102
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0587573
ProcessExecTime                                0.000953674
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:50 | [drl] epoch #69 | Obtaining samples...
2020-09-03 14:59:50 | [drl] epoch #69 | Obtaining samples for iteration 69...
2020-09-03 14:59:50 | [drl] epoch #69 | Logging diagnostics...
2020-09-03 14:59:50 | [drl] epoch #69 | Optimizing policy...
2020-09-03 14:59:50 | [drl] epoch #69 | Computing loss before
2020-09-03 14:59:50 | [drl] epoch #69 | Computing KL before
2020-09-03 14:59:50 | [drl] epoch #69 | Optimizing
2020-09-03 14:59:50 | [drl] epoch #69 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:50 | [drl] epoch #69 | computing loss before
2020-09-03 14:59:50 | [drl] epoch #69 | computing gradient
2020-09-03 14:59:51 | [drl] epoch #69 | gradient computed
2020-09-03 14:59:51 | [drl] epoch #69 | computing descent direction
2020-09-03 14:59:51 | [drl] epoch #69 | descent direction computed
2020-09-03 14:59:51 | [drl] epoch #69 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:51 | [drl] epoch #69 | Violated because loss is NaN
2020-09-03 14:59:51 | [drl] epoch #69 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:51 | [drl] epoch #69 | backtrack iters: 14
2020-09-03 14:59:51 | [drl] epoch #69 | optimization finished
2020-09-03 14:59:51 | [drl] epoch #69 | Computing KL after
2020-09-03 14:59:51 | [drl] epoch #69 | Computing loss after
2020-09-03 14:59:51 | [drl] epoch #69 | Fitting baseline...
2020-09-03 14:59:51 | [drl] epoch #69 | Saving snapshot...
2020-09-03 14:59:51 | [drl] epoch #69 | Saved
2020-09-03 14:59:51 | [drl] epoch #69 | Time 55.59 s
2020-09-03 14:59:51 | [drl] epoch #69 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -89373
AverageReturn                            -146017
Entropy                                        8.51363
EnvExecTime                                    0.0314977
Extras/EpisodeRewardMean                 -201540
Iteration                                     69
LinearFeatureBaseline/ExplainedVariance        0.918392
MaxReturn                                -146017
MinReturn                                -146017
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.061125
ProcessExecTime                                0.000956774
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:51 | [drl] epoch #70 | Obtaining samples...
2020-09-03 14:59:51 | [drl] epoch #70 | Obtaining samples for iteration 70...
2020-09-03 14:59:51 | [drl] epoch #70 | Logging diagnostics...
2020-09-03 14:59:51 | [drl] epoch #70 | Optimizing policy...
2020-09-03 14:59:51 | [drl] epoch #70 | Computing loss before
2020-09-03 14:59:51 | [drl] epoch #70 | Computing KL before
2020-09-03 14:59:51 | [drl] epoch #70 | Optimizing
2020-09-03 14:59:51 | [drl] epoch #70 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:51 | [drl] epoch #70 | computing loss before
2020-09-03 14:59:51 | [drl] epoch #70 | computing gradient
2020-09-03 14:59:51 | [drl] epoch #70 | gradient computed
2020-09-03 14:59:51 | [drl] epoch #70 | computing descent direction
2020-09-03 14:59:52 | [drl] epoch #70 | descent direction computed
2020-09-03 14:59:52 | [drl] epoch #70 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:52 | [drl] epoch #70 | Violated because loss is NaN
2020-09-03 14:59:52 | [drl] epoch #70 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:52 | [drl] epoch #70 | backtrack iters: 14
2020-09-03 14:59:52 | [drl] epoch #70 | optimization finished
2020-09-03 14:59:52 | [drl] epoch #70 | Computing KL after
2020-09-03 14:59:52 | [drl] epoch #70 | Computing loss after
2020-09-03 14:59:52 | [drl] epoch #70 | Fitting baseline...
2020-09-03 14:59:52 | [drl] epoch #70 | Saving snapshot...
2020-09-03 14:59:52 | [drl] epoch #70 | Saved
2020-09-03 14:59:52 | [drl] epoch #70 | Time 56.35 s
2020-09-03 14:59:52 | [drl] epoch #70 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -182188
AverageReturn                            -297893
Entropy                                        8.51363
EnvExecTime                                    0.0316899
Extras/EpisodeRewardMean                 -202897
Iteration                                     70
LinearFeatureBaseline/ExplainedVariance        0.73593
MaxReturn                                -297893
MinReturn                                -297893
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0530212
ProcessExecTime                                0.00137377
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:52 | [drl] epoch #71 | Obtaining samples...
2020-09-03 14:59:52 | [drl] epoch #71 | Obtaining samples for iteration 71...
2020-09-03 14:59:52 | [drl] epoch #71 | Logging diagnostics...
2020-09-03 14:59:52 | [drl] epoch #71 | Optimizing policy...
2020-09-03 14:59:52 | [drl] epoch #71 | Computing loss before
2020-09-03 14:59:52 | [drl] epoch #71 | Computing KL before
2020-09-03 14:59:52 | [drl] epoch #71 | Optimizing
2020-09-03 14:59:52 | [drl] epoch #71 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:52 | [drl] epoch #71 | computing loss before
2020-09-03 14:59:52 | [drl] epoch #71 | computing gradient
2020-09-03 14:59:52 | [drl] epoch #71 | gradient computed
2020-09-03 14:59:52 | [drl] epoch #71 | computing descent direction
2020-09-03 14:59:52 | [drl] epoch #71 | descent direction computed
2020-09-03 14:59:53 | [drl] epoch #71 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:53 | [drl] epoch #71 | Violated because loss is NaN
2020-09-03 14:59:53 | [drl] epoch #71 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:53 | [drl] epoch #71 | backtrack iters: 14
2020-09-03 14:59:53 | [drl] epoch #71 | optimization finished
2020-09-03 14:59:53 | [drl] epoch #71 | Computing KL after
2020-09-03 14:59:53 | [drl] epoch #71 | Computing loss after
2020-09-03 14:59:53 | [drl] epoch #71 | Fitting baseline...
2020-09-03 14:59:53 | [drl] epoch #71 | Saving snapshot...
2020-09-03 14:59:53 | [drl] epoch #71 | Saved
2020-09-03 14:59:53 | [drl] epoch #71 | Time 57.12 s
2020-09-03 14:59:53 | [drl] epoch #71 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -101167
AverageReturn                            -165303
Entropy                                        8.51363
EnvExecTime                                    0.0358346
Extras/EpisodeRewardMean                 -202375
Iteration                                     71
LinearFeatureBaseline/ExplainedVariance        0.335713
MaxReturn                                -165303
MinReturn                                -165303
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0539365
ProcessExecTime                                0.00095892
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:53 | [drl] epoch #72 | Obtaining samples...
2020-09-03 14:59:53 | [drl] epoch #72 | Obtaining samples for iteration 72...
2020-09-03 14:59:53 | [drl] epoch #72 | Logging diagnostics...
2020-09-03 14:59:53 | [drl] epoch #72 | Optimizing policy...
2020-09-03 14:59:53 | [drl] epoch #72 | Computing loss before
2020-09-03 14:59:53 | [drl] epoch #72 | Computing KL before
2020-09-03 14:59:53 | [drl] epoch #72 | Optimizing
2020-09-03 14:59:53 | [drl] epoch #72 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:53 | [drl] epoch #72 | computing loss before
2020-09-03 14:59:53 | [drl] epoch #72 | computing gradient
2020-09-03 14:59:53 | [drl] epoch #72 | gradient computed
2020-09-03 14:59:53 | [drl] epoch #72 | computing descent direction
2020-09-03 14:59:53 | [drl] epoch #72 | descent direction computed
2020-09-03 14:59:53 | [drl] epoch #72 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:53 | [drl] epoch #72 | Violated because loss is NaN
2020-09-03 14:59:53 | [drl] epoch #72 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:53 | [drl] epoch #72 | backtrack iters: 14
2020-09-03 14:59:53 | [drl] epoch #72 | optimization finished
2020-09-03 14:59:53 | [drl] epoch #72 | Computing KL after
2020-09-03 14:59:53 | [drl] epoch #72 | Computing loss after
2020-09-03 14:59:53 | [drl] epoch #72 | Fitting baseline...
2020-09-03 14:59:53 | [drl] epoch #72 | Saving snapshot...
2020-09-03 14:59:53 | [drl] epoch #72 | Saved
2020-09-03 14:59:53 | [drl] epoch #72 | Time 57.89 s
2020-09-03 14:59:53 | [drl] epoch #72 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -123442
AverageReturn                            -201765
Entropy                                        8.51363
EnvExecTime                                    0.0387921
Extras/EpisodeRewardMean                 -202367
Iteration                                     72
LinearFeatureBaseline/ExplainedVariance        0.966302
MaxReturn                                -201765
MinReturn                                -201765
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.060055
ProcessExecTime                                0.000984907
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:53 | [drl] epoch #73 | Obtaining samples...
2020-09-03 14:59:53 | [drl] epoch #73 | Obtaining samples for iteration 73...
2020-09-03 14:59:54 | [drl] epoch #73 | Logging diagnostics...
2020-09-03 14:59:54 | [drl] epoch #73 | Optimizing policy...
2020-09-03 14:59:54 | [drl] epoch #73 | Computing loss before
2020-09-03 14:59:54 | [drl] epoch #73 | Computing KL before
2020-09-03 14:59:54 | [drl] epoch #73 | Optimizing
2020-09-03 14:59:54 | [drl] epoch #73 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:54 | [drl] epoch #73 | computing loss before
2020-09-03 14:59:54 | [drl] epoch #73 | computing gradient
2020-09-03 14:59:54 | [drl] epoch #73 | gradient computed
2020-09-03 14:59:54 | [drl] epoch #73 | computing descent direction
2020-09-03 14:59:54 | [drl] epoch #73 | descent direction computed
2020-09-03 14:59:54 | [drl] epoch #73 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:54 | [drl] epoch #73 | Violated because loss is NaN
2020-09-03 14:59:54 | [drl] epoch #73 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:54 | [drl] epoch #73 | backtrack iters: 14
2020-09-03 14:59:54 | [drl] epoch #73 | optimization finished
2020-09-03 14:59:54 | [drl] epoch #73 | Computing KL after
2020-09-03 14:59:54 | [drl] epoch #73 | Computing loss after
2020-09-03 14:59:54 | [drl] epoch #73 | Fitting baseline...
2020-09-03 14:59:54 | [drl] epoch #73 | Saving snapshot...
2020-09-03 14:59:54 | [drl] epoch #73 | Saved
2020-09-03 14:59:54 | [drl] epoch #73 | Time 58.66 s
2020-09-03 14:59:54 | [drl] epoch #73 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -82541
AverageReturn                            -134836
Entropy                                        8.51363
EnvExecTime                                    0.0317318
Extras/EpisodeRewardMean                 -201454
Iteration                                     73
LinearFeatureBaseline/ExplainedVariance        0.744276
MaxReturn                                -134836
MinReturn                                -134836
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0400674
ProcessExecTime                                0.00139332
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:54 | [drl] epoch #74 | Obtaining samples...
2020-09-03 14:59:54 | [drl] epoch #74 | Obtaining samples for iteration 74...
2020-09-03 14:59:54 | [drl] epoch #74 | Logging diagnostics...
2020-09-03 14:59:54 | [drl] epoch #74 | Optimizing policy...
2020-09-03 14:59:54 | [drl] epoch #74 | Computing loss before
2020-09-03 14:59:54 | [drl] epoch #74 | Computing KL before
2020-09-03 14:59:54 | [drl] epoch #74 | Optimizing
2020-09-03 14:59:54 | [drl] epoch #74 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:54 | [drl] epoch #74 | computing loss before
2020-09-03 14:59:54 | [drl] epoch #74 | computing gradient
2020-09-03 14:59:54 | [drl] epoch #74 | gradient computed
2020-09-03 14:59:54 | [drl] epoch #74 | computing descent direction
2020-09-03 14:59:55 | [drl] epoch #74 | descent direction computed
2020-09-03 14:59:55 | [drl] epoch #74 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:55 | [drl] epoch #74 | Violated because loss is NaN
2020-09-03 14:59:55 | [drl] epoch #74 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:55 | [drl] epoch #74 | backtrack iters: 14
2020-09-03 14:59:55 | [drl] epoch #74 | optimization finished
2020-09-03 14:59:55 | [drl] epoch #74 | Computing KL after
2020-09-03 14:59:55 | [drl] epoch #74 | Computing loss after
2020-09-03 14:59:55 | [drl] epoch #74 | Fitting baseline...
2020-09-03 14:59:55 | [drl] epoch #74 | Saving snapshot...
2020-09-03 14:59:55 | [drl] epoch #74 | Saved
2020-09-03 14:59:55 | [drl] epoch #74 | Time 59.43 s
2020-09-03 14:59:55 | [drl] epoch #74 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -145122
AverageReturn                            -237232
Entropy                                        8.51363
EnvExecTime                                    0.0372231
Extras/EpisodeRewardMean                 -201931
Iteration                                     74
LinearFeatureBaseline/ExplainedVariance        0.810021
MaxReturn                                -237232
MinReturn                                -237232
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0541348
ProcessExecTime                                0.00140238
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 14:59:55 | [drl] epoch #75 | Obtaining samples...
2020-09-03 14:59:55 | [drl] epoch #75 | Obtaining samples for iteration 75...
2020-09-03 14:59:55 | [drl] epoch #75 | Logging diagnostics...
2020-09-03 14:59:55 | [drl] epoch #75 | Optimizing policy...
2020-09-03 14:59:55 | [drl] epoch #75 | Computing loss before
2020-09-03 14:59:55 | [drl] epoch #75 | Computing KL before
2020-09-03 14:59:55 | [drl] epoch #75 | Optimizing
2020-09-03 14:59:55 | [drl] epoch #75 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:55 | [drl] epoch #75 | computing loss before
2020-09-03 14:59:55 | [drl] epoch #75 | computing gradient
2020-09-03 14:59:55 | [drl] epoch #75 | gradient computed
2020-09-03 14:59:55 | [drl] epoch #75 | computing descent direction
2020-09-03 14:59:56 | [drl] epoch #75 | descent direction computed
2020-09-03 14:59:56 | [drl] epoch #75 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:56 | [drl] epoch #75 | Violated because loss is NaN
2020-09-03 14:59:56 | [drl] epoch #75 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:56 | [drl] epoch #75 | backtrack iters: 14
2020-09-03 14:59:56 | [drl] epoch #75 | optimization finished
2020-09-03 14:59:56 | [drl] epoch #75 | Computing KL after
2020-09-03 14:59:56 | [drl] epoch #75 | Computing loss after
2020-09-03 14:59:56 | [drl] epoch #75 | Fitting baseline...
2020-09-03 14:59:56 | [drl] epoch #75 | Saving snapshot...
2020-09-03 14:59:56 | [drl] epoch #75 | Saved
2020-09-03 14:59:56 | [drl] epoch #75 | Time 60.21 s
2020-09-03 14:59:56 | [drl] epoch #75 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114168
AverageReturn                            -186598
Entropy                                        8.51363
EnvExecTime                                    0.0342784
Extras/EpisodeRewardMean                 -201729
Iteration                                     75
LinearFeatureBaseline/ExplainedVariance        0.924675
MaxReturn                                -186598
MinReturn                                -186598
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0487647
ProcessExecTime                                0.000988722
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:56 | [drl] epoch #76 | Obtaining samples...
2020-09-03 14:59:56 | [drl] epoch #76 | Obtaining samples for iteration 76...
2020-09-03 14:59:56 | [drl] epoch #76 | Logging diagnostics...
2020-09-03 14:59:56 | [drl] epoch #76 | Optimizing policy...
2020-09-03 14:59:56 | [drl] epoch #76 | Computing loss before
2020-09-03 14:59:56 | [drl] epoch #76 | Computing KL before
2020-09-03 14:59:56 | [drl] epoch #76 | Optimizing
2020-09-03 14:59:56 | [drl] epoch #76 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:56 | [drl] epoch #76 | computing loss before
2020-09-03 14:59:56 | [drl] epoch #76 | computing gradient
2020-09-03 14:59:56 | [drl] epoch #76 | gradient computed
2020-09-03 14:59:56 | [drl] epoch #76 | computing descent direction
2020-09-03 14:59:56 | [drl] epoch #76 | descent direction computed
2020-09-03 14:59:56 | [drl] epoch #76 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:56 | [drl] epoch #76 | Violated because loss is NaN
2020-09-03 14:59:56 | [drl] epoch #76 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:56 | [drl] epoch #76 | backtrack iters: 14
2020-09-03 14:59:56 | [drl] epoch #76 | optimization finished
2020-09-03 14:59:56 | [drl] epoch #76 | Computing KL after
2020-09-03 14:59:56 | [drl] epoch #76 | Computing loss after
2020-09-03 14:59:56 | [drl] epoch #76 | Fitting baseline...
2020-09-03 14:59:56 | [drl] epoch #76 | Saving snapshot...
2020-09-03 14:59:56 | [drl] epoch #76 | Saved
2020-09-03 14:59:56 | [drl] epoch #76 | Time 60.98 s
2020-09-03 14:59:56 | [drl] epoch #76 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -109992
AverageReturn                            -179751
Entropy                                        8.51363
EnvExecTime                                    0.0381699
Extras/EpisodeRewardMean                 -201444
Iteration                                     76
LinearFeatureBaseline/ExplainedVariance        0.998529
MaxReturn                                -179751
MinReturn                                -179751
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0566161
ProcessExecTime                                0.000988483
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:56 | [drl] epoch #77 | Obtaining samples...
2020-09-03 14:59:56 | [drl] epoch #77 | Obtaining samples for iteration 77...
2020-09-03 14:59:57 | [drl] epoch #77 | Logging diagnostics...
2020-09-03 14:59:57 | [drl] epoch #77 | Optimizing policy...
2020-09-03 14:59:57 | [drl] epoch #77 | Computing loss before
2020-09-03 14:59:57 | [drl] epoch #77 | Computing KL before
2020-09-03 14:59:57 | [drl] epoch #77 | Optimizing
2020-09-03 14:59:57 | [drl] epoch #77 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:57 | [drl] epoch #77 | computing loss before
2020-09-03 14:59:57 | [drl] epoch #77 | computing gradient
2020-09-03 14:59:57 | [drl] epoch #77 | gradient computed
2020-09-03 14:59:57 | [drl] epoch #77 | computing descent direction
2020-09-03 14:59:57 | [drl] epoch #77 | descent direction computed
2020-09-03 14:59:57 | [drl] epoch #77 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:57 | [drl] epoch #77 | Violated because loss is NaN
2020-09-03 14:59:57 | [drl] epoch #77 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:57 | [drl] epoch #77 | backtrack iters: 14
2020-09-03 14:59:57 | [drl] epoch #77 | optimization finished
2020-09-03 14:59:57 | [drl] epoch #77 | Computing KL after
2020-09-03 14:59:57 | [drl] epoch #77 | Computing loss after
2020-09-03 14:59:57 | [drl] epoch #77 | Fitting baseline...
2020-09-03 14:59:57 | [drl] epoch #77 | Saving snapshot...
2020-09-03 14:59:57 | [drl] epoch #77 | Saved
2020-09-03 14:59:57 | [drl] epoch #77 | Time 61.76 s
2020-09-03 14:59:57 | [drl] epoch #77 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -100834
AverageReturn                            -164767
Entropy                                        8.51363
EnvExecTime                                    0.0316901
Extras/EpisodeRewardMean                 -200974
Iteration                                     77
LinearFeatureBaseline/ExplainedVariance        0.991394
MaxReturn                                -164767
MinReturn                                -164767
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0564008
ProcessExecTime                                0.000936031
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:57 | [drl] epoch #78 | Obtaining samples...
2020-09-03 14:59:57 | [drl] epoch #78 | Obtaining samples for iteration 78...
2020-09-03 14:59:57 | [drl] epoch #78 | Logging diagnostics...
2020-09-03 14:59:57 | [drl] epoch #78 | Optimizing policy...
2020-09-03 14:59:57 | [drl] epoch #78 | Computing loss before
2020-09-03 14:59:57 | [drl] epoch #78 | Computing KL before
2020-09-03 14:59:57 | [drl] epoch #78 | Optimizing
2020-09-03 14:59:57 | [drl] epoch #78 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:57 | [drl] epoch #78 | computing loss before
2020-09-03 14:59:57 | [drl] epoch #78 | computing gradient
2020-09-03 14:59:57 | [drl] epoch #78 | gradient computed
2020-09-03 14:59:57 | [drl] epoch #78 | computing descent direction
2020-09-03 14:59:58 | [drl] epoch #78 | descent direction computed
2020-09-03 14:59:58 | [drl] epoch #78 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:58 | [drl] epoch #78 | Violated because loss is NaN
2020-09-03 14:59:58 | [drl] epoch #78 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:58 | [drl] epoch #78 | backtrack iters: 14
2020-09-03 14:59:58 | [drl] epoch #78 | optimization finished
2020-09-03 14:59:58 | [drl] epoch #78 | Computing KL after
2020-09-03 14:59:58 | [drl] epoch #78 | Computing loss after
2020-09-03 14:59:58 | [drl] epoch #78 | Fitting baseline...
2020-09-03 14:59:58 | [drl] epoch #78 | Saving snapshot...
2020-09-03 14:59:58 | [drl] epoch #78 | Saved
2020-09-03 14:59:58 | [drl] epoch #78 | Time 62.53 s
2020-09-03 14:59:58 | [drl] epoch #78 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -88181.4
AverageReturn                            -144073
Entropy                                        8.51363
EnvExecTime                                    0.0328639
Extras/EpisodeRewardMean                 -200254
Iteration                                     78
LinearFeatureBaseline/ExplainedVariance        0.97888
MaxReturn                                -144073
MinReturn                                -144073
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0545733
ProcessExecTime                                0.000948429
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:58 | [drl] epoch #79 | Obtaining samples...
2020-09-03 14:59:58 | [drl] epoch #79 | Obtaining samples for iteration 79...
2020-09-03 14:59:58 | [drl] epoch #79 | Logging diagnostics...
2020-09-03 14:59:58 | [drl] epoch #79 | Optimizing policy...
2020-09-03 14:59:58 | [drl] epoch #79 | Computing loss before
2020-09-03 14:59:58 | [drl] epoch #79 | Computing KL before
2020-09-03 14:59:58 | [drl] epoch #79 | Optimizing
2020-09-03 14:59:58 | [drl] epoch #79 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:58 | [drl] epoch #79 | computing loss before
2020-09-03 14:59:58 | [drl] epoch #79 | computing gradient
2020-09-03 14:59:58 | [drl] epoch #79 | gradient computed
2020-09-03 14:59:58 | [drl] epoch #79 | computing descent direction
2020-09-03 14:59:59 | [drl] epoch #79 | descent direction computed
2020-09-03 14:59:59 | [drl] epoch #79 | Line search condition violated. Rejecting the step!
2020-09-03 14:59:59 | [drl] epoch #79 | Violated because loss is NaN
2020-09-03 14:59:59 | [drl] epoch #79 | Violated because constraint mean_kl is NaN
2020-09-03 14:59:59 | [drl] epoch #79 | backtrack iters: 14
2020-09-03 14:59:59 | [drl] epoch #79 | optimization finished
2020-09-03 14:59:59 | [drl] epoch #79 | Computing KL after
2020-09-03 14:59:59 | [drl] epoch #79 | Computing loss after
2020-09-03 14:59:59 | [drl] epoch #79 | Fitting baseline...
2020-09-03 14:59:59 | [drl] epoch #79 | Saving snapshot...
2020-09-03 14:59:59 | [drl] epoch #79 | Saved
2020-09-03 14:59:59 | [drl] epoch #79 | Time 63.30 s
2020-09-03 14:59:59 | [drl] epoch #79 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -102318
AverageReturn                            -167197
Entropy                                        8.51363
EnvExecTime                                    0.0417252
Extras/EpisodeRewardMean                 -199840
Iteration                                     79
LinearFeatureBaseline/ExplainedVariance        0.980415
MaxReturn                                -167197
MinReturn                                -167197
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0425258
ProcessExecTime                                0.000971317
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 14:59:59 | [drl] epoch #80 | Obtaining samples...
2020-09-03 14:59:59 | [drl] epoch #80 | Obtaining samples for iteration 80...
2020-09-03 14:59:59 | [drl] epoch #80 | Logging diagnostics...
2020-09-03 14:59:59 | [drl] epoch #80 | Optimizing policy...
2020-09-03 14:59:59 | [drl] epoch #80 | Computing loss before
2020-09-03 14:59:59 | [drl] epoch #80 | Computing KL before
2020-09-03 14:59:59 | [drl] epoch #80 | Optimizing
2020-09-03 14:59:59 | [drl] epoch #80 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 14:59:59 | [drl] epoch #80 | computing loss before
2020-09-03 14:59:59 | [drl] epoch #80 | computing gradient
2020-09-03 14:59:59 | [drl] epoch #80 | gradient computed
2020-09-03 14:59:59 | [drl] epoch #80 | computing descent direction
2020-09-03 14:59:59 | [drl] epoch #80 | descent direction computed
2020-09-03 15:00:00 | [drl] epoch #80 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:00 | [drl] epoch #80 | Violated because loss is NaN
2020-09-03 15:00:00 | [drl] epoch #80 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:00 | [drl] epoch #80 | backtrack iters: 14
2020-09-03 15:00:00 | [drl] epoch #80 | optimization finished
2020-09-03 15:00:00 | [drl] epoch #80 | Computing KL after
2020-09-03 15:00:00 | [drl] epoch #80 | Computing loss after
2020-09-03 15:00:00 | [drl] epoch #80 | Fitting baseline...
2020-09-03 15:00:00 | [drl] epoch #80 | Saving snapshot...
2020-09-03 15:00:00 | [drl] epoch #80 | Saved
2020-09-03 15:00:00 | [drl] epoch #80 | Time 64.06 s
2020-09-03 15:00:00 | [drl] epoch #80 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154554
AverageReturn                            -252680
Entropy                                        8.51363
EnvExecTime                                    0.0620165
Extras/EpisodeRewardMean                 -200493
Iteration                                     80
LinearFeatureBaseline/ExplainedVariance        0.883389
MaxReturn                                -252680
MinReturn                                -252680
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0511372
ProcessExecTime                                0.000952005
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:00 | [drl] epoch #81 | Obtaining samples...
2020-09-03 15:00:00 | [drl] epoch #81 | Obtaining samples for iteration 81...
2020-09-03 15:00:00 | [drl] epoch #81 | Logging diagnostics...
2020-09-03 15:00:00 | [drl] epoch #81 | Optimizing policy...
2020-09-03 15:00:00 | [drl] epoch #81 | Computing loss before
2020-09-03 15:00:00 | [drl] epoch #81 | Computing KL before
2020-09-03 15:00:00 | [drl] epoch #81 | Optimizing
2020-09-03 15:00:00 | [drl] epoch #81 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:00 | [drl] epoch #81 | computing loss before
2020-09-03 15:00:00 | [drl] epoch #81 | computing gradient
2020-09-03 15:00:00 | [drl] epoch #81 | gradient computed
2020-09-03 15:00:00 | [drl] epoch #81 | computing descent direction
2020-09-03 15:00:00 | [drl] epoch #81 | descent direction computed
2020-09-03 15:00:00 | [drl] epoch #81 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:00 | [drl] epoch #81 | Violated because loss is NaN
2020-09-03 15:00:00 | [drl] epoch #81 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:00 | [drl] epoch #81 | backtrack iters: 14
2020-09-03 15:00:00 | [drl] epoch #81 | optimization finished
2020-09-03 15:00:00 | [drl] epoch #81 | Computing KL after
2020-09-03 15:00:00 | [drl] epoch #81 | Computing loss after
2020-09-03 15:00:00 | [drl] epoch #81 | Fitting baseline...
2020-09-03 15:00:00 | [drl] epoch #81 | Saving snapshot...
2020-09-03 15:00:00 | [drl] epoch #81 | Saved
2020-09-03 15:00:00 | [drl] epoch #81 | Time 64.82 s
2020-09-03 15:00:00 | [drl] epoch #81 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -120394
AverageReturn                            -196788
Entropy                                        8.51363
EnvExecTime                                    0.0385315
Extras/EpisodeRewardMean                 -200447
Iteration                                     81
LinearFeatureBaseline/ExplainedVariance        0.918067
MaxReturn                                -196788
MinReturn                                -196788
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0498359
ProcessExecTime                                0.000950336
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:00 | [drl] epoch #82 | Obtaining samples...
2020-09-03 15:00:00 | [drl] epoch #82 | Obtaining samples for iteration 82...
2020-09-03 15:00:00 | [drl] epoch #82 | Logging diagnostics...
2020-09-03 15:00:00 | [drl] epoch #82 | Optimizing policy...
2020-09-03 15:00:00 | [drl] epoch #82 | Computing loss before
2020-09-03 15:00:00 | [drl] epoch #82 | Computing KL before
2020-09-03 15:00:00 | [drl] epoch #82 | Optimizing
2020-09-03 15:00:00 | [drl] epoch #82 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:00 | [drl] epoch #82 | computing loss before
2020-09-03 15:00:00 | [drl] epoch #82 | computing gradient
2020-09-03 15:00:01 | [drl] epoch #82 | gradient computed
2020-09-03 15:00:01 | [drl] epoch #82 | computing descent direction
2020-09-03 15:00:01 | [drl] epoch #82 | descent direction computed
2020-09-03 15:00:01 | [drl] epoch #82 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:01 | [drl] epoch #82 | Violated because loss is NaN
2020-09-03 15:00:01 | [drl] epoch #82 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:01 | [drl] epoch #82 | backtrack iters: 14
2020-09-03 15:00:01 | [drl] epoch #82 | optimization finished
2020-09-03 15:00:01 | [drl] epoch #82 | Computing KL after
2020-09-03 15:00:01 | [drl] epoch #82 | Computing loss after
2020-09-03 15:00:01 | [drl] epoch #82 | Fitting baseline...
2020-09-03 15:00:01 | [drl] epoch #82 | Saving snapshot...
2020-09-03 15:00:01 | [drl] epoch #82 | Saved
2020-09-03 15:00:01 | [drl] epoch #82 | Time 65.58 s
2020-09-03 15:00:01 | [drl] epoch #82 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -117471
AverageReturn                            -191996
Entropy                                        8.51363
EnvExecTime                                    0.04035
Extras/EpisodeRewardMean                 -200346
Iteration                                     82
LinearFeatureBaseline/ExplainedVariance        0.999319
MaxReturn                                -191996
MinReturn                                -191996
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0416703
ProcessExecTime                                0.000948429
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:01 | [drl] epoch #83 | Obtaining samples...
2020-09-03 15:00:01 | [drl] epoch #83 | Obtaining samples for iteration 83...
2020-09-03 15:00:01 | [drl] epoch #83 | Logging diagnostics...
2020-09-03 15:00:01 | [drl] epoch #83 | Optimizing policy...
2020-09-03 15:00:01 | [drl] epoch #83 | Computing loss before
2020-09-03 15:00:01 | [drl] epoch #83 | Computing KL before
2020-09-03 15:00:01 | [drl] epoch #83 | Optimizing
2020-09-03 15:00:01 | [drl] epoch #83 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:01 | [drl] epoch #83 | computing loss before
2020-09-03 15:00:01 | [drl] epoch #83 | computing gradient
2020-09-03 15:00:01 | [drl] epoch #83 | gradient computed
2020-09-03 15:00:01 | [drl] epoch #83 | computing descent direction
2020-09-03 15:00:02 | [drl] epoch #83 | descent direction computed
2020-09-03 15:00:02 | [drl] epoch #83 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:02 | [drl] epoch #83 | Violated because loss is NaN
2020-09-03 15:00:02 | [drl] epoch #83 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:02 | [drl] epoch #83 | backtrack iters: 14
2020-09-03 15:00:02 | [drl] epoch #83 | optimization finished
2020-09-03 15:00:02 | [drl] epoch #83 | Computing KL after
2020-09-03 15:00:02 | [drl] epoch #83 | Computing loss after
2020-09-03 15:00:02 | [drl] epoch #83 | Fitting baseline...
2020-09-03 15:00:02 | [drl] epoch #83 | Saving snapshot...
2020-09-03 15:00:02 | [drl] epoch #83 | Saved
2020-09-03 15:00:02 | [drl] epoch #83 | Time 66.36 s
2020-09-03 15:00:02 | [drl] epoch #83 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -184134
AverageReturn                            -301069
Entropy                                        8.51363
EnvExecTime                                    0.0361912
Extras/EpisodeRewardMean                 -201545
Iteration                                     83
LinearFeatureBaseline/ExplainedVariance        0.866805
MaxReturn                                -301069
MinReturn                                -301069
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0598845
ProcessExecTime                                0.000936747
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:02 | [drl] epoch #84 | Obtaining samples...
2020-09-03 15:00:02 | [drl] epoch #84 | Obtaining samples for iteration 84...
2020-09-03 15:00:02 | [drl] epoch #84 | Logging diagnostics...
2020-09-03 15:00:02 | [drl] epoch #84 | Optimizing policy...
2020-09-03 15:00:02 | [drl] epoch #84 | Computing loss before
2020-09-03 15:00:02 | [drl] epoch #84 | Computing KL before
2020-09-03 15:00:02 | [drl] epoch #84 | Optimizing
2020-09-03 15:00:02 | [drl] epoch #84 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:02 | [drl] epoch #84 | computing loss before
2020-09-03 15:00:02 | [drl] epoch #84 | computing gradient
2020-09-03 15:00:02 | [drl] epoch #84 | gradient computed
2020-09-03 15:00:02 | [drl] epoch #84 | computing descent direction
2020-09-03 15:00:03 | [drl] epoch #84 | descent direction computed
2020-09-03 15:00:03 | [drl] epoch #84 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:03 | [drl] epoch #84 | Violated because loss is NaN
2020-09-03 15:00:03 | [drl] epoch #84 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:03 | [drl] epoch #84 | backtrack iters: 14
2020-09-03 15:00:03 | [drl] epoch #84 | optimization finished
2020-09-03 15:00:03 | [drl] epoch #84 | Computing KL after
2020-09-03 15:00:03 | [drl] epoch #84 | Computing loss after
2020-09-03 15:00:03 | [drl] epoch #84 | Fitting baseline...
2020-09-03 15:00:03 | [drl] epoch #84 | Saving snapshot...
2020-09-03 15:00:03 | [drl] epoch #84 | Saved
2020-09-03 15:00:03 | [drl] epoch #84 | Time 67.14 s
2020-09-03 15:00:03 | [drl] epoch #84 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114705
AverageReturn                            -187460
Entropy                                        8.51363
EnvExecTime                                    0.0370436
Extras/EpisodeRewardMean                 -201379
Iteration                                     84
LinearFeatureBaseline/ExplainedVariance        0.62349
MaxReturn                                -187460
MinReturn                                -187460
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0508254
ProcessExecTime                                0.000943184
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:03 | [drl] epoch #85 | Obtaining samples...
2020-09-03 15:00:03 | [drl] epoch #85 | Obtaining samples for iteration 85...
2020-09-03 15:00:03 | [drl] epoch #85 | Logging diagnostics...
2020-09-03 15:00:03 | [drl] epoch #85 | Optimizing policy...
2020-09-03 15:00:03 | [drl] epoch #85 | Computing loss before
2020-09-03 15:00:03 | [drl] epoch #85 | Computing KL before
2020-09-03 15:00:03 | [drl] epoch #85 | Optimizing
2020-09-03 15:00:03 | [drl] epoch #85 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:03 | [drl] epoch #85 | computing loss before
2020-09-03 15:00:03 | [drl] epoch #85 | computing gradient
2020-09-03 15:00:03 | [drl] epoch #85 | gradient computed
2020-09-03 15:00:03 | [drl] epoch #85 | computing descent direction
2020-09-03 15:00:03 | [drl] epoch #85 | descent direction computed
2020-09-03 15:00:03 | [drl] epoch #85 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:03 | [drl] epoch #85 | Violated because loss is NaN
2020-09-03 15:00:03 | [drl] epoch #85 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:03 | [drl] epoch #85 | backtrack iters: 14
2020-09-03 15:00:03 | [drl] epoch #85 | optimization finished
2020-09-03 15:00:03 | [drl] epoch #85 | Computing KL after
2020-09-03 15:00:03 | [drl] epoch #85 | Computing loss after
2020-09-03 15:00:03 | [drl] epoch #85 | Fitting baseline...
2020-09-03 15:00:03 | [drl] epoch #85 | Saving snapshot...
2020-09-03 15:00:03 | [drl] epoch #85 | Saved
2020-09-03 15:00:03 | [drl] epoch #85 | Time 67.91 s
2020-09-03 15:00:03 | [drl] epoch #85 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -187372
AverageReturn                            -306359
Entropy                                        8.51363
EnvExecTime                                    0.0334694
Extras/EpisodeRewardMean                 -202600
Iteration                                     85
LinearFeatureBaseline/ExplainedVariance        0.847244
MaxReturn                                -306359
MinReturn                                -306359
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0561016
ProcessExecTime                                0.000966311
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:03 | [drl] epoch #86 | Obtaining samples...
2020-09-03 15:00:03 | [drl] epoch #86 | Obtaining samples for iteration 86...
2020-09-03 15:00:04 | [drl] epoch #86 | Logging diagnostics...
2020-09-03 15:00:04 | [drl] epoch #86 | Optimizing policy...
2020-09-03 15:00:04 | [drl] epoch #86 | Computing loss before
2020-09-03 15:00:04 | [drl] epoch #86 | Computing KL before
2020-09-03 15:00:04 | [drl] epoch #86 | Optimizing
2020-09-03 15:00:04 | [drl] epoch #86 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:04 | [drl] epoch #86 | computing loss before
2020-09-03 15:00:04 | [drl] epoch #86 | computing gradient
2020-09-03 15:00:04 | [drl] epoch #86 | gradient computed
2020-09-03 15:00:04 | [drl] epoch #86 | computing descent direction
2020-09-03 15:00:04 | [drl] epoch #86 | descent direction computed
2020-09-03 15:00:04 | [drl] epoch #86 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:04 | [drl] epoch #86 | Violated because loss is NaN
2020-09-03 15:00:04 | [drl] epoch #86 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:04 | [drl] epoch #86 | backtrack iters: 14
2020-09-03 15:00:04 | [drl] epoch #86 | optimization finished
2020-09-03 15:00:04 | [drl] epoch #86 | Computing KL after
2020-09-03 15:00:04 | [drl] epoch #86 | Computing loss after
2020-09-03 15:00:04 | [drl] epoch #86 | Fitting baseline...
2020-09-03 15:00:04 | [drl] epoch #86 | Saving snapshot...
2020-09-03 15:00:04 | [drl] epoch #86 | Saved
2020-09-03 15:00:04 | [drl] epoch #86 | Time 68.66 s
2020-09-03 15:00:04 | [drl] epoch #86 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -150679
AverageReturn                            -246334
Entropy                                        8.51363
EnvExecTime                                    0.0323961
Extras/EpisodeRewardMean                 -203102
Iteration                                     86
LinearFeatureBaseline/ExplainedVariance        0.93987
MaxReturn                                -246334
MinReturn                                -246334
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0568838
ProcessExecTime                                0.000947714
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:04 | [drl] epoch #87 | Obtaining samples...
2020-09-03 15:00:04 | [drl] epoch #87 | Obtaining samples for iteration 87...
2020-09-03 15:00:04 | [drl] epoch #87 | Logging diagnostics...
2020-09-03 15:00:04 | [drl] epoch #87 | Optimizing policy...
2020-09-03 15:00:04 | [drl] epoch #87 | Computing loss before
2020-09-03 15:00:04 | [drl] epoch #87 | Computing KL before
2020-09-03 15:00:04 | [drl] epoch #87 | Optimizing
2020-09-03 15:00:04 | [drl] epoch #87 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:04 | [drl] epoch #87 | computing loss before
2020-09-03 15:00:04 | [drl] epoch #87 | computing gradient
2020-09-03 15:00:04 | [drl] epoch #87 | gradient computed
2020-09-03 15:00:04 | [drl] epoch #87 | computing descent direction
2020-09-03 15:00:05 | [drl] epoch #87 | descent direction computed
2020-09-03 15:00:05 | [drl] epoch #87 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:05 | [drl] epoch #87 | Violated because loss is NaN
2020-09-03 15:00:05 | [drl] epoch #87 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:05 | [drl] epoch #87 | backtrack iters: 14
2020-09-03 15:00:05 | [drl] epoch #87 | optimization finished
2020-09-03 15:00:05 | [drl] epoch #87 | Computing KL after
2020-09-03 15:00:05 | [drl] epoch #87 | Computing loss after
2020-09-03 15:00:05 | [drl] epoch #87 | Fitting baseline...
2020-09-03 15:00:05 | [drl] epoch #87 | Saving snapshot...
2020-09-03 15:00:05 | [drl] epoch #87 | Saved
2020-09-03 15:00:05 | [drl] epoch #87 | Time 69.44 s
2020-09-03 15:00:05 | [drl] epoch #87 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101874
AverageReturn                            -166476
Entropy                                        8.51363
EnvExecTime                                    0.0374467
Extras/EpisodeRewardMean                 -202686
Iteration                                     87
LinearFeatureBaseline/ExplainedVariance        0.763915
MaxReturn                                -166476
MinReturn                                -166476
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0598273
ProcessExecTime                                0.000954151
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:05 | [drl] epoch #88 | Obtaining samples...
2020-09-03 15:00:05 | [drl] epoch #88 | Obtaining samples for iteration 88...
2020-09-03 15:00:05 | [drl] epoch #88 | Logging diagnostics...
2020-09-03 15:00:05 | [drl] epoch #88 | Optimizing policy...
2020-09-03 15:00:05 | [drl] epoch #88 | Computing loss before
2020-09-03 15:00:05 | [drl] epoch #88 | Computing KL before
2020-09-03 15:00:05 | [drl] epoch #88 | Optimizing
2020-09-03 15:00:05 | [drl] epoch #88 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:05 | [drl] epoch #88 | computing loss before
2020-09-03 15:00:05 | [drl] epoch #88 | computing gradient
2020-09-03 15:00:05 | [drl] epoch #88 | gradient computed
2020-09-03 15:00:05 | [drl] epoch #88 | computing descent direction
2020-09-03 15:00:06 | [drl] epoch #88 | descent direction computed
2020-09-03 15:00:06 | [drl] epoch #88 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:06 | [drl] epoch #88 | Violated because loss is NaN
2020-09-03 15:00:06 | [drl] epoch #88 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:06 | [drl] epoch #88 | backtrack iters: 14
2020-09-03 15:00:06 | [drl] epoch #88 | optimization finished
2020-09-03 15:00:06 | [drl] epoch #88 | Computing KL after
2020-09-03 15:00:06 | [drl] epoch #88 | Computing loss after
2020-09-03 15:00:06 | [drl] epoch #88 | Fitting baseline...
2020-09-03 15:00:06 | [drl] epoch #88 | Saving snapshot...
2020-09-03 15:00:06 | [drl] epoch #88 | Saved
2020-09-03 15:00:06 | [drl] epoch #88 | Time 70.21 s
2020-09-03 15:00:06 | [drl] epoch #88 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -170787
AverageReturn                            -279237
Entropy                                        8.51363
EnvExecTime                                    0.047776
Extras/EpisodeRewardMean                 -203546
Iteration                                     88
LinearFeatureBaseline/ExplainedVariance        0.834356
MaxReturn                                -279237
MinReturn                                -279237
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0379379
ProcessExecTime                                0.00097537
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 15:00:06 | [drl] epoch #89 | Obtaining samples...
2020-09-03 15:00:06 | [drl] epoch #89 | Obtaining samples for iteration 89...
2020-09-03 15:00:06 | [drl] epoch #89 | Logging diagnostics...
2020-09-03 15:00:06 | [drl] epoch #89 | Optimizing policy...
2020-09-03 15:00:06 | [drl] epoch #89 | Computing loss before
2020-09-03 15:00:06 | [drl] epoch #89 | Computing KL before
2020-09-03 15:00:06 | [drl] epoch #89 | Optimizing
2020-09-03 15:00:06 | [drl] epoch #89 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:06 | [drl] epoch #89 | computing loss before
2020-09-03 15:00:06 | [drl] epoch #89 | computing gradient
2020-09-03 15:00:06 | [drl] epoch #89 | gradient computed
2020-09-03 15:00:06 | [drl] epoch #89 | computing descent direction
2020-09-03 15:00:06 | [drl] epoch #89 | descent direction computed
2020-09-03 15:00:06 | [drl] epoch #89 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:06 | [drl] epoch #89 | Violated because loss is NaN
2020-09-03 15:00:06 | [drl] epoch #89 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:06 | [drl] epoch #89 | backtrack iters: 14
2020-09-03 15:00:06 | [drl] epoch #89 | optimization finished
2020-09-03 15:00:06 | [drl] epoch #89 | Computing KL after
2020-09-03 15:00:06 | [drl] epoch #89 | Computing loss after
2020-09-03 15:00:06 | [drl] epoch #89 | Fitting baseline...
2020-09-03 15:00:06 | [drl] epoch #89 | Saving snapshot...
2020-09-03 15:00:06 | [drl] epoch #89 | Saved
2020-09-03 15:00:06 | [drl] epoch #89 | Time 70.99 s
2020-09-03 15:00:06 | [drl] epoch #89 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -110587
AverageReturn                            -180725
Entropy                                        8.51363
EnvExecTime                                    0.0457215
Extras/EpisodeRewardMean                 -203293
Iteration                                     89
LinearFeatureBaseline/ExplainedVariance        0.694235
MaxReturn                                -180725
MinReturn                                -180725
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0455151
ProcessExecTime                                0.00099349
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 15:00:07 | [drl] epoch #90 | Obtaining samples...
2020-09-03 15:00:07 | [drl] epoch #90 | Obtaining samples for iteration 90...
2020-09-03 15:00:07 | [drl] epoch #90 | Logging diagnostics...
2020-09-03 15:00:07 | [drl] epoch #90 | Optimizing policy...
2020-09-03 15:00:07 | [drl] epoch #90 | Computing loss before
2020-09-03 15:00:07 | [drl] epoch #90 | Computing KL before
2020-09-03 15:00:07 | [drl] epoch #90 | Optimizing
2020-09-03 15:00:07 | [drl] epoch #90 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:07 | [drl] epoch #90 | computing loss before
2020-09-03 15:00:07 | [drl] epoch #90 | computing gradient
2020-09-03 15:00:07 | [drl] epoch #90 | gradient computed
2020-09-03 15:00:07 | [drl] epoch #90 | computing descent direction
2020-09-03 15:00:07 | [drl] epoch #90 | descent direction computed
2020-09-03 15:00:07 | [drl] epoch #90 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:07 | [drl] epoch #90 | Violated because loss is NaN
2020-09-03 15:00:07 | [drl] epoch #90 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:07 | [drl] epoch #90 | backtrack iters: 14
2020-09-03 15:00:07 | [drl] epoch #90 | optimization finished
2020-09-03 15:00:07 | [drl] epoch #90 | Computing KL after
2020-09-03 15:00:07 | [drl] epoch #90 | Computing loss after
2020-09-03 15:00:07 | [drl] epoch #90 | Fitting baseline...
2020-09-03 15:00:07 | [drl] epoch #90 | Saving snapshot...
2020-09-03 15:00:07 | [drl] epoch #90 | Saved
2020-09-03 15:00:07 | [drl] epoch #90 | Time 71.76 s
2020-09-03 15:00:07 | [drl] epoch #90 | EpochTime 0.75 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -83137.4
AverageReturn                            -135816
Entropy                                        8.51363
EnvExecTime                                    0.0474982
Extras/EpisodeRewardMean                 -202551
Iteration                                     90
LinearFeatureBaseline/ExplainedVariance        0.887458
MaxReturn                                -135816
MinReturn                                -135816
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0475831
ProcessExecTime                                0.0013907
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-03 15:00:07 | [drl] epoch #91 | Obtaining samples...
2020-09-03 15:00:07 | [drl] epoch #91 | Obtaining samples for iteration 91...
2020-09-03 15:00:07 | [drl] epoch #91 | Logging diagnostics...
2020-09-03 15:00:07 | [drl] epoch #91 | Optimizing policy...
2020-09-03 15:00:07 | [drl] epoch #91 | Computing loss before
2020-09-03 15:00:07 | [drl] epoch #91 | Computing KL before
2020-09-03 15:00:07 | [drl] epoch #91 | Optimizing
2020-09-03 15:00:07 | [drl] epoch #91 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:07 | [drl] epoch #91 | computing loss before
2020-09-03 15:00:07 | [drl] epoch #91 | computing gradient
2020-09-03 15:00:07 | [drl] epoch #91 | gradient computed
2020-09-03 15:00:07 | [drl] epoch #91 | computing descent direction
2020-09-03 15:00:08 | [drl] epoch #91 | descent direction computed
2020-09-03 15:00:08 | [drl] epoch #91 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:08 | [drl] epoch #91 | Violated because loss is NaN
2020-09-03 15:00:08 | [drl] epoch #91 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:08 | [drl] epoch #91 | backtrack iters: 14
2020-09-03 15:00:08 | [drl] epoch #91 | optimization finished
2020-09-03 15:00:08 | [drl] epoch #91 | Computing KL after
2020-09-03 15:00:08 | [drl] epoch #91 | Computing loss after
2020-09-03 15:00:08 | [drl] epoch #91 | Fitting baseline...
2020-09-03 15:00:08 | [drl] epoch #91 | Saving snapshot...
2020-09-03 15:00:08 | [drl] epoch #91 | Saved
2020-09-03 15:00:08 | [drl] epoch #91 | Time 72.55 s
2020-09-03 15:00:08 | [drl] epoch #91 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -108717
AverageReturn                            -177663
Entropy                                        8.51363
EnvExecTime                                    0.0377319
Extras/EpisodeRewardMean                 -202281
Iteration                                     91
LinearFeatureBaseline/ExplainedVariance        0.943164
MaxReturn                                -177663
MinReturn                                -177663
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0566392
ProcessExecTime                                0.000972986
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:08 | [drl] epoch #92 | Obtaining samples...
2020-09-03 15:00:08 | [drl] epoch #92 | Obtaining samples for iteration 92...
2020-09-03 15:00:08 | [drl] epoch #92 | Logging diagnostics...
2020-09-03 15:00:08 | [drl] epoch #92 | Optimizing policy...
2020-09-03 15:00:08 | [drl] epoch #92 | Computing loss before
2020-09-03 15:00:08 | [drl] epoch #92 | Computing KL before
2020-09-03 15:00:08 | [drl] epoch #92 | Optimizing
2020-09-03 15:00:08 | [drl] epoch #92 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:08 | [drl] epoch #92 | computing loss before
2020-09-03 15:00:08 | [drl] epoch #92 | computing gradient
2020-09-03 15:00:08 | [drl] epoch #92 | gradient computed
2020-09-03 15:00:08 | [drl] epoch #92 | computing descent direction
2020-09-03 15:00:09 | [drl] epoch #92 | descent direction computed
2020-09-03 15:00:09 | [drl] epoch #92 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:09 | [drl] epoch #92 | Violated because loss is NaN
2020-09-03 15:00:09 | [drl] epoch #92 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:09 | [drl] epoch #92 | backtrack iters: 14
2020-09-03 15:00:09 | [drl] epoch #92 | optimization finished
2020-09-03 15:00:09 | [drl] epoch #92 | Computing KL after
2020-09-03 15:00:09 | [drl] epoch #92 | Computing loss after
2020-09-03 15:00:09 | [drl] epoch #92 | Fitting baseline...
2020-09-03 15:00:09 | [drl] epoch #92 | Saving snapshot...
2020-09-03 15:00:09 | [drl] epoch #92 | Saved
2020-09-03 15:00:09 | [drl] epoch #92 | Time 73.29 s
2020-09-03 15:00:09 | [drl] epoch #92 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154879
AverageReturn                            -253203
Entropy                                        8.51363
EnvExecTime                                    0.0336773
Extras/EpisodeRewardMean                 -202828
Iteration                                     92
LinearFeatureBaseline/ExplainedVariance        0.909495
MaxReturn                                -253203
MinReturn                                -253203
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0492003
ProcessExecTime                                0.000943184
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:09 | [drl] epoch #93 | Obtaining samples...
2020-09-03 15:00:09 | [drl] epoch #93 | Obtaining samples for iteration 93...
2020-09-03 15:00:09 | [drl] epoch #93 | Logging diagnostics...
2020-09-03 15:00:09 | [drl] epoch #93 | Optimizing policy...
2020-09-03 15:00:09 | [drl] epoch #93 | Computing loss before
2020-09-03 15:00:09 | [drl] epoch #93 | Computing KL before
2020-09-03 15:00:09 | [drl] epoch #93 | Optimizing
2020-09-03 15:00:09 | [drl] epoch #93 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:09 | [drl] epoch #93 | computing loss before
2020-09-03 15:00:09 | [drl] epoch #93 | computing gradient
2020-09-03 15:00:09 | [drl] epoch #93 | gradient computed
2020-09-03 15:00:09 | [drl] epoch #93 | computing descent direction
2020-09-03 15:00:09 | [drl] epoch #93 | descent direction computed
2020-09-03 15:00:10 | [drl] epoch #93 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:10 | [drl] epoch #93 | Violated because loss is NaN
2020-09-03 15:00:10 | [drl] epoch #93 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:10 | [drl] epoch #93 | backtrack iters: 14
2020-09-03 15:00:10 | [drl] epoch #93 | optimization finished
2020-09-03 15:00:10 | [drl] epoch #93 | Computing KL after
2020-09-03 15:00:10 | [drl] epoch #93 | Computing loss after
2020-09-03 15:00:10 | [drl] epoch #93 | Fitting baseline...
2020-09-03 15:00:10 | [drl] epoch #93 | Saving snapshot...
2020-09-03 15:00:10 | [drl] epoch #93 | Saved
2020-09-03 15:00:10 | [drl] epoch #93 | Time 74.06 s
2020-09-03 15:00:10 | [drl] epoch #93 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -116601
AverageReturn                            -190586
Entropy                                        8.51363
EnvExecTime                                    0.0468929
Extras/EpisodeRewardMean                 -202698
Iteration                                     93
LinearFeatureBaseline/ExplainedVariance        0.890187
MaxReturn                                -190586
MinReturn                                -190586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0508211
ProcessExecTime                                0.00100589
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 15:00:10 | [drl] epoch #94 | Obtaining samples...
2020-09-03 15:00:10 | [drl] epoch #94 | Obtaining samples for iteration 94...
2020-09-03 15:00:10 | [drl] epoch #94 | Logging diagnostics...
2020-09-03 15:00:10 | [drl] epoch #94 | Optimizing policy...
2020-09-03 15:00:10 | [drl] epoch #94 | Computing loss before
2020-09-03 15:00:10 | [drl] epoch #94 | Computing KL before
2020-09-03 15:00:10 | [drl] epoch #94 | Optimizing
2020-09-03 15:00:10 | [drl] epoch #94 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:10 | [drl] epoch #94 | computing loss before
2020-09-03 15:00:10 | [drl] epoch #94 | computing gradient
2020-09-03 15:00:10 | [drl] epoch #94 | gradient computed
2020-09-03 15:00:10 | [drl] epoch #94 | computing descent direction
2020-09-03 15:00:10 | [drl] epoch #94 | descent direction computed
2020-09-03 15:00:10 | [drl] epoch #94 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:10 | [drl] epoch #94 | Violated because loss is NaN
2020-09-03 15:00:10 | [drl] epoch #94 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:10 | [drl] epoch #94 | backtrack iters: 14
2020-09-03 15:00:10 | [drl] epoch #94 | optimization finished
2020-09-03 15:00:10 | [drl] epoch #94 | Computing KL after
2020-09-03 15:00:10 | [drl] epoch #94 | Computing loss after
2020-09-03 15:00:10 | [drl] epoch #94 | Fitting baseline...
2020-09-03 15:00:10 | [drl] epoch #94 | Saving snapshot...
2020-09-03 15:00:10 | [drl] epoch #94 | Saved
2020-09-03 15:00:10 | [drl] epoch #94 | Time 74.84 s
2020-09-03 15:00:10 | [drl] epoch #94 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -110733
AverageReturn                            -180965
Entropy                                        8.51363
EnvExecTime                                    0.0336785
Extras/EpisodeRewardMean                 -202469
Iteration                                     94
LinearFeatureBaseline/ExplainedVariance        0.997062
MaxReturn                                -180965
MinReturn                                -180965
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0684896
ProcessExecTime                                0.000985622
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:10 | [drl] epoch #95 | Obtaining samples...
2020-09-03 15:00:10 | [drl] epoch #95 | Obtaining samples for iteration 95...
2020-09-03 15:00:10 | [drl] epoch #95 | Logging diagnostics...
2020-09-03 15:00:10 | [drl] epoch #95 | Optimizing policy...
2020-09-03 15:00:10 | [drl] epoch #95 | Computing loss before
2020-09-03 15:00:10 | [drl] epoch #95 | Computing KL before
2020-09-03 15:00:10 | [drl] epoch #95 | Optimizing
2020-09-03 15:00:10 | [drl] epoch #95 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:10 | [drl] epoch #95 | computing loss before
2020-09-03 15:00:10 | [drl] epoch #95 | computing gradient
2020-09-03 15:00:11 | [drl] epoch #95 | gradient computed
2020-09-03 15:00:11 | [drl] epoch #95 | computing descent direction
2020-09-03 15:00:11 | [drl] epoch #95 | descent direction computed
2020-09-03 15:00:11 | [drl] epoch #95 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:11 | [drl] epoch #95 | Violated because loss is NaN
2020-09-03 15:00:11 | [drl] epoch #95 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:11 | [drl] epoch #95 | backtrack iters: 14
2020-09-03 15:00:11 | [drl] epoch #95 | optimization finished
2020-09-03 15:00:11 | [drl] epoch #95 | Computing KL after
2020-09-03 15:00:11 | [drl] epoch #95 | Computing loss after
2020-09-03 15:00:11 | [drl] epoch #95 | Fitting baseline...
2020-09-03 15:00:11 | [drl] epoch #95 | Saving snapshot...
2020-09-03 15:00:11 | [drl] epoch #95 | Saved
2020-09-03 15:00:11 | [drl] epoch #95 | Time 75.61 s
2020-09-03 15:00:11 | [drl] epoch #95 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -160763
AverageReturn                            -262829
Entropy                                        8.51363
EnvExecTime                                    0.037267
Extras/EpisodeRewardMean                 -203098
Iteration                                     95
LinearFeatureBaseline/ExplainedVariance        0.901363
MaxReturn                                -262829
MinReturn                                -262829
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0501609
ProcessExecTime                                0.000962019
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:11 | [drl] epoch #96 | Obtaining samples...
2020-09-03 15:00:11 | [drl] epoch #96 | Obtaining samples for iteration 96...
2020-09-03 15:00:11 | [drl] epoch #96 | Logging diagnostics...
2020-09-03 15:00:11 | [drl] epoch #96 | Optimizing policy...
2020-09-03 15:00:11 | [drl] epoch #96 | Computing loss before
2020-09-03 15:00:11 | [drl] epoch #96 | Computing KL before
2020-09-03 15:00:11 | [drl] epoch #96 | Optimizing
2020-09-03 15:00:11 | [drl] epoch #96 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:11 | [drl] epoch #96 | computing loss before
2020-09-03 15:00:11 | [drl] epoch #96 | computing gradient
2020-09-03 15:00:11 | [drl] epoch #96 | gradient computed
2020-09-03 15:00:11 | [drl] epoch #96 | computing descent direction
2020-09-03 15:00:12 | [drl] epoch #96 | descent direction computed
2020-09-03 15:00:12 | [drl] epoch #96 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:12 | [drl] epoch #96 | Violated because loss is NaN
2020-09-03 15:00:12 | [drl] epoch #96 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:12 | [drl] epoch #96 | backtrack iters: 14
2020-09-03 15:00:12 | [drl] epoch #96 | optimization finished
2020-09-03 15:00:12 | [drl] epoch #96 | Computing KL after
2020-09-03 15:00:12 | [drl] epoch #96 | Computing loss after
2020-09-03 15:00:12 | [drl] epoch #96 | Fitting baseline...
2020-09-03 15:00:12 | [drl] epoch #96 | Saving snapshot...
2020-09-03 15:00:12 | [drl] epoch #96 | Saved
2020-09-03 15:00:12 | [drl] epoch #96 | Time 76.36 s
2020-09-03 15:00:12 | [drl] epoch #96 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -148977
AverageReturn                            -243555
Entropy                                        8.51363
EnvExecTime                                    0.0424142
Extras/EpisodeRewardMean                 -203515
Iteration                                     96
LinearFeatureBaseline/ExplainedVariance        0.99369
MaxReturn                                -243555
MinReturn                                -243555
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0431204
ProcessExecTime                                0.000964403
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-03 15:00:12 | [drl] epoch #97 | Obtaining samples...
2020-09-03 15:00:12 | [drl] epoch #97 | Obtaining samples for iteration 97...
2020-09-03 15:00:12 | [drl] epoch #97 | Logging diagnostics...
2020-09-03 15:00:12 | [drl] epoch #97 | Optimizing policy...
2020-09-03 15:00:12 | [drl] epoch #97 | Computing loss before
2020-09-03 15:00:12 | [drl] epoch #97 | Computing KL before
2020-09-03 15:00:12 | [drl] epoch #97 | Optimizing
2020-09-03 15:00:12 | [drl] epoch #97 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:12 | [drl] epoch #97 | computing loss before
2020-09-03 15:00:12 | [drl] epoch #97 | computing gradient
2020-09-03 15:00:12 | [drl] epoch #97 | gradient computed
2020-09-03 15:00:12 | [drl] epoch #97 | computing descent direction
2020-09-03 15:00:13 | [drl] epoch #97 | descent direction computed
2020-09-03 15:00:13 | [drl] epoch #97 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:13 | [drl] epoch #97 | Violated because loss is NaN
2020-09-03 15:00:13 | [drl] epoch #97 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:13 | [drl] epoch #97 | backtrack iters: 14
2020-09-03 15:00:13 | [drl] epoch #97 | optimization finished
2020-09-03 15:00:13 | [drl] epoch #97 | Computing KL after
2020-09-03 15:00:13 | [drl] epoch #97 | Computing loss after
2020-09-03 15:00:13 | [drl] epoch #97 | Fitting baseline...
2020-09-03 15:00:13 | [drl] epoch #97 | Saving snapshot...
2020-09-03 15:00:13 | [drl] epoch #97 | Saved
2020-09-03 15:00:13 | [drl] epoch #97 | Time 77.14 s
2020-09-03 15:00:13 | [drl] epoch #97 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -192232
AverageReturn                            -314329
Entropy                                        8.51363
EnvExecTime                                    0.0318396
Extras/EpisodeRewardMean                 -204646
Iteration                                     97
LinearFeatureBaseline/ExplainedVariance        0.948611
MaxReturn                                -314329
MinReturn                                -314329
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0622663
ProcessExecTime                                0.00101757
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 15:00:13 | [drl] epoch #98 | Obtaining samples...
2020-09-03 15:00:13 | [drl] epoch #98 | Obtaining samples for iteration 98...
2020-09-03 15:00:13 | [drl] epoch #98 | Logging diagnostics...
2020-09-03 15:00:13 | [drl] epoch #98 | Optimizing policy...
2020-09-03 15:00:13 | [drl] epoch #98 | Computing loss before
2020-09-03 15:00:13 | [drl] epoch #98 | Computing KL before
2020-09-03 15:00:13 | [drl] epoch #98 | Optimizing
2020-09-03 15:00:13 | [drl] epoch #98 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:13 | [drl] epoch #98 | computing loss before
2020-09-03 15:00:13 | [drl] epoch #98 | computing gradient
2020-09-03 15:00:13 | [drl] epoch #98 | gradient computed
2020-09-03 15:00:13 | [drl] epoch #98 | computing descent direction
2020-09-03 15:00:13 | [drl] epoch #98 | descent direction computed
2020-09-03 15:00:13 | [drl] epoch #98 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:13 | [drl] epoch #98 | Violated because loss is NaN
2020-09-03 15:00:13 | [drl] epoch #98 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:13 | [drl] epoch #98 | backtrack iters: 14
2020-09-03 15:00:13 | [drl] epoch #98 | optimization finished
2020-09-03 15:00:13 | [drl] epoch #98 | Computing KL after
2020-09-03 15:00:13 | [drl] epoch #98 | Computing loss after
2020-09-03 15:00:13 | [drl] epoch #98 | Fitting baseline...
2020-09-03 15:00:13 | [drl] epoch #98 | Saving snapshot...
2020-09-03 15:00:13 | [drl] epoch #98 | Saved
2020-09-03 15:00:13 | [drl] epoch #98 | Time 77.92 s
2020-09-03 15:00:13 | [drl] epoch #98 | EpochTime 0.76 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -79029.2
AverageReturn                            -129087
Entropy                                        8.51363
EnvExecTime                                    0.0386405
Extras/EpisodeRewardMean                 -203883
Iteration                                     98
LinearFeatureBaseline/ExplainedVariance       -1.14135
MaxReturn                                -129087
MinReturn                                -129087
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0387354
ProcessExecTime                                0.012727
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-03 15:00:13 | [drl] epoch #99 | Obtaining samples...
2020-09-03 15:00:13 | [drl] epoch #99 | Obtaining samples for iteration 99...
2020-09-03 15:00:14 | [drl] epoch #99 | Logging diagnostics...
2020-09-03 15:00:14 | [drl] epoch #99 | Optimizing policy...
2020-09-03 15:00:14 | [drl] epoch #99 | Computing loss before
2020-09-03 15:00:14 | [drl] epoch #99 | Computing KL before
2020-09-03 15:00:14 | [drl] epoch #99 | Optimizing
2020-09-03 15:00:14 | [drl] epoch #99 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:14 | [drl] epoch #99 | computing loss before
2020-09-03 15:00:14 | [drl] epoch #99 | computing gradient
2020-09-03 15:00:14 | [drl] epoch #99 | gradient computed
2020-09-03 15:00:14 | [drl] epoch #99 | computing descent direction
2020-09-03 15:00:14 | [drl] epoch #99 | descent direction computed
2020-09-03 15:00:14 | [drl] epoch #99 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:14 | [drl] epoch #99 | Violated because loss is NaN
2020-09-03 15:00:14 | [drl] epoch #99 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:14 | [drl] epoch #99 | backtrack iters: 14
2020-09-03 15:00:14 | [drl] epoch #99 | optimization finished
2020-09-03 15:00:14 | [drl] epoch #99 | Computing KL after
2020-09-03 15:00:14 | [drl] epoch #99 | Computing loss after
2020-09-03 15:00:14 | [drl] epoch #99 | Fitting baseline...
2020-09-03 15:00:14 | [drl] epoch #99 | Saving snapshot...
2020-09-03 15:00:14 | [drl] epoch #99 | Saved
2020-09-03 15:00:14 | [drl] epoch #99 | Time 78.70 s
2020-09-03 15:00:14 | [drl] epoch #99 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -149503
AverageReturn                            -244408
Entropy                                        8.51363
EnvExecTime                                    0.0415361
Extras/EpisodeRewardMean                 -204288
Iteration                                     99
LinearFeatureBaseline/ExplainedVariance        0.772612
MaxReturn                                -244408
MinReturn                                -244408
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0533478
ProcessExecTime                                0.00146723
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-03 15:00:14 | [drl] epoch #100 | Obtaining samples...
2020-09-03 15:00:14 | [drl] epoch #100 | Obtaining samples for iteration 100...
2020-09-03 15:00:14 | [drl] epoch #100 | Logging diagnostics...
2020-09-03 15:00:14 | [drl] epoch #100 | Optimizing policy...
2020-09-03 15:00:14 | [drl] epoch #100 | Computing loss before
2020-09-03 15:00:14 | [drl] epoch #100 | Computing KL before
2020-09-03 15:00:14 | [drl] epoch #100 | Optimizing
2020-09-03 15:00:14 | [drl] epoch #100 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-03 15:00:14 | [drl] epoch #100 | computing loss before
2020-09-03 15:00:14 | [drl] epoch #100 | computing gradient
2020-09-03 15:00:14 | [drl] epoch #100 | gradient computed
2020-09-03 15:00:14 | [drl] epoch #100 | computing descent direction
2020-09-03 15:00:15 | [drl] epoch #100 | descent direction computed
2020-09-03 15:00:15 | [drl] epoch #100 | Line search condition violated. Rejecting the step!
2020-09-03 15:00:15 | [drl] epoch #100 | Violated because loss is NaN
2020-09-03 15:00:15 | [drl] epoch #100 | Violated because constraint mean_kl is NaN
2020-09-03 15:00:15 | [drl] epoch #100 | backtrack iters: 14
2020-09-03 15:00:15 | [drl] epoch #100 | optimization finished
2020-09-03 15:00:15 | [drl] epoch #100 | Computing KL after
2020-09-03 15:00:15 | [drl] epoch #100 | Computing loss after
2020-09-03 15:00:15 | [drl] epoch #100 | Fitting baseline...
2020-09-03 15:00:15 | [drl] epoch #100 | Saving snapshot...
2020-09-03 15:00:15 | [drl] epoch #100 | Saved
2020-09-03 15:00:15 | [drl] epoch #100 | Time 79.48 s
2020-09-03 15:00:15 | [drl] epoch #100 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -95810.7
AverageReturn                            -156550
Entropy                                        8.51363
EnvExecTime                                    0.032994
Extras/EpisodeRewardMean                 -203888
Iteration                                    100
LinearFeatureBaseline/ExplainedVariance        0.675819
MaxReturn                                -156550
MinReturn                                -156550
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0617776
ProcessExecTime                                0.000984192
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:28:52 | [drl] epoch #0 | Obtaining samples...
2020-09-06 22:28:52 | [drl] epoch #0 | Obtaining samples for iteration 0...
2020-09-06 22:28:52 | [drl] epoch #0 | Logging diagnostics...
2020-09-06 22:28:52 | [drl] epoch #0 | Optimizing policy...
2020-09-06 22:28:52 | [drl] epoch #0 | Computing loss before
2020-09-06 22:28:53 | [drl] epoch #0 | Computing KL before
2020-09-06 22:28:53 | [drl] epoch #0 | Optimizing
2020-09-06 22:28:53 | [drl] epoch #0 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:28:53 | [drl] epoch #0 | computing loss before
2020-09-06 22:28:53 | [drl] epoch #0 | computing gradient
2020-09-06 22:28:54 | [drl] epoch #0 | gradient computed
2020-09-06 22:28:54 | [drl] epoch #0 | computing descent direction
2020-09-06 22:28:55 | [drl] epoch #0 | descent direction computed
2020-09-06 22:28:55 | [drl] epoch #0 | Line search condition violated. Rejecting the step!
2020-09-06 22:28:55 | [drl] epoch #0 | Violated because loss is NaN
2020-09-06 22:28:55 | [drl] epoch #0 | Violated because constraint mean_kl is NaN
2020-09-06 22:28:55 | [drl] epoch #0 | backtrack iters: 14
2020-09-06 22:28:55 | [drl] epoch #0 | optimization finished
2020-09-06 22:28:55 | [drl] epoch #0 | Computing KL after
2020-09-06 22:28:55 | [drl] epoch #0 | Computing loss after
2020-09-06 22:28:56 | [drl] epoch #0 | Fitting baseline...
2020-09-06 22:28:56 | [drl] epoch #0 | Saving snapshot...
2020-09-06 22:28:56 | [drl] epoch #0 | Saved
2020-09-06 22:28:56 | [drl] epoch #0 | Time 3.80 s
2020-09-06 22:28:56 | [drl] epoch #0 | EpochTime 3.80 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -120282
AverageReturn                            -196586
Entropy                                        8.51363
EnvExecTime                                    0.0513361
Extras/EpisodeRewardMean                 -196586
Iteration                                      0
LinearFeatureBaseline/ExplainedVariance        7.22073e-08
MaxReturn                                -196586
MinReturn                                -196586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.517201
ProcessExecTime                                0.000984192
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:28:56 | [drl] epoch #1 | Obtaining samples...
2020-09-06 22:28:56 | [drl] epoch #1 | Obtaining samples for iteration 1...
2020-09-06 22:28:56 | [drl] epoch #1 | Logging diagnostics...
2020-09-06 22:28:56 | [drl] epoch #1 | Optimizing policy...
2020-09-06 22:28:56 | [drl] epoch #1 | Computing loss before
2020-09-06 22:28:56 | [drl] epoch #1 | Computing KL before
2020-09-06 22:28:56 | [drl] epoch #1 | Optimizing
2020-09-06 22:28:56 | [drl] epoch #1 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:28:56 | [drl] epoch #1 | computing loss before
2020-09-06 22:28:56 | [drl] epoch #1 | computing gradient
2020-09-06 22:28:56 | [drl] epoch #1 | gradient computed
2020-09-06 22:28:56 | [drl] epoch #1 | computing descent direction
2020-09-06 22:28:57 | [drl] epoch #1 | descent direction computed
2020-09-06 22:28:57 | [drl] epoch #1 | Line search condition violated. Rejecting the step!
2020-09-06 22:28:57 | [drl] epoch #1 | Violated because loss is NaN
2020-09-06 22:28:57 | [drl] epoch #1 | Violated because constraint mean_kl is NaN
2020-09-06 22:28:57 | [drl] epoch #1 | backtrack iters: 14
2020-09-06 22:28:57 | [drl] epoch #1 | optimization finished
2020-09-06 22:28:57 | [drl] epoch #1 | Computing KL after
2020-09-06 22:28:57 | [drl] epoch #1 | Computing loss after
2020-09-06 22:28:57 | [drl] epoch #1 | Fitting baseline...
2020-09-06 22:28:57 | [drl] epoch #1 | Saving snapshot...
2020-09-06 22:28:57 | [drl] epoch #1 | Saved
2020-09-06 22:28:57 | [drl] epoch #1 | Time 5.46 s
2020-09-06 22:28:57 | [drl] epoch #1 | EpochTime 1.63 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -185827
AverageReturn                            -303842
Entropy                                        8.51363
EnvExecTime                                    0.0531754
Extras/EpisodeRewardMean                 -250214
Iteration                                      1
LinearFeatureBaseline/ExplainedVariance        0.873328
MaxReturn                                -303842
MinReturn                                -303842
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0748696
ProcessExecTime                                0.000994682
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:28:57 | [drl] epoch #2 | Obtaining samples...
2020-09-06 22:28:57 | [drl] epoch #2 | Obtaining samples for iteration 2...
2020-09-06 22:28:58 | [drl] epoch #2 | Logging diagnostics...
2020-09-06 22:28:58 | [drl] epoch #2 | Optimizing policy...
2020-09-06 22:28:58 | [drl] epoch #2 | Computing loss before
2020-09-06 22:28:58 | [drl] epoch #2 | Computing KL before
2020-09-06 22:28:58 | [drl] epoch #2 | Optimizing
2020-09-06 22:28:58 | [drl] epoch #2 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:28:58 | [drl] epoch #2 | computing loss before
2020-09-06 22:28:58 | [drl] epoch #2 | computing gradient
2020-09-06 22:28:58 | [drl] epoch #2 | gradient computed
2020-09-06 22:28:58 | [drl] epoch #2 | computing descent direction
2020-09-06 22:28:59 | [drl] epoch #2 | descent direction computed
2020-09-06 22:28:59 | [drl] epoch #2 | Line search condition violated. Rejecting the step!
2020-09-06 22:28:59 | [drl] epoch #2 | Violated because loss is NaN
2020-09-06 22:28:59 | [drl] epoch #2 | Violated because constraint mean_kl is NaN
2020-09-06 22:28:59 | [drl] epoch #2 | backtrack iters: 14
2020-09-06 22:28:59 | [drl] epoch #2 | optimization finished
2020-09-06 22:28:59 | [drl] epoch #2 | Computing KL after
2020-09-06 22:29:00 | [drl] epoch #2 | Computing loss after
2020-09-06 22:29:00 | [drl] epoch #2 | Fitting baseline...
2020-09-06 22:29:00 | [drl] epoch #2 | Saving snapshot...
2020-09-06 22:29:00 | [drl] epoch #2 | Saved
2020-09-06 22:29:00 | [drl] epoch #2 | Time 7.77 s
2020-09-06 22:29:00 | [drl] epoch #2 | EpochTime 2.29 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -137108
AverageReturn                            -224135
Entropy                                        8.51363
EnvExecTime                                    0.0682342
Extras/EpisodeRewardMean                 -241521
Iteration                                      2
LinearFeatureBaseline/ExplainedVariance        0.871718
MaxReturn                                -224135
MinReturn                                -224135
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.104449
ProcessExecTime                                0.00830102
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:00 | [drl] epoch #3 | Obtaining samples...
2020-09-06 22:29:00 | [drl] epoch #3 | Obtaining samples for iteration 3...
2020-09-06 22:29:00 | [drl] epoch #3 | Logging diagnostics...
2020-09-06 22:29:00 | [drl] epoch #3 | Optimizing policy...
2020-09-06 22:29:00 | [drl] epoch #3 | Computing loss before
2020-09-06 22:29:00 | [drl] epoch #3 | Computing KL before
2020-09-06 22:29:00 | [drl] epoch #3 | Optimizing
2020-09-06 22:29:00 | [drl] epoch #3 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:00 | [drl] epoch #3 | computing loss before
2020-09-06 22:29:00 | [drl] epoch #3 | computing gradient
2020-09-06 22:29:00 | [drl] epoch #3 | gradient computed
2020-09-06 22:29:00 | [drl] epoch #3 | computing descent direction
2020-09-06 22:29:01 | [drl] epoch #3 | descent direction computed
2020-09-06 22:29:02 | [drl] epoch #3 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:02 | [drl] epoch #3 | Violated because loss is NaN
2020-09-06 22:29:02 | [drl] epoch #3 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:02 | [drl] epoch #3 | backtrack iters: 14
2020-09-06 22:29:02 | [drl] epoch #3 | optimization finished
2020-09-06 22:29:02 | [drl] epoch #3 | Computing KL after
2020-09-06 22:29:02 | [drl] epoch #3 | Computing loss after
2020-09-06 22:29:02 | [drl] epoch #3 | Fitting baseline...
2020-09-06 22:29:02 | [drl] epoch #3 | Saving snapshot...
2020-09-06 22:29:02 | [drl] epoch #3 | Saved
2020-09-06 22:29:02 | [drl] epoch #3 | Time 9.94 s
2020-09-06 22:29:02 | [drl] epoch #3 | EpochTime 2.15 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -84596.1
AverageReturn                            -138193
Entropy                                        8.51363
EnvExecTime                                    0.106732
Extras/EpisodeRewardMean                 -215689
Iteration                                      3
LinearFeatureBaseline/ExplainedVariance        0.597185
MaxReturn                                -138193
MinReturn                                -138193
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.118838
ProcessExecTime                                0.00162506
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:02 | [drl] epoch #4 | Obtaining samples...
2020-09-06 22:29:02 | [drl] epoch #4 | Obtaining samples for iteration 4...
2020-09-06 22:29:02 | [drl] epoch #4 | Logging diagnostics...
2020-09-06 22:29:02 | [drl] epoch #4 | Optimizing policy...
2020-09-06 22:29:02 | [drl] epoch #4 | Computing loss before
2020-09-06 22:29:02 | [drl] epoch #4 | Computing KL before
2020-09-06 22:29:02 | [drl] epoch #4 | Optimizing
2020-09-06 22:29:02 | [drl] epoch #4 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:02 | [drl] epoch #4 | computing loss before
2020-09-06 22:29:02 | [drl] epoch #4 | computing gradient
2020-09-06 22:29:02 | [drl] epoch #4 | gradient computed
2020-09-06 22:29:02 | [drl] epoch #4 | computing descent direction
2020-09-06 22:29:04 | [drl] epoch #4 | descent direction computed
2020-09-06 22:29:05 | [drl] epoch #4 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:05 | [drl] epoch #4 | Violated because loss is NaN
2020-09-06 22:29:05 | [drl] epoch #4 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:05 | [drl] epoch #4 | backtrack iters: 14
2020-09-06 22:29:05 | [drl] epoch #4 | optimization finished
2020-09-06 22:29:05 | [drl] epoch #4 | Computing KL after
2020-09-06 22:29:05 | [drl] epoch #4 | Computing loss after
2020-09-06 22:29:05 | [drl] epoch #4 | Fitting baseline...
2020-09-06 22:29:05 | [drl] epoch #4 | Saving snapshot...
2020-09-06 22:29:05 | [drl] epoch #4 | Saved
2020-09-06 22:29:05 | [drl] epoch #4 | Time 13.14 s
2020-09-06 22:29:05 | [drl] epoch #4 | EpochTime 3.18 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -166430
AverageReturn                            -272108
Entropy                                        8.51363
EnvExecTime                                    0.13074
Extras/EpisodeRewardMean                 -226973
Iteration                                      4
LinearFeatureBaseline/ExplainedVariance        0.753183
MaxReturn                                -272108
MinReturn                                -272108
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0994198
ProcessExecTime                                0.00110197
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:05 | [drl] epoch #5 | Obtaining samples...
2020-09-06 22:29:05 | [drl] epoch #5 | Obtaining samples for iteration 5...
2020-09-06 22:29:05 | [drl] epoch #5 | Logging diagnostics...
2020-09-06 22:29:05 | [drl] epoch #5 | Optimizing policy...
2020-09-06 22:29:05 | [drl] epoch #5 | Computing loss before
2020-09-06 22:29:05 | [drl] epoch #5 | Computing KL before
2020-09-06 22:29:05 | [drl] epoch #5 | Optimizing
2020-09-06 22:29:05 | [drl] epoch #5 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:05 | [drl] epoch #5 | computing loss before
2020-09-06 22:29:05 | [drl] epoch #5 | computing gradient
2020-09-06 22:29:06 | [drl] epoch #5 | gradient computed
2020-09-06 22:29:06 | [drl] epoch #5 | computing descent direction
2020-09-06 22:29:07 | [drl] epoch #5 | descent direction computed
2020-09-06 22:29:07 | [drl] epoch #5 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:07 | [drl] epoch #5 | Violated because loss is NaN
2020-09-06 22:29:07 | [drl] epoch #5 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:07 | [drl] epoch #5 | backtrack iters: 14
2020-09-06 22:29:07 | [drl] epoch #5 | optimization finished
2020-09-06 22:29:07 | [drl] epoch #5 | Computing KL after
2020-09-06 22:29:07 | [drl] epoch #5 | Computing loss after
2020-09-06 22:29:07 | [drl] epoch #5 | Fitting baseline...
2020-09-06 22:29:07 | [drl] epoch #5 | Saving snapshot...
2020-09-06 22:29:07 | [drl] epoch #5 | Saved
2020-09-06 22:29:07 | [drl] epoch #5 | Time 15.65 s
2020-09-06 22:29:07 | [drl] epoch #5 | EpochTime 2.47 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -131569
AverageReturn                            -215054
Entropy                                        8.51363
EnvExecTime                                    0.0780301
Extras/EpisodeRewardMean                 -224986
Iteration                                      5
LinearFeatureBaseline/ExplainedVariance        0.927991
MaxReturn                                -215054
MinReturn                                -215054
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.154478
ProcessExecTime                                0.0136626
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:29:07 | [drl] epoch #6 | Obtaining samples...
2020-09-06 22:29:07 | [drl] epoch #6 | Obtaining samples for iteration 6...
2020-09-06 22:29:08 | [drl] epoch #6 | Logging diagnostics...
2020-09-06 22:29:08 | [drl] epoch #6 | Optimizing policy...
2020-09-06 22:29:08 | [drl] epoch #6 | Computing loss before
2020-09-06 22:29:08 | [drl] epoch #6 | Computing KL before
2020-09-06 22:29:08 | [drl] epoch #6 | Optimizing
2020-09-06 22:29:08 | [drl] epoch #6 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:08 | [drl] epoch #6 | computing loss before
2020-09-06 22:29:08 | [drl] epoch #6 | computing gradient
2020-09-06 22:29:08 | [drl] epoch #6 | gradient computed
2020-09-06 22:29:08 | [drl] epoch #6 | computing descent direction
2020-09-06 22:29:09 | [drl] epoch #6 | descent direction computed
2020-09-06 22:29:10 | [drl] epoch #6 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:10 | [drl] epoch #6 | Violated because loss is NaN
2020-09-06 22:29:10 | [drl] epoch #6 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:10 | [drl] epoch #6 | backtrack iters: 14
2020-09-06 22:29:10 | [drl] epoch #6 | optimization finished
2020-09-06 22:29:10 | [drl] epoch #6 | Computing KL after
2020-09-06 22:29:10 | [drl] epoch #6 | Computing loss after
2020-09-06 22:29:10 | [drl] epoch #6 | Fitting baseline...
2020-09-06 22:29:10 | [drl] epoch #6 | Saving snapshot...
2020-09-06 22:29:10 | [drl] epoch #6 | Saved
2020-09-06 22:29:10 | [drl] epoch #6 | Time 18.11 s
2020-09-06 22:29:10 | [drl] epoch #6 | EpochTime 2.44 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -100550
AverageReturn                            -164312
Entropy                                        8.51363
EnvExecTime                                    0.0658643
Extras/EpisodeRewardMean                 -216319
Iteration                                      6
LinearFeatureBaseline/ExplainedVariance        0.901804
MaxReturn                                -164312
MinReturn                                -164312
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.149825
ProcessExecTime                                0.00202394
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:10 | [drl] epoch #7 | Obtaining samples...
2020-09-06 22:29:10 | [drl] epoch #7 | Obtaining samples for iteration 7...
2020-09-06 22:29:10 | [drl] epoch #7 | Logging diagnostics...
2020-09-06 22:29:10 | [drl] epoch #7 | Optimizing policy...
2020-09-06 22:29:10 | [drl] epoch #7 | Computing loss before
2020-09-06 22:29:10 | [drl] epoch #7 | Computing KL before
2020-09-06 22:29:10 | [drl] epoch #7 | Optimizing
2020-09-06 22:29:10 | [drl] epoch #7 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:10 | [drl] epoch #7 | computing loss before
2020-09-06 22:29:10 | [drl] epoch #7 | computing gradient
2020-09-06 22:29:10 | [drl] epoch #7 | gradient computed
2020-09-06 22:29:10 | [drl] epoch #7 | computing descent direction
2020-09-06 22:29:12 | [drl] epoch #7 | descent direction computed
2020-09-06 22:29:12 | [drl] epoch #7 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:12 | [drl] epoch #7 | Violated because loss is NaN
2020-09-06 22:29:12 | [drl] epoch #7 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:12 | [drl] epoch #7 | backtrack iters: 14
2020-09-06 22:29:12 | [drl] epoch #7 | optimization finished
2020-09-06 22:29:12 | [drl] epoch #7 | Computing KL after
2020-09-06 22:29:12 | [drl] epoch #7 | Computing loss after
2020-09-06 22:29:12 | [drl] epoch #7 | Fitting baseline...
2020-09-06 22:29:12 | [drl] epoch #7 | Saving snapshot...
2020-09-06 22:29:12 | [drl] epoch #7 | Saved
2020-09-06 22:29:12 | [drl] epoch #7 | Time 20.54 s
2020-09-06 22:29:12 | [drl] epoch #7 | EpochTime 2.40 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -200005
AverageReturn                            -327052
Entropy                                        8.51363
EnvExecTime                                    0.0802653
Extras/EpisodeRewardMean                 -230160
Iteration                                      7
LinearFeatureBaseline/ExplainedVariance        0.748626
MaxReturn                                -327052
MinReturn                                -327052
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.126806
ProcessExecTime                                0.00949073
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:12 | [drl] epoch #8 | Obtaining samples...
2020-09-06 22:29:12 | [drl] epoch #8 | Obtaining samples for iteration 8...
2020-09-06 22:29:13 | [drl] epoch #8 | Logging diagnostics...
2020-09-06 22:29:13 | [drl] epoch #8 | Optimizing policy...
2020-09-06 22:29:13 | [drl] epoch #8 | Computing loss before
2020-09-06 22:29:13 | [drl] epoch #8 | Computing KL before
2020-09-06 22:29:13 | [drl] epoch #8 | Optimizing
2020-09-06 22:29:13 | [drl] epoch #8 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:13 | [drl] epoch #8 | computing loss before
2020-09-06 22:29:13 | [drl] epoch #8 | computing gradient
2020-09-06 22:29:13 | [drl] epoch #8 | gradient computed
2020-09-06 22:29:13 | [drl] epoch #8 | computing descent direction
2020-09-06 22:29:14 | [drl] epoch #8 | descent direction computed
2020-09-06 22:29:15 | [drl] epoch #8 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:15 | [drl] epoch #8 | Violated because loss is NaN
2020-09-06 22:29:15 | [drl] epoch #8 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:15 | [drl] epoch #8 | backtrack iters: 14
2020-09-06 22:29:15 | [drl] epoch #8 | optimization finished
2020-09-06 22:29:15 | [drl] epoch #8 | Computing KL after
2020-09-06 22:29:15 | [drl] epoch #8 | Computing loss after
2020-09-06 22:29:15 | [drl] epoch #8 | Fitting baseline...
2020-09-06 22:29:15 | [drl] epoch #8 | Saving snapshot...
2020-09-06 22:29:15 | [drl] epoch #8 | Saved
2020-09-06 22:29:15 | [drl] epoch #8 | Time 23.02 s
2020-09-06 22:29:15 | [drl] epoch #8 | EpochTime 2.45 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -144031
AverageReturn                            -235441
Entropy                                        8.51363
EnvExecTime                                    0.0843065
Extras/EpisodeRewardMean                 -230747
Iteration                                      8
LinearFeatureBaseline/ExplainedVariance        0.844583
MaxReturn                                -235441
MinReturn                                -235441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.12511
ProcessExecTime                                0.00100303
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:15 | [drl] epoch #9 | Obtaining samples...
2020-09-06 22:29:15 | [drl] epoch #9 | Obtaining samples for iteration 9...
2020-09-06 22:29:15 | [drl] epoch #9 | Logging diagnostics...
2020-09-06 22:29:15 | [drl] epoch #9 | Optimizing policy...
2020-09-06 22:29:15 | [drl] epoch #9 | Computing loss before
2020-09-06 22:29:15 | [drl] epoch #9 | Computing KL before
2020-09-06 22:29:15 | [drl] epoch #9 | Optimizing
2020-09-06 22:29:15 | [drl] epoch #9 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:15 | [drl] epoch #9 | computing loss before
2020-09-06 22:29:15 | [drl] epoch #9 | computing gradient
2020-09-06 22:29:15 | [drl] epoch #9 | gradient computed
2020-09-06 22:29:15 | [drl] epoch #9 | computing descent direction
2020-09-06 22:29:17 | [drl] epoch #9 | descent direction computed
2020-09-06 22:29:17 | [drl] epoch #9 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:17 | [drl] epoch #9 | Violated because loss is NaN
2020-09-06 22:29:17 | [drl] epoch #9 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:17 | [drl] epoch #9 | backtrack iters: 14
2020-09-06 22:29:17 | [drl] epoch #9 | optimization finished
2020-09-06 22:29:17 | [drl] epoch #9 | Computing KL after
2020-09-06 22:29:17 | [drl] epoch #9 | Computing loss after
2020-09-06 22:29:17 | [drl] epoch #9 | Fitting baseline...
2020-09-06 22:29:17 | [drl] epoch #9 | Saving snapshot...
2020-09-06 22:29:17 | [drl] epoch #9 | Saved
2020-09-06 22:29:17 | [drl] epoch #9 | Time 25.11 s
2020-09-06 22:29:17 | [drl] epoch #9 | EpochTime 2.07 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -171067
AverageReturn                            -279688
Entropy                                        8.51363
EnvExecTime                                    0.0962174
Extras/EpisodeRewardMean                 -235641
Iteration                                      9
LinearFeatureBaseline/ExplainedVariance        0.974453
MaxReturn                                -279688
MinReturn                                -279688
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0916631
ProcessExecTime                                0.00103354
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:17 | [drl] epoch #10 | Obtaining samples...
2020-09-06 22:29:17 | [drl] epoch #10 | Obtaining samples for iteration 10...
2020-09-06 22:29:17 | [drl] epoch #10 | Logging diagnostics...
2020-09-06 22:29:17 | [drl] epoch #10 | Optimizing policy...
2020-09-06 22:29:17 | [drl] epoch #10 | Computing loss before
2020-09-06 22:29:17 | [drl] epoch #10 | Computing KL before
2020-09-06 22:29:17 | [drl] epoch #10 | Optimizing
2020-09-06 22:29:17 | [drl] epoch #10 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:17 | [drl] epoch #10 | computing loss before
2020-09-06 22:29:17 | [drl] epoch #10 | computing gradient
2020-09-06 22:29:17 | [drl] epoch #10 | gradient computed
2020-09-06 22:29:17 | [drl] epoch #10 | computing descent direction
2020-09-06 22:29:18 | [drl] epoch #10 | descent direction computed
2020-09-06 22:29:19 | [drl] epoch #10 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:19 | [drl] epoch #10 | Violated because loss is NaN
2020-09-06 22:29:19 | [drl] epoch #10 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:19 | [drl] epoch #10 | backtrack iters: 14
2020-09-06 22:29:19 | [drl] epoch #10 | optimization finished
2020-09-06 22:29:19 | [drl] epoch #10 | Computing KL after
2020-09-06 22:29:19 | [drl] epoch #10 | Computing loss after
2020-09-06 22:29:19 | [drl] epoch #10 | Fitting baseline...
2020-09-06 22:29:19 | [drl] epoch #10 | Saving snapshot...
2020-09-06 22:29:19 | [drl] epoch #10 | Saved
2020-09-06 22:29:19 | [drl] epoch #10 | Time 26.93 s
2020-09-06 22:29:19 | [drl] epoch #10 | EpochTime 1.80 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -77695
AverageReturn                            -126915
Entropy                                        8.51363
EnvExecTime                                    0.0570672
Extras/EpisodeRewardMean                 -225757
Iteration                                     10
LinearFeatureBaseline/ExplainedVariance       -0.499061
MaxReturn                                -126915
MinReturn                                -126915
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0941517
ProcessExecTime                                0.000975132
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:19 | [drl] epoch #11 | Obtaining samples...
2020-09-06 22:29:19 | [drl] epoch #11 | Obtaining samples for iteration 11...
2020-09-06 22:29:19 | [drl] epoch #11 | Logging diagnostics...
2020-09-06 22:29:19 | [drl] epoch #11 | Optimizing policy...
2020-09-06 22:29:19 | [drl] epoch #11 | Computing loss before
2020-09-06 22:29:19 | [drl] epoch #11 | Computing KL before
2020-09-06 22:29:19 | [drl] epoch #11 | Optimizing
2020-09-06 22:29:19 | [drl] epoch #11 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:19 | [drl] epoch #11 | computing loss before
2020-09-06 22:29:19 | [drl] epoch #11 | computing gradient
2020-09-06 22:29:19 | [drl] epoch #11 | gradient computed
2020-09-06 22:29:19 | [drl] epoch #11 | computing descent direction
2020-09-06 22:29:20 | [drl] epoch #11 | descent direction computed
2020-09-06 22:29:20 | [drl] epoch #11 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:20 | [drl] epoch #11 | Violated because loss is NaN
2020-09-06 22:29:20 | [drl] epoch #11 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:20 | [drl] epoch #11 | backtrack iters: 14
2020-09-06 22:29:20 | [drl] epoch #11 | optimization finished
2020-09-06 22:29:20 | [drl] epoch #11 | Computing KL after
2020-09-06 22:29:20 | [drl] epoch #11 | Computing loss after
2020-09-06 22:29:20 | [drl] epoch #11 | Fitting baseline...
2020-09-06 22:29:20 | [drl] epoch #11 | Saving snapshot...
2020-09-06 22:29:20 | [drl] epoch #11 | Saved
2020-09-06 22:29:20 | [drl] epoch #11 | Time 28.43 s
2020-09-06 22:29:20 | [drl] epoch #11 | EpochTime 1.48 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -97539.2
AverageReturn                            -159379
Entropy                                        8.51363
EnvExecTime                                    0.0606103
Extras/EpisodeRewardMean                 -220225
Iteration                                     11
LinearFeatureBaseline/ExplainedVariance        0.957473
MaxReturn                                -159379
MinReturn                                -159379
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0716941
ProcessExecTime                                0.00101709
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:20 | [drl] epoch #12 | Obtaining samples...
2020-09-06 22:29:20 | [drl] epoch #12 | Obtaining samples for iteration 12...
2020-09-06 22:29:20 | [drl] epoch #12 | Logging diagnostics...
2020-09-06 22:29:20 | [drl] epoch #12 | Optimizing policy...
2020-09-06 22:29:20 | [drl] epoch #12 | Computing loss before
2020-09-06 22:29:20 | [drl] epoch #12 | Computing KL before
2020-09-06 22:29:21 | [drl] epoch #12 | Optimizing
2020-09-06 22:29:21 | [drl] epoch #12 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:21 | [drl] epoch #12 | computing loss before
2020-09-06 22:29:21 | [drl] epoch #12 | computing gradient
2020-09-06 22:29:21 | [drl] epoch #12 | gradient computed
2020-09-06 22:29:21 | [drl] epoch #12 | computing descent direction
2020-09-06 22:29:21 | [drl] epoch #12 | descent direction computed
2020-09-06 22:29:21 | [drl] epoch #12 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:21 | [drl] epoch #12 | Violated because loss is NaN
2020-09-06 22:29:21 | [drl] epoch #12 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:21 | [drl] epoch #12 | backtrack iters: 14
2020-09-06 22:29:21 | [drl] epoch #12 | optimization finished
2020-09-06 22:29:21 | [drl] epoch #12 | Computing KL after
2020-09-06 22:29:21 | [drl] epoch #12 | Computing loss after
2020-09-06 22:29:21 | [drl] epoch #12 | Fitting baseline...
2020-09-06 22:29:21 | [drl] epoch #12 | Saving snapshot...
2020-09-06 22:29:21 | [drl] epoch #12 | Saved
2020-09-06 22:29:21 | [drl] epoch #12 | Time 29.44 s
2020-09-06 22:29:21 | [drl] epoch #12 | EpochTime 0.99 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -171353
AverageReturn                            -280168
Entropy                                        8.51363
EnvExecTime                                    0.0738041
Extras/EpisodeRewardMean                 -224836
Iteration                                     12
LinearFeatureBaseline/ExplainedVariance        0.810962
MaxReturn                                -280168
MinReturn                                -280168
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0849154
ProcessExecTime                                0.00100422
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:21 | [drl] epoch #13 | Obtaining samples...
2020-09-06 22:29:21 | [drl] epoch #13 | Obtaining samples for iteration 13...
2020-09-06 22:29:21 | [drl] epoch #13 | Logging diagnostics...
2020-09-06 22:29:21 | [drl] epoch #13 | Optimizing policy...
2020-09-06 22:29:21 | [drl] epoch #13 | Computing loss before
2020-09-06 22:29:21 | [drl] epoch #13 | Computing KL before
2020-09-06 22:29:21 | [drl] epoch #13 | Optimizing
2020-09-06 22:29:21 | [drl] epoch #13 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:21 | [drl] epoch #13 | computing loss before
2020-09-06 22:29:21 | [drl] epoch #13 | computing gradient
2020-09-06 22:29:21 | [drl] epoch #13 | gradient computed
2020-09-06 22:29:21 | [drl] epoch #13 | computing descent direction
2020-09-06 22:29:22 | [drl] epoch #13 | descent direction computed
2020-09-06 22:29:22 | [drl] epoch #13 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:22 | [drl] epoch #13 | Violated because loss is NaN
2020-09-06 22:29:22 | [drl] epoch #13 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:22 | [drl] epoch #13 | backtrack iters: 14
2020-09-06 22:29:22 | [drl] epoch #13 | optimization finished
2020-09-06 22:29:22 | [drl] epoch #13 | Computing KL after
2020-09-06 22:29:22 | [drl] epoch #13 | Computing loss after
2020-09-06 22:29:22 | [drl] epoch #13 | Fitting baseline...
2020-09-06 22:29:22 | [drl] epoch #13 | Saving snapshot...
2020-09-06 22:29:22 | [drl] epoch #13 | Saved
2020-09-06 22:29:22 | [drl] epoch #13 | Time 30.25 s
2020-09-06 22:29:22 | [drl] epoch #13 | EpochTime 0.80 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -135676
AverageReturn                            -221781
Entropy                                        8.51363
EnvExecTime                                    0.0365391
Extras/EpisodeRewardMean                 -224618
Iteration                                     13
LinearFeatureBaseline/ExplainedVariance        0.929095
MaxReturn                                -221781
MinReturn                                -221781
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.045388
ProcessExecTime                                0.000978708
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:22 | [drl] epoch #14 | Obtaining samples...
2020-09-06 22:29:22 | [drl] epoch #14 | Obtaining samples for iteration 14...
2020-09-06 22:29:22 | [drl] epoch #14 | Logging diagnostics...
2020-09-06 22:29:22 | [drl] epoch #14 | Optimizing policy...
2020-09-06 22:29:22 | [drl] epoch #14 | Computing loss before
2020-09-06 22:29:22 | [drl] epoch #14 | Computing KL before
2020-09-06 22:29:22 | [drl] epoch #14 | Optimizing
2020-09-06 22:29:22 | [drl] epoch #14 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:22 | [drl] epoch #14 | computing loss before
2020-09-06 22:29:22 | [drl] epoch #14 | computing gradient
2020-09-06 22:29:22 | [drl] epoch #14 | gradient computed
2020-09-06 22:29:22 | [drl] epoch #14 | computing descent direction
2020-09-06 22:29:23 | [drl] epoch #14 | descent direction computed
2020-09-06 22:29:23 | [drl] epoch #14 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:23 | [drl] epoch #14 | Violated because loss is NaN
2020-09-06 22:29:23 | [drl] epoch #14 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:23 | [drl] epoch #14 | backtrack iters: 14
2020-09-06 22:29:23 | [drl] epoch #14 | optimization finished
2020-09-06 22:29:23 | [drl] epoch #14 | Computing KL after
2020-09-06 22:29:23 | [drl] epoch #14 | Computing loss after
2020-09-06 22:29:23 | [drl] epoch #14 | Fitting baseline...
2020-09-06 22:29:23 | [drl] epoch #14 | Saving snapshot...
2020-09-06 22:29:23 | [drl] epoch #14 | Saved
2020-09-06 22:29:23 | [drl] epoch #14 | Time 31.01 s
2020-09-06 22:29:23 | [drl] epoch #14 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93079.6
AverageReturn                            -152079
Entropy                                        8.51363
EnvExecTime                                    0.0324574
Extras/EpisodeRewardMean                 -219782
Iteration                                     14
LinearFeatureBaseline/ExplainedVariance        0.783378
MaxReturn                                -152079
MinReturn                                -152079
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0602539
ProcessExecTime                                0.000940084
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:23 | [drl] epoch #15 | Obtaining samples...
2020-09-06 22:29:23 | [drl] epoch #15 | Obtaining samples for iteration 15...
2020-09-06 22:29:23 | [drl] epoch #15 | Logging diagnostics...
2020-09-06 22:29:23 | [drl] epoch #15 | Optimizing policy...
2020-09-06 22:29:23 | [drl] epoch #15 | Computing loss before
2020-09-06 22:29:23 | [drl] epoch #15 | Computing KL before
2020-09-06 22:29:23 | [drl] epoch #15 | Optimizing
2020-09-06 22:29:23 | [drl] epoch #15 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:23 | [drl] epoch #15 | computing loss before
2020-09-06 22:29:23 | [drl] epoch #15 | computing gradient
2020-09-06 22:29:23 | [drl] epoch #15 | gradient computed
2020-09-06 22:29:23 | [drl] epoch #15 | computing descent direction
2020-09-06 22:29:23 | [drl] epoch #15 | descent direction computed
2020-09-06 22:29:24 | [drl] epoch #15 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:24 | [drl] epoch #15 | Violated because loss is NaN
2020-09-06 22:29:24 | [drl] epoch #15 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:24 | [drl] epoch #15 | backtrack iters: 14
2020-09-06 22:29:24 | [drl] epoch #15 | optimization finished
2020-09-06 22:29:24 | [drl] epoch #15 | Computing KL after
2020-09-06 22:29:24 | [drl] epoch #15 | Computing loss after
2020-09-06 22:29:24 | [drl] epoch #15 | Fitting baseline...
2020-09-06 22:29:24 | [drl] epoch #15 | Saving snapshot...
2020-09-06 22:29:24 | [drl] epoch #15 | Saved
2020-09-06 22:29:24 | [drl] epoch #15 | Time 31.76 s
2020-09-06 22:29:24 | [drl] epoch #15 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -86820.4
AverageReturn                            -141831
Entropy                                        8.51363
EnvExecTime                                    0.0395384
Extras/EpisodeRewardMean                 -214910
Iteration                                     15
LinearFeatureBaseline/ExplainedVariance        0.994511
MaxReturn                                -141831
MinReturn                                -141831
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0448866
ProcessExecTime                                0.000938654
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:24 | [drl] epoch #16 | Obtaining samples...
2020-09-06 22:29:24 | [drl] epoch #16 | Obtaining samples for iteration 16...
2020-09-06 22:29:24 | [drl] epoch #16 | Logging diagnostics...
2020-09-06 22:29:24 | [drl] epoch #16 | Optimizing policy...
2020-09-06 22:29:24 | [drl] epoch #16 | Computing loss before
2020-09-06 22:29:24 | [drl] epoch #16 | Computing KL before
2020-09-06 22:29:24 | [drl] epoch #16 | Optimizing
2020-09-06 22:29:24 | [drl] epoch #16 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:24 | [drl] epoch #16 | computing loss before
2020-09-06 22:29:24 | [drl] epoch #16 | computing gradient
2020-09-06 22:29:24 | [drl] epoch #16 | gradient computed
2020-09-06 22:29:24 | [drl] epoch #16 | computing descent direction
2020-09-06 22:29:24 | [drl] epoch #16 | descent direction computed
2020-09-06 22:29:24 | [drl] epoch #16 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:24 | [drl] epoch #16 | Violated because loss is NaN
2020-09-06 22:29:24 | [drl] epoch #16 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:24 | [drl] epoch #16 | backtrack iters: 14
2020-09-06 22:29:24 | [drl] epoch #16 | optimization finished
2020-09-06 22:29:24 | [drl] epoch #16 | Computing KL after
2020-09-06 22:29:24 | [drl] epoch #16 | Computing loss after
2020-09-06 22:29:24 | [drl] epoch #16 | Fitting baseline...
2020-09-06 22:29:24 | [drl] epoch #16 | Saving snapshot...
2020-09-06 22:29:24 | [drl] epoch #16 | Saved
2020-09-06 22:29:24 | [drl] epoch #16 | Time 32.51 s
2020-09-06 22:29:24 | [drl] epoch #16 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -89177.5
AverageReturn                            -145687
Entropy                                        8.51363
EnvExecTime                                    0.0415804
Extras/EpisodeRewardMean                 -210838
Iteration                                     16
LinearFeatureBaseline/ExplainedVariance        0.999301
MaxReturn                                -145687
MinReturn                                -145687
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0441616
ProcessExecTime                                0.00094676
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:24 | [drl] epoch #17 | Obtaining samples...
2020-09-06 22:29:24 | [drl] epoch #17 | Obtaining samples for iteration 17...
2020-09-06 22:29:24 | [drl] epoch #17 | Logging diagnostics...
2020-09-06 22:29:24 | [drl] epoch #17 | Optimizing policy...
2020-09-06 22:29:24 | [drl] epoch #17 | Computing loss before
2020-09-06 22:29:24 | [drl] epoch #17 | Computing KL before
2020-09-06 22:29:24 | [drl] epoch #17 | Optimizing
2020-09-06 22:29:24 | [drl] epoch #17 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:24 | [drl] epoch #17 | computing loss before
2020-09-06 22:29:24 | [drl] epoch #17 | computing gradient
2020-09-06 22:29:24 | [drl] epoch #17 | gradient computed
2020-09-06 22:29:24 | [drl] epoch #17 | computing descent direction
2020-09-06 22:29:25 | [drl] epoch #17 | descent direction computed
2020-09-06 22:29:25 | [drl] epoch #17 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:25 | [drl] epoch #17 | Violated because loss is NaN
2020-09-06 22:29:25 | [drl] epoch #17 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:25 | [drl] epoch #17 | backtrack iters: 14
2020-09-06 22:29:25 | [drl] epoch #17 | optimization finished
2020-09-06 22:29:25 | [drl] epoch #17 | Computing KL after
2020-09-06 22:29:25 | [drl] epoch #17 | Computing loss after
2020-09-06 22:29:25 | [drl] epoch #17 | Fitting baseline...
2020-09-06 22:29:25 | [drl] epoch #17 | Saving snapshot...
2020-09-06 22:29:25 | [drl] epoch #17 | Saved
2020-09-06 22:29:25 | [drl] epoch #17 | Time 33.29 s
2020-09-06 22:29:25 | [drl] epoch #17 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173471
AverageReturn                            -283627
Entropy                                        8.51363
EnvExecTime                                    0.04809
Extras/EpisodeRewardMean                 -214882
Iteration                                     17
LinearFeatureBaseline/ExplainedVariance        0.758987
MaxReturn                                -283627
MinReturn                                -283627
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0415344
ProcessExecTime                                0.000962496
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:25 | [drl] epoch #18 | Obtaining samples...
2020-09-06 22:29:25 | [drl] epoch #18 | Obtaining samples for iteration 18...
2020-09-06 22:29:25 | [drl] epoch #18 | Logging diagnostics...
2020-09-06 22:29:25 | [drl] epoch #18 | Optimizing policy...
2020-09-06 22:29:25 | [drl] epoch #18 | Computing loss before
2020-09-06 22:29:25 | [drl] epoch #18 | Computing KL before
2020-09-06 22:29:25 | [drl] epoch #18 | Optimizing
2020-09-06 22:29:25 | [drl] epoch #18 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:25 | [drl] epoch #18 | computing loss before
2020-09-06 22:29:25 | [drl] epoch #18 | computing gradient
2020-09-06 22:29:25 | [drl] epoch #18 | gradient computed
2020-09-06 22:29:25 | [drl] epoch #18 | computing descent direction
2020-09-06 22:29:26 | [drl] epoch #18 | descent direction computed
2020-09-06 22:29:26 | [drl] epoch #18 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:26 | [drl] epoch #18 | Violated because loss is NaN
2020-09-06 22:29:26 | [drl] epoch #18 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:26 | [drl] epoch #18 | backtrack iters: 14
2020-09-06 22:29:26 | [drl] epoch #18 | optimization finished
2020-09-06 22:29:26 | [drl] epoch #18 | Computing KL after
2020-09-06 22:29:26 | [drl] epoch #18 | Computing loss after
2020-09-06 22:29:26 | [drl] epoch #18 | Fitting baseline...
2020-09-06 22:29:26 | [drl] epoch #18 | Saving snapshot...
2020-09-06 22:29:26 | [drl] epoch #18 | Saved
2020-09-06 22:29:26 | [drl] epoch #18 | Time 34.03 s
2020-09-06 22:29:26 | [drl] epoch #18 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -90334.2
AverageReturn                            -147591
Entropy                                        8.51363
EnvExecTime                                    0.0506113
Extras/EpisodeRewardMean                 -211341
Iteration                                     18
LinearFeatureBaseline/ExplainedVariance        0.123617
MaxReturn                                -147591
MinReturn                                -147591
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0408573
ProcessExecTime                                0.00101995
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:26 | [drl] epoch #19 | Obtaining samples...
2020-09-06 22:29:26 | [drl] epoch #19 | Obtaining samples for iteration 19...
2020-09-06 22:29:26 | [drl] epoch #19 | Logging diagnostics...
2020-09-06 22:29:26 | [drl] epoch #19 | Optimizing policy...
2020-09-06 22:29:26 | [drl] epoch #19 | Computing loss before
2020-09-06 22:29:26 | [drl] epoch #19 | Computing KL before
2020-09-06 22:29:26 | [drl] epoch #19 | Optimizing
2020-09-06 22:29:26 | [drl] epoch #19 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:26 | [drl] epoch #19 | computing loss before
2020-09-06 22:29:26 | [drl] epoch #19 | computing gradient
2020-09-06 22:29:26 | [drl] epoch #19 | gradient computed
2020-09-06 22:29:26 | [drl] epoch #19 | computing descent direction
2020-09-06 22:29:26 | [drl] epoch #19 | descent direction computed
2020-09-06 22:29:27 | [drl] epoch #19 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:27 | [drl] epoch #19 | Violated because loss is NaN
2020-09-06 22:29:27 | [drl] epoch #19 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:27 | [drl] epoch #19 | backtrack iters: 14
2020-09-06 22:29:27 | [drl] epoch #19 | optimization finished
2020-09-06 22:29:27 | [drl] epoch #19 | Computing KL after
2020-09-06 22:29:27 | [drl] epoch #19 | Computing loss after
2020-09-06 22:29:27 | [drl] epoch #19 | Fitting baseline...
2020-09-06 22:29:27 | [drl] epoch #19 | Saving snapshot...
2020-09-06 22:29:27 | [drl] epoch #19 | Saved
2020-09-06 22:29:27 | [drl] epoch #19 | Time 34.81 s
2020-09-06 22:29:27 | [drl] epoch #19 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106449
AverageReturn                            -173957
Entropy                                        8.51363
EnvExecTime                                    0.0479858
Extras/EpisodeRewardMean                 -209471
Iteration                                     19
LinearFeatureBaseline/ExplainedVariance        0.976486
MaxReturn                                -173957
MinReturn                                -173957
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0575275
ProcessExecTime                                0.000940561
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:27 | [drl] epoch #20 | Obtaining samples...
2020-09-06 22:29:27 | [drl] epoch #20 | Obtaining samples for iteration 20...
2020-09-06 22:29:27 | [drl] epoch #20 | Logging diagnostics...
2020-09-06 22:29:27 | [drl] epoch #20 | Optimizing policy...
2020-09-06 22:29:27 | [drl] epoch #20 | Computing loss before
2020-09-06 22:29:27 | [drl] epoch #20 | Computing KL before
2020-09-06 22:29:27 | [drl] epoch #20 | Optimizing
2020-09-06 22:29:27 | [drl] epoch #20 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:27 | [drl] epoch #20 | computing loss before
2020-09-06 22:29:27 | [drl] epoch #20 | computing gradient
2020-09-06 22:29:27 | [drl] epoch #20 | gradient computed
2020-09-06 22:29:27 | [drl] epoch #20 | computing descent direction
2020-09-06 22:29:27 | [drl] epoch #20 | descent direction computed
2020-09-06 22:29:27 | [drl] epoch #20 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:27 | [drl] epoch #20 | Violated because loss is NaN
2020-09-06 22:29:27 | [drl] epoch #20 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:27 | [drl] epoch #20 | backtrack iters: 14
2020-09-06 22:29:27 | [drl] epoch #20 | optimization finished
2020-09-06 22:29:27 | [drl] epoch #20 | Computing KL after
2020-09-06 22:29:27 | [drl] epoch #20 | Computing loss after
2020-09-06 22:29:27 | [drl] epoch #20 | Fitting baseline...
2020-09-06 22:29:27 | [drl] epoch #20 | Saving snapshot...
2020-09-06 22:29:27 | [drl] epoch #20 | Saved
2020-09-06 22:29:27 | [drl] epoch #20 | Time 35.56 s
2020-09-06 22:29:27 | [drl] epoch #20 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -96632.3
AverageReturn                            -157899
Entropy                                        8.51363
EnvExecTime                                    0.0454204
Extras/EpisodeRewardMean                 -207015
Iteration                                     20
LinearFeatureBaseline/ExplainedVariance        0.989373
MaxReturn                                -157899
MinReturn                                -157899
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0434361
ProcessExecTime                                0.00101924
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:27 | [drl] epoch #21 | Obtaining samples...
2020-09-06 22:29:27 | [drl] epoch #21 | Obtaining samples for iteration 21...
2020-09-06 22:29:27 | [drl] epoch #21 | Logging diagnostics...
2020-09-06 22:29:27 | [drl] epoch #21 | Optimizing policy...
2020-09-06 22:29:27 | [drl] epoch #21 | Computing loss before
2020-09-06 22:29:27 | [drl] epoch #21 | Computing KL before
2020-09-06 22:29:27 | [drl] epoch #21 | Optimizing
2020-09-06 22:29:27 | [drl] epoch #21 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:27 | [drl] epoch #21 | computing loss before
2020-09-06 22:29:27 | [drl] epoch #21 | computing gradient
2020-09-06 22:29:28 | [drl] epoch #21 | gradient computed
2020-09-06 22:29:28 | [drl] epoch #21 | computing descent direction
2020-09-06 22:29:28 | [drl] epoch #21 | descent direction computed
2020-09-06 22:29:28 | [drl] epoch #21 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:28 | [drl] epoch #21 | Violated because loss is NaN
2020-09-06 22:29:28 | [drl] epoch #21 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:28 | [drl] epoch #21 | backtrack iters: 14
2020-09-06 22:29:28 | [drl] epoch #21 | optimization finished
2020-09-06 22:29:28 | [drl] epoch #21 | Computing KL after
2020-09-06 22:29:28 | [drl] epoch #21 | Computing loss after
2020-09-06 22:29:28 | [drl] epoch #21 | Fitting baseline...
2020-09-06 22:29:28 | [drl] epoch #21 | Saving snapshot...
2020-09-06 22:29:28 | [drl] epoch #21 | Saved
2020-09-06 22:29:28 | [drl] epoch #21 | Time 36.31 s
2020-09-06 22:29:28 | [drl] epoch #21 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -170612
AverageReturn                            -278935
Entropy                                        8.51363
EnvExecTime                                    0.047698
Extras/EpisodeRewardMean                 -210285
Iteration                                     21
LinearFeatureBaseline/ExplainedVariance        0.808798
MaxReturn                                -278935
MinReturn                                -278935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.046133
ProcessExecTime                                0.00102186
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:28 | [drl] epoch #22 | Obtaining samples...
2020-09-06 22:29:28 | [drl] epoch #22 | Obtaining samples for iteration 22...
2020-09-06 22:29:28 | [drl] epoch #22 | Logging diagnostics...
2020-09-06 22:29:28 | [drl] epoch #22 | Optimizing policy...
2020-09-06 22:29:28 | [drl] epoch #22 | Computing loss before
2020-09-06 22:29:28 | [drl] epoch #22 | Computing KL before
2020-09-06 22:29:28 | [drl] epoch #22 | Optimizing
2020-09-06 22:29:28 | [drl] epoch #22 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:28 | [drl] epoch #22 | computing loss before
2020-09-06 22:29:28 | [drl] epoch #22 | computing gradient
2020-09-06 22:29:28 | [drl] epoch #22 | gradient computed
2020-09-06 22:29:28 | [drl] epoch #22 | computing descent direction
2020-09-06 22:29:29 | [drl] epoch #22 | descent direction computed
2020-09-06 22:29:29 | [drl] epoch #22 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:29 | [drl] epoch #22 | Violated because loss is NaN
2020-09-06 22:29:29 | [drl] epoch #22 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:29 | [drl] epoch #22 | backtrack iters: 14
2020-09-06 22:29:29 | [drl] epoch #22 | optimization finished
2020-09-06 22:29:29 | [drl] epoch #22 | Computing KL after
2020-09-06 22:29:29 | [drl] epoch #22 | Computing loss after
2020-09-06 22:29:29 | [drl] epoch #22 | Fitting baseline...
2020-09-06 22:29:29 | [drl] epoch #22 | Saving snapshot...
2020-09-06 22:29:29 | [drl] epoch #22 | Saved
2020-09-06 22:29:29 | [drl] epoch #22 | Time 37.06 s
2020-09-06 22:29:29 | [drl] epoch #22 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -142558
AverageReturn                            -233040
Entropy                                        8.51363
EnvExecTime                                    0.0365055
Extras/EpisodeRewardMean                 -211274
Iteration                                     22
LinearFeatureBaseline/ExplainedVariance        0.960675
MaxReturn                                -233040
MinReturn                                -233040
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0527961
ProcessExecTime                                0.00121284
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:29 | [drl] epoch #23 | Obtaining samples...
2020-09-06 22:29:29 | [drl] epoch #23 | Obtaining samples for iteration 23...
2020-09-06 22:29:29 | [drl] epoch #23 | Logging diagnostics...
2020-09-06 22:29:29 | [drl] epoch #23 | Optimizing policy...
2020-09-06 22:29:29 | [drl] epoch #23 | Computing loss before
2020-09-06 22:29:29 | [drl] epoch #23 | Computing KL before
2020-09-06 22:29:29 | [drl] epoch #23 | Optimizing
2020-09-06 22:29:29 | [drl] epoch #23 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:29 | [drl] epoch #23 | computing loss before
2020-09-06 22:29:29 | [drl] epoch #23 | computing gradient
2020-09-06 22:29:29 | [drl] epoch #23 | gradient computed
2020-09-06 22:29:29 | [drl] epoch #23 | computing descent direction
2020-09-06 22:29:29 | [drl] epoch #23 | descent direction computed
2020-09-06 22:29:30 | [drl] epoch #23 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:30 | [drl] epoch #23 | Violated because loss is NaN
2020-09-06 22:29:30 | [drl] epoch #23 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:30 | [drl] epoch #23 | backtrack iters: 14
2020-09-06 22:29:30 | [drl] epoch #23 | optimization finished
2020-09-06 22:29:30 | [drl] epoch #23 | Computing KL after
2020-09-06 22:29:30 | [drl] epoch #23 | Computing loss after
2020-09-06 22:29:30 | [drl] epoch #23 | Fitting baseline...
2020-09-06 22:29:30 | [drl] epoch #23 | Saving snapshot...
2020-09-06 22:29:30 | [drl] epoch #23 | Saved
2020-09-06 22:29:30 | [drl] epoch #23 | Time 37.82 s
2020-09-06 22:29:30 | [drl] epoch #23 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -176606
AverageReturn                            -288756
Entropy                                        8.51363
EnvExecTime                                    0.0431914
Extras/EpisodeRewardMean                 -214502
Iteration                                     23
LinearFeatureBaseline/ExplainedVariance        0.962094
MaxReturn                                -288756
MinReturn                                -288756
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.054213
ProcessExecTime                                0.000978947
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:30 | [drl] epoch #24 | Obtaining samples...
2020-09-06 22:29:30 | [drl] epoch #24 | Obtaining samples for iteration 24...
2020-09-06 22:29:30 | [drl] epoch #24 | Logging diagnostics...
2020-09-06 22:29:30 | [drl] epoch #24 | Optimizing policy...
2020-09-06 22:29:30 | [drl] epoch #24 | Computing loss before
2020-09-06 22:29:30 | [drl] epoch #24 | Computing KL before
2020-09-06 22:29:30 | [drl] epoch #24 | Optimizing
2020-09-06 22:29:30 | [drl] epoch #24 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:30 | [drl] epoch #24 | computing loss before
2020-09-06 22:29:30 | [drl] epoch #24 | computing gradient
2020-09-06 22:29:30 | [drl] epoch #24 | gradient computed
2020-09-06 22:29:30 | [drl] epoch #24 | computing descent direction
2020-09-06 22:29:30 | [drl] epoch #24 | descent direction computed
2020-09-06 22:29:30 | [drl] epoch #24 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:30 | [drl] epoch #24 | Violated because loss is NaN
2020-09-06 22:29:30 | [drl] epoch #24 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:30 | [drl] epoch #24 | backtrack iters: 14
2020-09-06 22:29:30 | [drl] epoch #24 | optimization finished
2020-09-06 22:29:30 | [drl] epoch #24 | Computing KL after
2020-09-06 22:29:30 | [drl] epoch #24 | Computing loss after
2020-09-06 22:29:30 | [drl] epoch #24 | Fitting baseline...
2020-09-06 22:29:30 | [drl] epoch #24 | Saving snapshot...
2020-09-06 22:29:30 | [drl] epoch #24 | Saved
2020-09-06 22:29:30 | [drl] epoch #24 | Time 38.57 s
2020-09-06 22:29:30 | [drl] epoch #24 | EpochTime 0.73 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -109849
AverageReturn                            -179519
Entropy                                        8.51363
EnvExecTime                                    0.0343189
Extras/EpisodeRewardMean                 -213103
Iteration                                     24
LinearFeatureBaseline/ExplainedVariance        0.619529
MaxReturn                                -179519
MinReturn                                -179519
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0535305
ProcessExecTime                                0.000994205
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:30 | [drl] epoch #25 | Obtaining samples...
2020-09-06 22:29:30 | [drl] epoch #25 | Obtaining samples for iteration 25...
2020-09-06 22:29:30 | [drl] epoch #25 | Logging diagnostics...
2020-09-06 22:29:30 | [drl] epoch #25 | Optimizing policy...
2020-09-06 22:29:30 | [drl] epoch #25 | Computing loss before
2020-09-06 22:29:30 | [drl] epoch #25 | Computing KL before
2020-09-06 22:29:30 | [drl] epoch #25 | Optimizing
2020-09-06 22:29:30 | [drl] epoch #25 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:30 | [drl] epoch #25 | computing loss before
2020-09-06 22:29:31 | [drl] epoch #25 | computing gradient
2020-09-06 22:29:31 | [drl] epoch #25 | gradient computed
2020-09-06 22:29:31 | [drl] epoch #25 | computing descent direction
2020-09-06 22:29:31 | [drl] epoch #25 | descent direction computed
2020-09-06 22:29:31 | [drl] epoch #25 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:31 | [drl] epoch #25 | Violated because loss is NaN
2020-09-06 22:29:31 | [drl] epoch #25 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:31 | [drl] epoch #25 | backtrack iters: 14
2020-09-06 22:29:31 | [drl] epoch #25 | optimization finished
2020-09-06 22:29:31 | [drl] epoch #25 | Computing KL after
2020-09-06 22:29:31 | [drl] epoch #25 | Computing loss after
2020-09-06 22:29:31 | [drl] epoch #25 | Fitting baseline...
2020-09-06 22:29:31 | [drl] epoch #25 | Saving snapshot...
2020-09-06 22:29:31 | [drl] epoch #25 | Saved
2020-09-06 22:29:31 | [drl] epoch #25 | Time 39.41 s
2020-09-06 22:29:31 | [drl] epoch #25 | EpochTime 0.84 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -105961
AverageReturn                            -173154
Entropy                                        8.51363
EnvExecTime                                    0.0354054
Extras/EpisodeRewardMean                 -211567
Iteration                                     25
LinearFeatureBaseline/ExplainedVariance        0.998613
MaxReturn                                -173154
MinReturn                                -173154
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0499511
ProcessExecTime                                0.000973463
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:31 | [drl] epoch #26 | Obtaining samples...
2020-09-06 22:29:31 | [drl] epoch #26 | Obtaining samples for iteration 26...
2020-09-06 22:29:31 | [drl] epoch #26 | Logging diagnostics...
2020-09-06 22:29:31 | [drl] epoch #26 | Optimizing policy...
2020-09-06 22:29:31 | [drl] epoch #26 | Computing loss before
2020-09-06 22:29:31 | [drl] epoch #26 | Computing KL before
2020-09-06 22:29:31 | [drl] epoch #26 | Optimizing
2020-09-06 22:29:31 | [drl] epoch #26 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:31 | [drl] epoch #26 | computing loss before
2020-09-06 22:29:31 | [drl] epoch #26 | computing gradient
2020-09-06 22:29:31 | [drl] epoch #26 | gradient computed
2020-09-06 22:29:31 | [drl] epoch #26 | computing descent direction
2020-09-06 22:29:32 | [drl] epoch #26 | descent direction computed
2020-09-06 22:29:32 | [drl] epoch #26 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:32 | [drl] epoch #26 | Violated because loss is NaN
2020-09-06 22:29:32 | [drl] epoch #26 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:32 | [drl] epoch #26 | backtrack iters: 14
2020-09-06 22:29:32 | [drl] epoch #26 | optimization finished
2020-09-06 22:29:32 | [drl] epoch #26 | Computing KL after
2020-09-06 22:29:32 | [drl] epoch #26 | Computing loss after
2020-09-06 22:29:32 | [drl] epoch #26 | Fitting baseline...
2020-09-06 22:29:32 | [drl] epoch #26 | Saving snapshot...
2020-09-06 22:29:32 | [drl] epoch #26 | Saved
2020-09-06 22:29:32 | [drl] epoch #26 | Time 40.16 s
2020-09-06 22:29:32 | [drl] epoch #26 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -123080
AverageReturn                            -201169
Entropy                                        8.51363
EnvExecTime                                    0.0369754
Extras/EpisodeRewardMean                 -211181
Iteration                                     26
LinearFeatureBaseline/ExplainedVariance        0.980211
MaxReturn                                -201169
MinReturn                                -201169
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0442281
ProcessExecTime                                0.00095582
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:32 | [drl] epoch #27 | Obtaining samples...
2020-09-06 22:29:32 | [drl] epoch #27 | Obtaining samples for iteration 27...
2020-09-06 22:29:32 | [drl] epoch #27 | Logging diagnostics...
2020-09-06 22:29:32 | [drl] epoch #27 | Optimizing policy...
2020-09-06 22:29:32 | [drl] epoch #27 | Computing loss before
2020-09-06 22:29:32 | [drl] epoch #27 | Computing KL before
2020-09-06 22:29:32 | [drl] epoch #27 | Optimizing
2020-09-06 22:29:32 | [drl] epoch #27 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:32 | [drl] epoch #27 | computing loss before
2020-09-06 22:29:32 | [drl] epoch #27 | computing gradient
2020-09-06 22:29:32 | [drl] epoch #27 | gradient computed
2020-09-06 22:29:32 | [drl] epoch #27 | computing descent direction
2020-09-06 22:29:33 | [drl] epoch #27 | descent direction computed
2020-09-06 22:29:33 | [drl] epoch #27 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:33 | [drl] epoch #27 | Violated because loss is NaN
2020-09-06 22:29:33 | [drl] epoch #27 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:33 | [drl] epoch #27 | backtrack iters: 14
2020-09-06 22:29:33 | [drl] epoch #27 | optimization finished
2020-09-06 22:29:33 | [drl] epoch #27 | Computing KL after
2020-09-06 22:29:33 | [drl] epoch #27 | Computing loss after
2020-09-06 22:29:33 | [drl] epoch #27 | Fitting baseline...
2020-09-06 22:29:33 | [drl] epoch #27 | Saving snapshot...
2020-09-06 22:29:33 | [drl] epoch #27 | Saved
2020-09-06 22:29:33 | [drl] epoch #27 | Time 40.91 s
2020-09-06 22:29:33 | [drl] epoch #27 | EpochTime 0.73 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -98838.3
AverageReturn                            -161501
Entropy                                        8.51363
EnvExecTime                                    0.0365207
Extras/EpisodeRewardMean                 -209407
Iteration                                     27
LinearFeatureBaseline/ExplainedVariance        0.937946
MaxReturn                                -161501
MinReturn                                -161501
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0458355
ProcessExecTime                                0.0026412
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:29:33 | [drl] epoch #28 | Obtaining samples...
2020-09-06 22:29:33 | [drl] epoch #28 | Obtaining samples for iteration 28...
2020-09-06 22:29:33 | [drl] epoch #28 | Logging diagnostics...
2020-09-06 22:29:33 | [drl] epoch #28 | Optimizing policy...
2020-09-06 22:29:33 | [drl] epoch #28 | Computing loss before
2020-09-06 22:29:33 | [drl] epoch #28 | Computing KL before
2020-09-06 22:29:33 | [drl] epoch #28 | Optimizing
2020-09-06 22:29:33 | [drl] epoch #28 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:33 | [drl] epoch #28 | computing loss before
2020-09-06 22:29:33 | [drl] epoch #28 | computing gradient
2020-09-06 22:29:33 | [drl] epoch #28 | gradient computed
2020-09-06 22:29:33 | [drl] epoch #28 | computing descent direction
2020-09-06 22:29:33 | [drl] epoch #28 | descent direction computed
2020-09-06 22:29:33 | [drl] epoch #28 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:33 | [drl] epoch #28 | Violated because loss is NaN
2020-09-06 22:29:33 | [drl] epoch #28 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:33 | [drl] epoch #28 | backtrack iters: 14
2020-09-06 22:29:33 | [drl] epoch #28 | optimization finished
2020-09-06 22:29:33 | [drl] epoch #28 | Computing KL after
2020-09-06 22:29:33 | [drl] epoch #28 | Computing loss after
2020-09-06 22:29:33 | [drl] epoch #28 | Fitting baseline...
2020-09-06 22:29:33 | [drl] epoch #28 | Saving snapshot...
2020-09-06 22:29:33 | [drl] epoch #28 | Saved
2020-09-06 22:29:33 | [drl] epoch #28 | Time 41.67 s
2020-09-06 22:29:33 | [drl] epoch #28 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -76607.3
AverageReturn                            -125122
Entropy                                        8.51363
EnvExecTime                                    0.0361359
Extras/EpisodeRewardMean                 -206501
Iteration                                     28
LinearFeatureBaseline/ExplainedVariance        0.912185
MaxReturn                                -125122
MinReturn                                -125122
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0486934
ProcessExecTime                                0.00098443
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:33 | [drl] epoch #29 | Obtaining samples...
2020-09-06 22:29:33 | [drl] epoch #29 | Obtaining samples for iteration 29...
2020-09-06 22:29:34 | [drl] epoch #29 | Logging diagnostics...
2020-09-06 22:29:34 | [drl] epoch #29 | Optimizing policy...
2020-09-06 22:29:34 | [drl] epoch #29 | Computing loss before
2020-09-06 22:29:34 | [drl] epoch #29 | Computing KL before
2020-09-06 22:29:34 | [drl] epoch #29 | Optimizing
2020-09-06 22:29:34 | [drl] epoch #29 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:34 | [drl] epoch #29 | computing loss before
2020-09-06 22:29:34 | [drl] epoch #29 | computing gradient
2020-09-06 22:29:34 | [drl] epoch #29 | gradient computed
2020-09-06 22:29:34 | [drl] epoch #29 | computing descent direction
2020-09-06 22:29:34 | [drl] epoch #29 | descent direction computed
2020-09-06 22:29:34 | [drl] epoch #29 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:34 | [drl] epoch #29 | Violated because loss is NaN
2020-09-06 22:29:34 | [drl] epoch #29 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:34 | [drl] epoch #29 | backtrack iters: 14
2020-09-06 22:29:34 | [drl] epoch #29 | optimization finished
2020-09-06 22:29:34 | [drl] epoch #29 | Computing KL after
2020-09-06 22:29:34 | [drl] epoch #29 | Computing loss after
2020-09-06 22:29:34 | [drl] epoch #29 | Fitting baseline...
2020-09-06 22:29:34 | [drl] epoch #29 | Saving snapshot...
2020-09-06 22:29:34 | [drl] epoch #29 | Saved
2020-09-06 22:29:34 | [drl] epoch #29 | Time 42.42 s
2020-09-06 22:29:34 | [drl] epoch #29 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -101247
AverageReturn                            -165454
Entropy                                        8.51363
EnvExecTime                                    0.0363386
Extras/EpisodeRewardMean                 -205133
Iteration                                     29
LinearFeatureBaseline/ExplainedVariance        0.938442
MaxReturn                                -165454
MinReturn                                -165454
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0430875
ProcessExecTime                                0.00097084
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:34 | [drl] epoch #30 | Obtaining samples...
2020-09-06 22:29:34 | [drl] epoch #30 | Obtaining samples for iteration 30...
2020-09-06 22:29:34 | [drl] epoch #30 | Logging diagnostics...
2020-09-06 22:29:34 | [drl] epoch #30 | Optimizing policy...
2020-09-06 22:29:34 | [drl] epoch #30 | Computing loss before
2020-09-06 22:29:34 | [drl] epoch #30 | Computing KL before
2020-09-06 22:29:34 | [drl] epoch #30 | Optimizing
2020-09-06 22:29:34 | [drl] epoch #30 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:34 | [drl] epoch #30 | computing loss before
2020-09-06 22:29:34 | [drl] epoch #30 | computing gradient
2020-09-06 22:29:34 | [drl] epoch #30 | gradient computed
2020-09-06 22:29:34 | [drl] epoch #30 | computing descent direction
2020-09-06 22:29:35 | [drl] epoch #30 | descent direction computed
2020-09-06 22:29:35 | [drl] epoch #30 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:35 | [drl] epoch #30 | Violated because loss is NaN
2020-09-06 22:29:35 | [drl] epoch #30 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:35 | [drl] epoch #30 | backtrack iters: 14
2020-09-06 22:29:35 | [drl] epoch #30 | optimization finished
2020-09-06 22:29:35 | [drl] epoch #30 | Computing KL after
2020-09-06 22:29:35 | [drl] epoch #30 | Computing loss after
2020-09-06 22:29:35 | [drl] epoch #30 | Fitting baseline...
2020-09-06 22:29:35 | [drl] epoch #30 | Saving snapshot...
2020-09-06 22:29:35 | [drl] epoch #30 | Saved
2020-09-06 22:29:35 | [drl] epoch #30 | Time 43.21 s
2020-09-06 22:29:35 | [drl] epoch #30 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -122695
AverageReturn                            -200540
Entropy                                        8.51363
EnvExecTime                                    0.0413146
Extras/EpisodeRewardMean                 -204984
Iteration                                     30
LinearFeatureBaseline/ExplainedVariance        0.968962
MaxReturn                                -200540
MinReturn                                -200540
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0396342
ProcessExecTime                                0.000973701
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:35 | [drl] epoch #31 | Obtaining samples...
2020-09-06 22:29:35 | [drl] epoch #31 | Obtaining samples for iteration 31...
2020-09-06 22:29:35 | [drl] epoch #31 | Logging diagnostics...
2020-09-06 22:29:35 | [drl] epoch #31 | Optimizing policy...
2020-09-06 22:29:35 | [drl] epoch #31 | Computing loss before
2020-09-06 22:29:35 | [drl] epoch #31 | Computing KL before
2020-09-06 22:29:35 | [drl] epoch #31 | Optimizing
2020-09-06 22:29:35 | [drl] epoch #31 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:35 | [drl] epoch #31 | computing loss before
2020-09-06 22:29:35 | [drl] epoch #31 | computing gradient
2020-09-06 22:29:35 | [drl] epoch #31 | gradient computed
2020-09-06 22:29:35 | [drl] epoch #31 | computing descent direction
2020-09-06 22:29:36 | [drl] epoch #31 | descent direction computed
2020-09-06 22:29:36 | [drl] epoch #31 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:36 | [drl] epoch #31 | Violated because loss is NaN
2020-09-06 22:29:36 | [drl] epoch #31 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:36 | [drl] epoch #31 | backtrack iters: 14
2020-09-06 22:29:36 | [drl] epoch #31 | optimization finished
2020-09-06 22:29:36 | [drl] epoch #31 | Computing KL after
2020-09-06 22:29:36 | [drl] epoch #31 | Computing loss after
2020-09-06 22:29:36 | [drl] epoch #31 | Fitting baseline...
2020-09-06 22:29:36 | [drl] epoch #31 | Saving snapshot...
2020-09-06 22:29:36 | [drl] epoch #31 | Saved
2020-09-06 22:29:36 | [drl] epoch #31 | Time 43.97 s
2020-09-06 22:29:36 | [drl] epoch #31 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -81070.4
AverageReturn                            -132436
Entropy                                        8.51363
EnvExecTime                                    0.0353913
Extras/EpisodeRewardMean                 -202717
Iteration                                     31
LinearFeatureBaseline/ExplainedVariance        0.727661
MaxReturn                                -132436
MinReturn                                -132436
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0505748
ProcessExecTime                                0.000994682
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:36 | [drl] epoch #32 | Obtaining samples...
2020-09-06 22:29:36 | [drl] epoch #32 | Obtaining samples for iteration 32...
2020-09-06 22:29:36 | [drl] epoch #32 | Logging diagnostics...
2020-09-06 22:29:36 | [drl] epoch #32 | Optimizing policy...
2020-09-06 22:29:36 | [drl] epoch #32 | Computing loss before
2020-09-06 22:29:36 | [drl] epoch #32 | Computing KL before
2020-09-06 22:29:36 | [drl] epoch #32 | Optimizing
2020-09-06 22:29:36 | [drl] epoch #32 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:36 | [drl] epoch #32 | computing loss before
2020-09-06 22:29:36 | [drl] epoch #32 | computing gradient
2020-09-06 22:29:36 | [drl] epoch #32 | gradient computed
2020-09-06 22:29:36 | [drl] epoch #32 | computing descent direction
2020-09-06 22:29:36 | [drl] epoch #32 | descent direction computed
2020-09-06 22:29:36 | [drl] epoch #32 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:36 | [drl] epoch #32 | Violated because loss is NaN
2020-09-06 22:29:36 | [drl] epoch #32 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:36 | [drl] epoch #32 | backtrack iters: 14
2020-09-06 22:29:36 | [drl] epoch #32 | optimization finished
2020-09-06 22:29:36 | [drl] epoch #32 | Computing KL after
2020-09-06 22:29:37 | [drl] epoch #32 | Computing loss after
2020-09-06 22:29:37 | [drl] epoch #32 | Fitting baseline...
2020-09-06 22:29:37 | [drl] epoch #32 | Saving snapshot...
2020-09-06 22:29:37 | [drl] epoch #32 | Saved
2020-09-06 22:29:37 | [drl] epoch #32 | Time 44.73 s
2020-09-06 22:29:37 | [drl] epoch #32 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -152810
AverageReturn                            -249823
Entropy                                        8.51363
EnvExecTime                                    0.0345225
Extras/EpisodeRewardMean                 -204145
Iteration                                     32
LinearFeatureBaseline/ExplainedVariance        0.77543
MaxReturn                                -249823
MinReturn                                -249823
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0442643
ProcessExecTime                                0.000977278
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:37 | [drl] epoch #33 | Obtaining samples...
2020-09-06 22:29:37 | [drl] epoch #33 | Obtaining samples for iteration 33...
2020-09-06 22:29:37 | [drl] epoch #33 | Logging diagnostics...
2020-09-06 22:29:37 | [drl] epoch #33 | Optimizing policy...
2020-09-06 22:29:37 | [drl] epoch #33 | Computing loss before
2020-09-06 22:29:37 | [drl] epoch #33 | Computing KL before
2020-09-06 22:29:37 | [drl] epoch #33 | Optimizing
2020-09-06 22:29:37 | [drl] epoch #33 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:37 | [drl] epoch #33 | computing loss before
2020-09-06 22:29:37 | [drl] epoch #33 | computing gradient
2020-09-06 22:29:37 | [drl] epoch #33 | gradient computed
2020-09-06 22:29:37 | [drl] epoch #33 | computing descent direction
2020-09-06 22:29:37 | [drl] epoch #33 | descent direction computed
2020-09-06 22:29:37 | [drl] epoch #33 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:37 | [drl] epoch #33 | Violated because loss is NaN
2020-09-06 22:29:37 | [drl] epoch #33 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:37 | [drl] epoch #33 | backtrack iters: 14
2020-09-06 22:29:37 | [drl] epoch #33 | optimization finished
2020-09-06 22:29:37 | [drl] epoch #33 | Computing KL after
2020-09-06 22:29:37 | [drl] epoch #33 | Computing loss after
2020-09-06 22:29:37 | [drl] epoch #33 | Fitting baseline...
2020-09-06 22:29:37 | [drl] epoch #33 | Saving snapshot...
2020-09-06 22:29:37 | [drl] epoch #33 | Saved
2020-09-06 22:29:37 | [drl] epoch #33 | Time 45.49 s
2020-09-06 22:29:37 | [drl] epoch #33 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -149549
AverageReturn                            -244485
Entropy                                        8.51363
EnvExecTime                                    0.0346491
Extras/EpisodeRewardMean                 -205331
Iteration                                     33
LinearFeatureBaseline/ExplainedVariance        0.999521
MaxReturn                                -244485
MinReturn                                -244485
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0544562
ProcessExecTime                                0.000963688
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:37 | [drl] epoch #34 | Obtaining samples...
2020-09-06 22:29:37 | [drl] epoch #34 | Obtaining samples for iteration 34...
2020-09-06 22:29:37 | [drl] epoch #34 | Logging diagnostics...
2020-09-06 22:29:37 | [drl] epoch #34 | Optimizing policy...
2020-09-06 22:29:37 | [drl] epoch #34 | Computing loss before
2020-09-06 22:29:37 | [drl] epoch #34 | Computing KL before
2020-09-06 22:29:37 | [drl] epoch #34 | Optimizing
2020-09-06 22:29:37 | [drl] epoch #34 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:37 | [drl] epoch #34 | computing loss before
2020-09-06 22:29:37 | [drl] epoch #34 | computing gradient
2020-09-06 22:29:37 | [drl] epoch #34 | gradient computed
2020-09-06 22:29:37 | [drl] epoch #34 | computing descent direction
2020-09-06 22:29:38 | [drl] epoch #34 | descent direction computed
2020-09-06 22:29:38 | [drl] epoch #34 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:38 | [drl] epoch #34 | Violated because loss is NaN
2020-09-06 22:29:38 | [drl] epoch #34 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:38 | [drl] epoch #34 | backtrack iters: 14
2020-09-06 22:29:38 | [drl] epoch #34 | optimization finished
2020-09-06 22:29:38 | [drl] epoch #34 | Computing KL after
2020-09-06 22:29:38 | [drl] epoch #34 | Computing loss after
2020-09-06 22:29:38 | [drl] epoch #34 | Fitting baseline...
2020-09-06 22:29:38 | [drl] epoch #34 | Saving snapshot...
2020-09-06 22:29:38 | [drl] epoch #34 | Saved
2020-09-06 22:29:38 | [drl] epoch #34 | Time 46.25 s
2020-09-06 22:29:38 | [drl] epoch #34 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -105282
AverageReturn                            -172041
Entropy                                        8.51363
EnvExecTime                                    0.0354073
Extras/EpisodeRewardMean                 -204380
Iteration                                     34
LinearFeatureBaseline/ExplainedVariance        0.8175
MaxReturn                                -172041
MinReturn                                -172041
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0492663
ProcessExecTime                                0.000939369
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:38 | [drl] epoch #35 | Obtaining samples...
2020-09-06 22:29:38 | [drl] epoch #35 | Obtaining samples for iteration 35...
2020-09-06 22:29:38 | [drl] epoch #35 | Logging diagnostics...
2020-09-06 22:29:38 | [drl] epoch #35 | Optimizing policy...
2020-09-06 22:29:38 | [drl] epoch #35 | Computing loss before
2020-09-06 22:29:38 | [drl] epoch #35 | Computing KL before
2020-09-06 22:29:38 | [drl] epoch #35 | Optimizing
2020-09-06 22:29:38 | [drl] epoch #35 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:38 | [drl] epoch #35 | computing loss before
2020-09-06 22:29:38 | [drl] epoch #35 | computing gradient
2020-09-06 22:29:38 | [drl] epoch #35 | gradient computed
2020-09-06 22:29:38 | [drl] epoch #35 | computing descent direction
2020-09-06 22:29:39 | [drl] epoch #35 | descent direction computed
2020-09-06 22:29:39 | [drl] epoch #35 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:39 | [drl] epoch #35 | Violated because loss is NaN
2020-09-06 22:29:39 | [drl] epoch #35 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:39 | [drl] epoch #35 | backtrack iters: 14
2020-09-06 22:29:39 | [drl] epoch #35 | optimization finished
2020-09-06 22:29:39 | [drl] epoch #35 | Computing KL after
2020-09-06 22:29:39 | [drl] epoch #35 | Computing loss after
2020-09-06 22:29:39 | [drl] epoch #35 | Fitting baseline...
2020-09-06 22:29:39 | [drl] epoch #35 | Saving snapshot...
2020-09-06 22:29:39 | [drl] epoch #35 | Saved
2020-09-06 22:29:39 | [drl] epoch #35 | Time 47.03 s
2020-09-06 22:29:39 | [drl] epoch #35 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -83754.4
AverageReturn                            -136818
Entropy                                        8.51363
EnvExecTime                                    0.0404289
Extras/EpisodeRewardMean                 -202503
Iteration                                     35
LinearFeatureBaseline/ExplainedVariance        0.931261
MaxReturn                                -136818
MinReturn                                -136818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0442407
ProcessExecTime                                0.00423551
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:39 | [drl] epoch #36 | Obtaining samples...
2020-09-06 22:29:39 | [drl] epoch #36 | Obtaining samples for iteration 36...
2020-09-06 22:29:39 | [drl] epoch #36 | Logging diagnostics...
2020-09-06 22:29:39 | [drl] epoch #36 | Optimizing policy...
2020-09-06 22:29:39 | [drl] epoch #36 | Computing loss before
2020-09-06 22:29:39 | [drl] epoch #36 | Computing KL before
2020-09-06 22:29:39 | [drl] epoch #36 | Optimizing
2020-09-06 22:29:39 | [drl] epoch #36 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:39 | [drl] epoch #36 | computing loss before
2020-09-06 22:29:39 | [drl] epoch #36 | computing gradient
2020-09-06 22:29:39 | [drl] epoch #36 | gradient computed
2020-09-06 22:29:39 | [drl] epoch #36 | computing descent direction
2020-09-06 22:29:39 | [drl] epoch #36 | descent direction computed
2020-09-06 22:29:40 | [drl] epoch #36 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:40 | [drl] epoch #36 | Violated because loss is NaN
2020-09-06 22:29:40 | [drl] epoch #36 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:40 | [drl] epoch #36 | backtrack iters: 14
2020-09-06 22:29:40 | [drl] epoch #36 | optimization finished
2020-09-06 22:29:40 | [drl] epoch #36 | Computing KL after
2020-09-06 22:29:40 | [drl] epoch #36 | Computing loss after
2020-09-06 22:29:40 | [drl] epoch #36 | Fitting baseline...
2020-09-06 22:29:40 | [drl] epoch #36 | Saving snapshot...
2020-09-06 22:29:40 | [drl] epoch #36 | Saved
2020-09-06 22:29:40 | [drl] epoch #36 | Time 47.79 s
2020-09-06 22:29:40 | [drl] epoch #36 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -95636
AverageReturn                            -156260
Entropy                                        8.51363
EnvExecTime                                    0.0335059
Extras/EpisodeRewardMean                 -201253
Iteration                                     36
LinearFeatureBaseline/ExplainedVariance        0.983943
MaxReturn                                -156260
MinReturn                                -156260
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0469759
ProcessExecTime                                0.00092864
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:40 | [drl] epoch #37 | Obtaining samples...
2020-09-06 22:29:40 | [drl] epoch #37 | Obtaining samples for iteration 37...
2020-09-06 22:29:40 | [drl] epoch #37 | Logging diagnostics...
2020-09-06 22:29:40 | [drl] epoch #37 | Optimizing policy...
2020-09-06 22:29:40 | [drl] epoch #37 | Computing loss before
2020-09-06 22:29:40 | [drl] epoch #37 | Computing KL before
2020-09-06 22:29:40 | [drl] epoch #37 | Optimizing
2020-09-06 22:29:40 | [drl] epoch #37 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:40 | [drl] epoch #37 | computing loss before
2020-09-06 22:29:40 | [drl] epoch #37 | computing gradient
2020-09-06 22:29:40 | [drl] epoch #37 | gradient computed
2020-09-06 22:29:40 | [drl] epoch #37 | computing descent direction
2020-09-06 22:29:40 | [drl] epoch #37 | descent direction computed
2020-09-06 22:29:40 | [drl] epoch #37 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:40 | [drl] epoch #37 | Violated because loss is NaN
2020-09-06 22:29:40 | [drl] epoch #37 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:40 | [drl] epoch #37 | backtrack iters: 14
2020-09-06 22:29:40 | [drl] epoch #37 | optimization finished
2020-09-06 22:29:40 | [drl] epoch #37 | Computing KL after
2020-09-06 22:29:40 | [drl] epoch #37 | Computing loss after
2020-09-06 22:29:40 | [drl] epoch #37 | Fitting baseline...
2020-09-06 22:29:40 | [drl] epoch #37 | Saving snapshot...
2020-09-06 22:29:40 | [drl] epoch #37 | Saved
2020-09-06 22:29:40 | [drl] epoch #37 | Time 48.55 s
2020-09-06 22:29:40 | [drl] epoch #37 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -127458
AverageReturn                            -208340
Entropy                                        8.51363
EnvExecTime                                    0.0485709
Extras/EpisodeRewardMean                 -201440
Iteration                                     37
LinearFeatureBaseline/ExplainedVariance        0.936051
MaxReturn                                -208340
MinReturn                                -208340
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0454893
ProcessExecTime                                0.00100303
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:40 | [drl] epoch #38 | Obtaining samples...
2020-09-06 22:29:40 | [drl] epoch #38 | Obtaining samples for iteration 38...
2020-09-06 22:29:40 | [drl] epoch #38 | Logging diagnostics...
2020-09-06 22:29:40 | [drl] epoch #38 | Optimizing policy...
2020-09-06 22:29:40 | [drl] epoch #38 | Computing loss before
2020-09-06 22:29:40 | [drl] epoch #38 | Computing KL before
2020-09-06 22:29:40 | [drl] epoch #38 | Optimizing
2020-09-06 22:29:40 | [drl] epoch #38 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:40 | [drl] epoch #38 | computing loss before
2020-09-06 22:29:40 | [drl] epoch #38 | computing gradient
2020-09-06 22:29:41 | [drl] epoch #38 | gradient computed
2020-09-06 22:29:41 | [drl] epoch #38 | computing descent direction
2020-09-06 22:29:41 | [drl] epoch #38 | descent direction computed
2020-09-06 22:29:41 | [drl] epoch #38 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:41 | [drl] epoch #38 | Violated because loss is NaN
2020-09-06 22:29:41 | [drl] epoch #38 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:41 | [drl] epoch #38 | backtrack iters: 14
2020-09-06 22:29:41 | [drl] epoch #38 | optimization finished
2020-09-06 22:29:41 | [drl] epoch #38 | Computing KL after
2020-09-06 22:29:41 | [drl] epoch #38 | Computing loss after
2020-09-06 22:29:41 | [drl] epoch #38 | Fitting baseline...
2020-09-06 22:29:41 | [drl] epoch #38 | Saving snapshot...
2020-09-06 22:29:41 | [drl] epoch #38 | Saved
2020-09-06 22:29:41 | [drl] epoch #38 | Time 49.32 s
2020-09-06 22:29:41 | [drl] epoch #38 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -182617
AverageReturn                            -298590
Entropy                                        8.51363
EnvExecTime                                    0.0391061
Extras/EpisodeRewardMean                 -203931
Iteration                                     38
LinearFeatureBaseline/ExplainedVariance        0.907401
MaxReturn                                -298590
MinReturn                                -298590
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0548189
ProcessExecTime                                0.000964165
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:41 | [drl] epoch #39 | Obtaining samples...
2020-09-06 22:29:41 | [drl] epoch #39 | Obtaining samples for iteration 39...
2020-09-06 22:29:41 | [drl] epoch #39 | Logging diagnostics...
2020-09-06 22:29:41 | [drl] epoch #39 | Optimizing policy...
2020-09-06 22:29:41 | [drl] epoch #39 | Computing loss before
2020-09-06 22:29:41 | [drl] epoch #39 | Computing KL before
2020-09-06 22:29:41 | [drl] epoch #39 | Optimizing
2020-09-06 22:29:41 | [drl] epoch #39 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:41 | [drl] epoch #39 | computing loss before
2020-09-06 22:29:41 | [drl] epoch #39 | computing gradient
2020-09-06 22:29:41 | [drl] epoch #39 | gradient computed
2020-09-06 22:29:41 | [drl] epoch #39 | computing descent direction
2020-09-06 22:29:42 | [drl] epoch #39 | descent direction computed
2020-09-06 22:29:42 | [drl] epoch #39 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:42 | [drl] epoch #39 | Violated because loss is NaN
2020-09-06 22:29:42 | [drl] epoch #39 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:42 | [drl] epoch #39 | backtrack iters: 14
2020-09-06 22:29:42 | [drl] epoch #39 | optimization finished
2020-09-06 22:29:42 | [drl] epoch #39 | Computing KL after
2020-09-06 22:29:42 | [drl] epoch #39 | Computing loss after
2020-09-06 22:29:42 | [drl] epoch #39 | Fitting baseline...
2020-09-06 22:29:42 | [drl] epoch #39 | Saving snapshot...
2020-09-06 22:29:42 | [drl] epoch #39 | Saved
2020-09-06 22:29:42 | [drl] epoch #39 | Time 50.25 s
2020-09-06 22:29:42 | [drl] epoch #39 | EpochTime 0.92 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -94049.3
AverageReturn                            -153662
Entropy                                        8.51363
EnvExecTime                                    0.0548074
Extras/EpisodeRewardMean                 -202674
Iteration                                     39
LinearFeatureBaseline/ExplainedVariance        0.0829904
MaxReturn                                -153662
MinReturn                                -153662
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.05638
ProcessExecTime                                0.0012753
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:29:42 | [drl] epoch #40 | Obtaining samples...
2020-09-06 22:29:42 | [drl] epoch #40 | Obtaining samples for iteration 40...
2020-09-06 22:29:42 | [drl] epoch #40 | Logging diagnostics...
2020-09-06 22:29:42 | [drl] epoch #40 | Optimizing policy...
2020-09-06 22:29:42 | [drl] epoch #40 | Computing loss before
2020-09-06 22:29:42 | [drl] epoch #40 | Computing KL before
2020-09-06 22:29:42 | [drl] epoch #40 | Optimizing
2020-09-06 22:29:42 | [drl] epoch #40 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:42 | [drl] epoch #40 | computing loss before
2020-09-06 22:29:42 | [drl] epoch #40 | computing gradient
2020-09-06 22:29:42 | [drl] epoch #40 | gradient computed
2020-09-06 22:29:42 | [drl] epoch #40 | computing descent direction
2020-09-06 22:29:43 | [drl] epoch #40 | descent direction computed
2020-09-06 22:29:43 | [drl] epoch #40 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:43 | [drl] epoch #40 | Violated because loss is NaN
2020-09-06 22:29:43 | [drl] epoch #40 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:43 | [drl] epoch #40 | backtrack iters: 14
2020-09-06 22:29:43 | [drl] epoch #40 | optimization finished
2020-09-06 22:29:43 | [drl] epoch #40 | Computing KL after
2020-09-06 22:29:43 | [drl] epoch #40 | Computing loss after
2020-09-06 22:29:43 | [drl] epoch #40 | Fitting baseline...
2020-09-06 22:29:43 | [drl] epoch #40 | Saving snapshot...
2020-09-06 22:29:43 | [drl] epoch #40 | Saved
2020-09-06 22:29:43 | [drl] epoch #40 | Time 51.01 s
2020-09-06 22:29:43 | [drl] epoch #40 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -175642
AverageReturn                            -287175
Entropy                                        8.51363
EnvExecTime                                    0.034611
Extras/EpisodeRewardMean                 -204735
Iteration                                     40
LinearFeatureBaseline/ExplainedVariance        0.780284
MaxReturn                                -287175
MinReturn                                -287175
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0435417
ProcessExecTime                                0.000975609
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:43 | [drl] epoch #41 | Obtaining samples...
2020-09-06 22:29:43 | [drl] epoch #41 | Obtaining samples for iteration 41...
2020-09-06 22:29:43 | [drl] epoch #41 | Logging diagnostics...
2020-09-06 22:29:43 | [drl] epoch #41 | Optimizing policy...
2020-09-06 22:29:43 | [drl] epoch #41 | Computing loss before
2020-09-06 22:29:43 | [drl] epoch #41 | Computing KL before
2020-09-06 22:29:43 | [drl] epoch #41 | Optimizing
2020-09-06 22:29:43 | [drl] epoch #41 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:43 | [drl] epoch #41 | computing loss before
2020-09-06 22:29:43 | [drl] epoch #41 | computing gradient
2020-09-06 22:29:43 | [drl] epoch #41 | gradient computed
2020-09-06 22:29:43 | [drl] epoch #41 | computing descent direction
2020-09-06 22:29:43 | [drl] epoch #41 | descent direction computed
2020-09-06 22:29:44 | [drl] epoch #41 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:44 | [drl] epoch #41 | Violated because loss is NaN
2020-09-06 22:29:44 | [drl] epoch #41 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:44 | [drl] epoch #41 | backtrack iters: 14
2020-09-06 22:29:44 | [drl] epoch #41 | optimization finished
2020-09-06 22:29:44 | [drl] epoch #41 | Computing KL after
2020-09-06 22:29:44 | [drl] epoch #41 | Computing loss after
2020-09-06 22:29:44 | [drl] epoch #41 | Fitting baseline...
2020-09-06 22:29:44 | [drl] epoch #41 | Saving snapshot...
2020-09-06 22:29:44 | [drl] epoch #41 | Saved
2020-09-06 22:29:44 | [drl] epoch #41 | Time 51.79 s
2020-09-06 22:29:44 | [drl] epoch #41 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -157949
AverageReturn                            -258225
Entropy                                        8.51363
EnvExecTime                                    0.0352619
Extras/EpisodeRewardMean                 -206009
Iteration                                     41
LinearFeatureBaseline/ExplainedVariance        0.987174
MaxReturn                                -258225
MinReturn                                -258225
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0446336
ProcessExecTime                                0.00100374
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:44 | [drl] epoch #42 | Obtaining samples...
2020-09-06 22:29:44 | [drl] epoch #42 | Obtaining samples for iteration 42...
2020-09-06 22:29:44 | [drl] epoch #42 | Logging diagnostics...
2020-09-06 22:29:44 | [drl] epoch #42 | Optimizing policy...
2020-09-06 22:29:44 | [drl] epoch #42 | Computing loss before
2020-09-06 22:29:44 | [drl] epoch #42 | Computing KL before
2020-09-06 22:29:44 | [drl] epoch #42 | Optimizing
2020-09-06 22:29:44 | [drl] epoch #42 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:44 | [drl] epoch #42 | computing loss before
2020-09-06 22:29:44 | [drl] epoch #42 | computing gradient
2020-09-06 22:29:44 | [drl] epoch #42 | gradient computed
2020-09-06 22:29:44 | [drl] epoch #42 | computing descent direction
2020-09-06 22:29:44 | [drl] epoch #42 | descent direction computed
2020-09-06 22:29:44 | [drl] epoch #42 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:44 | [drl] epoch #42 | Violated because loss is NaN
2020-09-06 22:29:44 | [drl] epoch #42 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:44 | [drl] epoch #42 | backtrack iters: 14
2020-09-06 22:29:44 | [drl] epoch #42 | optimization finished
2020-09-06 22:29:44 | [drl] epoch #42 | Computing KL after
2020-09-06 22:29:44 | [drl] epoch #42 | Computing loss after
2020-09-06 22:29:44 | [drl] epoch #42 | Fitting baseline...
2020-09-06 22:29:44 | [drl] epoch #42 | Saving snapshot...
2020-09-06 22:29:44 | [drl] epoch #42 | Saved
2020-09-06 22:29:44 | [drl] epoch #42 | Time 52.57 s
2020-09-06 22:29:44 | [drl] epoch #42 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -93356.8
AverageReturn                            -152530
Entropy                                        8.51363
EnvExecTime                                    0.0320373
Extras/EpisodeRewardMean                 -204765
Iteration                                     42
LinearFeatureBaseline/ExplainedVariance        0.50533
MaxReturn                                -152530
MinReturn                                -152530
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0607359
ProcessExecTime                                0.00121379
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:44 | [drl] epoch #43 | Obtaining samples...
2020-09-06 22:29:44 | [drl] epoch #43 | Obtaining samples for iteration 43...
2020-09-06 22:29:44 | [drl] epoch #43 | Logging diagnostics...
2020-09-06 22:29:44 | [drl] epoch #43 | Optimizing policy...
2020-09-06 22:29:44 | [drl] epoch #43 | Computing loss before
2020-09-06 22:29:44 | [drl] epoch #43 | Computing KL before
2020-09-06 22:29:44 | [drl] epoch #43 | Optimizing
2020-09-06 22:29:44 | [drl] epoch #43 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:44 | [drl] epoch #43 | computing loss before
2020-09-06 22:29:44 | [drl] epoch #43 | computing gradient
2020-09-06 22:29:45 | [drl] epoch #43 | gradient computed
2020-09-06 22:29:45 | [drl] epoch #43 | computing descent direction
2020-09-06 22:29:45 | [drl] epoch #43 | descent direction computed
2020-09-06 22:29:45 | [drl] epoch #43 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:45 | [drl] epoch #43 | Violated because loss is NaN
2020-09-06 22:29:45 | [drl] epoch #43 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:45 | [drl] epoch #43 | backtrack iters: 14
2020-09-06 22:29:45 | [drl] epoch #43 | optimization finished
2020-09-06 22:29:45 | [drl] epoch #43 | Computing KL after
2020-09-06 22:29:45 | [drl] epoch #43 | Computing loss after
2020-09-06 22:29:45 | [drl] epoch #43 | Fitting baseline...
2020-09-06 22:29:45 | [drl] epoch #43 | Saving snapshot...
2020-09-06 22:29:45 | [drl] epoch #43 | Saved
2020-09-06 22:29:45 | [drl] epoch #43 | Time 53.32 s
2020-09-06 22:29:45 | [drl] epoch #43 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -174311
AverageReturn                            -285009
Entropy                                        8.51363
EnvExecTime                                    0.0328372
Extras/EpisodeRewardMean                 -206589
Iteration                                     43
LinearFeatureBaseline/ExplainedVariance        0.780239
MaxReturn                                -285009
MinReturn                                -285009
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0609171
ProcessExecTime                                0.000980854
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:45 | [drl] epoch #44 | Obtaining samples...
2020-09-06 22:29:45 | [drl] epoch #44 | Obtaining samples for iteration 44...
2020-09-06 22:29:45 | [drl] epoch #44 | Logging diagnostics...
2020-09-06 22:29:45 | [drl] epoch #44 | Optimizing policy...
2020-09-06 22:29:45 | [drl] epoch #44 | Computing loss before
2020-09-06 22:29:45 | [drl] epoch #44 | Computing KL before
2020-09-06 22:29:45 | [drl] epoch #44 | Optimizing
2020-09-06 22:29:45 | [drl] epoch #44 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:45 | [drl] epoch #44 | computing loss before
2020-09-06 22:29:45 | [drl] epoch #44 | computing gradient
2020-09-06 22:29:45 | [drl] epoch #44 | gradient computed
2020-09-06 22:29:45 | [drl] epoch #44 | computing descent direction
2020-09-06 22:29:46 | [drl] epoch #44 | descent direction computed
2020-09-06 22:29:46 | [drl] epoch #44 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:46 | [drl] epoch #44 | Violated because loss is NaN
2020-09-06 22:29:46 | [drl] epoch #44 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:46 | [drl] epoch #44 | backtrack iters: 14
2020-09-06 22:29:46 | [drl] epoch #44 | optimization finished
2020-09-06 22:29:46 | [drl] epoch #44 | Computing KL after
2020-09-06 22:29:46 | [drl] epoch #44 | Computing loss after
2020-09-06 22:29:46 | [drl] epoch #44 | Fitting baseline...
2020-09-06 22:29:46 | [drl] epoch #44 | Saving snapshot...
2020-09-06 22:29:46 | [drl] epoch #44 | Saved
2020-09-06 22:29:46 | [drl] epoch #44 | Time 54.09 s
2020-09-06 22:29:46 | [drl] epoch #44 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -174310
AverageReturn                            -284997
Entropy                                        8.51363
EnvExecTime                                    0.0357881
Extras/EpisodeRewardMean                 -208331
Iteration                                     44
LinearFeatureBaseline/ExplainedVariance        1
MaxReturn                                -284997
MinReturn                                -284997
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0458653
ProcessExecTime                                0.00100636
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:46 | [drl] epoch #45 | Obtaining samples...
2020-09-06 22:29:46 | [drl] epoch #45 | Obtaining samples for iteration 45...
2020-09-06 22:29:46 | [drl] epoch #45 | Logging diagnostics...
2020-09-06 22:29:46 | [drl] epoch #45 | Optimizing policy...
2020-09-06 22:29:46 | [drl] epoch #45 | Computing loss before
2020-09-06 22:29:46 | [drl] epoch #45 | Computing KL before
2020-09-06 22:29:46 | [drl] epoch #45 | Optimizing
2020-09-06 22:29:46 | [drl] epoch #45 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:46 | [drl] epoch #45 | computing loss before
2020-09-06 22:29:46 | [drl] epoch #45 | computing gradient
2020-09-06 22:29:46 | [drl] epoch #45 | gradient computed
2020-09-06 22:29:46 | [drl] epoch #45 | computing descent direction
2020-09-06 22:29:47 | [drl] epoch #45 | descent direction computed
2020-09-06 22:29:47 | [drl] epoch #45 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:47 | [drl] epoch #45 | Violated because loss is NaN
2020-09-06 22:29:47 | [drl] epoch #45 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:47 | [drl] epoch #45 | backtrack iters: 14
2020-09-06 22:29:47 | [drl] epoch #45 | optimization finished
2020-09-06 22:29:47 | [drl] epoch #45 | Computing KL after
2020-09-06 22:29:47 | [drl] epoch #45 | Computing loss after
2020-09-06 22:29:47 | [drl] epoch #45 | Fitting baseline...
2020-09-06 22:29:47 | [drl] epoch #45 | Saving snapshot...
2020-09-06 22:29:47 | [drl] epoch #45 | Saved
2020-09-06 22:29:47 | [drl] epoch #45 | Time 54.85 s
2020-09-06 22:29:47 | [drl] epoch #45 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -77151.7
AverageReturn                            -126014
Entropy                                        8.51363
EnvExecTime                                    0.03461
Extras/EpisodeRewardMean                 -206542
Iteration                                     45
LinearFeatureBaseline/ExplainedVariance       -0.651504
MaxReturn                                -126014
MinReturn                                -126014
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0473375
ProcessExecTime                                0.00120306
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:47 | [drl] epoch #46 | Obtaining samples...
2020-09-06 22:29:47 | [drl] epoch #46 | Obtaining samples for iteration 46...
2020-09-06 22:29:47 | [drl] epoch #46 | Logging diagnostics...
2020-09-06 22:29:47 | [drl] epoch #46 | Optimizing policy...
2020-09-06 22:29:47 | [drl] epoch #46 | Computing loss before
2020-09-06 22:29:47 | [drl] epoch #46 | Computing KL before
2020-09-06 22:29:47 | [drl] epoch #46 | Optimizing
2020-09-06 22:29:47 | [drl] epoch #46 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:47 | [drl] epoch #46 | computing loss before
2020-09-06 22:29:47 | [drl] epoch #46 | computing gradient
2020-09-06 22:29:47 | [drl] epoch #46 | gradient computed
2020-09-06 22:29:47 | [drl] epoch #46 | computing descent direction
2020-09-06 22:29:47 | [drl] epoch #46 | descent direction computed
2020-09-06 22:29:47 | [drl] epoch #46 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:47 | [drl] epoch #46 | Violated because loss is NaN
2020-09-06 22:29:47 | [drl] epoch #46 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:47 | [drl] epoch #46 | backtrack iters: 14
2020-09-06 22:29:47 | [drl] epoch #46 | optimization finished
2020-09-06 22:29:47 | [drl] epoch #46 | Computing KL after
2020-09-06 22:29:47 | [drl] epoch #46 | Computing loss after
2020-09-06 22:29:47 | [drl] epoch #46 | Fitting baseline...
2020-09-06 22:29:47 | [drl] epoch #46 | Saving snapshot...
2020-09-06 22:29:47 | [drl] epoch #46 | Saved
2020-09-06 22:29:47 | [drl] epoch #46 | Time 55.61 s
2020-09-06 22:29:47 | [drl] epoch #46 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -165927
AverageReturn                            -271277
Entropy                                        8.51363
EnvExecTime                                    0.0327594
Extras/EpisodeRewardMean                 -207919
Iteration                                     46
LinearFeatureBaseline/ExplainedVariance        0.708287
MaxReturn                                -271277
MinReturn                                -271277
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0544605
ProcessExecTime                                0.00243044
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:47 | [drl] epoch #47 | Obtaining samples...
2020-09-06 22:29:47 | [drl] epoch #47 | Obtaining samples for iteration 47...
2020-09-06 22:29:48 | [drl] epoch #47 | Logging diagnostics...
2020-09-06 22:29:48 | [drl] epoch #47 | Optimizing policy...
2020-09-06 22:29:48 | [drl] epoch #47 | Computing loss before
2020-09-06 22:29:48 | [drl] epoch #47 | Computing KL before
2020-09-06 22:29:48 | [drl] epoch #47 | Optimizing
2020-09-06 22:29:48 | [drl] epoch #47 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:48 | [drl] epoch #47 | computing loss before
2020-09-06 22:29:48 | [drl] epoch #47 | computing gradient
2020-09-06 22:29:48 | [drl] epoch #47 | gradient computed
2020-09-06 22:29:48 | [drl] epoch #47 | computing descent direction
2020-09-06 22:29:48 | [drl] epoch #47 | descent direction computed
2020-09-06 22:29:48 | [drl] epoch #47 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:48 | [drl] epoch #47 | Violated because loss is NaN
2020-09-06 22:29:48 | [drl] epoch #47 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:48 | [drl] epoch #47 | backtrack iters: 14
2020-09-06 22:29:48 | [drl] epoch #47 | optimization finished
2020-09-06 22:29:48 | [drl] epoch #47 | Computing KL after
2020-09-06 22:29:48 | [drl] epoch #47 | Computing loss after
2020-09-06 22:29:48 | [drl] epoch #47 | Fitting baseline...
2020-09-06 22:29:48 | [drl] epoch #47 | Saving snapshot...
2020-09-06 22:29:48 | [drl] epoch #47 | Saved
2020-09-06 22:29:48 | [drl] epoch #47 | Time 56.37 s
2020-09-06 22:29:48 | [drl] epoch #47 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -85876.8
AverageReturn                            -140289
Entropy                                        8.51363
EnvExecTime                                    0.0405226
Extras/EpisodeRewardMean                 -206510
Iteration                                     47
LinearFeatureBaseline/ExplainedVariance        0.097853
MaxReturn                                -140289
MinReturn                                -140289
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0450008
ProcessExecTime                                0.000945807
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:48 | [drl] epoch #48 | Obtaining samples...
2020-09-06 22:29:48 | [drl] epoch #48 | Obtaining samples for iteration 48...
2020-09-06 22:29:48 | [drl] epoch #48 | Logging diagnostics...
2020-09-06 22:29:48 | [drl] epoch #48 | Optimizing policy...
2020-09-06 22:29:48 | [drl] epoch #48 | Computing loss before
2020-09-06 22:29:48 | [drl] epoch #48 | Computing KL before
2020-09-06 22:29:48 | [drl] epoch #48 | Optimizing
2020-09-06 22:29:48 | [drl] epoch #48 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:48 | [drl] epoch #48 | computing loss before
2020-09-06 22:29:48 | [drl] epoch #48 | computing gradient
2020-09-06 22:29:48 | [drl] epoch #48 | gradient computed
2020-09-06 22:29:48 | [drl] epoch #48 | computing descent direction
2020-09-06 22:29:49 | [drl] epoch #48 | descent direction computed
2020-09-06 22:29:49 | [drl] epoch #48 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:49 | [drl] epoch #48 | Violated because loss is NaN
2020-09-06 22:29:49 | [drl] epoch #48 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:49 | [drl] epoch #48 | backtrack iters: 14
2020-09-06 22:29:49 | [drl] epoch #48 | optimization finished
2020-09-06 22:29:49 | [drl] epoch #48 | Computing KL after
2020-09-06 22:29:49 | [drl] epoch #48 | Computing loss after
2020-09-06 22:29:49 | [drl] epoch #48 | Fitting baseline...
2020-09-06 22:29:49 | [drl] epoch #48 | Saving snapshot...
2020-09-06 22:29:49 | [drl] epoch #48 | Saved
2020-09-06 22:29:49 | [drl] epoch #48 | Time 57.13 s
2020-09-06 22:29:49 | [drl] epoch #48 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -177630
AverageReturn                            -290441
Entropy                                        8.51363
EnvExecTime                                    0.0355594
Extras/EpisodeRewardMean                 -208223
Iteration                                     48
LinearFeatureBaseline/ExplainedVariance        0.72819
MaxReturn                                -290441
MinReturn                                -290441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0442913
ProcessExecTime                                0.00100899
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:49 | [drl] epoch #49 | Obtaining samples...
2020-09-06 22:29:49 | [drl] epoch #49 | Obtaining samples for iteration 49...
2020-09-06 22:29:49 | [drl] epoch #49 | Logging diagnostics...
2020-09-06 22:29:49 | [drl] epoch #49 | Optimizing policy...
2020-09-06 22:29:49 | [drl] epoch #49 | Computing loss before
2020-09-06 22:29:49 | [drl] epoch #49 | Computing KL before
2020-09-06 22:29:49 | [drl] epoch #49 | Optimizing
2020-09-06 22:29:49 | [drl] epoch #49 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:49 | [drl] epoch #49 | computing loss before
2020-09-06 22:29:49 | [drl] epoch #49 | computing gradient
2020-09-06 22:29:49 | [drl] epoch #49 | gradient computed
2020-09-06 22:29:49 | [drl] epoch #49 | computing descent direction
2020-09-06 22:29:50 | [drl] epoch #49 | descent direction computed
2020-09-06 22:29:50 | [drl] epoch #49 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:50 | [drl] epoch #49 | Violated because loss is NaN
2020-09-06 22:29:50 | [drl] epoch #49 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:50 | [drl] epoch #49 | backtrack iters: 14
2020-09-06 22:29:50 | [drl] epoch #49 | optimization finished
2020-09-06 22:29:50 | [drl] epoch #49 | Computing KL after
2020-09-06 22:29:50 | [drl] epoch #49 | Computing loss after
2020-09-06 22:29:50 | [drl] epoch #49 | Fitting baseline...
2020-09-06 22:29:50 | [drl] epoch #49 | Saving snapshot...
2020-09-06 22:29:50 | [drl] epoch #49 | Saved
2020-09-06 22:29:50 | [drl] epoch #49 | Time 57.89 s
2020-09-06 22:29:50 | [drl] epoch #49 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93604.7
AverageReturn                            -152935
Entropy                                        8.51363
EnvExecTime                                    0.0342524
Extras/EpisodeRewardMean                 -207117
Iteration                                     49
LinearFeatureBaseline/ExplainedVariance        0.165185
MaxReturn                                -152935
MinReturn                                -152935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0486171
ProcessExecTime                                0.000938654
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:50 | [drl] epoch #50 | Obtaining samples...
2020-09-06 22:29:50 | [drl] epoch #50 | Obtaining samples for iteration 50...
2020-09-06 22:29:50 | [drl] epoch #50 | Logging diagnostics...
2020-09-06 22:29:50 | [drl] epoch #50 | Optimizing policy...
2020-09-06 22:29:50 | [drl] epoch #50 | Computing loss before
2020-09-06 22:29:50 | [drl] epoch #50 | Computing KL before
2020-09-06 22:29:50 | [drl] epoch #50 | Optimizing
2020-09-06 22:29:50 | [drl] epoch #50 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:50 | [drl] epoch #50 | computing loss before
2020-09-06 22:29:50 | [drl] epoch #50 | computing gradient
2020-09-06 22:29:50 | [drl] epoch #50 | gradient computed
2020-09-06 22:29:50 | [drl] epoch #50 | computing descent direction
2020-09-06 22:29:50 | [drl] epoch #50 | descent direction computed
2020-09-06 22:29:50 | [drl] epoch #50 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:50 | [drl] epoch #50 | Violated because loss is NaN
2020-09-06 22:29:50 | [drl] epoch #50 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:50 | [drl] epoch #50 | backtrack iters: 14
2020-09-06 22:29:50 | [drl] epoch #50 | optimization finished
2020-09-06 22:29:50 | [drl] epoch #50 | Computing KL after
2020-09-06 22:29:50 | [drl] epoch #50 | Computing loss after
2020-09-06 22:29:50 | [drl] epoch #50 | Fitting baseline...
2020-09-06 22:29:50 | [drl] epoch #50 | Saving snapshot...
2020-09-06 22:29:50 | [drl] epoch #50 | Saved
2020-09-06 22:29:50 | [drl] epoch #50 | Time 58.66 s
2020-09-06 22:29:50 | [drl] epoch #50 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -128502
AverageReturn                            -210039
Entropy                                        8.51363
EnvExecTime                                    0.0359261
Extras/EpisodeRewardMean                 -207175
Iteration                                     50
LinearFeatureBaseline/ExplainedVariance        0.924474
MaxReturn                                -210039
MinReturn                                -210039
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0574131
ProcessExecTime                                0.000937223
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:50 | [drl] epoch #51 | Obtaining samples...
2020-09-06 22:29:50 | [drl] epoch #51 | Obtaining samples for iteration 51...
2020-09-06 22:29:51 | [drl] epoch #51 | Logging diagnostics...
2020-09-06 22:29:51 | [drl] epoch #51 | Optimizing policy...
2020-09-06 22:29:51 | [drl] epoch #51 | Computing loss before
2020-09-06 22:29:51 | [drl] epoch #51 | Computing KL before
2020-09-06 22:29:51 | [drl] epoch #51 | Optimizing
2020-09-06 22:29:51 | [drl] epoch #51 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:51 | [drl] epoch #51 | computing loss before
2020-09-06 22:29:51 | [drl] epoch #51 | computing gradient
2020-09-06 22:29:51 | [drl] epoch #51 | gradient computed
2020-09-06 22:29:51 | [drl] epoch #51 | computing descent direction
2020-09-06 22:29:51 | [drl] epoch #51 | descent direction computed
2020-09-06 22:29:51 | [drl] epoch #51 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:51 | [drl] epoch #51 | Violated because loss is NaN
2020-09-06 22:29:51 | [drl] epoch #51 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:51 | [drl] epoch #51 | backtrack iters: 14
2020-09-06 22:29:51 | [drl] epoch #51 | optimization finished
2020-09-06 22:29:51 | [drl] epoch #51 | Computing KL after
2020-09-06 22:29:51 | [drl] epoch #51 | Computing loss after
2020-09-06 22:29:51 | [drl] epoch #51 | Fitting baseline...
2020-09-06 22:29:51 | [drl] epoch #51 | Saving snapshot...
2020-09-06 22:29:51 | [drl] epoch #51 | Saved
2020-09-06 22:29:51 | [drl] epoch #51 | Time 59.43 s
2020-09-06 22:29:51 | [drl] epoch #51 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -137705
AverageReturn                            -225111
Entropy                                        8.51363
EnvExecTime                                    0.0397334
Extras/EpisodeRewardMean                 -207519
Iteration                                     51
LinearFeatureBaseline/ExplainedVariance        0.995334
MaxReturn                                -225111
MinReturn                                -225111
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0510237
ProcessExecTime                                0.00097847
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:51 | [drl] epoch #52 | Obtaining samples...
2020-09-06 22:29:51 | [drl] epoch #52 | Obtaining samples for iteration 52...
2020-09-06 22:29:51 | [drl] epoch #52 | Logging diagnostics...
2020-09-06 22:29:51 | [drl] epoch #52 | Optimizing policy...
2020-09-06 22:29:51 | [drl] epoch #52 | Computing loss before
2020-09-06 22:29:51 | [drl] epoch #52 | Computing KL before
2020-09-06 22:29:51 | [drl] epoch #52 | Optimizing
2020-09-06 22:29:51 | [drl] epoch #52 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:51 | [drl] epoch #52 | computing loss before
2020-09-06 22:29:51 | [drl] epoch #52 | computing gradient
2020-09-06 22:29:51 | [drl] epoch #52 | gradient computed
2020-09-06 22:29:51 | [drl] epoch #52 | computing descent direction
2020-09-06 22:29:52 | [drl] epoch #52 | descent direction computed
2020-09-06 22:29:52 | [drl] epoch #52 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:52 | [drl] epoch #52 | Violated because loss is NaN
2020-09-06 22:29:52 | [drl] epoch #52 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:52 | [drl] epoch #52 | backtrack iters: 14
2020-09-06 22:29:52 | [drl] epoch #52 | optimization finished
2020-09-06 22:29:52 | [drl] epoch #52 | Computing KL after
2020-09-06 22:29:52 | [drl] epoch #52 | Computing loss after
2020-09-06 22:29:52 | [drl] epoch #52 | Fitting baseline...
2020-09-06 22:29:52 | [drl] epoch #52 | Saving snapshot...
2020-09-06 22:29:52 | [drl] epoch #52 | Saved
2020-09-06 22:29:52 | [drl] epoch #52 | Time 60.19 s
2020-09-06 22:29:52 | [drl] epoch #52 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -94635.8
AverageReturn                            -154637
Entropy                                        8.51363
EnvExecTime                                    0.0376699
Extras/EpisodeRewardMean                 -206522
Iteration                                     52
LinearFeatureBaseline/ExplainedVariance        0.785821
MaxReturn                                -154637
MinReturn                                -154637
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0454569
ProcessExecTime                                0.00118589
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:52 | [drl] epoch #53 | Obtaining samples...
2020-09-06 22:29:52 | [drl] epoch #53 | Obtaining samples for iteration 53...
2020-09-06 22:29:52 | [drl] epoch #53 | Logging diagnostics...
2020-09-06 22:29:52 | [drl] epoch #53 | Optimizing policy...
2020-09-06 22:29:52 | [drl] epoch #53 | Computing loss before
2020-09-06 22:29:52 | [drl] epoch #53 | Computing KL before
2020-09-06 22:29:52 | [drl] epoch #53 | Optimizing
2020-09-06 22:29:52 | [drl] epoch #53 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:52 | [drl] epoch #53 | computing loss before
2020-09-06 22:29:52 | [drl] epoch #53 | computing gradient
2020-09-06 22:29:52 | [drl] epoch #53 | gradient computed
2020-09-06 22:29:52 | [drl] epoch #53 | computing descent direction
2020-09-06 22:29:53 | [drl] epoch #53 | descent direction computed
2020-09-06 22:29:53 | [drl] epoch #53 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:53 | [drl] epoch #53 | Violated because loss is NaN
2020-09-06 22:29:53 | [drl] epoch #53 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:53 | [drl] epoch #53 | backtrack iters: 14
2020-09-06 22:29:53 | [drl] epoch #53 | optimization finished
2020-09-06 22:29:53 | [drl] epoch #53 | Computing KL after
2020-09-06 22:29:53 | [drl] epoch #53 | Computing loss after
2020-09-06 22:29:53 | [drl] epoch #53 | Fitting baseline...
2020-09-06 22:29:53 | [drl] epoch #53 | Saving snapshot...
2020-09-06 22:29:53 | [drl] epoch #53 | Saved
2020-09-06 22:29:53 | [drl] epoch #53 | Time 60.95 s
2020-09-06 22:29:53 | [drl] epoch #53 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -96025.6
AverageReturn                            -156887
Entropy                                        8.51363
EnvExecTime                                    0.0415711
Extras/EpisodeRewardMean                 -205603
Iteration                                     53
LinearFeatureBaseline/ExplainedVariance        0.999817
MaxReturn                                -156887
MinReturn                                -156887
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0444677
ProcessExecTime                                0.00100017
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:53 | [drl] epoch #54 | Obtaining samples...
2020-09-06 22:29:53 | [drl] epoch #54 | Obtaining samples for iteration 54...
2020-09-06 22:29:53 | [drl] epoch #54 | Logging diagnostics...
2020-09-06 22:29:53 | [drl] epoch #54 | Optimizing policy...
2020-09-06 22:29:53 | [drl] epoch #54 | Computing loss before
2020-09-06 22:29:53 | [drl] epoch #54 | Computing KL before
2020-09-06 22:29:53 | [drl] epoch #54 | Optimizing
2020-09-06 22:29:53 | [drl] epoch #54 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:53 | [drl] epoch #54 | computing loss before
2020-09-06 22:29:53 | [drl] epoch #54 | computing gradient
2020-09-06 22:29:53 | [drl] epoch #54 | gradient computed
2020-09-06 22:29:53 | [drl] epoch #54 | computing descent direction
2020-09-06 22:29:53 | [drl] epoch #54 | descent direction computed
2020-09-06 22:29:53 | [drl] epoch #54 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:53 | [drl] epoch #54 | Violated because loss is NaN
2020-09-06 22:29:53 | [drl] epoch #54 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:53 | [drl] epoch #54 | backtrack iters: 14
2020-09-06 22:29:53 | [drl] epoch #54 | optimization finished
2020-09-06 22:29:53 | [drl] epoch #54 | Computing KL after
2020-09-06 22:29:53 | [drl] epoch #54 | Computing loss after
2020-09-06 22:29:53 | [drl] epoch #54 | Fitting baseline...
2020-09-06 22:29:53 | [drl] epoch #54 | Saving snapshot...
2020-09-06 22:29:53 | [drl] epoch #54 | Saved
2020-09-06 22:29:54 | [drl] epoch #54 | Time 61.71 s
2020-09-06 22:29:54 | [drl] epoch #54 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -94380.9
AverageReturn                            -154213
Entropy                                        8.51363
EnvExecTime                                    0.0415032
Extras/EpisodeRewardMean                 -204668
Iteration                                     54
LinearFeatureBaseline/ExplainedVariance        0.999722
MaxReturn                                -154213
MinReturn                                -154213
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0478499
ProcessExecTime                                0.00100732
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:54 | [drl] epoch #55 | Obtaining samples...
2020-09-06 22:29:54 | [drl] epoch #55 | Obtaining samples for iteration 55...
2020-09-06 22:29:54 | [drl] epoch #55 | Logging diagnostics...
2020-09-06 22:29:54 | [drl] epoch #55 | Optimizing policy...
2020-09-06 22:29:54 | [drl] epoch #55 | Computing loss before
2020-09-06 22:29:54 | [drl] epoch #55 | Computing KL before
2020-09-06 22:29:54 | [drl] epoch #55 | Optimizing
2020-09-06 22:29:54 | [drl] epoch #55 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:54 | [drl] epoch #55 | computing loss before
2020-09-06 22:29:54 | [drl] epoch #55 | computing gradient
2020-09-06 22:29:54 | [drl] epoch #55 | gradient computed
2020-09-06 22:29:54 | [drl] epoch #55 | computing descent direction
2020-09-06 22:29:54 | [drl] epoch #55 | descent direction computed
2020-09-06 22:29:54 | [drl] epoch #55 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:54 | [drl] epoch #55 | Violated because loss is NaN
2020-09-06 22:29:54 | [drl] epoch #55 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:54 | [drl] epoch #55 | backtrack iters: 14
2020-09-06 22:29:54 | [drl] epoch #55 | optimization finished
2020-09-06 22:29:54 | [drl] epoch #55 | Computing KL after
2020-09-06 22:29:54 | [drl] epoch #55 | Computing loss after
2020-09-06 22:29:54 | [drl] epoch #55 | Fitting baseline...
2020-09-06 22:29:54 | [drl] epoch #55 | Saving snapshot...
2020-09-06 22:29:54 | [drl] epoch #55 | Saved
2020-09-06 22:29:54 | [drl] epoch #55 | Time 62.47 s
2020-09-06 22:29:54 | [drl] epoch #55 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -102312
AverageReturn                            -167192
Entropy                                        8.51363
EnvExecTime                                    0.0370178
Extras/EpisodeRewardMean                 -203999
Iteration                                     55
LinearFeatureBaseline/ExplainedVariance        0.99385
MaxReturn                                -167192
MinReturn                                -167192
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0498929
ProcessExecTime                                0.00102329
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:54 | [drl] epoch #56 | Obtaining samples...
2020-09-06 22:29:54 | [drl] epoch #56 | Obtaining samples for iteration 56...
2020-09-06 22:29:54 | [drl] epoch #56 | Logging diagnostics...
2020-09-06 22:29:54 | [drl] epoch #56 | Optimizing policy...
2020-09-06 22:29:54 | [drl] epoch #56 | Computing loss before
2020-09-06 22:29:54 | [drl] epoch #56 | Computing KL before
2020-09-06 22:29:54 | [drl] epoch #56 | Optimizing
2020-09-06 22:29:54 | [drl] epoch #56 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:54 | [drl] epoch #56 | computing loss before
2020-09-06 22:29:54 | [drl] epoch #56 | computing gradient
2020-09-06 22:29:54 | [drl] epoch #56 | gradient computed
2020-09-06 22:29:54 | [drl] epoch #56 | computing descent direction
2020-09-06 22:29:55 | [drl] epoch #56 | descent direction computed
2020-09-06 22:29:55 | [drl] epoch #56 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:55 | [drl] epoch #56 | Violated because loss is NaN
2020-09-06 22:29:55 | [drl] epoch #56 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:55 | [drl] epoch #56 | backtrack iters: 14
2020-09-06 22:29:55 | [drl] epoch #56 | optimization finished
2020-09-06 22:29:55 | [drl] epoch #56 | Computing KL after
2020-09-06 22:29:55 | [drl] epoch #56 | Computing loss after
2020-09-06 22:29:55 | [drl] epoch #56 | Fitting baseline...
2020-09-06 22:29:55 | [drl] epoch #56 | Saving snapshot...
2020-09-06 22:29:55 | [drl] epoch #56 | Saved
2020-09-06 22:29:55 | [drl] epoch #56 | Time 63.26 s
2020-09-06 22:29:55 | [drl] epoch #56 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -98891.9
AverageReturn                            -161580
Entropy                                        8.51363
EnvExecTime                                    0.0350926
Extras/EpisodeRewardMean                 -203255
Iteration                                     56
LinearFeatureBaseline/ExplainedVariance        0.998727
MaxReturn                                -161580
MinReturn                                -161580
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0448811
ProcessExecTime                                0.00187945
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:55 | [drl] epoch #57 | Obtaining samples...
2020-09-06 22:29:55 | [drl] epoch #57 | Obtaining samples for iteration 57...
2020-09-06 22:29:55 | [drl] epoch #57 | Logging diagnostics...
2020-09-06 22:29:55 | [drl] epoch #57 | Optimizing policy...
2020-09-06 22:29:55 | [drl] epoch #57 | Computing loss before
2020-09-06 22:29:55 | [drl] epoch #57 | Computing KL before
2020-09-06 22:29:55 | [drl] epoch #57 | Optimizing
2020-09-06 22:29:55 | [drl] epoch #57 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:55 | [drl] epoch #57 | computing loss before
2020-09-06 22:29:55 | [drl] epoch #57 | computing gradient
2020-09-06 22:29:55 | [drl] epoch #57 | gradient computed
2020-09-06 22:29:55 | [drl] epoch #57 | computing descent direction
2020-09-06 22:29:56 | [drl] epoch #57 | descent direction computed
2020-09-06 22:29:56 | [drl] epoch #57 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:56 | [drl] epoch #57 | Violated because loss is NaN
2020-09-06 22:29:56 | [drl] epoch #57 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:56 | [drl] epoch #57 | backtrack iters: 14
2020-09-06 22:29:56 | [drl] epoch #57 | optimization finished
2020-09-06 22:29:56 | [drl] epoch #57 | Computing KL after
2020-09-06 22:29:56 | [drl] epoch #57 | Computing loss after
2020-09-06 22:29:56 | [drl] epoch #57 | Fitting baseline...
2020-09-06 22:29:56 | [drl] epoch #57 | Saving snapshot...
2020-09-06 22:29:56 | [drl] epoch #57 | Saved
2020-09-06 22:29:56 | [drl] epoch #57 | Time 64.02 s
2020-09-06 22:29:56 | [drl] epoch #57 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173259
AverageReturn                            -283275
Entropy                                        8.51363
EnvExecTime                                    0.0392904
Extras/EpisodeRewardMean                 -204634
Iteration                                     57
LinearFeatureBaseline/ExplainedVariance        0.812135
MaxReturn                                -283275
MinReturn                                -283275
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0436127
ProcessExecTime                                0.000965595
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:56 | [drl] epoch #58 | Obtaining samples...
2020-09-06 22:29:56 | [drl] epoch #58 | Obtaining samples for iteration 58...
2020-09-06 22:29:56 | [drl] epoch #58 | Logging diagnostics...
2020-09-06 22:29:56 | [drl] epoch #58 | Optimizing policy...
2020-09-06 22:29:56 | [drl] epoch #58 | Computing loss before
2020-09-06 22:29:56 | [drl] epoch #58 | Computing KL before
2020-09-06 22:29:56 | [drl] epoch #58 | Optimizing
2020-09-06 22:29:56 | [drl] epoch #58 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:56 | [drl] epoch #58 | computing loss before
2020-09-06 22:29:56 | [drl] epoch #58 | computing gradient
2020-09-06 22:29:56 | [drl] epoch #58 | gradient computed
2020-09-06 22:29:56 | [drl] epoch #58 | computing descent direction
2020-09-06 22:29:56 | [drl] epoch #58 | descent direction computed
2020-09-06 22:29:57 | [drl] epoch #58 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:57 | [drl] epoch #58 | Violated because loss is NaN
2020-09-06 22:29:57 | [drl] epoch #58 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:57 | [drl] epoch #58 | backtrack iters: 14
2020-09-06 22:29:57 | [drl] epoch #58 | optimization finished
2020-09-06 22:29:57 | [drl] epoch #58 | Computing KL after
2020-09-06 22:29:57 | [drl] epoch #58 | Computing loss after
2020-09-06 22:29:57 | [drl] epoch #58 | Fitting baseline...
2020-09-06 22:29:57 | [drl] epoch #58 | Saving snapshot...
2020-09-06 22:29:57 | [drl] epoch #58 | Saved
2020-09-06 22:29:57 | [drl] epoch #58 | Time 64.77 s
2020-09-06 22:29:57 | [drl] epoch #58 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106860
AverageReturn                            -174630
Entropy                                        8.51363
EnvExecTime                                    0.0392144
Extras/EpisodeRewardMean                 -204126
Iteration                                     58
LinearFeatureBaseline/ExplainedVariance        0.602093
MaxReturn                                -174630
MinReturn                                -174630
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0489573
ProcessExecTime                                0.000948668
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:57 | [drl] epoch #59 | Obtaining samples...
2020-09-06 22:29:57 | [drl] epoch #59 | Obtaining samples for iteration 59...
2020-09-06 22:29:57 | [drl] epoch #59 | Logging diagnostics...
2020-09-06 22:29:57 | [drl] epoch #59 | Optimizing policy...
2020-09-06 22:29:57 | [drl] epoch #59 | Computing loss before
2020-09-06 22:29:57 | [drl] epoch #59 | Computing KL before
2020-09-06 22:29:57 | [drl] epoch #59 | Optimizing
2020-09-06 22:29:57 | [drl] epoch #59 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:57 | [drl] epoch #59 | computing loss before
2020-09-06 22:29:57 | [drl] epoch #59 | computing gradient
2020-09-06 22:29:57 | [drl] epoch #59 | gradient computed
2020-09-06 22:29:57 | [drl] epoch #59 | computing descent direction
2020-09-06 22:29:57 | [drl] epoch #59 | descent direction computed
2020-09-06 22:29:57 | [drl] epoch #59 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:57 | [drl] epoch #59 | Violated because loss is NaN
2020-09-06 22:29:57 | [drl] epoch #59 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:57 | [drl] epoch #59 | backtrack iters: 14
2020-09-06 22:29:57 | [drl] epoch #59 | optimization finished
2020-09-06 22:29:57 | [drl] epoch #59 | Computing KL after
2020-09-06 22:29:57 | [drl] epoch #59 | Computing loss after
2020-09-06 22:29:57 | [drl] epoch #59 | Fitting baseline...
2020-09-06 22:29:57 | [drl] epoch #59 | Saving snapshot...
2020-09-06 22:29:57 | [drl] epoch #59 | Saved
2020-09-06 22:29:57 | [drl] epoch #59 | Time 65.54 s
2020-09-06 22:29:57 | [drl] epoch #59 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -85407.1
AverageReturn                            -139527
Entropy                                        8.51363
EnvExecTime                                    0.0505705
Extras/EpisodeRewardMean                 -203049
Iteration                                     59
LinearFeatureBaseline/ExplainedVariance        0.93504
MaxReturn                                -139527
MinReturn                                -139527
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0406053
ProcessExecTime                                0.000995636
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:29:57 | [drl] epoch #60 | Obtaining samples...
2020-09-06 22:29:57 | [drl] epoch #60 | Obtaining samples for iteration 60...
2020-09-06 22:29:57 | [drl] epoch #60 | Logging diagnostics...
2020-09-06 22:29:57 | [drl] epoch #60 | Optimizing policy...
2020-09-06 22:29:57 | [drl] epoch #60 | Computing loss before
2020-09-06 22:29:57 | [drl] epoch #60 | Computing KL before
2020-09-06 22:29:57 | [drl] epoch #60 | Optimizing
2020-09-06 22:29:57 | [drl] epoch #60 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:57 | [drl] epoch #60 | computing loss before
2020-09-06 22:29:57 | [drl] epoch #60 | computing gradient
2020-09-06 22:29:58 | [drl] epoch #60 | gradient computed
2020-09-06 22:29:58 | [drl] epoch #60 | computing descent direction
2020-09-06 22:29:58 | [drl] epoch #60 | descent direction computed
2020-09-06 22:29:58 | [drl] epoch #60 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:58 | [drl] epoch #60 | Violated because loss is NaN
2020-09-06 22:29:58 | [drl] epoch #60 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:58 | [drl] epoch #60 | backtrack iters: 14
2020-09-06 22:29:58 | [drl] epoch #60 | optimization finished
2020-09-06 22:29:58 | [drl] epoch #60 | Computing KL after
2020-09-06 22:29:58 | [drl] epoch #60 | Computing loss after
2020-09-06 22:29:58 | [drl] epoch #60 | Fitting baseline...
2020-09-06 22:29:58 | [drl] epoch #60 | Saving snapshot...
2020-09-06 22:29:58 | [drl] epoch #60 | Saved
2020-09-06 22:29:58 | [drl] epoch #60 | Time 66.32 s
2020-09-06 22:29:58 | [drl] epoch #60 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -181040
AverageReturn                            -296004
Entropy                                        8.51363
EnvExecTime                                    0.0435209
Extras/EpisodeRewardMean                 -204573
Iteration                                     60
LinearFeatureBaseline/ExplainedVariance        0.716422
MaxReturn                                -296004
MinReturn                                -296004
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0541668
ProcessExecTime                                0.00303745
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:58 | [drl] epoch #61 | Obtaining samples...
2020-09-06 22:29:58 | [drl] epoch #61 | Obtaining samples for iteration 61...
2020-09-06 22:29:58 | [drl] epoch #61 | Logging diagnostics...
2020-09-06 22:29:58 | [drl] epoch #61 | Optimizing policy...
2020-09-06 22:29:58 | [drl] epoch #61 | Computing loss before
2020-09-06 22:29:58 | [drl] epoch #61 | Computing KL before
2020-09-06 22:29:58 | [drl] epoch #61 | Optimizing
2020-09-06 22:29:58 | [drl] epoch #61 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:58 | [drl] epoch #61 | computing loss before
2020-09-06 22:29:58 | [drl] epoch #61 | computing gradient
2020-09-06 22:29:58 | [drl] epoch #61 | gradient computed
2020-09-06 22:29:58 | [drl] epoch #61 | computing descent direction
2020-09-06 22:29:59 | [drl] epoch #61 | descent direction computed
2020-09-06 22:29:59 | [drl] epoch #61 | Line search condition violated. Rejecting the step!
2020-09-06 22:29:59 | [drl] epoch #61 | Violated because loss is NaN
2020-09-06 22:29:59 | [drl] epoch #61 | Violated because constraint mean_kl is NaN
2020-09-06 22:29:59 | [drl] epoch #61 | backtrack iters: 14
2020-09-06 22:29:59 | [drl] epoch #61 | optimization finished
2020-09-06 22:29:59 | [drl] epoch #61 | Computing KL after
2020-09-06 22:29:59 | [drl] epoch #61 | Computing loss after
2020-09-06 22:29:59 | [drl] epoch #61 | Fitting baseline...
2020-09-06 22:29:59 | [drl] epoch #61 | Saving snapshot...
2020-09-06 22:29:59 | [drl] epoch #61 | Saved
2020-09-06 22:29:59 | [drl] epoch #61 | Time 67.09 s
2020-09-06 22:29:59 | [drl] epoch #61 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -163842
AverageReturn                            -267869
Entropy                                        8.51363
EnvExecTime                                    0.033855
Extras/EpisodeRewardMean                 -205594
Iteration                                     61
LinearFeatureBaseline/ExplainedVariance        0.988761
MaxReturn                                -267869
MinReturn                                -267869
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0499249
ProcessExecTime                                0.00094986
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:29:59 | [drl] epoch #62 | Obtaining samples...
2020-09-06 22:29:59 | [drl] epoch #62 | Obtaining samples for iteration 62...
2020-09-06 22:29:59 | [drl] epoch #62 | Logging diagnostics...
2020-09-06 22:29:59 | [drl] epoch #62 | Optimizing policy...
2020-09-06 22:29:59 | [drl] epoch #62 | Computing loss before
2020-09-06 22:29:59 | [drl] epoch #62 | Computing KL before
2020-09-06 22:29:59 | [drl] epoch #62 | Optimizing
2020-09-06 22:29:59 | [drl] epoch #62 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:29:59 | [drl] epoch #62 | computing loss before
2020-09-06 22:29:59 | [drl] epoch #62 | computing gradient
2020-09-06 22:29:59 | [drl] epoch #62 | gradient computed
2020-09-06 22:29:59 | [drl] epoch #62 | computing descent direction
2020-09-06 22:30:00 | [drl] epoch #62 | descent direction computed
2020-09-06 22:30:00 | [drl] epoch #62 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:00 | [drl] epoch #62 | Violated because loss is NaN
2020-09-06 22:30:00 | [drl] epoch #62 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:00 | [drl] epoch #62 | backtrack iters: 14
2020-09-06 22:30:00 | [drl] epoch #62 | optimization finished
2020-09-06 22:30:00 | [drl] epoch #62 | Computing KL after
2020-09-06 22:30:00 | [drl] epoch #62 | Computing loss after
2020-09-06 22:30:00 | [drl] epoch #62 | Fitting baseline...
2020-09-06 22:30:00 | [drl] epoch #62 | Saving snapshot...
2020-09-06 22:30:00 | [drl] epoch #62 | Saved
2020-09-06 22:30:00 | [drl] epoch #62 | Time 67.85 s
2020-09-06 22:30:00 | [drl] epoch #62 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -97578.5
AverageReturn                            -159450
Entropy                                        8.51363
EnvExecTime                                    0.0410557
Extras/EpisodeRewardMean                 -204862
Iteration                                     62
LinearFeatureBaseline/ExplainedVariance        0.524721
MaxReturn                                -159450
MinReturn                                -159450
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0415452
ProcessExecTime                                0.00138712
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:00 | [drl] epoch #63 | Obtaining samples...
2020-09-06 22:30:00 | [drl] epoch #63 | Obtaining samples for iteration 63...
2020-09-06 22:30:00 | [drl] epoch #63 | Logging diagnostics...
2020-09-06 22:30:00 | [drl] epoch #63 | Optimizing policy...
2020-09-06 22:30:00 | [drl] epoch #63 | Computing loss before
2020-09-06 22:30:00 | [drl] epoch #63 | Computing KL before
2020-09-06 22:30:00 | [drl] epoch #63 | Optimizing
2020-09-06 22:30:00 | [drl] epoch #63 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:00 | [drl] epoch #63 | computing loss before
2020-09-06 22:30:00 | [drl] epoch #63 | computing gradient
2020-09-06 22:30:00 | [drl] epoch #63 | gradient computed
2020-09-06 22:30:00 | [drl] epoch #63 | computing descent direction
2020-09-06 22:30:00 | [drl] epoch #63 | descent direction computed
2020-09-06 22:30:00 | [drl] epoch #63 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:00 | [drl] epoch #63 | Violated because loss is NaN
2020-09-06 22:30:00 | [drl] epoch #63 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:00 | [drl] epoch #63 | backtrack iters: 14
2020-09-06 22:30:00 | [drl] epoch #63 | optimization finished
2020-09-06 22:30:00 | [drl] epoch #63 | Computing KL after
2020-09-06 22:30:00 | [drl] epoch #63 | Computing loss after
2020-09-06 22:30:00 | [drl] epoch #63 | Fitting baseline...
2020-09-06 22:30:00 | [drl] epoch #63 | Saving snapshot...
2020-09-06 22:30:00 | [drl] epoch #63 | Saved
2020-09-06 22:30:00 | [drl] epoch #63 | Time 68.62 s
2020-09-06 22:30:00 | [drl] epoch #63 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -88079
AverageReturn                            -143903
Entropy                                        8.51363
EnvExecTime                                    0.0370588
Extras/EpisodeRewardMean                 -203909
Iteration                                     63
LinearFeatureBaseline/ExplainedVariance        0.988021
MaxReturn                                -143903
MinReturn                                -143903
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0534167
ProcessExecTime                                0.00119758
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:00 | [drl] epoch #64 | Obtaining samples...
2020-09-06 22:30:00 | [drl] epoch #64 | Obtaining samples for iteration 64...
2020-09-06 22:30:01 | [drl] epoch #64 | Logging diagnostics...
2020-09-06 22:30:01 | [drl] epoch #64 | Optimizing policy...
2020-09-06 22:30:01 | [drl] epoch #64 | Computing loss before
2020-09-06 22:30:01 | [drl] epoch #64 | Computing KL before
2020-09-06 22:30:01 | [drl] epoch #64 | Optimizing
2020-09-06 22:30:01 | [drl] epoch #64 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:01 | [drl] epoch #64 | computing loss before
2020-09-06 22:30:01 | [drl] epoch #64 | computing gradient
2020-09-06 22:30:01 | [drl] epoch #64 | gradient computed
2020-09-06 22:30:01 | [drl] epoch #64 | computing descent direction
2020-09-06 22:30:01 | [drl] epoch #64 | descent direction computed
2020-09-06 22:30:01 | [drl] epoch #64 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:01 | [drl] epoch #64 | Violated because loss is NaN
2020-09-06 22:30:01 | [drl] epoch #64 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:01 | [drl] epoch #64 | backtrack iters: 14
2020-09-06 22:30:01 | [drl] epoch #64 | optimization finished
2020-09-06 22:30:01 | [drl] epoch #64 | Computing KL after
2020-09-06 22:30:01 | [drl] epoch #64 | Computing loss after
2020-09-06 22:30:01 | [drl] epoch #64 | Fitting baseline...
2020-09-06 22:30:01 | [drl] epoch #64 | Saving snapshot...
2020-09-06 22:30:01 | [drl] epoch #64 | Saved
2020-09-06 22:30:01 | [drl] epoch #64 | Time 69.39 s
2020-09-06 22:30:01 | [drl] epoch #64 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -87203.5
AverageReturn                            -142464
Entropy                                        8.51363
EnvExecTime                                    0.034277
Extras/EpisodeRewardMean                 -202964
Iteration                                     64
LinearFeatureBaseline/ExplainedVariance        0.999881
MaxReturn                                -142464
MinReturn                                -142464
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.049145
ProcessExecTime                                0.000980139
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:01 | [drl] epoch #65 | Obtaining samples...
2020-09-06 22:30:01 | [drl] epoch #65 | Obtaining samples for iteration 65...
2020-09-06 22:30:01 | [drl] epoch #65 | Logging diagnostics...
2020-09-06 22:30:01 | [drl] epoch #65 | Optimizing policy...
2020-09-06 22:30:01 | [drl] epoch #65 | Computing loss before
2020-09-06 22:30:01 | [drl] epoch #65 | Computing KL before
2020-09-06 22:30:01 | [drl] epoch #65 | Optimizing
2020-09-06 22:30:01 | [drl] epoch #65 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:01 | [drl] epoch #65 | computing loss before
2020-09-06 22:30:01 | [drl] epoch #65 | computing gradient
2020-09-06 22:30:01 | [drl] epoch #65 | gradient computed
2020-09-06 22:30:01 | [drl] epoch #65 | computing descent direction
2020-09-06 22:30:02 | [drl] epoch #65 | descent direction computed
2020-09-06 22:30:02 | [drl] epoch #65 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:02 | [drl] epoch #65 | Violated because loss is NaN
2020-09-06 22:30:02 | [drl] epoch #65 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:02 | [drl] epoch #65 | backtrack iters: 14
2020-09-06 22:30:02 | [drl] epoch #65 | optimization finished
2020-09-06 22:30:02 | [drl] epoch #65 | Computing KL after
2020-09-06 22:30:02 | [drl] epoch #65 | Computing loss after
2020-09-06 22:30:02 | [drl] epoch #65 | Fitting baseline...
2020-09-06 22:30:02 | [drl] epoch #65 | Saving snapshot...
2020-09-06 22:30:02 | [drl] epoch #65 | Saved
2020-09-06 22:30:02 | [drl] epoch #65 | Time 70.16 s
2020-09-06 22:30:02 | [drl] epoch #65 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -164100
AverageReturn                            -268298
Entropy                                        8.51363
EnvExecTime                                    0.0374067
Extras/EpisodeRewardMean                 -203954
Iteration                                     65
LinearFeatureBaseline/ExplainedVariance        0.776063
MaxReturn                                -268298
MinReturn                                -268298
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0458119
ProcessExecTime                                0.00095892
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:02 | [drl] epoch #66 | Obtaining samples...
2020-09-06 22:30:02 | [drl] epoch #66 | Obtaining samples for iteration 66...
2020-09-06 22:30:02 | [drl] epoch #66 | Logging diagnostics...
2020-09-06 22:30:02 | [drl] epoch #66 | Optimizing policy...
2020-09-06 22:30:02 | [drl] epoch #66 | Computing loss before
2020-09-06 22:30:02 | [drl] epoch #66 | Computing KL before
2020-09-06 22:30:02 | [drl] epoch #66 | Optimizing
2020-09-06 22:30:02 | [drl] epoch #66 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:02 | [drl] epoch #66 | computing loss before
2020-09-06 22:30:02 | [drl] epoch #66 | computing gradient
2020-09-06 22:30:02 | [drl] epoch #66 | gradient computed
2020-09-06 22:30:02 | [drl] epoch #66 | computing descent direction
2020-09-06 22:30:03 | [drl] epoch #66 | descent direction computed
2020-09-06 22:30:03 | [drl] epoch #66 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:03 | [drl] epoch #66 | Violated because loss is NaN
2020-09-06 22:30:03 | [drl] epoch #66 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:03 | [drl] epoch #66 | backtrack iters: 14
2020-09-06 22:30:03 | [drl] epoch #66 | optimization finished
2020-09-06 22:30:03 | [drl] epoch #66 | Computing KL after
2020-09-06 22:30:03 | [drl] epoch #66 | Computing loss after
2020-09-06 22:30:03 | [drl] epoch #66 | Fitting baseline...
2020-09-06 22:30:03 | [drl] epoch #66 | Saving snapshot...
2020-09-06 22:30:03 | [drl] epoch #66 | Saved
2020-09-06 22:30:03 | [drl] epoch #66 | Time 70.95 s
2020-09-06 22:30:03 | [drl] epoch #66 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -92386
AverageReturn                            -150933
Entropy                                        8.51363
EnvExecTime                                    0.032331
Extras/EpisodeRewardMean                 -203162
Iteration                                     66
LinearFeatureBaseline/ExplainedVariance        0.374969
MaxReturn                                -150933
MinReturn                                -150933
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0464361
ProcessExecTime                                0.000948668
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:03 | [drl] epoch #67 | Obtaining samples...
2020-09-06 22:30:03 | [drl] epoch #67 | Obtaining samples for iteration 67...
2020-09-06 22:30:03 | [drl] epoch #67 | Logging diagnostics...
2020-09-06 22:30:03 | [drl] epoch #67 | Optimizing policy...
2020-09-06 22:30:03 | [drl] epoch #67 | Computing loss before
2020-09-06 22:30:03 | [drl] epoch #67 | Computing KL before
2020-09-06 22:30:03 | [drl] epoch #67 | Optimizing
2020-09-06 22:30:03 | [drl] epoch #67 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:03 | [drl] epoch #67 | computing loss before
2020-09-06 22:30:03 | [drl] epoch #67 | computing gradient
2020-09-06 22:30:03 | [drl] epoch #67 | gradient computed
2020-09-06 22:30:03 | [drl] epoch #67 | computing descent direction
2020-09-06 22:30:03 | [drl] epoch #67 | descent direction computed
2020-09-06 22:30:04 | [drl] epoch #67 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:04 | [drl] epoch #67 | Violated because loss is NaN
2020-09-06 22:30:04 | [drl] epoch #67 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:04 | [drl] epoch #67 | backtrack iters: 14
2020-09-06 22:30:04 | [drl] epoch #67 | optimization finished
2020-09-06 22:30:04 | [drl] epoch #67 | Computing KL after
2020-09-06 22:30:04 | [drl] epoch #67 | Computing loss after
2020-09-06 22:30:04 | [drl] epoch #67 | Fitting baseline...
2020-09-06 22:30:04 | [drl] epoch #67 | Saving snapshot...
2020-09-06 22:30:04 | [drl] epoch #67 | Saved
2020-09-06 22:30:04 | [drl] epoch #67 | Time 71.76 s
2020-09-06 22:30:04 | [drl] epoch #67 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -99646.6
AverageReturn                            -162818
Entropy                                        8.51363
EnvExecTime                                    0.0394356
Extras/EpisodeRewardMean                 -202569
Iteration                                     67
LinearFeatureBaseline/ExplainedVariance        0.994453
MaxReturn                                -162818
MinReturn                                -162818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0467501
ProcessExecTime                                0.000959158
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:04 | [drl] epoch #68 | Obtaining samples...
2020-09-06 22:30:04 | [drl] epoch #68 | Obtaining samples for iteration 68...
2020-09-06 22:30:04 | [drl] epoch #68 | Logging diagnostics...
2020-09-06 22:30:04 | [drl] epoch #68 | Optimizing policy...
2020-09-06 22:30:04 | [drl] epoch #68 | Computing loss before
2020-09-06 22:30:04 | [drl] epoch #68 | Computing KL before
2020-09-06 22:30:04 | [drl] epoch #68 | Optimizing
2020-09-06 22:30:04 | [drl] epoch #68 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:04 | [drl] epoch #68 | computing loss before
2020-09-06 22:30:04 | [drl] epoch #68 | computing gradient
2020-09-06 22:30:04 | [drl] epoch #68 | gradient computed
2020-09-06 22:30:04 | [drl] epoch #68 | computing descent direction
2020-09-06 22:30:04 | [drl] epoch #68 | descent direction computed
2020-09-06 22:30:04 | [drl] epoch #68 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:04 | [drl] epoch #68 | Violated because loss is NaN
2020-09-06 22:30:04 | [drl] epoch #68 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:04 | [drl] epoch #68 | backtrack iters: 14
2020-09-06 22:30:04 | [drl] epoch #68 | optimization finished
2020-09-06 22:30:04 | [drl] epoch #68 | Computing KL after
2020-09-06 22:30:04 | [drl] epoch #68 | Computing loss after
2020-09-06 22:30:04 | [drl] epoch #68 | Fitting baseline...
2020-09-06 22:30:04 | [drl] epoch #68 | Saving snapshot...
2020-09-06 22:30:04 | [drl] epoch #68 | Saved
2020-09-06 22:30:04 | [drl] epoch #68 | Time 72.53 s
2020-09-06 22:30:04 | [drl] epoch #68 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114481
AverageReturn                            -187102
Entropy                                        8.51363
EnvExecTime                                    0.0438306
Extras/EpisodeRewardMean                 -202345
Iteration                                     68
LinearFeatureBaseline/ExplainedVariance        0.982752
MaxReturn                                -187102
MinReturn                                -187102
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0414586
ProcessExecTime                                0.000961065
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:04 | [drl] epoch #69 | Obtaining samples...
2020-09-06 22:30:04 | [drl] epoch #69 | Obtaining samples for iteration 69...
2020-09-06 22:30:04 | [drl] epoch #69 | Logging diagnostics...
2020-09-06 22:30:04 | [drl] epoch #69 | Optimizing policy...
2020-09-06 22:30:04 | [drl] epoch #69 | Computing loss before
2020-09-06 22:30:04 | [drl] epoch #69 | Computing KL before
2020-09-06 22:30:04 | [drl] epoch #69 | Optimizing
2020-09-06 22:30:04 | [drl] epoch #69 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:04 | [drl] epoch #69 | computing loss before
2020-09-06 22:30:04 | [drl] epoch #69 | computing gradient
2020-09-06 22:30:05 | [drl] epoch #69 | gradient computed
2020-09-06 22:30:05 | [drl] epoch #69 | computing descent direction
2020-09-06 22:30:05 | [drl] epoch #69 | descent direction computed
2020-09-06 22:30:05 | [drl] epoch #69 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:05 | [drl] epoch #69 | Violated because loss is NaN
2020-09-06 22:30:05 | [drl] epoch #69 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:05 | [drl] epoch #69 | backtrack iters: 14
2020-09-06 22:30:05 | [drl] epoch #69 | optimization finished
2020-09-06 22:30:05 | [drl] epoch #69 | Computing KL after
2020-09-06 22:30:05 | [drl] epoch #69 | Computing loss after
2020-09-06 22:30:05 | [drl] epoch #69 | Fitting baseline...
2020-09-06 22:30:05 | [drl] epoch #69 | Saving snapshot...
2020-09-06 22:30:05 | [drl] epoch #69 | Saved
2020-09-06 22:30:05 | [drl] epoch #69 | Time 73.31 s
2020-09-06 22:30:05 | [drl] epoch #69 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -89373
AverageReturn                            -146017
Entropy                                        8.51363
EnvExecTime                                    0.0380576
Extras/EpisodeRewardMean                 -201540
Iteration                                     69
LinearFeatureBaseline/ExplainedVariance        0.918392
MaxReturn                                -146017
MinReturn                                -146017
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.057194
ProcessExecTime                                0.000956059
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:05 | [drl] epoch #70 | Obtaining samples...
2020-09-06 22:30:05 | [drl] epoch #70 | Obtaining samples for iteration 70...
2020-09-06 22:30:05 | [drl] epoch #70 | Logging diagnostics...
2020-09-06 22:30:05 | [drl] epoch #70 | Optimizing policy...
2020-09-06 22:30:05 | [drl] epoch #70 | Computing loss before
2020-09-06 22:30:05 | [drl] epoch #70 | Computing KL before
2020-09-06 22:30:05 | [drl] epoch #70 | Optimizing
2020-09-06 22:30:05 | [drl] epoch #70 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:05 | [drl] epoch #70 | computing loss before
2020-09-06 22:30:05 | [drl] epoch #70 | computing gradient
2020-09-06 22:30:05 | [drl] epoch #70 | gradient computed
2020-09-06 22:30:05 | [drl] epoch #70 | computing descent direction
2020-09-06 22:30:06 | [drl] epoch #70 | descent direction computed
2020-09-06 22:30:06 | [drl] epoch #70 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:06 | [drl] epoch #70 | Violated because loss is NaN
2020-09-06 22:30:06 | [drl] epoch #70 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:06 | [drl] epoch #70 | backtrack iters: 14
2020-09-06 22:30:06 | [drl] epoch #70 | optimization finished
2020-09-06 22:30:06 | [drl] epoch #70 | Computing KL after
2020-09-06 22:30:06 | [drl] epoch #70 | Computing loss after
2020-09-06 22:30:06 | [drl] epoch #70 | Fitting baseline...
2020-09-06 22:30:06 | [drl] epoch #70 | Saving snapshot...
2020-09-06 22:30:06 | [drl] epoch #70 | Saved
2020-09-06 22:30:06 | [drl] epoch #70 | Time 74.12 s
2020-09-06 22:30:06 | [drl] epoch #70 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -182188
AverageReturn                            -297893
Entropy                                        8.51363
EnvExecTime                                    0.0356715
Extras/EpisodeRewardMean                 -202897
Iteration                                     70
LinearFeatureBaseline/ExplainedVariance        0.73593
MaxReturn                                -297893
MinReturn                                -297893
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0488386
ProcessExecTime                                0.000983953
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:06 | [drl] epoch #71 | Obtaining samples...
2020-09-06 22:30:06 | [drl] epoch #71 | Obtaining samples for iteration 71...
2020-09-06 22:30:06 | [drl] epoch #71 | Logging diagnostics...
2020-09-06 22:30:06 | [drl] epoch #71 | Optimizing policy...
2020-09-06 22:30:06 | [drl] epoch #71 | Computing loss before
2020-09-06 22:30:06 | [drl] epoch #71 | Computing KL before
2020-09-06 22:30:06 | [drl] epoch #71 | Optimizing
2020-09-06 22:30:06 | [drl] epoch #71 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:06 | [drl] epoch #71 | computing loss before
2020-09-06 22:30:06 | [drl] epoch #71 | computing gradient
2020-09-06 22:30:06 | [drl] epoch #71 | gradient computed
2020-09-06 22:30:06 | [drl] epoch #71 | computing descent direction
2020-09-06 22:30:07 | [drl] epoch #71 | descent direction computed
2020-09-06 22:30:07 | [drl] epoch #71 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:07 | [drl] epoch #71 | Violated because loss is NaN
2020-09-06 22:30:07 | [drl] epoch #71 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:07 | [drl] epoch #71 | backtrack iters: 14
2020-09-06 22:30:07 | [drl] epoch #71 | optimization finished
2020-09-06 22:30:07 | [drl] epoch #71 | Computing KL after
2020-09-06 22:30:07 | [drl] epoch #71 | Computing loss after
2020-09-06 22:30:07 | [drl] epoch #71 | Fitting baseline...
2020-09-06 22:30:07 | [drl] epoch #71 | Saving snapshot...
2020-09-06 22:30:07 | [drl] epoch #71 | Saved
2020-09-06 22:30:07 | [drl] epoch #71 | Time 74.88 s
2020-09-06 22:30:07 | [drl] epoch #71 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101167
AverageReturn                            -165303
Entropy                                        8.51363
EnvExecTime                                    0.036051
Extras/EpisodeRewardMean                 -202375
Iteration                                     71
LinearFeatureBaseline/ExplainedVariance        0.335713
MaxReturn                                -165303
MinReturn                                -165303
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0450943
ProcessExecTime                                0.000996113
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:07 | [drl] epoch #72 | Obtaining samples...
2020-09-06 22:30:07 | [drl] epoch #72 | Obtaining samples for iteration 72...
2020-09-06 22:30:07 | [drl] epoch #72 | Logging diagnostics...
2020-09-06 22:30:07 | [drl] epoch #72 | Optimizing policy...
2020-09-06 22:30:07 | [drl] epoch #72 | Computing loss before
2020-09-06 22:30:07 | [drl] epoch #72 | Computing KL before
2020-09-06 22:30:07 | [drl] epoch #72 | Optimizing
2020-09-06 22:30:07 | [drl] epoch #72 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:07 | [drl] epoch #72 | computing loss before
2020-09-06 22:30:07 | [drl] epoch #72 | computing gradient
2020-09-06 22:30:07 | [drl] epoch #72 | gradient computed
2020-09-06 22:30:07 | [drl] epoch #72 | computing descent direction
2020-09-06 22:30:07 | [drl] epoch #72 | descent direction computed
2020-09-06 22:30:07 | [drl] epoch #72 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:07 | [drl] epoch #72 | Violated because loss is NaN
2020-09-06 22:30:07 | [drl] epoch #72 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:07 | [drl] epoch #72 | backtrack iters: 14
2020-09-06 22:30:07 | [drl] epoch #72 | optimization finished
2020-09-06 22:30:07 | [drl] epoch #72 | Computing KL after
2020-09-06 22:30:07 | [drl] epoch #72 | Computing loss after
2020-09-06 22:30:07 | [drl] epoch #72 | Fitting baseline...
2020-09-06 22:30:07 | [drl] epoch #72 | Saving snapshot...
2020-09-06 22:30:07 | [drl] epoch #72 | Saved
2020-09-06 22:30:07 | [drl] epoch #72 | Time 75.67 s
2020-09-06 22:30:07 | [drl] epoch #72 | EpochTime 0.77 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -123442
AverageReturn                            -201765
Entropy                                        8.51363
EnvExecTime                                    0.0349998
Extras/EpisodeRewardMean                 -202367
Iteration                                     72
LinearFeatureBaseline/ExplainedVariance        0.966302
MaxReturn                                -201765
MinReturn                                -201765
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0521934
ProcessExecTime                                0.010206
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:30:07 | [drl] epoch #73 | Obtaining samples...
2020-09-06 22:30:07 | [drl] epoch #73 | Obtaining samples for iteration 73...
2020-09-06 22:30:08 | [drl] epoch #73 | Logging diagnostics...
2020-09-06 22:30:08 | [drl] epoch #73 | Optimizing policy...
2020-09-06 22:30:08 | [drl] epoch #73 | Computing loss before
2020-09-06 22:30:08 | [drl] epoch #73 | Computing KL before
2020-09-06 22:30:08 | [drl] epoch #73 | Optimizing
2020-09-06 22:30:08 | [drl] epoch #73 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:08 | [drl] epoch #73 | computing loss before
2020-09-06 22:30:08 | [drl] epoch #73 | computing gradient
2020-09-06 22:30:08 | [drl] epoch #73 | gradient computed
2020-09-06 22:30:08 | [drl] epoch #73 | computing descent direction
2020-09-06 22:30:08 | [drl] epoch #73 | descent direction computed
2020-09-06 22:30:08 | [drl] epoch #73 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:08 | [drl] epoch #73 | Violated because loss is NaN
2020-09-06 22:30:08 | [drl] epoch #73 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:08 | [drl] epoch #73 | backtrack iters: 14
2020-09-06 22:30:08 | [drl] epoch #73 | optimization finished
2020-09-06 22:30:08 | [drl] epoch #73 | Computing KL after
2020-09-06 22:30:08 | [drl] epoch #73 | Computing loss after
2020-09-06 22:30:08 | [drl] epoch #73 | Fitting baseline...
2020-09-06 22:30:08 | [drl] epoch #73 | Saving snapshot...
2020-09-06 22:30:08 | [drl] epoch #73 | Saved
2020-09-06 22:30:08 | [drl] epoch #73 | Time 76.52 s
2020-09-06 22:30:08 | [drl] epoch #73 | EpochTime 0.84 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -82541
AverageReturn                            -134836
Entropy                                        8.51363
EnvExecTime                                    0.0328815
Extras/EpisodeRewardMean                 -201454
Iteration                                     73
LinearFeatureBaseline/ExplainedVariance        0.744276
MaxReturn                                -134836
MinReturn                                -134836
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0726023
ProcessExecTime                                0.00121784
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:08 | [drl] epoch #74 | Obtaining samples...
2020-09-06 22:30:08 | [drl] epoch #74 | Obtaining samples for iteration 74...
2020-09-06 22:30:08 | [drl] epoch #74 | Logging diagnostics...
2020-09-06 22:30:08 | [drl] epoch #74 | Optimizing policy...
2020-09-06 22:30:08 | [drl] epoch #74 | Computing loss before
2020-09-06 22:30:08 | [drl] epoch #74 | Computing KL before
2020-09-06 22:30:08 | [drl] epoch #74 | Optimizing
2020-09-06 22:30:08 | [drl] epoch #74 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:08 | [drl] epoch #74 | computing loss before
2020-09-06 22:30:08 | [drl] epoch #74 | computing gradient
2020-09-06 22:30:08 | [drl] epoch #74 | gradient computed
2020-09-06 22:30:08 | [drl] epoch #74 | computing descent direction
2020-09-06 22:30:09 | [drl] epoch #74 | descent direction computed
2020-09-06 22:30:09 | [drl] epoch #74 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:09 | [drl] epoch #74 | Violated because loss is NaN
2020-09-06 22:30:09 | [drl] epoch #74 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:09 | [drl] epoch #74 | backtrack iters: 14
2020-09-06 22:30:09 | [drl] epoch #74 | optimization finished
2020-09-06 22:30:09 | [drl] epoch #74 | Computing KL after
2020-09-06 22:30:09 | [drl] epoch #74 | Computing loss after
2020-09-06 22:30:09 | [drl] epoch #74 | Fitting baseline...
2020-09-06 22:30:09 | [drl] epoch #74 | Saving snapshot...
2020-09-06 22:30:09 | [drl] epoch #74 | Saved
2020-09-06 22:30:09 | [drl] epoch #74 | Time 77.32 s
2020-09-06 22:30:09 | [drl] epoch #74 | EpochTime 0.78 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -145122
AverageReturn                            -237232
Entropy                                        8.51363
EnvExecTime                                    0.0487893
Extras/EpisodeRewardMean                 -201931
Iteration                                     74
LinearFeatureBaseline/ExplainedVariance        0.810021
MaxReturn                                -237232
MinReturn                                -237232
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0538647
ProcessExecTime                                0.0010097
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:30:09 | [drl] epoch #75 | Obtaining samples...
2020-09-06 22:30:09 | [drl] epoch #75 | Obtaining samples for iteration 75...
2020-09-06 22:30:09 | [drl] epoch #75 | Logging diagnostics...
2020-09-06 22:30:09 | [drl] epoch #75 | Optimizing policy...
2020-09-06 22:30:09 | [drl] epoch #75 | Computing loss before
2020-09-06 22:30:09 | [drl] epoch #75 | Computing KL before
2020-09-06 22:30:09 | [drl] epoch #75 | Optimizing
2020-09-06 22:30:09 | [drl] epoch #75 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:09 | [drl] epoch #75 | computing loss before
2020-09-06 22:30:09 | [drl] epoch #75 | computing gradient
2020-09-06 22:30:09 | [drl] epoch #75 | gradient computed
2020-09-06 22:30:09 | [drl] epoch #75 | computing descent direction
2020-09-06 22:30:10 | [drl] epoch #75 | descent direction computed
2020-09-06 22:30:10 | [drl] epoch #75 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:10 | [drl] epoch #75 | Violated because loss is NaN
2020-09-06 22:30:10 | [drl] epoch #75 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:10 | [drl] epoch #75 | backtrack iters: 14
2020-09-06 22:30:10 | [drl] epoch #75 | optimization finished
2020-09-06 22:30:10 | [drl] epoch #75 | Computing KL after
2020-09-06 22:30:10 | [drl] epoch #75 | Computing loss after
2020-09-06 22:30:10 | [drl] epoch #75 | Fitting baseline...
2020-09-06 22:30:10 | [drl] epoch #75 | Saving snapshot...
2020-09-06 22:30:10 | [drl] epoch #75 | Saved
2020-09-06 22:30:10 | [drl] epoch #75 | Time 78.10 s
2020-09-06 22:30:10 | [drl] epoch #75 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -114168
AverageReturn                            -186598
Entropy                                        8.51363
EnvExecTime                                    0.0440021
Extras/EpisodeRewardMean                 -201729
Iteration                                     75
LinearFeatureBaseline/ExplainedVariance        0.924675
MaxReturn                                -186598
MinReturn                                -186598
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0493262
ProcessExecTime                                0.00103474
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:10 | [drl] epoch #76 | Obtaining samples...
2020-09-06 22:30:10 | [drl] epoch #76 | Obtaining samples for iteration 76...
2020-09-06 22:30:10 | [drl] epoch #76 | Logging diagnostics...
2020-09-06 22:30:10 | [drl] epoch #76 | Optimizing policy...
2020-09-06 22:30:10 | [drl] epoch #76 | Computing loss before
2020-09-06 22:30:10 | [drl] epoch #76 | Computing KL before
2020-09-06 22:30:10 | [drl] epoch #76 | Optimizing
2020-09-06 22:30:10 | [drl] epoch #76 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:10 | [drl] epoch #76 | computing loss before
2020-09-06 22:30:10 | [drl] epoch #76 | computing gradient
2020-09-06 22:30:10 | [drl] epoch #76 | gradient computed
2020-09-06 22:30:10 | [drl] epoch #76 | computing descent direction
2020-09-06 22:30:11 | [drl] epoch #76 | descent direction computed
2020-09-06 22:30:11 | [drl] epoch #76 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:11 | [drl] epoch #76 | Violated because loss is NaN
2020-09-06 22:30:11 | [drl] epoch #76 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:11 | [drl] epoch #76 | backtrack iters: 14
2020-09-06 22:30:11 | [drl] epoch #76 | optimization finished
2020-09-06 22:30:11 | [drl] epoch #76 | Computing KL after
2020-09-06 22:30:11 | [drl] epoch #76 | Computing loss after
2020-09-06 22:30:11 | [drl] epoch #76 | Fitting baseline...
2020-09-06 22:30:11 | [drl] epoch #76 | Saving snapshot...
2020-09-06 22:30:11 | [drl] epoch #76 | Saved
2020-09-06 22:30:11 | [drl] epoch #76 | Time 78.89 s
2020-09-06 22:30:11 | [drl] epoch #76 | EpochTime 0.78 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -109992
AverageReturn                            -179751
Entropy                                        8.51363
EnvExecTime                                    0.0489728
Extras/EpisodeRewardMean                 -201444
Iteration                                     76
LinearFeatureBaseline/ExplainedVariance        0.998529
MaxReturn                                -179751
MinReturn                                -179751
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0501564
ProcessExecTime                                0.000943661
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:11 | [drl] epoch #77 | Obtaining samples...
2020-09-06 22:30:11 | [drl] epoch #77 | Obtaining samples for iteration 77...
2020-09-06 22:30:11 | [drl] epoch #77 | Logging diagnostics...
2020-09-06 22:30:11 | [drl] epoch #77 | Optimizing policy...
2020-09-06 22:30:11 | [drl] epoch #77 | Computing loss before
2020-09-06 22:30:11 | [drl] epoch #77 | Computing KL before
2020-09-06 22:30:11 | [drl] epoch #77 | Optimizing
2020-09-06 22:30:11 | [drl] epoch #77 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:11 | [drl] epoch #77 | computing loss before
2020-09-06 22:30:11 | [drl] epoch #77 | computing gradient
2020-09-06 22:30:11 | [drl] epoch #77 | gradient computed
2020-09-06 22:30:11 | [drl] epoch #77 | computing descent direction
2020-09-06 22:30:11 | [drl] epoch #77 | descent direction computed
2020-09-06 22:30:11 | [drl] epoch #77 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:11 | [drl] epoch #77 | Violated because loss is NaN
2020-09-06 22:30:11 | [drl] epoch #77 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:11 | [drl] epoch #77 | backtrack iters: 14
2020-09-06 22:30:11 | [drl] epoch #77 | optimization finished
2020-09-06 22:30:11 | [drl] epoch #77 | Computing KL after
2020-09-06 22:30:11 | [drl] epoch #77 | Computing loss after
2020-09-06 22:30:11 | [drl] epoch #77 | Fitting baseline...
2020-09-06 22:30:11 | [drl] epoch #77 | Saving snapshot...
2020-09-06 22:30:11 | [drl] epoch #77 | Saved
2020-09-06 22:30:11 | [drl] epoch #77 | Time 79.67 s
2020-09-06 22:30:11 | [drl] epoch #77 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -100834
AverageReturn                            -164767
Entropy                                        8.51363
EnvExecTime                                    0.0338116
Extras/EpisodeRewardMean                 -200974
Iteration                                     77
LinearFeatureBaseline/ExplainedVariance        0.991394
MaxReturn                                -164767
MinReturn                                -164767
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0507357
ProcessExecTime                                0.000952482
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:11 | [drl] epoch #78 | Obtaining samples...
2020-09-06 22:30:11 | [drl] epoch #78 | Obtaining samples for iteration 78...
2020-09-06 22:30:12 | [drl] epoch #78 | Logging diagnostics...
2020-09-06 22:30:12 | [drl] epoch #78 | Optimizing policy...
2020-09-06 22:30:12 | [drl] epoch #78 | Computing loss before
2020-09-06 22:30:12 | [drl] epoch #78 | Computing KL before
2020-09-06 22:30:12 | [drl] epoch #78 | Optimizing
2020-09-06 22:30:12 | [drl] epoch #78 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:12 | [drl] epoch #78 | computing loss before
2020-09-06 22:30:12 | [drl] epoch #78 | computing gradient
2020-09-06 22:30:12 | [drl] epoch #78 | gradient computed
2020-09-06 22:30:12 | [drl] epoch #78 | computing descent direction
2020-09-06 22:30:12 | [drl] epoch #78 | descent direction computed
2020-09-06 22:30:12 | [drl] epoch #78 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:12 | [drl] epoch #78 | Violated because loss is NaN
2020-09-06 22:30:12 | [drl] epoch #78 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:12 | [drl] epoch #78 | backtrack iters: 14
2020-09-06 22:30:12 | [drl] epoch #78 | optimization finished
2020-09-06 22:30:12 | [drl] epoch #78 | Computing KL after
2020-09-06 22:30:12 | [drl] epoch #78 | Computing loss after
2020-09-06 22:30:12 | [drl] epoch #78 | Fitting baseline...
2020-09-06 22:30:12 | [drl] epoch #78 | Saving snapshot...
2020-09-06 22:30:12 | [drl] epoch #78 | Saved
2020-09-06 22:30:12 | [drl] epoch #78 | Time 80.44 s
2020-09-06 22:30:12 | [drl] epoch #78 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -88181.4
AverageReturn                            -144073
Entropy                                        8.51363
EnvExecTime                                    0.0381427
Extras/EpisodeRewardMean                 -200254
Iteration                                     78
LinearFeatureBaseline/ExplainedVariance        0.97888
MaxReturn                                -144073
MinReturn                                -144073
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.048341
ProcessExecTime                                0.000943899
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:12 | [drl] epoch #79 | Obtaining samples...
2020-09-06 22:30:12 | [drl] epoch #79 | Obtaining samples for iteration 79...
2020-09-06 22:30:12 | [drl] epoch #79 | Logging diagnostics...
2020-09-06 22:30:12 | [drl] epoch #79 | Optimizing policy...
2020-09-06 22:30:12 | [drl] epoch #79 | Computing loss before
2020-09-06 22:30:12 | [drl] epoch #79 | Computing KL before
2020-09-06 22:30:12 | [drl] epoch #79 | Optimizing
2020-09-06 22:30:12 | [drl] epoch #79 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:12 | [drl] epoch #79 | computing loss before
2020-09-06 22:30:12 | [drl] epoch #79 | computing gradient
2020-09-06 22:30:12 | [drl] epoch #79 | gradient computed
2020-09-06 22:30:12 | [drl] epoch #79 | computing descent direction
2020-09-06 22:30:13 | [drl] epoch #79 | descent direction computed
2020-09-06 22:30:13 | [drl] epoch #79 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:13 | [drl] epoch #79 | Violated because loss is NaN
2020-09-06 22:30:13 | [drl] epoch #79 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:13 | [drl] epoch #79 | backtrack iters: 14
2020-09-06 22:30:13 | [drl] epoch #79 | optimization finished
2020-09-06 22:30:13 | [drl] epoch #79 | Computing KL after
2020-09-06 22:30:13 | [drl] epoch #79 | Computing loss after
2020-09-06 22:30:13 | [drl] epoch #79 | Fitting baseline...
2020-09-06 22:30:13 | [drl] epoch #79 | Saving snapshot...
2020-09-06 22:30:13 | [drl] epoch #79 | Saved
2020-09-06 22:30:13 | [drl] epoch #79 | Time 81.21 s
2020-09-06 22:30:13 | [drl] epoch #79 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -102318
AverageReturn                            -167197
Entropy                                        8.51363
EnvExecTime                                    0.0369275
Extras/EpisodeRewardMean                 -199840
Iteration                                     79
LinearFeatureBaseline/ExplainedVariance        0.980415
MaxReturn                                -167197
MinReturn                                -167197
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0423348
ProcessExecTime                                0.00117564
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:13 | [drl] epoch #80 | Obtaining samples...
2020-09-06 22:30:13 | [drl] epoch #80 | Obtaining samples for iteration 80...
2020-09-06 22:30:13 | [drl] epoch #80 | Logging diagnostics...
2020-09-06 22:30:13 | [drl] epoch #80 | Optimizing policy...
2020-09-06 22:30:13 | [drl] epoch #80 | Computing loss before
2020-09-06 22:30:13 | [drl] epoch #80 | Computing KL before
2020-09-06 22:30:13 | [drl] epoch #80 | Optimizing
2020-09-06 22:30:13 | [drl] epoch #80 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:13 | [drl] epoch #80 | computing loss before
2020-09-06 22:30:13 | [drl] epoch #80 | computing gradient
2020-09-06 22:30:13 | [drl] epoch #80 | gradient computed
2020-09-06 22:30:13 | [drl] epoch #80 | computing descent direction
2020-09-06 22:30:14 | [drl] epoch #80 | descent direction computed
2020-09-06 22:30:14 | [drl] epoch #80 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:14 | [drl] epoch #80 | Violated because loss is NaN
2020-09-06 22:30:14 | [drl] epoch #80 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:14 | [drl] epoch #80 | backtrack iters: 14
2020-09-06 22:30:14 | [drl] epoch #80 | optimization finished
2020-09-06 22:30:14 | [drl] epoch #80 | Computing KL after
2020-09-06 22:30:14 | [drl] epoch #80 | Computing loss after
2020-09-06 22:30:14 | [drl] epoch #80 | Fitting baseline...
2020-09-06 22:30:14 | [drl] epoch #80 | Saving snapshot...
2020-09-06 22:30:14 | [drl] epoch #80 | Saved
2020-09-06 22:30:14 | [drl] epoch #80 | Time 81.98 s
2020-09-06 22:30:14 | [drl] epoch #80 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154554
AverageReturn                            -252680
Entropy                                        8.51363
EnvExecTime                                    0.0355093
Extras/EpisodeRewardMean                 -200493
Iteration                                     80
LinearFeatureBaseline/ExplainedVariance        0.883389
MaxReturn                                -252680
MinReturn                                -252680
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0487461
ProcessExecTime                                0.000990391
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:14 | [drl] epoch #81 | Obtaining samples...
2020-09-06 22:30:14 | [drl] epoch #81 | Obtaining samples for iteration 81...
2020-09-06 22:30:14 | [drl] epoch #81 | Logging diagnostics...
2020-09-06 22:30:14 | [drl] epoch #81 | Optimizing policy...
2020-09-06 22:30:14 | [drl] epoch #81 | Computing loss before
2020-09-06 22:30:14 | [drl] epoch #81 | Computing KL before
2020-09-06 22:30:14 | [drl] epoch #81 | Optimizing
2020-09-06 22:30:14 | [drl] epoch #81 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:14 | [drl] epoch #81 | computing loss before
2020-09-06 22:30:14 | [drl] epoch #81 | computing gradient
2020-09-06 22:30:14 | [drl] epoch #81 | gradient computed
2020-09-06 22:30:14 | [drl] epoch #81 | computing descent direction
2020-09-06 22:30:15 | [drl] epoch #81 | descent direction computed
2020-09-06 22:30:15 | [drl] epoch #81 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:15 | [drl] epoch #81 | Violated because loss is NaN
2020-09-06 22:30:15 | [drl] epoch #81 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:15 | [drl] epoch #81 | backtrack iters: 14
2020-09-06 22:30:15 | [drl] epoch #81 | optimization finished
2020-09-06 22:30:15 | [drl] epoch #81 | Computing KL after
2020-09-06 22:30:15 | [drl] epoch #81 | Computing loss after
2020-09-06 22:30:15 | [drl] epoch #81 | Fitting baseline...
2020-09-06 22:30:15 | [drl] epoch #81 | Saving snapshot...
2020-09-06 22:30:15 | [drl] epoch #81 | Saved
2020-09-06 22:30:15 | [drl] epoch #81 | Time 82.85 s
2020-09-06 22:30:15 | [drl] epoch #81 | EpochTime 0.85 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -120394
AverageReturn                            -196788
Entropy                                        8.51363
EnvExecTime                                    0.043889
Extras/EpisodeRewardMean                 -200447
Iteration                                     81
LinearFeatureBaseline/ExplainedVariance        0.918067
MaxReturn                                -196788
MinReturn                                -196788
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0444257
ProcessExecTime                                0.000991344
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:15 | [drl] epoch #82 | Obtaining samples...
2020-09-06 22:30:15 | [drl] epoch #82 | Obtaining samples for iteration 82...
2020-09-06 22:30:15 | [drl] epoch #82 | Logging diagnostics...
2020-09-06 22:30:15 | [drl] epoch #82 | Optimizing policy...
2020-09-06 22:30:15 | [drl] epoch #82 | Computing loss before
2020-09-06 22:30:15 | [drl] epoch #82 | Computing KL before
2020-09-06 22:30:15 | [drl] epoch #82 | Optimizing
2020-09-06 22:30:15 | [drl] epoch #82 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:15 | [drl] epoch #82 | computing loss before
2020-09-06 22:30:15 | [drl] epoch #82 | computing gradient
2020-09-06 22:30:15 | [drl] epoch #82 | gradient computed
2020-09-06 22:30:15 | [drl] epoch #82 | computing descent direction
2020-09-06 22:30:15 | [drl] epoch #82 | descent direction computed
2020-09-06 22:30:15 | [drl] epoch #82 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:15 | [drl] epoch #82 | Violated because loss is NaN
2020-09-06 22:30:15 | [drl] epoch #82 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:15 | [drl] epoch #82 | backtrack iters: 14
2020-09-06 22:30:15 | [drl] epoch #82 | optimization finished
2020-09-06 22:30:15 | [drl] epoch #82 | Computing KL after
2020-09-06 22:30:15 | [drl] epoch #82 | Computing loss after
2020-09-06 22:30:15 | [drl] epoch #82 | Fitting baseline...
2020-09-06 22:30:15 | [drl] epoch #82 | Saving snapshot...
2020-09-06 22:30:15 | [drl] epoch #82 | Saved
2020-09-06 22:30:15 | [drl] epoch #82 | Time 83.64 s
2020-09-06 22:30:15 | [drl] epoch #82 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -117471
AverageReturn                            -191996
Entropy                                        8.51363
EnvExecTime                                    0.0336301
Extras/EpisodeRewardMean                 -200346
Iteration                                     82
LinearFeatureBaseline/ExplainedVariance        0.999319
MaxReturn                                -191996
MinReturn                                -191996
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0581617
ProcessExecTime                                0.000968218
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:15 | [drl] epoch #83 | Obtaining samples...
2020-09-06 22:30:15 | [drl] epoch #83 | Obtaining samples for iteration 83...
2020-09-06 22:30:16 | [drl] epoch #83 | Logging diagnostics...
2020-09-06 22:30:16 | [drl] epoch #83 | Optimizing policy...
2020-09-06 22:30:16 | [drl] epoch #83 | Computing loss before
2020-09-06 22:30:16 | [drl] epoch #83 | Computing KL before
2020-09-06 22:30:16 | [drl] epoch #83 | Optimizing
2020-09-06 22:30:16 | [drl] epoch #83 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:16 | [drl] epoch #83 | computing loss before
2020-09-06 22:30:16 | [drl] epoch #83 | computing gradient
2020-09-06 22:30:16 | [drl] epoch #83 | gradient computed
2020-09-06 22:30:16 | [drl] epoch #83 | computing descent direction
2020-09-06 22:30:16 | [drl] epoch #83 | descent direction computed
2020-09-06 22:30:16 | [drl] epoch #83 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:16 | [drl] epoch #83 | Violated because loss is NaN
2020-09-06 22:30:16 | [drl] epoch #83 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:16 | [drl] epoch #83 | backtrack iters: 14
2020-09-06 22:30:16 | [drl] epoch #83 | optimization finished
2020-09-06 22:30:16 | [drl] epoch #83 | Computing KL after
2020-09-06 22:30:16 | [drl] epoch #83 | Computing loss after
2020-09-06 22:30:16 | [drl] epoch #83 | Fitting baseline...
2020-09-06 22:30:16 | [drl] epoch #83 | Saving snapshot...
2020-09-06 22:30:16 | [drl] epoch #83 | Saved
2020-09-06 22:30:16 | [drl] epoch #83 | Time 84.41 s
2020-09-06 22:30:16 | [drl] epoch #83 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -184134
AverageReturn                            -301069
Entropy                                        8.51363
EnvExecTime                                    0.0473988
Extras/EpisodeRewardMean                 -201545
Iteration                                     83
LinearFeatureBaseline/ExplainedVariance        0.866805
MaxReturn                                -301069
MinReturn                                -301069
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0473022
ProcessExecTime                                0.000983715
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:16 | [drl] epoch #84 | Obtaining samples...
2020-09-06 22:30:16 | [drl] epoch #84 | Obtaining samples for iteration 84...
2020-09-06 22:30:16 | [drl] epoch #84 | Logging diagnostics...
2020-09-06 22:30:16 | [drl] epoch #84 | Optimizing policy...
2020-09-06 22:30:16 | [drl] epoch #84 | Computing loss before
2020-09-06 22:30:16 | [drl] epoch #84 | Computing KL before
2020-09-06 22:30:16 | [drl] epoch #84 | Optimizing
2020-09-06 22:30:16 | [drl] epoch #84 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:16 | [drl] epoch #84 | computing loss before
2020-09-06 22:30:16 | [drl] epoch #84 | computing gradient
2020-09-06 22:30:16 | [drl] epoch #84 | gradient computed
2020-09-06 22:30:16 | [drl] epoch #84 | computing descent direction
2020-09-06 22:30:17 | [drl] epoch #84 | descent direction computed
2020-09-06 22:30:17 | [drl] epoch #84 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:17 | [drl] epoch #84 | Violated because loss is NaN
2020-09-06 22:30:17 | [drl] epoch #84 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:17 | [drl] epoch #84 | backtrack iters: 14
2020-09-06 22:30:17 | [drl] epoch #84 | optimization finished
2020-09-06 22:30:17 | [drl] epoch #84 | Computing KL after
2020-09-06 22:30:17 | [drl] epoch #84 | Computing loss after
2020-09-06 22:30:17 | [drl] epoch #84 | Fitting baseline...
2020-09-06 22:30:17 | [drl] epoch #84 | Saving snapshot...
2020-09-06 22:30:17 | [drl] epoch #84 | Saved
2020-09-06 22:30:17 | [drl] epoch #84 | Time 85.19 s
2020-09-06 22:30:17 | [drl] epoch #84 | EpochTime 0.77 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -114705
AverageReturn                            -187460
Entropy                                        8.51363
EnvExecTime                                    0.0342019
Extras/EpisodeRewardMean                 -201379
Iteration                                     84
LinearFeatureBaseline/ExplainedVariance        0.62349
MaxReturn                                -187460
MinReturn                                -187460
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0544622
ProcessExecTime                                0.00094676
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:17 | [drl] epoch #85 | Obtaining samples...
2020-09-06 22:30:17 | [drl] epoch #85 | Obtaining samples for iteration 85...
2020-09-06 22:30:17 | [drl] epoch #85 | Logging diagnostics...
2020-09-06 22:30:17 | [drl] epoch #85 | Optimizing policy...
2020-09-06 22:30:17 | [drl] epoch #85 | Computing loss before
2020-09-06 22:30:17 | [drl] epoch #85 | Computing KL before
2020-09-06 22:30:17 | [drl] epoch #85 | Optimizing
2020-09-06 22:30:17 | [drl] epoch #85 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:17 | [drl] epoch #85 | computing loss before
2020-09-06 22:30:17 | [drl] epoch #85 | computing gradient
2020-09-06 22:30:17 | [drl] epoch #85 | gradient computed
2020-09-06 22:30:17 | [drl] epoch #85 | computing descent direction
2020-09-06 22:30:18 | [drl] epoch #85 | descent direction computed
2020-09-06 22:30:18 | [drl] epoch #85 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:18 | [drl] epoch #85 | Violated because loss is NaN
2020-09-06 22:30:18 | [drl] epoch #85 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:18 | [drl] epoch #85 | backtrack iters: 14
2020-09-06 22:30:18 | [drl] epoch #85 | optimization finished
2020-09-06 22:30:18 | [drl] epoch #85 | Computing KL after
2020-09-06 22:30:18 | [drl] epoch #85 | Computing loss after
2020-09-06 22:30:18 | [drl] epoch #85 | Fitting baseline...
2020-09-06 22:30:18 | [drl] epoch #85 | Saving snapshot...
2020-09-06 22:30:18 | [drl] epoch #85 | Saved
2020-09-06 22:30:18 | [drl] epoch #85 | Time 85.96 s
2020-09-06 22:30:18 | [drl] epoch #85 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -187372
AverageReturn                            -306359
Entropy                                        8.51363
EnvExecTime                                    0.0395482
Extras/EpisodeRewardMean                 -202600
Iteration                                     85
LinearFeatureBaseline/ExplainedVariance        0.847244
MaxReturn                                -306359
MinReturn                                -306359
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0405602
ProcessExecTime                                0.00118041
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:18 | [drl] epoch #86 | Obtaining samples...
2020-09-06 22:30:18 | [drl] epoch #86 | Obtaining samples for iteration 86...
2020-09-06 22:30:18 | [drl] epoch #86 | Logging diagnostics...
2020-09-06 22:30:18 | [drl] epoch #86 | Optimizing policy...
2020-09-06 22:30:18 | [drl] epoch #86 | Computing loss before
2020-09-06 22:30:18 | [drl] epoch #86 | Computing KL before
2020-09-06 22:30:18 | [drl] epoch #86 | Optimizing
2020-09-06 22:30:18 | [drl] epoch #86 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:18 | [drl] epoch #86 | computing loss before
2020-09-06 22:30:18 | [drl] epoch #86 | computing gradient
2020-09-06 22:30:18 | [drl] epoch #86 | gradient computed
2020-09-06 22:30:18 | [drl] epoch #86 | computing descent direction
2020-09-06 22:30:18 | [drl] epoch #86 | descent direction computed
2020-09-06 22:30:19 | [drl] epoch #86 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:19 | [drl] epoch #86 | Violated because loss is NaN
2020-09-06 22:30:19 | [drl] epoch #86 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:19 | [drl] epoch #86 | backtrack iters: 14
2020-09-06 22:30:19 | [drl] epoch #86 | optimization finished
2020-09-06 22:30:19 | [drl] epoch #86 | Computing KL after
2020-09-06 22:30:19 | [drl] epoch #86 | Computing loss after
2020-09-06 22:30:19 | [drl] epoch #86 | Fitting baseline...
2020-09-06 22:30:19 | [drl] epoch #86 | Saving snapshot...
2020-09-06 22:30:19 | [drl] epoch #86 | Saved
2020-09-06 22:30:19 | [drl] epoch #86 | Time 86.75 s
2020-09-06 22:30:19 | [drl] epoch #86 | EpochTime 0.78 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -150679
AverageReturn                            -246334
Entropy                                        8.51363
EnvExecTime                                    0.0344987
Extras/EpisodeRewardMean                 -203102
Iteration                                     86
LinearFeatureBaseline/ExplainedVariance        0.93987
MaxReturn                                -246334
MinReturn                                -246334
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0465193
ProcessExecTime                                0.000962257
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:19 | [drl] epoch #87 | Obtaining samples...
2020-09-06 22:30:19 | [drl] epoch #87 | Obtaining samples for iteration 87...
2020-09-06 22:30:19 | [drl] epoch #87 | Logging diagnostics...
2020-09-06 22:30:19 | [drl] epoch #87 | Optimizing policy...
2020-09-06 22:30:19 | [drl] epoch #87 | Computing loss before
2020-09-06 22:30:19 | [drl] epoch #87 | Computing KL before
2020-09-06 22:30:19 | [drl] epoch #87 | Optimizing
2020-09-06 22:30:19 | [drl] epoch #87 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:19 | [drl] epoch #87 | computing loss before
2020-09-06 22:30:19 | [drl] epoch #87 | computing gradient
2020-09-06 22:30:19 | [drl] epoch #87 | gradient computed
2020-09-06 22:30:19 | [drl] epoch #87 | computing descent direction
2020-09-06 22:30:19 | [drl] epoch #87 | descent direction computed
2020-09-06 22:30:19 | [drl] epoch #87 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:19 | [drl] epoch #87 | Violated because loss is NaN
2020-09-06 22:30:19 | [drl] epoch #87 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:19 | [drl] epoch #87 | backtrack iters: 14
2020-09-06 22:30:19 | [drl] epoch #87 | optimization finished
2020-09-06 22:30:19 | [drl] epoch #87 | Computing KL after
2020-09-06 22:30:19 | [drl] epoch #87 | Computing loss after
2020-09-06 22:30:19 | [drl] epoch #87 | Fitting baseline...
2020-09-06 22:30:19 | [drl] epoch #87 | Saving snapshot...
2020-09-06 22:30:19 | [drl] epoch #87 | Saved
2020-09-06 22:30:19 | [drl] epoch #87 | Time 87.54 s
2020-09-06 22:30:19 | [drl] epoch #87 | EpochTime 0.78 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101874
AverageReturn                            -166476
Entropy                                        8.51363
EnvExecTime                                    0.0344298
Extras/EpisodeRewardMean                 -202686
Iteration                                     87
LinearFeatureBaseline/ExplainedVariance        0.763915
MaxReturn                                -166476
MinReturn                                -166476
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0630653
ProcessExecTime                                0.000954866
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:19 | [drl] epoch #88 | Obtaining samples...
2020-09-06 22:30:19 | [drl] epoch #88 | Obtaining samples for iteration 88...
2020-09-06 22:30:19 | [drl] epoch #88 | Logging diagnostics...
2020-09-06 22:30:19 | [drl] epoch #88 | Optimizing policy...
2020-09-06 22:30:19 | [drl] epoch #88 | Computing loss before
2020-09-06 22:30:19 | [drl] epoch #88 | Computing KL before
2020-09-06 22:30:19 | [drl] epoch #88 | Optimizing
2020-09-06 22:30:19 | [drl] epoch #88 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:19 | [drl] epoch #88 | computing loss before
2020-09-06 22:30:19 | [drl] epoch #88 | computing gradient
2020-09-06 22:30:20 | [drl] epoch #88 | gradient computed
2020-09-06 22:30:20 | [drl] epoch #88 | computing descent direction
2020-09-06 22:30:20 | [drl] epoch #88 | descent direction computed
2020-09-06 22:30:20 | [drl] epoch #88 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:20 | [drl] epoch #88 | Violated because loss is NaN
2020-09-06 22:30:20 | [drl] epoch #88 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:20 | [drl] epoch #88 | backtrack iters: 14
2020-09-06 22:30:20 | [drl] epoch #88 | optimization finished
2020-09-06 22:30:20 | [drl] epoch #88 | Computing KL after
2020-09-06 22:30:20 | [drl] epoch #88 | Computing loss after
2020-09-06 22:30:20 | [drl] epoch #88 | Fitting baseline...
2020-09-06 22:30:20 | [drl] epoch #88 | Saving snapshot...
2020-09-06 22:30:20 | [drl] epoch #88 | Saved
2020-09-06 22:30:20 | [drl] epoch #88 | Time 88.30 s
2020-09-06 22:30:20 | [drl] epoch #88 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -170787
AverageReturn                            -279237
Entropy                                        8.51363
EnvExecTime                                    0.0390511
Extras/EpisodeRewardMean                 -203546
Iteration                                     88
LinearFeatureBaseline/ExplainedVariance        0.834356
MaxReturn                                -279237
MinReturn                                -279237
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0494316
ProcessExecTime                                0.000962496
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:20 | [drl] epoch #89 | Obtaining samples...
2020-09-06 22:30:20 | [drl] epoch #89 | Obtaining samples for iteration 89...
2020-09-06 22:30:20 | [drl] epoch #89 | Logging diagnostics...
2020-09-06 22:30:20 | [drl] epoch #89 | Optimizing policy...
2020-09-06 22:30:20 | [drl] epoch #89 | Computing loss before
2020-09-06 22:30:20 | [drl] epoch #89 | Computing KL before
2020-09-06 22:30:20 | [drl] epoch #89 | Optimizing
2020-09-06 22:30:20 | [drl] epoch #89 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:20 | [drl] epoch #89 | computing loss before
2020-09-06 22:30:20 | [drl] epoch #89 | computing gradient
2020-09-06 22:30:20 | [drl] epoch #89 | gradient computed
2020-09-06 22:30:20 | [drl] epoch #89 | computing descent direction
2020-09-06 22:30:21 | [drl] epoch #89 | descent direction computed
2020-09-06 22:30:21 | [drl] epoch #89 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:21 | [drl] epoch #89 | Violated because loss is NaN
2020-09-06 22:30:21 | [drl] epoch #89 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:21 | [drl] epoch #89 | backtrack iters: 14
2020-09-06 22:30:21 | [drl] epoch #89 | optimization finished
2020-09-06 22:30:21 | [drl] epoch #89 | Computing KL after
2020-09-06 22:30:21 | [drl] epoch #89 | Computing loss after
2020-09-06 22:30:21 | [drl] epoch #89 | Fitting baseline...
2020-09-06 22:30:21 | [drl] epoch #89 | Saving snapshot...
2020-09-06 22:30:21 | [drl] epoch #89 | Saved
2020-09-06 22:30:21 | [drl] epoch #89 | Time 89.07 s
2020-09-06 22:30:21 | [drl] epoch #89 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -110587
AverageReturn                            -180725
Entropy                                        8.51363
EnvExecTime                                    0.0406435
Extras/EpisodeRewardMean                 -203293
Iteration                                     89
LinearFeatureBaseline/ExplainedVariance        0.694235
MaxReturn                                -180725
MinReturn                                -180725
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0426872
ProcessExecTime                                0.00093627
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:21 | [drl] epoch #90 | Obtaining samples...
2020-09-06 22:30:21 | [drl] epoch #90 | Obtaining samples for iteration 90...
2020-09-06 22:30:21 | [drl] epoch #90 | Logging diagnostics...
2020-09-06 22:30:21 | [drl] epoch #90 | Optimizing policy...
2020-09-06 22:30:21 | [drl] epoch #90 | Computing loss before
2020-09-06 22:30:21 | [drl] epoch #90 | Computing KL before
2020-09-06 22:30:21 | [drl] epoch #90 | Optimizing
2020-09-06 22:30:21 | [drl] epoch #90 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:21 | [drl] epoch #90 | computing loss before
2020-09-06 22:30:21 | [drl] epoch #90 | computing gradient
2020-09-06 22:30:21 | [drl] epoch #90 | gradient computed
2020-09-06 22:30:21 | [drl] epoch #90 | computing descent direction
2020-09-06 22:30:22 | [drl] epoch #90 | descent direction computed
2020-09-06 22:30:22 | [drl] epoch #90 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:22 | [drl] epoch #90 | Violated because loss is NaN
2020-09-06 22:30:22 | [drl] epoch #90 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:22 | [drl] epoch #90 | backtrack iters: 14
2020-09-06 22:30:22 | [drl] epoch #90 | optimization finished
2020-09-06 22:30:22 | [drl] epoch #90 | Computing KL after
2020-09-06 22:30:22 | [drl] epoch #90 | Computing loss after
2020-09-06 22:30:22 | [drl] epoch #90 | Fitting baseline...
2020-09-06 22:30:22 | [drl] epoch #90 | Saving snapshot...
2020-09-06 22:30:22 | [drl] epoch #90 | Saved
2020-09-06 22:30:22 | [drl] epoch #90 | Time 89.84 s
2020-09-06 22:30:22 | [drl] epoch #90 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -83137.4
AverageReturn                            -135816
Entropy                                        8.51363
EnvExecTime                                    0.0357208
Extras/EpisodeRewardMean                 -202551
Iteration                                     90
LinearFeatureBaseline/ExplainedVariance        0.887458
MaxReturn                                -135816
MinReturn                                -135816
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.050086
ProcessExecTime                                0.000957251
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:22 | [drl] epoch #91 | Obtaining samples...
2020-09-06 22:30:22 | [drl] epoch #91 | Obtaining samples for iteration 91...
2020-09-06 22:30:22 | [drl] epoch #91 | Logging diagnostics...
2020-09-06 22:30:22 | [drl] epoch #91 | Optimizing policy...
2020-09-06 22:30:22 | [drl] epoch #91 | Computing loss before
2020-09-06 22:30:22 | [drl] epoch #91 | Computing KL before
2020-09-06 22:30:22 | [drl] epoch #91 | Optimizing
2020-09-06 22:30:22 | [drl] epoch #91 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:22 | [drl] epoch #91 | computing loss before
2020-09-06 22:30:22 | [drl] epoch #91 | computing gradient
2020-09-06 22:30:22 | [drl] epoch #91 | gradient computed
2020-09-06 22:30:22 | [drl] epoch #91 | computing descent direction
2020-09-06 22:30:22 | [drl] epoch #91 | descent direction computed
2020-09-06 22:30:22 | [drl] epoch #91 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:22 | [drl] epoch #91 | Violated because loss is NaN
2020-09-06 22:30:22 | [drl] epoch #91 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:22 | [drl] epoch #91 | backtrack iters: 14
2020-09-06 22:30:22 | [drl] epoch #91 | optimization finished
2020-09-06 22:30:22 | [drl] epoch #91 | Computing KL after
2020-09-06 22:30:22 | [drl] epoch #91 | Computing loss after
2020-09-06 22:30:22 | [drl] epoch #91 | Fitting baseline...
2020-09-06 22:30:22 | [drl] epoch #91 | Saving snapshot...
2020-09-06 22:30:22 | [drl] epoch #91 | Saved
2020-09-06 22:30:22 | [drl] epoch #91 | Time 90.61 s
2020-09-06 22:30:22 | [drl] epoch #91 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -108717
AverageReturn                            -177663
Entropy                                        8.51363
EnvExecTime                                    0.0352399
Extras/EpisodeRewardMean                 -202281
Iteration                                     91
LinearFeatureBaseline/ExplainedVariance        0.943164
MaxReturn                                -177663
MinReturn                                -177663
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0594773
ProcessExecTime                                0.00102568
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:22 | [drl] epoch #92 | Obtaining samples...
2020-09-06 22:30:22 | [drl] epoch #92 | Obtaining samples for iteration 92...
2020-09-06 22:30:23 | [drl] epoch #92 | Logging diagnostics...
2020-09-06 22:30:23 | [drl] epoch #92 | Optimizing policy...
2020-09-06 22:30:23 | [drl] epoch #92 | Computing loss before
2020-09-06 22:30:23 | [drl] epoch #92 | Computing KL before
2020-09-06 22:30:23 | [drl] epoch #92 | Optimizing
2020-09-06 22:30:23 | [drl] epoch #92 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:23 | [drl] epoch #92 | computing loss before
2020-09-06 22:30:23 | [drl] epoch #92 | computing gradient
2020-09-06 22:30:23 | [drl] epoch #92 | gradient computed
2020-09-06 22:30:23 | [drl] epoch #92 | computing descent direction
2020-09-06 22:30:23 | [drl] epoch #92 | descent direction computed
2020-09-06 22:30:23 | [drl] epoch #92 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:23 | [drl] epoch #92 | Violated because loss is NaN
2020-09-06 22:30:23 | [drl] epoch #92 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:23 | [drl] epoch #92 | backtrack iters: 14
2020-09-06 22:30:23 | [drl] epoch #92 | optimization finished
2020-09-06 22:30:23 | [drl] epoch #92 | Computing KL after
2020-09-06 22:30:23 | [drl] epoch #92 | Computing loss after
2020-09-06 22:30:23 | [drl] epoch #92 | Fitting baseline...
2020-09-06 22:30:23 | [drl] epoch #92 | Saving snapshot...
2020-09-06 22:30:23 | [drl] epoch #92 | Saved
2020-09-06 22:30:23 | [drl] epoch #92 | Time 91.39 s
2020-09-06 22:30:23 | [drl] epoch #92 | EpochTime 0.77 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154879
AverageReturn                            -253203
Entropy                                        8.51363
EnvExecTime                                    0.0327363
Extras/EpisodeRewardMean                 -202828
Iteration                                     92
LinearFeatureBaseline/ExplainedVariance        0.909495
MaxReturn                                -253203
MinReturn                                -253203
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0614426
ProcessExecTime                                0.000986576
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:23 | [drl] epoch #93 | Obtaining samples...
2020-09-06 22:30:23 | [drl] epoch #93 | Obtaining samples for iteration 93...
2020-09-06 22:30:23 | [drl] epoch #93 | Logging diagnostics...
2020-09-06 22:30:23 | [drl] epoch #93 | Optimizing policy...
2020-09-06 22:30:23 | [drl] epoch #93 | Computing loss before
2020-09-06 22:30:23 | [drl] epoch #93 | Computing KL before
2020-09-06 22:30:23 | [drl] epoch #93 | Optimizing
2020-09-06 22:30:23 | [drl] epoch #93 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:23 | [drl] epoch #93 | computing loss before
2020-09-06 22:30:23 | [drl] epoch #93 | computing gradient
2020-09-06 22:30:23 | [drl] epoch #93 | gradient computed
2020-09-06 22:30:23 | [drl] epoch #93 | computing descent direction
2020-09-06 22:30:24 | [drl] epoch #93 | descent direction computed
2020-09-06 22:30:24 | [drl] epoch #93 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:24 | [drl] epoch #93 | Violated because loss is NaN
2020-09-06 22:30:24 | [drl] epoch #93 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:24 | [drl] epoch #93 | backtrack iters: 14
2020-09-06 22:30:24 | [drl] epoch #93 | optimization finished
2020-09-06 22:30:24 | [drl] epoch #93 | Computing KL after
2020-09-06 22:30:24 | [drl] epoch #93 | Computing loss after
2020-09-06 22:30:24 | [drl] epoch #93 | Fitting baseline...
2020-09-06 22:30:24 | [drl] epoch #93 | Saving snapshot...
2020-09-06 22:30:24 | [drl] epoch #93 | Saved
2020-09-06 22:30:24 | [drl] epoch #93 | Time 92.16 s
2020-09-06 22:30:24 | [drl] epoch #93 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -116601
AverageReturn                            -190586
Entropy                                        8.51363
EnvExecTime                                    0.03777
Extras/EpisodeRewardMean                 -202698
Iteration                                     93
LinearFeatureBaseline/ExplainedVariance        0.890187
MaxReturn                                -190586
MinReturn                                -190586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0479288
ProcessExecTime                                0.000979662
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:24 | [drl] epoch #94 | Obtaining samples...
2020-09-06 22:30:24 | [drl] epoch #94 | Obtaining samples for iteration 94...
2020-09-06 22:30:24 | [drl] epoch #94 | Logging diagnostics...
2020-09-06 22:30:24 | [drl] epoch #94 | Optimizing policy...
2020-09-06 22:30:24 | [drl] epoch #94 | Computing loss before
2020-09-06 22:30:24 | [drl] epoch #94 | Computing KL before
2020-09-06 22:30:24 | [drl] epoch #94 | Optimizing
2020-09-06 22:30:24 | [drl] epoch #94 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:24 | [drl] epoch #94 | computing loss before
2020-09-06 22:30:24 | [drl] epoch #94 | computing gradient
2020-09-06 22:30:24 | [drl] epoch #94 | gradient computed
2020-09-06 22:30:24 | [drl] epoch #94 | computing descent direction
2020-09-06 22:30:25 | [drl] epoch #94 | descent direction computed
2020-09-06 22:30:25 | [drl] epoch #94 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:25 | [drl] epoch #94 | Violated because loss is NaN
2020-09-06 22:30:25 | [drl] epoch #94 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:25 | [drl] epoch #94 | backtrack iters: 14
2020-09-06 22:30:25 | [drl] epoch #94 | optimization finished
2020-09-06 22:30:25 | [drl] epoch #94 | Computing KL after
2020-09-06 22:30:25 | [drl] epoch #94 | Computing loss after
2020-09-06 22:30:25 | [drl] epoch #94 | Fitting baseline...
2020-09-06 22:30:25 | [drl] epoch #94 | Saving snapshot...
2020-09-06 22:30:25 | [drl] epoch #94 | Saved
2020-09-06 22:30:25 | [drl] epoch #94 | Time 92.93 s
2020-09-06 22:30:25 | [drl] epoch #94 | EpochTime 0.76 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -110733
AverageReturn                            -180965
Entropy                                        8.51363
EnvExecTime                                    0.0357091
Extras/EpisodeRewardMean                 -202469
Iteration                                     94
LinearFeatureBaseline/ExplainedVariance        0.997062
MaxReturn                                -180965
MinReturn                                -180965
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0539241
ProcessExecTime                                0.000983
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:30:25 | [drl] epoch #95 | Obtaining samples...
2020-09-06 22:30:25 | [drl] epoch #95 | Obtaining samples for iteration 95...
2020-09-06 22:30:25 | [drl] epoch #95 | Logging diagnostics...
2020-09-06 22:30:25 | [drl] epoch #95 | Optimizing policy...
2020-09-06 22:30:25 | [drl] epoch #95 | Computing loss before
2020-09-06 22:30:25 | [drl] epoch #95 | Computing KL before
2020-09-06 22:30:25 | [drl] epoch #95 | Optimizing
2020-09-06 22:30:25 | [drl] epoch #95 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:25 | [drl] epoch #95 | computing loss before
2020-09-06 22:30:25 | [drl] epoch #95 | computing gradient
2020-09-06 22:30:25 | [drl] epoch #95 | gradient computed
2020-09-06 22:30:25 | [drl] epoch #95 | computing descent direction
2020-09-06 22:30:25 | [drl] epoch #95 | descent direction computed
2020-09-06 22:30:25 | [drl] epoch #95 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:25 | [drl] epoch #95 | Violated because loss is NaN
2020-09-06 22:30:25 | [drl] epoch #95 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:25 | [drl] epoch #95 | backtrack iters: 14
2020-09-06 22:30:25 | [drl] epoch #95 | optimization finished
2020-09-06 22:30:25 | [drl] epoch #95 | Computing KL after
2020-09-06 22:30:25 | [drl] epoch #95 | Computing loss after
2020-09-06 22:30:25 | [drl] epoch #95 | Fitting baseline...
2020-09-06 22:30:25 | [drl] epoch #95 | Saving snapshot...
2020-09-06 22:30:25 | [drl] epoch #95 | Saved
2020-09-06 22:30:25 | [drl] epoch #95 | Time 93.68 s
2020-09-06 22:30:25 | [drl] epoch #95 | EpochTime 0.74 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -160763
AverageReturn                            -262829
Entropy                                        8.51363
EnvExecTime                                    0.0345941
Extras/EpisodeRewardMean                 -203098
Iteration                                     95
LinearFeatureBaseline/ExplainedVariance        0.901363
MaxReturn                                -262829
MinReturn                                -262829
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0391734
ProcessExecTime                                0.0009799
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 22:30:25 | [drl] epoch #96 | Obtaining samples...
2020-09-06 22:30:25 | [drl] epoch #96 | Obtaining samples for iteration 96...
2020-09-06 22:30:26 | [drl] epoch #96 | Logging diagnostics...
2020-09-06 22:30:26 | [drl] epoch #96 | Optimizing policy...
2020-09-06 22:30:26 | [drl] epoch #96 | Computing loss before
2020-09-06 22:30:26 | [drl] epoch #96 | Computing KL before
2020-09-06 22:30:26 | [drl] epoch #96 | Optimizing
2020-09-06 22:30:26 | [drl] epoch #96 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:26 | [drl] epoch #96 | computing loss before
2020-09-06 22:30:26 | [drl] epoch #96 | computing gradient
2020-09-06 22:30:26 | [drl] epoch #96 | gradient computed
2020-09-06 22:30:26 | [drl] epoch #96 | computing descent direction
2020-09-06 22:30:26 | [drl] epoch #96 | descent direction computed
2020-09-06 22:30:26 | [drl] epoch #96 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:26 | [drl] epoch #96 | Violated because loss is NaN
2020-09-06 22:30:26 | [drl] epoch #96 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:26 | [drl] epoch #96 | backtrack iters: 14
2020-09-06 22:30:26 | [drl] epoch #96 | optimization finished
2020-09-06 22:30:26 | [drl] epoch #96 | Computing KL after
2020-09-06 22:30:26 | [drl] epoch #96 | Computing loss after
2020-09-06 22:30:26 | [drl] epoch #96 | Fitting baseline...
2020-09-06 22:30:26 | [drl] epoch #96 | Saving snapshot...
2020-09-06 22:30:26 | [drl] epoch #96 | Saved
2020-09-06 22:30:26 | [drl] epoch #96 | Time 94.44 s
2020-09-06 22:30:26 | [drl] epoch #96 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -148977
AverageReturn                            -243555
Entropy                                        8.51363
EnvExecTime                                    0.0369542
Extras/EpisodeRewardMean                 -203515
Iteration                                     96
LinearFeatureBaseline/ExplainedVariance        0.99369
MaxReturn                                -243555
MinReturn                                -243555
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0494416
ProcessExecTime                                0.000974417
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:26 | [drl] epoch #97 | Obtaining samples...
2020-09-06 22:30:26 | [drl] epoch #97 | Obtaining samples for iteration 97...
2020-09-06 22:30:26 | [drl] epoch #97 | Logging diagnostics...
2020-09-06 22:30:26 | [drl] epoch #97 | Optimizing policy...
2020-09-06 22:30:26 | [drl] epoch #97 | Computing loss before
2020-09-06 22:30:26 | [drl] epoch #97 | Computing KL before
2020-09-06 22:30:26 | [drl] epoch #97 | Optimizing
2020-09-06 22:30:26 | [drl] epoch #97 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:26 | [drl] epoch #97 | computing loss before
2020-09-06 22:30:26 | [drl] epoch #97 | computing gradient
2020-09-06 22:30:26 | [drl] epoch #97 | gradient computed
2020-09-06 22:30:26 | [drl] epoch #97 | computing descent direction
2020-09-06 22:30:27 | [drl] epoch #97 | descent direction computed
2020-09-06 22:30:27 | [drl] epoch #97 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:27 | [drl] epoch #97 | Violated because loss is NaN
2020-09-06 22:30:27 | [drl] epoch #97 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:27 | [drl] epoch #97 | backtrack iters: 14
2020-09-06 22:30:27 | [drl] epoch #97 | optimization finished
2020-09-06 22:30:27 | [drl] epoch #97 | Computing KL after
2020-09-06 22:30:27 | [drl] epoch #97 | Computing loss after
2020-09-06 22:30:27 | [drl] epoch #97 | Fitting baseline...
2020-09-06 22:30:27 | [drl] epoch #97 | Saving snapshot...
2020-09-06 22:30:27 | [drl] epoch #97 | Saved
2020-09-06 22:30:27 | [drl] epoch #97 | Time 95.19 s
2020-09-06 22:30:27 | [drl] epoch #97 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -192232
AverageReturn                            -314329
Entropy                                        8.51363
EnvExecTime                                    0.0347629
Extras/EpisodeRewardMean                 -204646
Iteration                                     97
LinearFeatureBaseline/ExplainedVariance        0.948611
MaxReturn                                -314329
MinReturn                                -314329
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0477726
ProcessExecTime                                0.000941753
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:27 | [drl] epoch #98 | Obtaining samples...
2020-09-06 22:30:27 | [drl] epoch #98 | Obtaining samples for iteration 98...
2020-09-06 22:30:27 | [drl] epoch #98 | Logging diagnostics...
2020-09-06 22:30:27 | [drl] epoch #98 | Optimizing policy...
2020-09-06 22:30:27 | [drl] epoch #98 | Computing loss before
2020-09-06 22:30:27 | [drl] epoch #98 | Computing KL before
2020-09-06 22:30:27 | [drl] epoch #98 | Optimizing
2020-09-06 22:30:27 | [drl] epoch #98 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:27 | [drl] epoch #98 | computing loss before
2020-09-06 22:30:27 | [drl] epoch #98 | computing gradient
2020-09-06 22:30:27 | [drl] epoch #98 | gradient computed
2020-09-06 22:30:27 | [drl] epoch #98 | computing descent direction
2020-09-06 22:30:28 | [drl] epoch #98 | descent direction computed
2020-09-06 22:30:28 | [drl] epoch #98 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:28 | [drl] epoch #98 | Violated because loss is NaN
2020-09-06 22:30:28 | [drl] epoch #98 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:28 | [drl] epoch #98 | backtrack iters: 14
2020-09-06 22:30:28 | [drl] epoch #98 | optimization finished
2020-09-06 22:30:28 | [drl] epoch #98 | Computing KL after
2020-09-06 22:30:28 | [drl] epoch #98 | Computing loss after
2020-09-06 22:30:28 | [drl] epoch #98 | Fitting baseline...
2020-09-06 22:30:28 | [drl] epoch #98 | Saving snapshot...
2020-09-06 22:30:28 | [drl] epoch #98 | Saved
2020-09-06 22:30:28 | [drl] epoch #98 | Time 95.95 s
2020-09-06 22:30:28 | [drl] epoch #98 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -79029.2
AverageReturn                            -129087
Entropy                                        8.51363
EnvExecTime                                    0.0408165
Extras/EpisodeRewardMean                 -203883
Iteration                                     98
LinearFeatureBaseline/ExplainedVariance       -1.14135
MaxReturn                                -129087
MinReturn                                -129087
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0507593
ProcessExecTime                                0.00099659
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 22:30:28 | [drl] epoch #99 | Obtaining samples...
2020-09-06 22:30:28 | [drl] epoch #99 | Obtaining samples for iteration 99...
2020-09-06 22:30:28 | [drl] epoch #99 | Logging diagnostics...
2020-09-06 22:30:28 | [drl] epoch #99 | Optimizing policy...
2020-09-06 22:30:28 | [drl] epoch #99 | Computing loss before
2020-09-06 22:30:28 | [drl] epoch #99 | Computing KL before
2020-09-06 22:30:28 | [drl] epoch #99 | Optimizing
2020-09-06 22:30:28 | [drl] epoch #99 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:28 | [drl] epoch #99 | computing loss before
2020-09-06 22:30:28 | [drl] epoch #99 | computing gradient
2020-09-06 22:30:28 | [drl] epoch #99 | gradient computed
2020-09-06 22:30:28 | [drl] epoch #99 | computing descent direction
2020-09-06 22:30:28 | [drl] epoch #99 | descent direction computed
2020-09-06 22:30:28 | [drl] epoch #99 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:28 | [drl] epoch #99 | Violated because loss is NaN
2020-09-06 22:30:28 | [drl] epoch #99 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:28 | [drl] epoch #99 | backtrack iters: 14
2020-09-06 22:30:28 | [drl] epoch #99 | optimization finished
2020-09-06 22:30:28 | [drl] epoch #99 | Computing KL after
2020-09-06 22:30:28 | [drl] epoch #99 | Computing loss after
2020-09-06 22:30:28 | [drl] epoch #99 | Fitting baseline...
2020-09-06 22:30:28 | [drl] epoch #99 | Saving snapshot...
2020-09-06 22:30:28 | [drl] epoch #99 | Saved
2020-09-06 22:30:29 | [drl] epoch #99 | Time 96.71 s
2020-09-06 22:30:29 | [drl] epoch #99 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -149503
AverageReturn                            -244408
Entropy                                        8.51363
EnvExecTime                                    0.0394251
Extras/EpisodeRewardMean                 -204288
Iteration                                     99
LinearFeatureBaseline/ExplainedVariance        0.772612
MaxReturn                                -244408
MinReturn                                -244408
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0460134
ProcessExecTime                                0.000947475
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 22:30:29 | [drl] epoch #100 | Obtaining samples...
2020-09-06 22:30:29 | [drl] epoch #100 | Obtaining samples for iteration 100...
2020-09-06 22:30:29 | [drl] epoch #100 | Logging diagnostics...
2020-09-06 22:30:29 | [drl] epoch #100 | Optimizing policy...
2020-09-06 22:30:29 | [drl] epoch #100 | Computing loss before
2020-09-06 22:30:29 | [drl] epoch #100 | Computing KL before
2020-09-06 22:30:29 | [drl] epoch #100 | Optimizing
2020-09-06 22:30:29 | [drl] epoch #100 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 22:30:29 | [drl] epoch #100 | computing loss before
2020-09-06 22:30:29 | [drl] epoch #100 | computing gradient
2020-09-06 22:30:29 | [drl] epoch #100 | gradient computed
2020-09-06 22:30:29 | [drl] epoch #100 | computing descent direction
2020-09-06 22:30:29 | [drl] epoch #100 | descent direction computed
2020-09-06 22:30:29 | [drl] epoch #100 | Line search condition violated. Rejecting the step!
2020-09-06 22:30:29 | [drl] epoch #100 | Violated because loss is NaN
2020-09-06 22:30:29 | [drl] epoch #100 | Violated because constraint mean_kl is NaN
2020-09-06 22:30:29 | [drl] epoch #100 | backtrack iters: 14
2020-09-06 22:30:29 | [drl] epoch #100 | optimization finished
2020-09-06 22:30:29 | [drl] epoch #100 | Computing KL after
2020-09-06 22:30:29 | [drl] epoch #100 | Computing loss after
2020-09-06 22:30:29 | [drl] epoch #100 | Fitting baseline...
2020-09-06 22:30:29 | [drl] epoch #100 | Saving snapshot...
2020-09-06 22:30:29 | [drl] epoch #100 | Saved
2020-09-06 22:30:29 | [drl] epoch #100 | Time 97.48 s
2020-09-06 22:30:29 | [drl] epoch #100 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -95810.7
AverageReturn                            -156550
Entropy                                        8.51363
EnvExecTime                                    0.0369868
Extras/EpisodeRewardMean                 -203888
Iteration                                    100
LinearFeatureBaseline/ExplainedVariance        0.675819
MaxReturn                                -156550
MinReturn                                -156550
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0489366
ProcessExecTime                                0.000950575
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:09 | [drl] epoch #0 | Obtaining samples...
2020-09-06 23:01:09 | [drl] epoch #0 | Obtaining samples for iteration 0...
2020-09-06 23:01:09 | [drl] epoch #0 | Logging diagnostics...
2020-09-06 23:01:10 | [drl] epoch #0 | Optimizing policy...
2020-09-06 23:01:10 | [drl] epoch #0 | Computing loss before
2020-09-06 23:01:10 | [drl] epoch #0 | Computing KL before
2020-09-06 23:01:10 | [drl] epoch #0 | Optimizing
2020-09-06 23:01:10 | [drl] epoch #0 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:10 | [drl] epoch #0 | computing loss before
2020-09-06 23:01:10 | [drl] epoch #0 | computing gradient
2020-09-06 23:01:10 | [drl] epoch #0 | gradient computed
2020-09-06 23:01:10 | [drl] epoch #0 | computing descent direction
2020-09-06 23:01:11 | [drl] epoch #0 | descent direction computed
2020-09-06 23:01:11 | [drl] epoch #0 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:11 | [drl] epoch #0 | Violated because loss is NaN
2020-09-06 23:01:11 | [drl] epoch #0 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:11 | [drl] epoch #0 | backtrack iters: 14
2020-09-06 23:01:11 | [drl] epoch #0 | optimization finished
2020-09-06 23:01:11 | [drl] epoch #0 | Computing KL after
2020-09-06 23:01:11 | [drl] epoch #0 | Computing loss after
2020-09-06 23:01:11 | [drl] epoch #0 | Fitting baseline...
2020-09-06 23:01:11 | [drl] epoch #0 | Saving snapshot...
2020-09-06 23:01:11 | [drl] epoch #0 | Saved
2020-09-06 23:01:11 | [drl] epoch #0 | Time 2.27 s
2020-09-06 23:01:11 | [drl] epoch #0 | EpochTime 2.27 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -120282
AverageReturn                            -196586
Entropy                                        8.51363
EnvExecTime                                    0.0560694
Extras/EpisodeRewardMean                 -196586
Iteration                                      0
LinearFeatureBaseline/ExplainedVariance        7.22073e-08
MaxReturn                                -196586
MinReturn                                -196586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.273392
ProcessExecTime                                0.000998974
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:11 | [drl] epoch #1 | Obtaining samples...
2020-09-06 23:01:11 | [drl] epoch #1 | Obtaining samples for iteration 1...
2020-09-06 23:01:12 | [drl] epoch #1 | Logging diagnostics...
2020-09-06 23:01:12 | [drl] epoch #1 | Optimizing policy...
2020-09-06 23:01:12 | [drl] epoch #1 | Computing loss before
2020-09-06 23:01:12 | [drl] epoch #1 | Computing KL before
2020-09-06 23:01:12 | [drl] epoch #1 | Optimizing
2020-09-06 23:01:12 | [drl] epoch #1 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:12 | [drl] epoch #1 | computing loss before
2020-09-06 23:01:12 | [drl] epoch #1 | computing gradient
2020-09-06 23:01:12 | [drl] epoch #1 | gradient computed
2020-09-06 23:01:12 | [drl] epoch #1 | computing descent direction
2020-09-06 23:01:12 | [drl] epoch #1 | descent direction computed
2020-09-06 23:01:12 | [drl] epoch #1 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:12 | [drl] epoch #1 | Violated because loss is NaN
2020-09-06 23:01:12 | [drl] epoch #1 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:12 | [drl] epoch #1 | backtrack iters: 14
2020-09-06 23:01:12 | [drl] epoch #1 | optimization finished
2020-09-06 23:01:12 | [drl] epoch #1 | Computing KL after
2020-09-06 23:01:12 | [drl] epoch #1 | Computing loss after
2020-09-06 23:01:12 | [drl] epoch #1 | Fitting baseline...
2020-09-06 23:01:12 | [drl] epoch #1 | Saving snapshot...
2020-09-06 23:01:12 | [drl] epoch #1 | Saved
2020-09-06 23:01:12 | [drl] epoch #1 | Time 3.04 s
2020-09-06 23:01:12 | [drl] epoch #1 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -185827
AverageReturn                            -303842
Entropy                                        8.51363
EnvExecTime                                    0.0420821
Extras/EpisodeRewardMean                 -250214
Iteration                                      1
LinearFeatureBaseline/ExplainedVariance        0.873328
MaxReturn                                -303842
MinReturn                                -303842
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0484855
ProcessExecTime                                0.000967503
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:12 | [drl] epoch #2 | Obtaining samples...
2020-09-06 23:01:12 | [drl] epoch #2 | Obtaining samples for iteration 2...
2020-09-06 23:01:12 | [drl] epoch #2 | Logging diagnostics...
2020-09-06 23:01:12 | [drl] epoch #2 | Optimizing policy...
2020-09-06 23:01:12 | [drl] epoch #2 | Computing loss before
2020-09-06 23:01:12 | [drl] epoch #2 | Computing KL before
2020-09-06 23:01:12 | [drl] epoch #2 | Optimizing
2020-09-06 23:01:12 | [drl] epoch #2 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:12 | [drl] epoch #2 | computing loss before
2020-09-06 23:01:12 | [drl] epoch #2 | computing gradient
2020-09-06 23:01:12 | [drl] epoch #2 | gradient computed
2020-09-06 23:01:12 | [drl] epoch #2 | computing descent direction
2020-09-06 23:01:13 | [drl] epoch #2 | descent direction computed
2020-09-06 23:01:13 | [drl] epoch #2 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:13 | [drl] epoch #2 | Violated because loss is NaN
2020-09-06 23:01:13 | [drl] epoch #2 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:13 | [drl] epoch #2 | backtrack iters: 14
2020-09-06 23:01:13 | [drl] epoch #2 | optimization finished
2020-09-06 23:01:13 | [drl] epoch #2 | Computing KL after
2020-09-06 23:01:13 | [drl] epoch #2 | Computing loss after
2020-09-06 23:01:13 | [drl] epoch #2 | Fitting baseline...
2020-09-06 23:01:13 | [drl] epoch #2 | Saving snapshot...
2020-09-06 23:01:13 | [drl] epoch #2 | Saved
2020-09-06 23:01:13 | [drl] epoch #2 | Time 3.80 s
2020-09-06 23:01:13 | [drl] epoch #2 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -137108
AverageReturn                            -224135
Entropy                                        8.51363
EnvExecTime                                    0.0452311
Extras/EpisodeRewardMean                 -241521
Iteration                                      2
LinearFeatureBaseline/ExplainedVariance        0.871718
MaxReturn                                -224135
MinReturn                                -224135
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0387521
ProcessExecTime                                0.00101852
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:13 | [drl] epoch #3 | Obtaining samples...
2020-09-06 23:01:13 | [drl] epoch #3 | Obtaining samples for iteration 3...
2020-09-06 23:01:13 | [drl] epoch #3 | Logging diagnostics...
2020-09-06 23:01:13 | [drl] epoch #3 | Optimizing policy...
2020-09-06 23:01:13 | [drl] epoch #3 | Computing loss before
2020-09-06 23:01:13 | [drl] epoch #3 | Computing KL before
2020-09-06 23:01:13 | [drl] epoch #3 | Optimizing
2020-09-06 23:01:13 | [drl] epoch #3 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:13 | [drl] epoch #3 | computing loss before
2020-09-06 23:01:13 | [drl] epoch #3 | computing gradient
2020-09-06 23:01:13 | [drl] epoch #3 | gradient computed
2020-09-06 23:01:13 | [drl] epoch #3 | computing descent direction
2020-09-06 23:01:14 | [drl] epoch #3 | descent direction computed
2020-09-06 23:01:14 | [drl] epoch #3 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:14 | [drl] epoch #3 | Violated because loss is NaN
2020-09-06 23:01:14 | [drl] epoch #3 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:14 | [drl] epoch #3 | backtrack iters: 14
2020-09-06 23:01:14 | [drl] epoch #3 | optimization finished
2020-09-06 23:01:14 | [drl] epoch #3 | Computing KL after
2020-09-06 23:01:14 | [drl] epoch #3 | Computing loss after
2020-09-06 23:01:14 | [drl] epoch #3 | Fitting baseline...
2020-09-06 23:01:14 | [drl] epoch #3 | Saving snapshot...
2020-09-06 23:01:14 | [drl] epoch #3 | Saved
2020-09-06 23:01:14 | [drl] epoch #3 | Time 4.56 s
2020-09-06 23:01:14 | [drl] epoch #3 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -84596.1
AverageReturn                            -138193
Entropy                                        8.51363
EnvExecTime                                    0.0405025
Extras/EpisodeRewardMean                 -215689
Iteration                                      3
LinearFeatureBaseline/ExplainedVariance        0.597185
MaxReturn                                -138193
MinReturn                                -138193
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0424135
ProcessExecTime                                0.00159192
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:14 | [drl] epoch #4 | Obtaining samples...
2020-09-06 23:01:14 | [drl] epoch #4 | Obtaining samples for iteration 4...
2020-09-06 23:01:14 | [drl] epoch #4 | Logging diagnostics...
2020-09-06 23:01:14 | [drl] epoch #4 | Optimizing policy...
2020-09-06 23:01:14 | [drl] epoch #4 | Computing loss before
2020-09-06 23:01:14 | [drl] epoch #4 | Computing KL before
2020-09-06 23:01:14 | [drl] epoch #4 | Optimizing
2020-09-06 23:01:14 | [drl] epoch #4 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:14 | [drl] epoch #4 | computing loss before
2020-09-06 23:01:14 | [drl] epoch #4 | computing gradient
2020-09-06 23:01:14 | [drl] epoch #4 | gradient computed
2020-09-06 23:01:14 | [drl] epoch #4 | computing descent direction
2020-09-06 23:01:14 | [drl] epoch #4 | descent direction computed
2020-09-06 23:01:14 | [drl] epoch #4 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:14 | [drl] epoch #4 | Violated because loss is NaN
2020-09-06 23:01:14 | [drl] epoch #4 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:14 | [drl] epoch #4 | backtrack iters: 14
2020-09-06 23:01:14 | [drl] epoch #4 | optimization finished
2020-09-06 23:01:14 | [drl] epoch #4 | Computing KL after
2020-09-06 23:01:14 | [drl] epoch #4 | Computing loss after
2020-09-06 23:01:14 | [drl] epoch #4 | Fitting baseline...
2020-09-06 23:01:14 | [drl] epoch #4 | Saving snapshot...
2020-09-06 23:01:14 | [drl] epoch #4 | Saved
2020-09-06 23:01:14 | [drl] epoch #4 | Time 5.32 s
2020-09-06 23:01:14 | [drl] epoch #4 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -166430
AverageReturn                            -272108
Entropy                                        8.51363
EnvExecTime                                    0.0329072
Extras/EpisodeRewardMean                 -226973
Iteration                                      4
LinearFeatureBaseline/ExplainedVariance        0.753183
MaxReturn                                -272108
MinReturn                                -272108
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0441206
ProcessExecTime                                0.00147557
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:14 | [drl] epoch #5 | Obtaining samples...
2020-09-06 23:01:14 | [drl] epoch #5 | Obtaining samples for iteration 5...
2020-09-06 23:01:15 | [drl] epoch #5 | Logging diagnostics...
2020-09-06 23:01:15 | [drl] epoch #5 | Optimizing policy...
2020-09-06 23:01:15 | [drl] epoch #5 | Computing loss before
2020-09-06 23:01:15 | [drl] epoch #5 | Computing KL before
2020-09-06 23:01:15 | [drl] epoch #5 | Optimizing
2020-09-06 23:01:15 | [drl] epoch #5 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:15 | [drl] epoch #5 | computing loss before
2020-09-06 23:01:15 | [drl] epoch #5 | computing gradient
2020-09-06 23:01:15 | [drl] epoch #5 | gradient computed
2020-09-06 23:01:15 | [drl] epoch #5 | computing descent direction
2020-09-06 23:01:15 | [drl] epoch #5 | descent direction computed
2020-09-06 23:01:15 | [drl] epoch #5 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:15 | [drl] epoch #5 | Violated because loss is NaN
2020-09-06 23:01:15 | [drl] epoch #5 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:15 | [drl] epoch #5 | backtrack iters: 14
2020-09-06 23:01:15 | [drl] epoch #5 | optimization finished
2020-09-06 23:01:15 | [drl] epoch #5 | Computing KL after
2020-09-06 23:01:15 | [drl] epoch #5 | Computing loss after
2020-09-06 23:01:15 | [drl] epoch #5 | Fitting baseline...
2020-09-06 23:01:15 | [drl] epoch #5 | Saving snapshot...
2020-09-06 23:01:15 | [drl] epoch #5 | Saved
2020-09-06 23:01:15 | [drl] epoch #5 | Time 6.09 s
2020-09-06 23:01:15 | [drl] epoch #5 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -131569
AverageReturn                            -215054
Entropy                                        8.51363
EnvExecTime                                    0.0400577
Extras/EpisodeRewardMean                 -224986
Iteration                                      5
LinearFeatureBaseline/ExplainedVariance        0.927991
MaxReturn                                -215054
MinReturn                                -215054
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0483205
ProcessExecTime                                0.000967979
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:15 | [drl] epoch #6 | Obtaining samples...
2020-09-06 23:01:15 | [drl] epoch #6 | Obtaining samples for iteration 6...
2020-09-06 23:01:15 | [drl] epoch #6 | Logging diagnostics...
2020-09-06 23:01:15 | [drl] epoch #6 | Optimizing policy...
2020-09-06 23:01:15 | [drl] epoch #6 | Computing loss before
2020-09-06 23:01:15 | [drl] epoch #6 | Computing KL before
2020-09-06 23:01:15 | [drl] epoch #6 | Optimizing
2020-09-06 23:01:15 | [drl] epoch #6 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:15 | [drl] epoch #6 | computing loss before
2020-09-06 23:01:15 | [drl] epoch #6 | computing gradient
2020-09-06 23:01:15 | [drl] epoch #6 | gradient computed
2020-09-06 23:01:15 | [drl] epoch #6 | computing descent direction
2020-09-06 23:01:16 | [drl] epoch #6 | descent direction computed
2020-09-06 23:01:16 | [drl] epoch #6 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:16 | [drl] epoch #6 | Violated because loss is NaN
2020-09-06 23:01:16 | [drl] epoch #6 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:16 | [drl] epoch #6 | backtrack iters: 14
2020-09-06 23:01:16 | [drl] epoch #6 | optimization finished
2020-09-06 23:01:16 | [drl] epoch #6 | Computing KL after
2020-09-06 23:01:16 | [drl] epoch #6 | Computing loss after
2020-09-06 23:01:16 | [drl] epoch #6 | Fitting baseline...
2020-09-06 23:01:16 | [drl] epoch #6 | Saving snapshot...
2020-09-06 23:01:16 | [drl] epoch #6 | Saved
2020-09-06 23:01:16 | [drl] epoch #6 | Time 6.85 s
2020-09-06 23:01:16 | [drl] epoch #6 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -100550
AverageReturn                            -164312
Entropy                                        8.51363
EnvExecTime                                    0.0374067
Extras/EpisodeRewardMean                 -216319
Iteration                                      6
LinearFeatureBaseline/ExplainedVariance        0.901804
MaxReturn                                -164312
MinReturn                                -164312
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0450871
ProcessExecTime                                0.00562024
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:16 | [drl] epoch #7 | Obtaining samples...
2020-09-06 23:01:16 | [drl] epoch #7 | Obtaining samples for iteration 7...
2020-09-06 23:01:16 | [drl] epoch #7 | Logging diagnostics...
2020-09-06 23:01:16 | [drl] epoch #7 | Optimizing policy...
2020-09-06 23:01:16 | [drl] epoch #7 | Computing loss before
2020-09-06 23:01:16 | [drl] epoch #7 | Computing KL before
2020-09-06 23:01:16 | [drl] epoch #7 | Optimizing
2020-09-06 23:01:16 | [drl] epoch #7 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:16 | [drl] epoch #7 | computing loss before
2020-09-06 23:01:16 | [drl] epoch #7 | computing gradient
2020-09-06 23:01:16 | [drl] epoch #7 | gradient computed
2020-09-06 23:01:16 | [drl] epoch #7 | computing descent direction
2020-09-06 23:01:17 | [drl] epoch #7 | descent direction computed
2020-09-06 23:01:17 | [drl] epoch #7 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:17 | [drl] epoch #7 | Violated because loss is NaN
2020-09-06 23:01:17 | [drl] epoch #7 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:17 | [drl] epoch #7 | backtrack iters: 14
2020-09-06 23:01:17 | [drl] epoch #7 | optimization finished
2020-09-06 23:01:17 | [drl] epoch #7 | Computing KL after
2020-09-06 23:01:17 | [drl] epoch #7 | Computing loss after
2020-09-06 23:01:17 | [drl] epoch #7 | Fitting baseline...
2020-09-06 23:01:17 | [drl] epoch #7 | Saving snapshot...
2020-09-06 23:01:17 | [drl] epoch #7 | Saved
2020-09-06 23:01:17 | [drl] epoch #7 | Time 7.60 s
2020-09-06 23:01:17 | [drl] epoch #7 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -200005
AverageReturn                            -327052
Entropy                                        8.51363
EnvExecTime                                    0.034409
Extras/EpisodeRewardMean                 -230160
Iteration                                      7
LinearFeatureBaseline/ExplainedVariance        0.748626
MaxReturn                                -327052
MinReturn                                -327052
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0390921
ProcessExecTime                                0.00129032
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:17 | [drl] epoch #8 | Obtaining samples...
2020-09-06 23:01:17 | [drl] epoch #8 | Obtaining samples for iteration 8...
2020-09-06 23:01:17 | [drl] epoch #8 | Logging diagnostics...
2020-09-06 23:01:17 | [drl] epoch #8 | Optimizing policy...
2020-09-06 23:01:17 | [drl] epoch #8 | Computing loss before
2020-09-06 23:01:17 | [drl] epoch #8 | Computing KL before
2020-09-06 23:01:17 | [drl] epoch #8 | Optimizing
2020-09-06 23:01:17 | [drl] epoch #8 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:17 | [drl] epoch #8 | computing loss before
2020-09-06 23:01:17 | [drl] epoch #8 | computing gradient
2020-09-06 23:01:17 | [drl] epoch #8 | gradient computed
2020-09-06 23:01:17 | [drl] epoch #8 | computing descent direction
2020-09-06 23:01:17 | [drl] epoch #8 | descent direction computed
2020-09-06 23:01:17 | [drl] epoch #8 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:17 | [drl] epoch #8 | Violated because loss is NaN
2020-09-06 23:01:17 | [drl] epoch #8 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:17 | [drl] epoch #8 | backtrack iters: 14
2020-09-06 23:01:17 | [drl] epoch #8 | optimization finished
2020-09-06 23:01:17 | [drl] epoch #8 | Computing KL after
2020-09-06 23:01:17 | [drl] epoch #8 | Computing loss after
2020-09-06 23:01:17 | [drl] epoch #8 | Fitting baseline...
2020-09-06 23:01:17 | [drl] epoch #8 | Saving snapshot...
2020-09-06 23:01:17 | [drl] epoch #8 | Saved
2020-09-06 23:01:17 | [drl] epoch #8 | Time 8.36 s
2020-09-06 23:01:17 | [drl] epoch #8 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -144031
AverageReturn                            -235441
Entropy                                        8.51363
EnvExecTime                                    0.0338199
Extras/EpisodeRewardMean                 -230747
Iteration                                      8
LinearFeatureBaseline/ExplainedVariance        0.844583
MaxReturn                                -235441
MinReturn                                -235441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0473423
ProcessExecTime                                0.00098443
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:17 | [drl] epoch #9 | Obtaining samples...
2020-09-06 23:01:17 | [drl] epoch #9 | Obtaining samples for iteration 9...
2020-09-06 23:01:18 | [drl] epoch #9 | Logging diagnostics...
2020-09-06 23:01:18 | [drl] epoch #9 | Optimizing policy...
2020-09-06 23:01:18 | [drl] epoch #9 | Computing loss before
2020-09-06 23:01:18 | [drl] epoch #9 | Computing KL before
2020-09-06 23:01:18 | [drl] epoch #9 | Optimizing
2020-09-06 23:01:18 | [drl] epoch #9 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:18 | [drl] epoch #9 | computing loss before
2020-09-06 23:01:18 | [drl] epoch #9 | computing gradient
2020-09-06 23:01:18 | [drl] epoch #9 | gradient computed
2020-09-06 23:01:18 | [drl] epoch #9 | computing descent direction
2020-09-06 23:01:18 | [drl] epoch #9 | descent direction computed
2020-09-06 23:01:18 | [drl] epoch #9 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:18 | [drl] epoch #9 | Violated because loss is NaN
2020-09-06 23:01:18 | [drl] epoch #9 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:18 | [drl] epoch #9 | backtrack iters: 14
2020-09-06 23:01:18 | [drl] epoch #9 | optimization finished
2020-09-06 23:01:18 | [drl] epoch #9 | Computing KL after
2020-09-06 23:01:18 | [drl] epoch #9 | Computing loss after
2020-09-06 23:01:18 | [drl] epoch #9 | Fitting baseline...
2020-09-06 23:01:18 | [drl] epoch #9 | Saving snapshot...
2020-09-06 23:01:18 | [drl] epoch #9 | Saved
2020-09-06 23:01:18 | [drl] epoch #9 | Time 9.10 s
2020-09-06 23:01:18 | [drl] epoch #9 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -171067
AverageReturn                            -279688
Entropy                                        8.51363
EnvExecTime                                    0.0326798
Extras/EpisodeRewardMean                 -235641
Iteration                                      9
LinearFeatureBaseline/ExplainedVariance        0.974453
MaxReturn                                -279688
MinReturn                                -279688
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0421066
ProcessExecTime                                0.000969648
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:18 | [drl] epoch #10 | Obtaining samples...
2020-09-06 23:01:18 | [drl] epoch #10 | Obtaining samples for iteration 10...
2020-09-06 23:01:18 | [drl] epoch #10 | Logging diagnostics...
2020-09-06 23:01:18 | [drl] epoch #10 | Optimizing policy...
2020-09-06 23:01:18 | [drl] epoch #10 | Computing loss before
2020-09-06 23:01:18 | [drl] epoch #10 | Computing KL before
2020-09-06 23:01:18 | [drl] epoch #10 | Optimizing
2020-09-06 23:01:18 | [drl] epoch #10 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:18 | [drl] epoch #10 | computing loss before
2020-09-06 23:01:18 | [drl] epoch #10 | computing gradient
2020-09-06 23:01:18 | [drl] epoch #10 | gradient computed
2020-09-06 23:01:18 | [drl] epoch #10 | computing descent direction
2020-09-06 23:01:19 | [drl] epoch #10 | descent direction computed
2020-09-06 23:01:19 | [drl] epoch #10 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:19 | [drl] epoch #10 | Violated because loss is NaN
2020-09-06 23:01:19 | [drl] epoch #10 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:19 | [drl] epoch #10 | backtrack iters: 14
2020-09-06 23:01:19 | [drl] epoch #10 | optimization finished
2020-09-06 23:01:19 | [drl] epoch #10 | Computing KL after
2020-09-06 23:01:19 | [drl] epoch #10 | Computing loss after
2020-09-06 23:01:19 | [drl] epoch #10 | Fitting baseline...
2020-09-06 23:01:19 | [drl] epoch #10 | Saving snapshot...
2020-09-06 23:01:19 | [drl] epoch #10 | Saved
2020-09-06 23:01:19 | [drl] epoch #10 | Time 9.86 s
2020-09-06 23:01:19 | [drl] epoch #10 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -77695
AverageReturn                            -126915
Entropy                                        8.51363
EnvExecTime                                    0.0384724
Extras/EpisodeRewardMean                 -225757
Iteration                                     10
LinearFeatureBaseline/ExplainedVariance       -0.499061
MaxReturn                                -126915
MinReturn                                -126915
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0490735
ProcessExecTime                                0.00122213
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:19 | [drl] epoch #11 | Obtaining samples...
2020-09-06 23:01:19 | [drl] epoch #11 | Obtaining samples for iteration 11...
2020-09-06 23:01:19 | [drl] epoch #11 | Logging diagnostics...
2020-09-06 23:01:19 | [drl] epoch #11 | Optimizing policy...
2020-09-06 23:01:19 | [drl] epoch #11 | Computing loss before
2020-09-06 23:01:19 | [drl] epoch #11 | Computing KL before
2020-09-06 23:01:19 | [drl] epoch #11 | Optimizing
2020-09-06 23:01:19 | [drl] epoch #11 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:19 | [drl] epoch #11 | computing loss before
2020-09-06 23:01:19 | [drl] epoch #11 | computing gradient
2020-09-06 23:01:19 | [drl] epoch #11 | gradient computed
2020-09-06 23:01:19 | [drl] epoch #11 | computing descent direction
2020-09-06 23:01:20 | [drl] epoch #11 | descent direction computed
2020-09-06 23:01:20 | [drl] epoch #11 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:20 | [drl] epoch #11 | Violated because loss is NaN
2020-09-06 23:01:20 | [drl] epoch #11 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:20 | [drl] epoch #11 | backtrack iters: 14
2020-09-06 23:01:20 | [drl] epoch #11 | optimization finished
2020-09-06 23:01:20 | [drl] epoch #11 | Computing KL after
2020-09-06 23:01:20 | [drl] epoch #11 | Computing loss after
2020-09-06 23:01:20 | [drl] epoch #11 | Fitting baseline...
2020-09-06 23:01:20 | [drl] epoch #11 | Saving snapshot...
2020-09-06 23:01:20 | [drl] epoch #11 | Saved
2020-09-06 23:01:20 | [drl] epoch #11 | Time 10.62 s
2020-09-06 23:01:20 | [drl] epoch #11 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -97539.2
AverageReturn                            -159379
Entropy                                        8.51363
EnvExecTime                                    0.034606
Extras/EpisodeRewardMean                 -220225
Iteration                                     11
LinearFeatureBaseline/ExplainedVariance        0.957473
MaxReturn                                -159379
MinReturn                                -159379
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0380406
ProcessExecTime                                0.000954151
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:20 | [drl] epoch #12 | Obtaining samples...
2020-09-06 23:01:20 | [drl] epoch #12 | Obtaining samples for iteration 12...
2020-09-06 23:01:20 | [drl] epoch #12 | Logging diagnostics...
2020-09-06 23:01:20 | [drl] epoch #12 | Optimizing policy...
2020-09-06 23:01:20 | [drl] epoch #12 | Computing loss before
2020-09-06 23:01:20 | [drl] epoch #12 | Computing KL before
2020-09-06 23:01:20 | [drl] epoch #12 | Optimizing
2020-09-06 23:01:20 | [drl] epoch #12 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:20 | [drl] epoch #12 | computing loss before
2020-09-06 23:01:20 | [drl] epoch #12 | computing gradient
2020-09-06 23:01:20 | [drl] epoch #12 | gradient computed
2020-09-06 23:01:20 | [drl] epoch #12 | computing descent direction
2020-09-06 23:01:20 | [drl] epoch #12 | descent direction computed
2020-09-06 23:01:20 | [drl] epoch #12 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:20 | [drl] epoch #12 | Violated because loss is NaN
2020-09-06 23:01:20 | [drl] epoch #12 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:20 | [drl] epoch #12 | backtrack iters: 14
2020-09-06 23:01:20 | [drl] epoch #12 | optimization finished
2020-09-06 23:01:20 | [drl] epoch #12 | Computing KL after
2020-09-06 23:01:20 | [drl] epoch #12 | Computing loss after
2020-09-06 23:01:20 | [drl] epoch #12 | Fitting baseline...
2020-09-06 23:01:20 | [drl] epoch #12 | Saving snapshot...
2020-09-06 23:01:20 | [drl] epoch #12 | Saved
2020-09-06 23:01:20 | [drl] epoch #12 | Time 11.38 s
2020-09-06 23:01:20 | [drl] epoch #12 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -171353
AverageReturn                            -280168
Entropy                                        8.51363
EnvExecTime                                    0.039912
Extras/EpisodeRewardMean                 -224836
Iteration                                     12
LinearFeatureBaseline/ExplainedVariance        0.810962
MaxReturn                                -280168
MinReturn                                -280168
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0474668
ProcessExecTime                                0.00100994
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:21 | [drl] epoch #13 | Obtaining samples...
2020-09-06 23:01:21 | [drl] epoch #13 | Obtaining samples for iteration 13...
2020-09-06 23:01:21 | [drl] epoch #13 | Logging diagnostics...
2020-09-06 23:01:21 | [drl] epoch #13 | Optimizing policy...
2020-09-06 23:01:21 | [drl] epoch #13 | Computing loss before
2020-09-06 23:01:21 | [drl] epoch #13 | Computing KL before
2020-09-06 23:01:21 | [drl] epoch #13 | Optimizing
2020-09-06 23:01:21 | [drl] epoch #13 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:21 | [drl] epoch #13 | computing loss before
2020-09-06 23:01:21 | [drl] epoch #13 | computing gradient
2020-09-06 23:01:21 | [drl] epoch #13 | gradient computed
2020-09-06 23:01:21 | [drl] epoch #13 | computing descent direction
2020-09-06 23:01:21 | [drl] epoch #13 | descent direction computed
2020-09-06 23:01:21 | [drl] epoch #13 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:21 | [drl] epoch #13 | Violated because loss is NaN
2020-09-06 23:01:21 | [drl] epoch #13 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:21 | [drl] epoch #13 | backtrack iters: 14
2020-09-06 23:01:21 | [drl] epoch #13 | optimization finished
2020-09-06 23:01:21 | [drl] epoch #13 | Computing KL after
2020-09-06 23:01:21 | [drl] epoch #13 | Computing loss after
2020-09-06 23:01:21 | [drl] epoch #13 | Fitting baseline...
2020-09-06 23:01:21 | [drl] epoch #13 | Saving snapshot...
2020-09-06 23:01:21 | [drl] epoch #13 | Saved
2020-09-06 23:01:21 | [drl] epoch #13 | Time 12.14 s
2020-09-06 23:01:21 | [drl] epoch #13 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -135676
AverageReturn                            -221781
Entropy                                        8.51363
EnvExecTime                                    0.0335972
Extras/EpisodeRewardMean                 -224618
Iteration                                     13
LinearFeatureBaseline/ExplainedVariance        0.929095
MaxReturn                                -221781
MinReturn                                -221781
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0476182
ProcessExecTime                                0.000994444
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:21 | [drl] epoch #14 | Obtaining samples...
2020-09-06 23:01:21 | [drl] epoch #14 | Obtaining samples for iteration 14...
2020-09-06 23:01:21 | [drl] epoch #14 | Logging diagnostics...
2020-09-06 23:01:21 | [drl] epoch #14 | Optimizing policy...
2020-09-06 23:01:21 | [drl] epoch #14 | Computing loss before
2020-09-06 23:01:21 | [drl] epoch #14 | Computing KL before
2020-09-06 23:01:21 | [drl] epoch #14 | Optimizing
2020-09-06 23:01:21 | [drl] epoch #14 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:21 | [drl] epoch #14 | computing loss before
2020-09-06 23:01:21 | [drl] epoch #14 | computing gradient
2020-09-06 23:01:21 | [drl] epoch #14 | gradient computed
2020-09-06 23:01:21 | [drl] epoch #14 | computing descent direction
2020-09-06 23:01:22 | [drl] epoch #14 | descent direction computed
2020-09-06 23:01:22 | [drl] epoch #14 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:22 | [drl] epoch #14 | Violated because loss is NaN
2020-09-06 23:01:22 | [drl] epoch #14 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:22 | [drl] epoch #14 | backtrack iters: 14
2020-09-06 23:01:22 | [drl] epoch #14 | optimization finished
2020-09-06 23:01:22 | [drl] epoch #14 | Computing KL after
2020-09-06 23:01:22 | [drl] epoch #14 | Computing loss after
2020-09-06 23:01:22 | [drl] epoch #14 | Fitting baseline...
2020-09-06 23:01:22 | [drl] epoch #14 | Saving snapshot...
2020-09-06 23:01:22 | [drl] epoch #14 | Saved
2020-09-06 23:01:22 | [drl] epoch #14 | Time 12.89 s
2020-09-06 23:01:22 | [drl] epoch #14 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -93079.6
AverageReturn                            -152079
Entropy                                        8.51363
EnvExecTime                                    0.033814
Extras/EpisodeRewardMean                 -219782
Iteration                                     14
LinearFeatureBaseline/ExplainedVariance        0.783378
MaxReturn                                -152079
MinReturn                                -152079
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0486932
ProcessExecTime                                0.000974894
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:22 | [drl] epoch #15 | Obtaining samples...
2020-09-06 23:01:22 | [drl] epoch #15 | Obtaining samples for iteration 15...
2020-09-06 23:01:22 | [drl] epoch #15 | Logging diagnostics...
2020-09-06 23:01:22 | [drl] epoch #15 | Optimizing policy...
2020-09-06 23:01:22 | [drl] epoch #15 | Computing loss before
2020-09-06 23:01:22 | [drl] epoch #15 | Computing KL before
2020-09-06 23:01:22 | [drl] epoch #15 | Optimizing
2020-09-06 23:01:22 | [drl] epoch #15 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:22 | [drl] epoch #15 | computing loss before
2020-09-06 23:01:22 | [drl] epoch #15 | computing gradient
2020-09-06 23:01:22 | [drl] epoch #15 | gradient computed
2020-09-06 23:01:22 | [drl] epoch #15 | computing descent direction
2020-09-06 23:01:23 | [drl] epoch #15 | descent direction computed
2020-09-06 23:01:23 | [drl] epoch #15 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:23 | [drl] epoch #15 | Violated because loss is NaN
2020-09-06 23:01:23 | [drl] epoch #15 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:23 | [drl] epoch #15 | backtrack iters: 14
2020-09-06 23:01:23 | [drl] epoch #15 | optimization finished
2020-09-06 23:01:23 | [drl] epoch #15 | Computing KL after
2020-09-06 23:01:23 | [drl] epoch #15 | Computing loss after
2020-09-06 23:01:23 | [drl] epoch #15 | Fitting baseline...
2020-09-06 23:01:23 | [drl] epoch #15 | Saving snapshot...
2020-09-06 23:01:23 | [drl] epoch #15 | Saved
2020-09-06 23:01:23 | [drl] epoch #15 | Time 14.06 s
2020-09-06 23:01:23 | [drl] epoch #15 | EpochTime 1.16 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -86820.4
AverageReturn                            -141831
Entropy                                        8.51363
EnvExecTime                                    0.0496018
Extras/EpisodeRewardMean                 -214910
Iteration                                     15
LinearFeatureBaseline/ExplainedVariance        0.994511
MaxReturn                                -141831
MinReturn                                -141831
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0558772
ProcessExecTime                                0.00278783
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:23 | [drl] epoch #16 | Obtaining samples...
2020-09-06 23:01:23 | [drl] epoch #16 | Obtaining samples for iteration 16...
2020-09-06 23:01:23 | [drl] epoch #16 | Logging diagnostics...
2020-09-06 23:01:23 | [drl] epoch #16 | Optimizing policy...
2020-09-06 23:01:23 | [drl] epoch #16 | Computing loss before
2020-09-06 23:01:23 | [drl] epoch #16 | Computing KL before
2020-09-06 23:01:23 | [drl] epoch #16 | Optimizing
2020-09-06 23:01:23 | [drl] epoch #16 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:23 | [drl] epoch #16 | computing loss before
2020-09-06 23:01:23 | [drl] epoch #16 | computing gradient
2020-09-06 23:01:23 | [drl] epoch #16 | gradient computed
2020-09-06 23:01:23 | [drl] epoch #16 | computing descent direction
2020-09-06 23:01:24 | [drl] epoch #16 | descent direction computed
2020-09-06 23:01:24 | [drl] epoch #16 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:24 | [drl] epoch #16 | Violated because loss is NaN
2020-09-06 23:01:24 | [drl] epoch #16 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:24 | [drl] epoch #16 | backtrack iters: 14
2020-09-06 23:01:24 | [drl] epoch #16 | optimization finished
2020-09-06 23:01:24 | [drl] epoch #16 | Computing KL after
2020-09-06 23:01:24 | [drl] epoch #16 | Computing loss after
2020-09-06 23:01:24 | [drl] epoch #16 | Fitting baseline...
2020-09-06 23:01:24 | [drl] epoch #16 | Saving snapshot...
2020-09-06 23:01:24 | [drl] epoch #16 | Saved
2020-09-06 23:01:24 | [drl] epoch #16 | Time 15.35 s
2020-09-06 23:01:24 | [drl] epoch #16 | EpochTime 1.27 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -89177.5
AverageReturn                            -145687
Entropy                                        8.51363
EnvExecTime                                    0.0664399
Extras/EpisodeRewardMean                 -210838
Iteration                                     16
LinearFeatureBaseline/ExplainedVariance        0.999301
MaxReturn                                -145687
MinReturn                                -145687
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0746353
ProcessExecTime                                0.00102186
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:24 | [drl] epoch #17 | Obtaining samples...
2020-09-06 23:01:24 | [drl] epoch #17 | Obtaining samples for iteration 17...
2020-09-06 23:01:25 | [drl] epoch #17 | Logging diagnostics...
2020-09-06 23:01:25 | [drl] epoch #17 | Optimizing policy...
2020-09-06 23:01:25 | [drl] epoch #17 | Computing loss before
2020-09-06 23:01:25 | [drl] epoch #17 | Computing KL before
2020-09-06 23:01:25 | [drl] epoch #17 | Optimizing
2020-09-06 23:01:25 | [drl] epoch #17 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:25 | [drl] epoch #17 | computing loss before
2020-09-06 23:01:25 | [drl] epoch #17 | computing gradient
2020-09-06 23:01:25 | [drl] epoch #17 | gradient computed
2020-09-06 23:01:25 | [drl] epoch #17 | computing descent direction
2020-09-06 23:01:25 | [drl] epoch #17 | descent direction computed
2020-09-06 23:01:25 | [drl] epoch #17 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:25 | [drl] epoch #17 | Violated because loss is NaN
2020-09-06 23:01:25 | [drl] epoch #17 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:25 | [drl] epoch #17 | backtrack iters: 14
2020-09-06 23:01:25 | [drl] epoch #17 | optimization finished
2020-09-06 23:01:25 | [drl] epoch #17 | Computing KL after
2020-09-06 23:01:25 | [drl] epoch #17 | Computing loss after
2020-09-06 23:01:25 | [drl] epoch #17 | Fitting baseline...
2020-09-06 23:01:25 | [drl] epoch #17 | Saving snapshot...
2020-09-06 23:01:25 | [drl] epoch #17 | Saved
2020-09-06 23:01:25 | [drl] epoch #17 | Time 16.17 s
2020-09-06 23:01:25 | [drl] epoch #17 | EpochTime 0.81 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173471
AverageReturn                            -283627
Entropy                                        8.51363
EnvExecTime                                    0.0420973
Extras/EpisodeRewardMean                 -214882
Iteration                                     17
LinearFeatureBaseline/ExplainedVariance        0.758987
MaxReturn                                -283627
MinReturn                                -283627
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0382457
ProcessExecTime                                0.000953913
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:25 | [drl] epoch #18 | Obtaining samples...
2020-09-06 23:01:25 | [drl] epoch #18 | Obtaining samples for iteration 18...
2020-09-06 23:01:25 | [drl] epoch #18 | Logging diagnostics...
2020-09-06 23:01:25 | [drl] epoch #18 | Optimizing policy...
2020-09-06 23:01:25 | [drl] epoch #18 | Computing loss before
2020-09-06 23:01:25 | [drl] epoch #18 | Computing KL before
2020-09-06 23:01:25 | [drl] epoch #18 | Optimizing
2020-09-06 23:01:25 | [drl] epoch #18 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:25 | [drl] epoch #18 | computing loss before
2020-09-06 23:01:25 | [drl] epoch #18 | computing gradient
2020-09-06 23:01:25 | [drl] epoch #18 | gradient computed
2020-09-06 23:01:25 | [drl] epoch #18 | computing descent direction
2020-09-06 23:01:26 | [drl] epoch #18 | descent direction computed
2020-09-06 23:01:26 | [drl] epoch #18 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:26 | [drl] epoch #18 | Violated because loss is NaN
2020-09-06 23:01:26 | [drl] epoch #18 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:26 | [drl] epoch #18 | backtrack iters: 14
2020-09-06 23:01:26 | [drl] epoch #18 | optimization finished
2020-09-06 23:01:26 | [drl] epoch #18 | Computing KL after
2020-09-06 23:01:26 | [drl] epoch #18 | Computing loss after
2020-09-06 23:01:26 | [drl] epoch #18 | Fitting baseline...
2020-09-06 23:01:26 | [drl] epoch #18 | Saving snapshot...
2020-09-06 23:01:26 | [drl] epoch #18 | Saved
2020-09-06 23:01:26 | [drl] epoch #18 | Time 16.93 s
2020-09-06 23:01:26 | [drl] epoch #18 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -90334.2
AverageReturn                            -147591
Entropy                                        8.51363
EnvExecTime                                    0.0400391
Extras/EpisodeRewardMean                 -211341
Iteration                                     18
LinearFeatureBaseline/ExplainedVariance        0.123617
MaxReturn                                -147591
MinReturn                                -147591
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0474429
ProcessExecTime                                0.000947952
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:26 | [drl] epoch #19 | Obtaining samples...
2020-09-06 23:01:26 | [drl] epoch #19 | Obtaining samples for iteration 19...
2020-09-06 23:01:26 | [drl] epoch #19 | Logging diagnostics...
2020-09-06 23:01:26 | [drl] epoch #19 | Optimizing policy...
2020-09-06 23:01:26 | [drl] epoch #19 | Computing loss before
2020-09-06 23:01:26 | [drl] epoch #19 | Computing KL before
2020-09-06 23:01:26 | [drl] epoch #19 | Optimizing
2020-09-06 23:01:26 | [drl] epoch #19 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:26 | [drl] epoch #19 | computing loss before
2020-09-06 23:01:26 | [drl] epoch #19 | computing gradient
2020-09-06 23:01:26 | [drl] epoch #19 | gradient computed
2020-09-06 23:01:26 | [drl] epoch #19 | computing descent direction
2020-09-06 23:01:27 | [drl] epoch #19 | descent direction computed
2020-09-06 23:01:27 | [drl] epoch #19 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:27 | [drl] epoch #19 | Violated because loss is NaN
2020-09-06 23:01:27 | [drl] epoch #19 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:27 | [drl] epoch #19 | backtrack iters: 14
2020-09-06 23:01:27 | [drl] epoch #19 | optimization finished
2020-09-06 23:01:27 | [drl] epoch #19 | Computing KL after
2020-09-06 23:01:27 | [drl] epoch #19 | Computing loss after
2020-09-06 23:01:27 | [drl] epoch #19 | Fitting baseline...
2020-09-06 23:01:27 | [drl] epoch #19 | Saving snapshot...
2020-09-06 23:01:27 | [drl] epoch #19 | Saved
2020-09-06 23:01:27 | [drl] epoch #19 | Time 17.68 s
2020-09-06 23:01:27 | [drl] epoch #19 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106449
AverageReturn                            -173957
Entropy                                        8.51363
EnvExecTime                                    0.0419371
Extras/EpisodeRewardMean                 -209471
Iteration                                     19
LinearFeatureBaseline/ExplainedVariance        0.976486
MaxReturn                                -173957
MinReturn                                -173957
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0432363
ProcessExecTime                                0.000979662
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:27 | [drl] epoch #20 | Obtaining samples...
2020-09-06 23:01:27 | [drl] epoch #20 | Obtaining samples for iteration 20...
2020-09-06 23:01:27 | [drl] epoch #20 | Logging diagnostics...
2020-09-06 23:01:27 | [drl] epoch #20 | Optimizing policy...
2020-09-06 23:01:27 | [drl] epoch #20 | Computing loss before
2020-09-06 23:01:27 | [drl] epoch #20 | Computing KL before
2020-09-06 23:01:27 | [drl] epoch #20 | Optimizing
2020-09-06 23:01:27 | [drl] epoch #20 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:27 | [drl] epoch #20 | computing loss before
2020-09-06 23:01:27 | [drl] epoch #20 | computing gradient
2020-09-06 23:01:27 | [drl] epoch #20 | gradient computed
2020-09-06 23:01:27 | [drl] epoch #20 | computing descent direction
2020-09-06 23:01:27 | [drl] epoch #20 | descent direction computed
2020-09-06 23:01:28 | [drl] epoch #20 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:28 | [drl] epoch #20 | Violated because loss is NaN
2020-09-06 23:01:28 | [drl] epoch #20 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:28 | [drl] epoch #20 | backtrack iters: 14
2020-09-06 23:01:28 | [drl] epoch #20 | optimization finished
2020-09-06 23:01:28 | [drl] epoch #20 | Computing KL after
2020-09-06 23:01:28 | [drl] epoch #20 | Computing loss after
2020-09-06 23:01:28 | [drl] epoch #20 | Fitting baseline...
2020-09-06 23:01:28 | [drl] epoch #20 | Saving snapshot...
2020-09-06 23:01:28 | [drl] epoch #20 | Saved
2020-09-06 23:01:28 | [drl] epoch #20 | Time 18.50 s
2020-09-06 23:01:28 | [drl] epoch #20 | EpochTime 0.80 s
---------------------------------------  ---------------
AverageDiscountedReturn                   -96632.3
AverageReturn                            -157899
Entropy                                        8.51363
EnvExecTime                                    0.0428669
Extras/EpisodeRewardMean                 -207015
Iteration                                     20
LinearFeatureBaseline/ExplainedVariance        0.989373
MaxReturn                                -157899
MinReturn                                -157899
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0379963
ProcessExecTime                                0.0019176
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 23:01:28 | [drl] epoch #21 | Obtaining samples...
2020-09-06 23:01:28 | [drl] epoch #21 | Obtaining samples for iteration 21...
2020-09-06 23:01:28 | [drl] epoch #21 | Logging diagnostics...
2020-09-06 23:01:28 | [drl] epoch #21 | Optimizing policy...
2020-09-06 23:01:28 | [drl] epoch #21 | Computing loss before
2020-09-06 23:01:28 | [drl] epoch #21 | Computing KL before
2020-09-06 23:01:28 | [drl] epoch #21 | Optimizing
2020-09-06 23:01:28 | [drl] epoch #21 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:28 | [drl] epoch #21 | computing loss before
2020-09-06 23:01:28 | [drl] epoch #21 | computing gradient
2020-09-06 23:01:28 | [drl] epoch #21 | gradient computed
2020-09-06 23:01:28 | [drl] epoch #21 | computing descent direction
2020-09-06 23:01:28 | [drl] epoch #21 | descent direction computed
2020-09-06 23:01:28 | [drl] epoch #21 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:28 | [drl] epoch #21 | Violated because loss is NaN
2020-09-06 23:01:28 | [drl] epoch #21 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:28 | [drl] epoch #21 | backtrack iters: 14
2020-09-06 23:01:28 | [drl] epoch #21 | optimization finished
2020-09-06 23:01:28 | [drl] epoch #21 | Computing KL after
2020-09-06 23:01:28 | [drl] epoch #21 | Computing loss after
2020-09-06 23:01:28 | [drl] epoch #21 | Fitting baseline...
2020-09-06 23:01:28 | [drl] epoch #21 | Saving snapshot...
2020-09-06 23:01:28 | [drl] epoch #21 | Saved
2020-09-06 23:01:28 | [drl] epoch #21 | Time 19.31 s
2020-09-06 23:01:28 | [drl] epoch #21 | EpochTime 0.80 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -170612
AverageReturn                            -278935
Entropy                                        8.51363
EnvExecTime                                    0.0446951
Extras/EpisodeRewardMean                 -210285
Iteration                                     21
LinearFeatureBaseline/ExplainedVariance        0.808798
MaxReturn                                -278935
MinReturn                                -278935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0597849
ProcessExecTime                                0.000982761
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:28 | [drl] epoch #22 | Obtaining samples...
2020-09-06 23:01:28 | [drl] epoch #22 | Obtaining samples for iteration 22...
2020-09-06 23:01:29 | [drl] epoch #22 | Logging diagnostics...
2020-09-06 23:01:29 | [drl] epoch #22 | Optimizing policy...
2020-09-06 23:01:29 | [drl] epoch #22 | Computing loss before
2020-09-06 23:01:29 | [drl] epoch #22 | Computing KL before
2020-09-06 23:01:29 | [drl] epoch #22 | Optimizing
2020-09-06 23:01:29 | [drl] epoch #22 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:29 | [drl] epoch #22 | computing loss before
2020-09-06 23:01:29 | [drl] epoch #22 | computing gradient
2020-09-06 23:01:29 | [drl] epoch #22 | gradient computed
2020-09-06 23:01:29 | [drl] epoch #22 | computing descent direction
2020-09-06 23:01:29 | [drl] epoch #22 | descent direction computed
2020-09-06 23:01:29 | [drl] epoch #22 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:29 | [drl] epoch #22 | Violated because loss is NaN
2020-09-06 23:01:29 | [drl] epoch #22 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:29 | [drl] epoch #22 | backtrack iters: 14
2020-09-06 23:01:29 | [drl] epoch #22 | optimization finished
2020-09-06 23:01:29 | [drl] epoch #22 | Computing KL after
2020-09-06 23:01:29 | [drl] epoch #22 | Computing loss after
2020-09-06 23:01:29 | [drl] epoch #22 | Fitting baseline...
2020-09-06 23:01:29 | [drl] epoch #22 | Saving snapshot...
2020-09-06 23:01:29 | [drl] epoch #22 | Saved
2020-09-06 23:01:29 | [drl] epoch #22 | Time 20.07 s
2020-09-06 23:01:29 | [drl] epoch #22 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -142558
AverageReturn                            -233040
Entropy                                        8.51363
EnvExecTime                                    0.0374033
Extras/EpisodeRewardMean                 -211274
Iteration                                     22
LinearFeatureBaseline/ExplainedVariance        0.960675
MaxReturn                                -233040
MinReturn                                -233040
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0401373
ProcessExecTime                                0.00119019
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:29 | [drl] epoch #23 | Obtaining samples...
2020-09-06 23:01:29 | [drl] epoch #23 | Obtaining samples for iteration 23...
2020-09-06 23:01:29 | [drl] epoch #23 | Logging diagnostics...
2020-09-06 23:01:29 | [drl] epoch #23 | Optimizing policy...
2020-09-06 23:01:29 | [drl] epoch #23 | Computing loss before
2020-09-06 23:01:29 | [drl] epoch #23 | Computing KL before
2020-09-06 23:01:29 | [drl] epoch #23 | Optimizing
2020-09-06 23:01:29 | [drl] epoch #23 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:29 | [drl] epoch #23 | computing loss before
2020-09-06 23:01:29 | [drl] epoch #23 | computing gradient
2020-09-06 23:01:29 | [drl] epoch #23 | gradient computed
2020-09-06 23:01:29 | [drl] epoch #23 | computing descent direction
2020-09-06 23:01:30 | [drl] epoch #23 | descent direction computed
2020-09-06 23:01:30 | [drl] epoch #23 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:30 | [drl] epoch #23 | Violated because loss is NaN
2020-09-06 23:01:30 | [drl] epoch #23 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:30 | [drl] epoch #23 | backtrack iters: 14
2020-09-06 23:01:30 | [drl] epoch #23 | optimization finished
2020-09-06 23:01:30 | [drl] epoch #23 | Computing KL after
2020-09-06 23:01:30 | [drl] epoch #23 | Computing loss after
2020-09-06 23:01:30 | [drl] epoch #23 | Fitting baseline...
2020-09-06 23:01:30 | [drl] epoch #23 | Saving snapshot...
2020-09-06 23:01:30 | [drl] epoch #23 | Saved
2020-09-06 23:01:30 | [drl] epoch #23 | Time 20.90 s
2020-09-06 23:01:30 | [drl] epoch #23 | EpochTime 0.82 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -176606
AverageReturn                            -288756
Entropy                                        8.51363
EnvExecTime                                    0.041321
Extras/EpisodeRewardMean                 -214502
Iteration                                     23
LinearFeatureBaseline/ExplainedVariance        0.962094
MaxReturn                                -288756
MinReturn                                -288756
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0382137
ProcessExecTime                                0.00101018
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:30 | [drl] epoch #24 | Obtaining samples...
2020-09-06 23:01:30 | [drl] epoch #24 | Obtaining samples for iteration 24...
2020-09-06 23:01:30 | [drl] epoch #24 | Logging diagnostics...
2020-09-06 23:01:30 | [drl] epoch #24 | Optimizing policy...
2020-09-06 23:01:30 | [drl] epoch #24 | Computing loss before
2020-09-06 23:01:30 | [drl] epoch #24 | Computing KL before
2020-09-06 23:01:30 | [drl] epoch #24 | Optimizing
2020-09-06 23:01:30 | [drl] epoch #24 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:30 | [drl] epoch #24 | computing loss before
2020-09-06 23:01:30 | [drl] epoch #24 | computing gradient
2020-09-06 23:01:30 | [drl] epoch #24 | gradient computed
2020-09-06 23:01:30 | [drl] epoch #24 | computing descent direction
2020-09-06 23:01:31 | [drl] epoch #24 | descent direction computed
2020-09-06 23:01:31 | [drl] epoch #24 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:31 | [drl] epoch #24 | Violated because loss is NaN
2020-09-06 23:01:31 | [drl] epoch #24 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:31 | [drl] epoch #24 | backtrack iters: 14
2020-09-06 23:01:31 | [drl] epoch #24 | optimization finished
2020-09-06 23:01:31 | [drl] epoch #24 | Computing KL after
2020-09-06 23:01:31 | [drl] epoch #24 | Computing loss after
2020-09-06 23:01:31 | [drl] epoch #24 | Fitting baseline...
2020-09-06 23:01:31 | [drl] epoch #24 | Saving snapshot...
2020-09-06 23:01:31 | [drl] epoch #24 | Saved
2020-09-06 23:01:31 | [drl] epoch #24 | Time 21.70 s
2020-09-06 23:01:31 | [drl] epoch #24 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -109849
AverageReturn                            -179519
Entropy                                        8.51363
EnvExecTime                                    0.0418522
Extras/EpisodeRewardMean                 -213103
Iteration                                     24
LinearFeatureBaseline/ExplainedVariance        0.619529
MaxReturn                                -179519
MinReturn                                -179519
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.051435
ProcessExecTime                                0.000970125
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:31 | [drl] epoch #25 | Obtaining samples...
2020-09-06 23:01:31 | [drl] epoch #25 | Obtaining samples for iteration 25...
2020-09-06 23:01:31 | [drl] epoch #25 | Logging diagnostics...
2020-09-06 23:01:31 | [drl] epoch #25 | Optimizing policy...
2020-09-06 23:01:31 | [drl] epoch #25 | Computing loss before
2020-09-06 23:01:31 | [drl] epoch #25 | Computing KL before
2020-09-06 23:01:31 | [drl] epoch #25 | Optimizing
2020-09-06 23:01:31 | [drl] epoch #25 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:31 | [drl] epoch #25 | computing loss before
2020-09-06 23:01:31 | [drl] epoch #25 | computing gradient
2020-09-06 23:01:31 | [drl] epoch #25 | gradient computed
2020-09-06 23:01:31 | [drl] epoch #25 | computing descent direction
2020-09-06 23:01:31 | [drl] epoch #25 | descent direction computed
2020-09-06 23:01:32 | [drl] epoch #25 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:32 | [drl] epoch #25 | Violated because loss is NaN
2020-09-06 23:01:32 | [drl] epoch #25 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:32 | [drl] epoch #25 | backtrack iters: 14
2020-09-06 23:01:32 | [drl] epoch #25 | optimization finished
2020-09-06 23:01:32 | [drl] epoch #25 | Computing KL after
2020-09-06 23:01:32 | [drl] epoch #25 | Computing loss after
2020-09-06 23:01:32 | [drl] epoch #25 | Fitting baseline...
2020-09-06 23:01:32 | [drl] epoch #25 | Saving snapshot...
2020-09-06 23:01:32 | [drl] epoch #25 | Saved
2020-09-06 23:01:32 | [drl] epoch #25 | Time 22.46 s
2020-09-06 23:01:32 | [drl] epoch #25 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -105961
AverageReturn                            -173154
Entropy                                        8.51363
EnvExecTime                                    0.0336032
Extras/EpisodeRewardMean                 -211567
Iteration                                     25
LinearFeatureBaseline/ExplainedVariance        0.998613
MaxReturn                                -173154
MinReturn                                -173154
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0534966
ProcessExecTime                                0.00097394
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:32 | [drl] epoch #26 | Obtaining samples...
2020-09-06 23:01:32 | [drl] epoch #26 | Obtaining samples for iteration 26...
2020-09-06 23:01:32 | [drl] epoch #26 | Logging diagnostics...
2020-09-06 23:01:32 | [drl] epoch #26 | Optimizing policy...
2020-09-06 23:01:32 | [drl] epoch #26 | Computing loss before
2020-09-06 23:01:32 | [drl] epoch #26 | Computing KL before
2020-09-06 23:01:32 | [drl] epoch #26 | Optimizing
2020-09-06 23:01:32 | [drl] epoch #26 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:32 | [drl] epoch #26 | computing loss before
2020-09-06 23:01:32 | [drl] epoch #26 | computing gradient
2020-09-06 23:01:32 | [drl] epoch #26 | gradient computed
2020-09-06 23:01:32 | [drl] epoch #26 | computing descent direction
2020-09-06 23:01:32 | [drl] epoch #26 | descent direction computed
2020-09-06 23:01:32 | [drl] epoch #26 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:32 | [drl] epoch #26 | Violated because loss is NaN
2020-09-06 23:01:32 | [drl] epoch #26 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:32 | [drl] epoch #26 | backtrack iters: 14
2020-09-06 23:01:32 | [drl] epoch #26 | optimization finished
2020-09-06 23:01:32 | [drl] epoch #26 | Computing KL after
2020-09-06 23:01:32 | [drl] epoch #26 | Computing loss after
2020-09-06 23:01:32 | [drl] epoch #26 | Fitting baseline...
2020-09-06 23:01:32 | [drl] epoch #26 | Saving snapshot...
2020-09-06 23:01:32 | [drl] epoch #26 | Saved
2020-09-06 23:01:32 | [drl] epoch #26 | Time 23.30 s
2020-09-06 23:01:32 | [drl] epoch #26 | EpochTime 0.84 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -123080
AverageReturn                            -201169
Entropy                                        8.51363
EnvExecTime                                    0.0403242
Extras/EpisodeRewardMean                 -211181
Iteration                                     26
LinearFeatureBaseline/ExplainedVariance        0.980211
MaxReturn                                -201169
MinReturn                                -201169
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.039952
ProcessExecTime                                0.000992298
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:32 | [drl] epoch #27 | Obtaining samples...
2020-09-06 23:01:32 | [drl] epoch #27 | Obtaining samples for iteration 27...
2020-09-06 23:01:33 | [drl] epoch #27 | Logging diagnostics...
2020-09-06 23:01:33 | [drl] epoch #27 | Optimizing policy...
2020-09-06 23:01:33 | [drl] epoch #27 | Computing loss before
2020-09-06 23:01:33 | [drl] epoch #27 | Computing KL before
2020-09-06 23:01:33 | [drl] epoch #27 | Optimizing
2020-09-06 23:01:33 | [drl] epoch #27 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:33 | [drl] epoch #27 | computing loss before
2020-09-06 23:01:33 | [drl] epoch #27 | computing gradient
2020-09-06 23:01:33 | [drl] epoch #27 | gradient computed
2020-09-06 23:01:33 | [drl] epoch #27 | computing descent direction
2020-09-06 23:01:33 | [drl] epoch #27 | descent direction computed
2020-09-06 23:01:33 | [drl] epoch #27 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:33 | [drl] epoch #27 | Violated because loss is NaN
2020-09-06 23:01:33 | [drl] epoch #27 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:33 | [drl] epoch #27 | backtrack iters: 14
2020-09-06 23:01:33 | [drl] epoch #27 | optimization finished
2020-09-06 23:01:33 | [drl] epoch #27 | Computing KL after
2020-09-06 23:01:33 | [drl] epoch #27 | Computing loss after
2020-09-06 23:01:33 | [drl] epoch #27 | Fitting baseline...
2020-09-06 23:01:33 | [drl] epoch #27 | Saving snapshot...
2020-09-06 23:01:33 | [drl] epoch #27 | Saved
2020-09-06 23:01:33 | [drl] epoch #27 | Time 24.10 s
2020-09-06 23:01:33 | [drl] epoch #27 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -98838.3
AverageReturn                            -161501
Entropy                                        8.51363
EnvExecTime                                    0.0383098
Extras/EpisodeRewardMean                 -209407
Iteration                                     27
LinearFeatureBaseline/ExplainedVariance        0.937946
MaxReturn                                -161501
MinReturn                                -161501
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.059634
ProcessExecTime                                0.000993252
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:33 | [drl] epoch #28 | Obtaining samples...
2020-09-06 23:01:33 | [drl] epoch #28 | Obtaining samples for iteration 28...
2020-09-06 23:01:33 | [drl] epoch #28 | Logging diagnostics...
2020-09-06 23:01:33 | [drl] epoch #28 | Optimizing policy...
2020-09-06 23:01:33 | [drl] epoch #28 | Computing loss before
2020-09-06 23:01:33 | [drl] epoch #28 | Computing KL before
2020-09-06 23:01:33 | [drl] epoch #28 | Optimizing
2020-09-06 23:01:33 | [drl] epoch #28 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:33 | [drl] epoch #28 | computing loss before
2020-09-06 23:01:33 | [drl] epoch #28 | computing gradient
2020-09-06 23:01:33 | [drl] epoch #28 | gradient computed
2020-09-06 23:01:33 | [drl] epoch #28 | computing descent direction
2020-09-06 23:01:34 | [drl] epoch #28 | descent direction computed
2020-09-06 23:01:34 | [drl] epoch #28 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:34 | [drl] epoch #28 | Violated because loss is NaN
2020-09-06 23:01:34 | [drl] epoch #28 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:34 | [drl] epoch #28 | backtrack iters: 14
2020-09-06 23:01:34 | [drl] epoch #28 | optimization finished
2020-09-06 23:01:34 | [drl] epoch #28 | Computing KL after
2020-09-06 23:01:34 | [drl] epoch #28 | Computing loss after
2020-09-06 23:01:34 | [drl] epoch #28 | Fitting baseline...
2020-09-06 23:01:34 | [drl] epoch #28 | Saving snapshot...
2020-09-06 23:01:34 | [drl] epoch #28 | Saved
2020-09-06 23:01:34 | [drl] epoch #28 | Time 24.85 s
2020-09-06 23:01:34 | [drl] epoch #28 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -76607.3
AverageReturn                            -125122
Entropy                                        8.51363
EnvExecTime                                    0.0383694
Extras/EpisodeRewardMean                 -206501
Iteration                                     28
LinearFeatureBaseline/ExplainedVariance        0.912185
MaxReturn                                -125122
MinReturn                                -125122
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0413048
ProcessExecTime                                0.000985861
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:34 | [drl] epoch #29 | Obtaining samples...
2020-09-06 23:01:34 | [drl] epoch #29 | Obtaining samples for iteration 29...
2020-09-06 23:01:34 | [drl] epoch #29 | Logging diagnostics...
2020-09-06 23:01:34 | [drl] epoch #29 | Optimizing policy...
2020-09-06 23:01:34 | [drl] epoch #29 | Computing loss before
2020-09-06 23:01:34 | [drl] epoch #29 | Computing KL before
2020-09-06 23:01:34 | [drl] epoch #29 | Optimizing
2020-09-06 23:01:34 | [drl] epoch #29 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:34 | [drl] epoch #29 | computing loss before
2020-09-06 23:01:34 | [drl] epoch #29 | computing gradient
2020-09-06 23:01:34 | [drl] epoch #29 | gradient computed
2020-09-06 23:01:34 | [drl] epoch #29 | computing descent direction
2020-09-06 23:01:35 | [drl] epoch #29 | descent direction computed
2020-09-06 23:01:35 | [drl] epoch #29 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:35 | [drl] epoch #29 | Violated because loss is NaN
2020-09-06 23:01:35 | [drl] epoch #29 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:35 | [drl] epoch #29 | backtrack iters: 14
2020-09-06 23:01:35 | [drl] epoch #29 | optimization finished
2020-09-06 23:01:35 | [drl] epoch #29 | Computing KL after
2020-09-06 23:01:35 | [drl] epoch #29 | Computing loss after
2020-09-06 23:01:35 | [drl] epoch #29 | Fitting baseline...
2020-09-06 23:01:35 | [drl] epoch #29 | Saving snapshot...
2020-09-06 23:01:35 | [drl] epoch #29 | Saved
2020-09-06 23:01:35 | [drl] epoch #29 | Time 25.64 s
2020-09-06 23:01:35 | [drl] epoch #29 | EpochTime 0.78 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101247
AverageReturn                            -165454
Entropy                                        8.51363
EnvExecTime                                    0.0355146
Extras/EpisodeRewardMean                 -205133
Iteration                                     29
LinearFeatureBaseline/ExplainedVariance        0.938442
MaxReturn                                -165454
MinReturn                                -165454
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0405781
ProcessExecTime                                0.000967503
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:35 | [drl] epoch #30 | Obtaining samples...
2020-09-06 23:01:35 | [drl] epoch #30 | Obtaining samples for iteration 30...
2020-09-06 23:01:35 | [drl] epoch #30 | Logging diagnostics...
2020-09-06 23:01:35 | [drl] epoch #30 | Optimizing policy...
2020-09-06 23:01:35 | [drl] epoch #30 | Computing loss before
2020-09-06 23:01:35 | [drl] epoch #30 | Computing KL before
2020-09-06 23:01:35 | [drl] epoch #30 | Optimizing
2020-09-06 23:01:35 | [drl] epoch #30 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:35 | [drl] epoch #30 | computing loss before
2020-09-06 23:01:35 | [drl] epoch #30 | computing gradient
2020-09-06 23:01:35 | [drl] epoch #30 | gradient computed
2020-09-06 23:01:35 | [drl] epoch #30 | computing descent direction
2020-09-06 23:01:36 | [drl] epoch #30 | descent direction computed
2020-09-06 23:01:36 | [drl] epoch #30 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:36 | [drl] epoch #30 | Violated because loss is NaN
2020-09-06 23:01:36 | [drl] epoch #30 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:36 | [drl] epoch #30 | backtrack iters: 14
2020-09-06 23:01:36 | [drl] epoch #30 | optimization finished
2020-09-06 23:01:36 | [drl] epoch #30 | Computing KL after
2020-09-06 23:01:36 | [drl] epoch #30 | Computing loss after
2020-09-06 23:01:36 | [drl] epoch #30 | Fitting baseline...
2020-09-06 23:01:36 | [drl] epoch #30 | Saving snapshot...
2020-09-06 23:01:36 | [drl] epoch #30 | Saved
2020-09-06 23:01:36 | [drl] epoch #30 | Time 26.53 s
2020-09-06 23:01:36 | [drl] epoch #30 | EpochTime 0.88 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -122695
AverageReturn                            -200540
Entropy                                        8.51363
EnvExecTime                                    0.0484607
Extras/EpisodeRewardMean                 -204984
Iteration                                     30
LinearFeatureBaseline/ExplainedVariance        0.968962
MaxReturn                                -200540
MinReturn                                -200540
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0669372
ProcessExecTime                                0.00101876
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:36 | [drl] epoch #31 | Obtaining samples...
2020-09-06 23:01:36 | [drl] epoch #31 | Obtaining samples for iteration 31...
2020-09-06 23:01:36 | [drl] epoch #31 | Logging diagnostics...
2020-09-06 23:01:36 | [drl] epoch #31 | Optimizing policy...
2020-09-06 23:01:36 | [drl] epoch #31 | Computing loss before
2020-09-06 23:01:36 | [drl] epoch #31 | Computing KL before
2020-09-06 23:01:36 | [drl] epoch #31 | Optimizing
2020-09-06 23:01:36 | [drl] epoch #31 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:36 | [drl] epoch #31 | computing loss before
2020-09-06 23:01:36 | [drl] epoch #31 | computing gradient
2020-09-06 23:01:36 | [drl] epoch #31 | gradient computed
2020-09-06 23:01:36 | [drl] epoch #31 | computing descent direction
2020-09-06 23:01:36 | [drl] epoch #31 | descent direction computed
2020-09-06 23:01:36 | [drl] epoch #31 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:36 | [drl] epoch #31 | Violated because loss is NaN
2020-09-06 23:01:36 | [drl] epoch #31 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:36 | [drl] epoch #31 | backtrack iters: 14
2020-09-06 23:01:36 | [drl] epoch #31 | optimization finished
2020-09-06 23:01:36 | [drl] epoch #31 | Computing KL after
2020-09-06 23:01:36 | [drl] epoch #31 | Computing loss after
2020-09-06 23:01:36 | [drl] epoch #31 | Fitting baseline...
2020-09-06 23:01:36 | [drl] epoch #31 | Saving snapshot...
2020-09-06 23:01:36 | [drl] epoch #31 | Saved
2020-09-06 23:01:36 | [drl] epoch #31 | Time 27.33 s
2020-09-06 23:01:36 | [drl] epoch #31 | EpochTime 0.79 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -81070.4
AverageReturn                            -132436
Entropy                                        8.51363
EnvExecTime                                    0.0336049
Extras/EpisodeRewardMean                 -202717
Iteration                                     31
LinearFeatureBaseline/ExplainedVariance        0.727661
MaxReturn                                -132436
MinReturn                                -132436
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0486534
ProcessExecTime                                0.00103164
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:36 | [drl] epoch #32 | Obtaining samples...
2020-09-06 23:01:36 | [drl] epoch #32 | Obtaining samples for iteration 32...
2020-09-06 23:01:37 | [drl] epoch #32 | Logging diagnostics...
2020-09-06 23:01:37 | [drl] epoch #32 | Optimizing policy...
2020-09-06 23:01:37 | [drl] epoch #32 | Computing loss before
2020-09-06 23:01:37 | [drl] epoch #32 | Computing KL before
2020-09-06 23:01:37 | [drl] epoch #32 | Optimizing
2020-09-06 23:01:37 | [drl] epoch #32 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:37 | [drl] epoch #32 | computing loss before
2020-09-06 23:01:37 | [drl] epoch #32 | computing gradient
2020-09-06 23:01:37 | [drl] epoch #32 | gradient computed
2020-09-06 23:01:37 | [drl] epoch #32 | computing descent direction
2020-09-06 23:01:37 | [drl] epoch #32 | descent direction computed
2020-09-06 23:01:37 | [drl] epoch #32 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:37 | [drl] epoch #32 | Violated because loss is NaN
2020-09-06 23:01:37 | [drl] epoch #32 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:37 | [drl] epoch #32 | backtrack iters: 14
2020-09-06 23:01:37 | [drl] epoch #32 | optimization finished
2020-09-06 23:01:37 | [drl] epoch #32 | Computing KL after
2020-09-06 23:01:37 | [drl] epoch #32 | Computing loss after
2020-09-06 23:01:37 | [drl] epoch #32 | Fitting baseline...
2020-09-06 23:01:37 | [drl] epoch #32 | Saving snapshot...
2020-09-06 23:01:37 | [drl] epoch #32 | Saved
2020-09-06 23:01:37 | [drl] epoch #32 | Time 28.15 s
2020-09-06 23:01:37 | [drl] epoch #32 | EpochTime 0.80 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -152810
AverageReturn                            -249823
Entropy                                        8.51363
EnvExecTime                                    0.0390825
Extras/EpisodeRewardMean                 -204145
Iteration                                     32
LinearFeatureBaseline/ExplainedVariance        0.77543
MaxReturn                                -249823
MinReturn                                -249823
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0553598
ProcessExecTime                                0.0010078
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 23:01:37 | [drl] epoch #33 | Obtaining samples...
2020-09-06 23:01:37 | [drl] epoch #33 | Obtaining samples for iteration 33...
2020-09-06 23:01:37 | [drl] epoch #33 | Logging diagnostics...
2020-09-06 23:01:37 | [drl] epoch #33 | Optimizing policy...
2020-09-06 23:01:37 | [drl] epoch #33 | Computing loss before
2020-09-06 23:01:37 | [drl] epoch #33 | Computing KL before
2020-09-06 23:01:37 | [drl] epoch #33 | Optimizing
2020-09-06 23:01:37 | [drl] epoch #33 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:37 | [drl] epoch #33 | computing loss before
2020-09-06 23:01:37 | [drl] epoch #33 | computing gradient
2020-09-06 23:01:37 | [drl] epoch #33 | gradient computed
2020-09-06 23:01:37 | [drl] epoch #33 | computing descent direction
2020-09-06 23:01:38 | [drl] epoch #33 | descent direction computed
2020-09-06 23:01:38 | [drl] epoch #33 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:38 | [drl] epoch #33 | Violated because loss is NaN
2020-09-06 23:01:38 | [drl] epoch #33 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:38 | [drl] epoch #33 | backtrack iters: 14
2020-09-06 23:01:38 | [drl] epoch #33 | optimization finished
2020-09-06 23:01:38 | [drl] epoch #33 | Computing KL after
2020-09-06 23:01:38 | [drl] epoch #33 | Computing loss after
2020-09-06 23:01:38 | [drl] epoch #33 | Fitting baseline...
2020-09-06 23:01:38 | [drl] epoch #33 | Saving snapshot...
2020-09-06 23:01:38 | [drl] epoch #33 | Saved
2020-09-06 23:01:38 | [drl] epoch #33 | Time 28.99 s
2020-09-06 23:01:38 | [drl] epoch #33 | EpochTime 0.83 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -149549
AverageReturn                            -244485
Entropy                                        8.51363
EnvExecTime                                    0.0385878
Extras/EpisodeRewardMean                 -205331
Iteration                                     33
LinearFeatureBaseline/ExplainedVariance        0.999521
MaxReturn                                -244485
MinReturn                                -244485
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0498617
ProcessExecTime                                0.000944138
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:38 | [drl] epoch #34 | Obtaining samples...
2020-09-06 23:01:38 | [drl] epoch #34 | Obtaining samples for iteration 34...
2020-09-06 23:01:38 | [drl] epoch #34 | Logging diagnostics...
2020-09-06 23:01:38 | [drl] epoch #34 | Optimizing policy...
2020-09-06 23:01:38 | [drl] epoch #34 | Computing loss before
2020-09-06 23:01:38 | [drl] epoch #34 | Computing KL before
2020-09-06 23:01:38 | [drl] epoch #34 | Optimizing
2020-09-06 23:01:38 | [drl] epoch #34 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:38 | [drl] epoch #34 | computing loss before
2020-09-06 23:01:38 | [drl] epoch #34 | computing gradient
2020-09-06 23:01:38 | [drl] epoch #34 | gradient computed
2020-09-06 23:01:38 | [drl] epoch #34 | computing descent direction
2020-09-06 23:01:39 | [drl] epoch #34 | descent direction computed
2020-09-06 23:01:39 | [drl] epoch #34 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:39 | [drl] epoch #34 | Violated because loss is NaN
2020-09-06 23:01:39 | [drl] epoch #34 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:39 | [drl] epoch #34 | backtrack iters: 14
2020-09-06 23:01:39 | [drl] epoch #34 | optimization finished
2020-09-06 23:01:39 | [drl] epoch #34 | Computing KL after
2020-09-06 23:01:39 | [drl] epoch #34 | Computing loss after
2020-09-06 23:01:39 | [drl] epoch #34 | Fitting baseline...
2020-09-06 23:01:39 | [drl] epoch #34 | Saving snapshot...
2020-09-06 23:01:39 | [drl] epoch #34 | Saved
2020-09-06 23:01:39 | [drl] epoch #34 | Time 29.77 s
2020-09-06 23:01:39 | [drl] epoch #34 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -105282
AverageReturn                            -172041
Entropy                                        8.51363
EnvExecTime                                    0.0381501
Extras/EpisodeRewardMean                 -204380
Iteration                                     34
LinearFeatureBaseline/ExplainedVariance        0.8175
MaxReturn                                -172041
MinReturn                                -172041
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0480289
ProcessExecTime                                0.00145173
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:39 | [drl] epoch #35 | Obtaining samples...
2020-09-06 23:01:39 | [drl] epoch #35 | Obtaining samples for iteration 35...
2020-09-06 23:01:39 | [drl] epoch #35 | Logging diagnostics...
2020-09-06 23:01:39 | [drl] epoch #35 | Optimizing policy...
2020-09-06 23:01:39 | [drl] epoch #35 | Computing loss before
2020-09-06 23:01:39 | [drl] epoch #35 | Computing KL before
2020-09-06 23:01:39 | [drl] epoch #35 | Optimizing
2020-09-06 23:01:39 | [drl] epoch #35 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:39 | [drl] epoch #35 | computing loss before
2020-09-06 23:01:39 | [drl] epoch #35 | computing gradient
2020-09-06 23:01:39 | [drl] epoch #35 | gradient computed
2020-09-06 23:01:39 | [drl] epoch #35 | computing descent direction
2020-09-06 23:01:40 | [drl] epoch #35 | descent direction computed
2020-09-06 23:01:40 | [drl] epoch #35 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:40 | [drl] epoch #35 | Violated because loss is NaN
2020-09-06 23:01:40 | [drl] epoch #35 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:40 | [drl] epoch #35 | backtrack iters: 14
2020-09-06 23:01:40 | [drl] epoch #35 | optimization finished
2020-09-06 23:01:40 | [drl] epoch #35 | Computing KL after
2020-09-06 23:01:40 | [drl] epoch #35 | Computing loss after
2020-09-06 23:01:40 | [drl] epoch #35 | Fitting baseline...
2020-09-06 23:01:40 | [drl] epoch #35 | Saving snapshot...
2020-09-06 23:01:40 | [drl] epoch #35 | Saved
2020-09-06 23:01:40 | [drl] epoch #35 | Time 30.64 s
2020-09-06 23:01:40 | [drl] epoch #35 | EpochTime 0.86 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -83754.4
AverageReturn                            -136818
Entropy                                        8.51363
EnvExecTime                                    0.0335324
Extras/EpisodeRewardMean                 -202503
Iteration                                     35
LinearFeatureBaseline/ExplainedVariance        0.931261
MaxReturn                                -136818
MinReturn                                -136818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0513246
ProcessExecTime                                0.000996828
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:40 | [drl] epoch #36 | Obtaining samples...
2020-09-06 23:01:40 | [drl] epoch #36 | Obtaining samples for iteration 36...
2020-09-06 23:01:40 | [drl] epoch #36 | Logging diagnostics...
2020-09-06 23:01:40 | [drl] epoch #36 | Optimizing policy...
2020-09-06 23:01:40 | [drl] epoch #36 | Computing loss before
2020-09-06 23:01:40 | [drl] epoch #36 | Computing KL before
2020-09-06 23:01:40 | [drl] epoch #36 | Optimizing
2020-09-06 23:01:40 | [drl] epoch #36 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:40 | [drl] epoch #36 | computing loss before
2020-09-06 23:01:40 | [drl] epoch #36 | computing gradient
2020-09-06 23:01:40 | [drl] epoch #36 | gradient computed
2020-09-06 23:01:40 | [drl] epoch #36 | computing descent direction
2020-09-06 23:01:40 | [drl] epoch #36 | descent direction computed
2020-09-06 23:01:41 | [drl] epoch #36 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:41 | [drl] epoch #36 | Violated because loss is NaN
2020-09-06 23:01:41 | [drl] epoch #36 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:41 | [drl] epoch #36 | backtrack iters: 14
2020-09-06 23:01:41 | [drl] epoch #36 | optimization finished
2020-09-06 23:01:41 | [drl] epoch #36 | Computing KL after
2020-09-06 23:01:41 | [drl] epoch #36 | Computing loss after
2020-09-06 23:01:41 | [drl] epoch #36 | Fitting baseline...
2020-09-06 23:01:41 | [drl] epoch #36 | Saving snapshot...
2020-09-06 23:01:41 | [drl] epoch #36 | Saved
2020-09-06 23:01:41 | [drl] epoch #36 | Time 31.43 s
2020-09-06 23:01:41 | [drl] epoch #36 | EpochTime 0.78 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -95636
AverageReturn                            -156260
Entropy                                        8.51363
EnvExecTime                                    0.0389998
Extras/EpisodeRewardMean                 -201253
Iteration                                     36
LinearFeatureBaseline/ExplainedVariance        0.983943
MaxReturn                                -156260
MinReturn                                -156260
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0497975
ProcessExecTime                                0.00102949
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:41 | [drl] epoch #37 | Obtaining samples...
2020-09-06 23:01:41 | [drl] epoch #37 | Obtaining samples for iteration 37...
2020-09-06 23:01:41 | [drl] epoch #37 | Logging diagnostics...
2020-09-06 23:01:41 | [drl] epoch #37 | Optimizing policy...
2020-09-06 23:01:41 | [drl] epoch #37 | Computing loss before
2020-09-06 23:01:41 | [drl] epoch #37 | Computing KL before
2020-09-06 23:01:41 | [drl] epoch #37 | Optimizing
2020-09-06 23:01:41 | [drl] epoch #37 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:41 | [drl] epoch #37 | computing loss before
2020-09-06 23:01:41 | [drl] epoch #37 | computing gradient
2020-09-06 23:01:41 | [drl] epoch #37 | gradient computed
2020-09-06 23:01:41 | [drl] epoch #37 | computing descent direction
2020-09-06 23:01:41 | [drl] epoch #37 | descent direction computed
2020-09-06 23:01:41 | [drl] epoch #37 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:41 | [drl] epoch #37 | Violated because loss is NaN
2020-09-06 23:01:41 | [drl] epoch #37 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:41 | [drl] epoch #37 | backtrack iters: 14
2020-09-06 23:01:41 | [drl] epoch #37 | optimization finished
2020-09-06 23:01:41 | [drl] epoch #37 | Computing KL after
2020-09-06 23:01:41 | [drl] epoch #37 | Computing loss after
2020-09-06 23:01:41 | [drl] epoch #37 | Fitting baseline...
2020-09-06 23:01:41 | [drl] epoch #37 | Saving snapshot...
2020-09-06 23:01:41 | [drl] epoch #37 | Saved
2020-09-06 23:01:41 | [drl] epoch #37 | Time 32.22 s
2020-09-06 23:01:41 | [drl] epoch #37 | EpochTime 0.78 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -127458
AverageReturn                            -208340
Entropy                                        8.51363
EnvExecTime                                    0.0349267
Extras/EpisodeRewardMean                 -201440
Iteration                                     37
LinearFeatureBaseline/ExplainedVariance        0.936051
MaxReturn                                -208340
MinReturn                                -208340
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0553658
ProcessExecTime                                0.00100446
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:41 | [drl] epoch #38 | Obtaining samples...
2020-09-06 23:01:41 | [drl] epoch #38 | Obtaining samples for iteration 38...
2020-09-06 23:01:41 | [drl] epoch #38 | Logging diagnostics...
2020-09-06 23:01:41 | [drl] epoch #38 | Optimizing policy...
2020-09-06 23:01:41 | [drl] epoch #38 | Computing loss before
2020-09-06 23:01:41 | [drl] epoch #38 | Computing KL before
2020-09-06 23:01:41 | [drl] epoch #38 | Optimizing
2020-09-06 23:01:41 | [drl] epoch #38 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:41 | [drl] epoch #38 | computing loss before
2020-09-06 23:01:41 | [drl] epoch #38 | computing gradient
2020-09-06 23:01:41 | [drl] epoch #38 | gradient computed
2020-09-06 23:01:41 | [drl] epoch #38 | computing descent direction
2020-09-06 23:01:42 | [drl] epoch #38 | descent direction computed
2020-09-06 23:01:42 | [drl] epoch #38 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:42 | [drl] epoch #38 | Violated because loss is NaN
2020-09-06 23:01:42 | [drl] epoch #38 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:42 | [drl] epoch #38 | backtrack iters: 14
2020-09-06 23:01:42 | [drl] epoch #38 | optimization finished
2020-09-06 23:01:42 | [drl] epoch #38 | Computing KL after
2020-09-06 23:01:42 | [drl] epoch #38 | Computing loss after
2020-09-06 23:01:42 | [drl] epoch #38 | Fitting baseline...
2020-09-06 23:01:42 | [drl] epoch #38 | Saving snapshot...
2020-09-06 23:01:42 | [drl] epoch #38 | Saved
2020-09-06 23:01:42 | [drl] epoch #38 | Time 33.00 s
2020-09-06 23:01:42 | [drl] epoch #38 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -182617
AverageReturn                            -298590
Entropy                                        8.51363
EnvExecTime                                    0.0331564
Extras/EpisodeRewardMean                 -203931
Iteration                                     38
LinearFeatureBaseline/ExplainedVariance        0.907401
MaxReturn                                -298590
MinReturn                                -298590
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0436592
ProcessExecTime                                0.00112939
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:42 | [drl] epoch #39 | Obtaining samples...
2020-09-06 23:01:42 | [drl] epoch #39 | Obtaining samples for iteration 39...
2020-09-06 23:01:42 | [drl] epoch #39 | Logging diagnostics...
2020-09-06 23:01:42 | [drl] epoch #39 | Optimizing policy...
2020-09-06 23:01:42 | [drl] epoch #39 | Computing loss before
2020-09-06 23:01:42 | [drl] epoch #39 | Computing KL before
2020-09-06 23:01:42 | [drl] epoch #39 | Optimizing
2020-09-06 23:01:42 | [drl] epoch #39 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:42 | [drl] epoch #39 | computing loss before
2020-09-06 23:01:42 | [drl] epoch #39 | computing gradient
2020-09-06 23:01:42 | [drl] epoch #39 | gradient computed
2020-09-06 23:01:42 | [drl] epoch #39 | computing descent direction
2020-09-06 23:01:43 | [drl] epoch #39 | descent direction computed
2020-09-06 23:01:43 | [drl] epoch #39 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:43 | [drl] epoch #39 | Violated because loss is NaN
2020-09-06 23:01:43 | [drl] epoch #39 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:43 | [drl] epoch #39 | backtrack iters: 14
2020-09-06 23:01:43 | [drl] epoch #39 | optimization finished
2020-09-06 23:01:43 | [drl] epoch #39 | Computing KL after
2020-09-06 23:01:43 | [drl] epoch #39 | Computing loss after
2020-09-06 23:01:43 | [drl] epoch #39 | Fitting baseline...
2020-09-06 23:01:43 | [drl] epoch #39 | Saving snapshot...
2020-09-06 23:01:43 | [drl] epoch #39 | Saved
2020-09-06 23:01:43 | [drl] epoch #39 | Time 33.76 s
2020-09-06 23:01:43 | [drl] epoch #39 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -94049.3
AverageReturn                            -153662
Entropy                                        8.51363
EnvExecTime                                    0.0397179
Extras/EpisodeRewardMean                 -202674
Iteration                                     39
LinearFeatureBaseline/ExplainedVariance        0.0829904
MaxReturn                                -153662
MinReturn                                -153662
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0411885
ProcessExecTime                                0.00103045
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:43 | [drl] epoch #40 | Obtaining samples...
2020-09-06 23:01:43 | [drl] epoch #40 | Obtaining samples for iteration 40...
2020-09-06 23:01:43 | [drl] epoch #40 | Logging diagnostics...
2020-09-06 23:01:43 | [drl] epoch #40 | Optimizing policy...
2020-09-06 23:01:43 | [drl] epoch #40 | Computing loss before
2020-09-06 23:01:43 | [drl] epoch #40 | Computing KL before
2020-09-06 23:01:43 | [drl] epoch #40 | Optimizing
2020-09-06 23:01:43 | [drl] epoch #40 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:43 | [drl] epoch #40 | computing loss before
2020-09-06 23:01:43 | [drl] epoch #40 | computing gradient
2020-09-06 23:01:43 | [drl] epoch #40 | gradient computed
2020-09-06 23:01:43 | [drl] epoch #40 | computing descent direction
2020-09-06 23:01:44 | [drl] epoch #40 | descent direction computed
2020-09-06 23:01:44 | [drl] epoch #40 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:44 | [drl] epoch #40 | Violated because loss is NaN
2020-09-06 23:01:44 | [drl] epoch #40 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:44 | [drl] epoch #40 | backtrack iters: 14
2020-09-06 23:01:44 | [drl] epoch #40 | optimization finished
2020-09-06 23:01:44 | [drl] epoch #40 | Computing KL after
2020-09-06 23:01:44 | [drl] epoch #40 | Computing loss after
2020-09-06 23:01:44 | [drl] epoch #40 | Fitting baseline...
2020-09-06 23:01:44 | [drl] epoch #40 | Saving snapshot...
2020-09-06 23:01:44 | [drl] epoch #40 | Saved
2020-09-06 23:01:44 | [drl] epoch #40 | Time 34.51 s
2020-09-06 23:01:44 | [drl] epoch #40 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -175642
AverageReturn                            -287175
Entropy                                        8.51363
EnvExecTime                                    0.0327539
Extras/EpisodeRewardMean                 -204735
Iteration                                     40
LinearFeatureBaseline/ExplainedVariance        0.780284
MaxReturn                                -287175
MinReturn                                -287175
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0474198
ProcessExecTime                                0.00122881
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:44 | [drl] epoch #41 | Obtaining samples...
2020-09-06 23:01:44 | [drl] epoch #41 | Obtaining samples for iteration 41...
2020-09-06 23:01:44 | [drl] epoch #41 | Logging diagnostics...
2020-09-06 23:01:44 | [drl] epoch #41 | Optimizing policy...
2020-09-06 23:01:44 | [drl] epoch #41 | Computing loss before
2020-09-06 23:01:44 | [drl] epoch #41 | Computing KL before
2020-09-06 23:01:44 | [drl] epoch #41 | Optimizing
2020-09-06 23:01:44 | [drl] epoch #41 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:44 | [drl] epoch #41 | computing loss before
2020-09-06 23:01:44 | [drl] epoch #41 | computing gradient
2020-09-06 23:01:44 | [drl] epoch #41 | gradient computed
2020-09-06 23:01:44 | [drl] epoch #41 | computing descent direction
2020-09-06 23:01:44 | [drl] epoch #41 | descent direction computed
2020-09-06 23:01:44 | [drl] epoch #41 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:44 | [drl] epoch #41 | Violated because loss is NaN
2020-09-06 23:01:44 | [drl] epoch #41 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:44 | [drl] epoch #41 | backtrack iters: 14
2020-09-06 23:01:44 | [drl] epoch #41 | optimization finished
2020-09-06 23:01:44 | [drl] epoch #41 | Computing KL after
2020-09-06 23:01:44 | [drl] epoch #41 | Computing loss after
2020-09-06 23:01:44 | [drl] epoch #41 | Fitting baseline...
2020-09-06 23:01:44 | [drl] epoch #41 | Saving snapshot...
2020-09-06 23:01:44 | [drl] epoch #41 | Saved
2020-09-06 23:01:44 | [drl] epoch #41 | Time 35.27 s
2020-09-06 23:01:44 | [drl] epoch #41 | EpochTime 0.75 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -157949
AverageReturn                            -258225
Entropy                                        8.51363
EnvExecTime                                    0.0387173
Extras/EpisodeRewardMean                 -206009
Iteration                                     41
LinearFeatureBaseline/ExplainedVariance        0.987174
MaxReturn                                -258225
MinReturn                                -258225
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.041898
ProcessExecTime                                0.0009799
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 23:01:44 | [drl] epoch #42 | Obtaining samples...
2020-09-06 23:01:44 | [drl] epoch #42 | Obtaining samples for iteration 42...
2020-09-06 23:01:45 | [drl] epoch #42 | Logging diagnostics...
2020-09-06 23:01:45 | [drl] epoch #42 | Optimizing policy...
2020-09-06 23:01:45 | [drl] epoch #42 | Computing loss before
2020-09-06 23:01:45 | [drl] epoch #42 | Computing KL before
2020-09-06 23:01:45 | [drl] epoch #42 | Optimizing
2020-09-06 23:01:45 | [drl] epoch #42 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:45 | [drl] epoch #42 | computing loss before
2020-09-06 23:01:45 | [drl] epoch #42 | computing gradient
2020-09-06 23:01:45 | [drl] epoch #42 | gradient computed
2020-09-06 23:01:45 | [drl] epoch #42 | computing descent direction
2020-09-06 23:01:45 | [drl] epoch #42 | descent direction computed
2020-09-06 23:01:45 | [drl] epoch #42 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:45 | [drl] epoch #42 | Violated because loss is NaN
2020-09-06 23:01:45 | [drl] epoch #42 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:45 | [drl] epoch #42 | backtrack iters: 14
2020-09-06 23:01:45 | [drl] epoch #42 | optimization finished
2020-09-06 23:01:45 | [drl] epoch #42 | Computing KL after
2020-09-06 23:01:45 | [drl] epoch #42 | Computing loss after
2020-09-06 23:01:45 | [drl] epoch #42 | Fitting baseline...
2020-09-06 23:01:45 | [drl] epoch #42 | Saving snapshot...
2020-09-06 23:01:45 | [drl] epoch #42 | Saved
2020-09-06 23:01:45 | [drl] epoch #42 | Time 36.04 s
2020-09-06 23:01:45 | [drl] epoch #42 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -93356.8
AverageReturn                            -152530
Entropy                                        8.51363
EnvExecTime                                    0.034157
Extras/EpisodeRewardMean                 -204765
Iteration                                     42
LinearFeatureBaseline/ExplainedVariance        0.50533
MaxReturn                                -152530
MinReturn                                -152530
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0465469
ProcessExecTime                                0.00509977
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:45 | [drl] epoch #43 | Obtaining samples...
2020-09-06 23:01:45 | [drl] epoch #43 | Obtaining samples for iteration 43...
2020-09-06 23:01:45 | [drl] epoch #43 | Logging diagnostics...
2020-09-06 23:01:45 | [drl] epoch #43 | Optimizing policy...
2020-09-06 23:01:45 | [drl] epoch #43 | Computing loss before
2020-09-06 23:01:45 | [drl] epoch #43 | Computing KL before
2020-09-06 23:01:45 | [drl] epoch #43 | Optimizing
2020-09-06 23:01:45 | [drl] epoch #43 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:45 | [drl] epoch #43 | computing loss before
2020-09-06 23:01:45 | [drl] epoch #43 | computing gradient
2020-09-06 23:01:45 | [drl] epoch #43 | gradient computed
2020-09-06 23:01:45 | [drl] epoch #43 | computing descent direction
2020-09-06 23:01:46 | [drl] epoch #43 | descent direction computed
2020-09-06 23:01:46 | [drl] epoch #43 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:46 | [drl] epoch #43 | Violated because loss is NaN
2020-09-06 23:01:46 | [drl] epoch #43 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:46 | [drl] epoch #43 | backtrack iters: 14
2020-09-06 23:01:46 | [drl] epoch #43 | optimization finished
2020-09-06 23:01:46 | [drl] epoch #43 | Computing KL after
2020-09-06 23:01:46 | [drl] epoch #43 | Computing loss after
2020-09-06 23:01:46 | [drl] epoch #43 | Fitting baseline...
2020-09-06 23:01:46 | [drl] epoch #43 | Saving snapshot...
2020-09-06 23:01:46 | [drl] epoch #43 | Saved
2020-09-06 23:01:46 | [drl] epoch #43 | Time 36.82 s
2020-09-06 23:01:46 | [drl] epoch #43 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -174311
AverageReturn                            -285009
Entropy                                        8.51363
EnvExecTime                                    0.0387127
Extras/EpisodeRewardMean                 -206589
Iteration                                     43
LinearFeatureBaseline/ExplainedVariance        0.780239
MaxReturn                                -285009
MinReturn                                -285009
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0417252
ProcessExecTime                                0.00143099
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:46 | [drl] epoch #44 | Obtaining samples...
2020-09-06 23:01:46 | [drl] epoch #44 | Obtaining samples for iteration 44...
2020-09-06 23:01:46 | [drl] epoch #44 | Logging diagnostics...
2020-09-06 23:01:46 | [drl] epoch #44 | Optimizing policy...
2020-09-06 23:01:46 | [drl] epoch #44 | Computing loss before
2020-09-06 23:01:46 | [drl] epoch #44 | Computing KL before
2020-09-06 23:01:46 | [drl] epoch #44 | Optimizing
2020-09-06 23:01:46 | [drl] epoch #44 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:46 | [drl] epoch #44 | computing loss before
2020-09-06 23:01:46 | [drl] epoch #44 | computing gradient
2020-09-06 23:01:46 | [drl] epoch #44 | gradient computed
2020-09-06 23:01:46 | [drl] epoch #44 | computing descent direction
2020-09-06 23:01:47 | [drl] epoch #44 | descent direction computed
2020-09-06 23:01:47 | [drl] epoch #44 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:47 | [drl] epoch #44 | Violated because loss is NaN
2020-09-06 23:01:47 | [drl] epoch #44 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:47 | [drl] epoch #44 | backtrack iters: 14
2020-09-06 23:01:47 | [drl] epoch #44 | optimization finished
2020-09-06 23:01:47 | [drl] epoch #44 | Computing KL after
2020-09-06 23:01:47 | [drl] epoch #44 | Computing loss after
2020-09-06 23:01:47 | [drl] epoch #44 | Fitting baseline...
2020-09-06 23:01:47 | [drl] epoch #44 | Saving snapshot...
2020-09-06 23:01:47 | [drl] epoch #44 | Saved
2020-09-06 23:01:47 | [drl] epoch #44 | Time 37.59 s
2020-09-06 23:01:47 | [drl] epoch #44 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -174310
AverageReturn                            -284997
Entropy                                        8.51363
EnvExecTime                                    0.04248
Extras/EpisodeRewardMean                 -208331
Iteration                                     44
LinearFeatureBaseline/ExplainedVariance        1
MaxReturn                                -284997
MinReturn                                -284997
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.047406
ProcessExecTime                                0.000995159
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:47 | [drl] epoch #45 | Obtaining samples...
2020-09-06 23:01:47 | [drl] epoch #45 | Obtaining samples for iteration 45...
2020-09-06 23:01:47 | [drl] epoch #45 | Logging diagnostics...
2020-09-06 23:01:47 | [drl] epoch #45 | Optimizing policy...
2020-09-06 23:01:47 | [drl] epoch #45 | Computing loss before
2020-09-06 23:01:47 | [drl] epoch #45 | Computing KL before
2020-09-06 23:01:47 | [drl] epoch #45 | Optimizing
2020-09-06 23:01:47 | [drl] epoch #45 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:47 | [drl] epoch #45 | computing loss before
2020-09-06 23:01:47 | [drl] epoch #45 | computing gradient
2020-09-06 23:01:47 | [drl] epoch #45 | gradient computed
2020-09-06 23:01:47 | [drl] epoch #45 | computing descent direction
2020-09-06 23:01:47 | [drl] epoch #45 | descent direction computed
2020-09-06 23:01:48 | [drl] epoch #45 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:48 | [drl] epoch #45 | Violated because loss is NaN
2020-09-06 23:01:48 | [drl] epoch #45 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:48 | [drl] epoch #45 | backtrack iters: 14
2020-09-06 23:01:48 | [drl] epoch #45 | optimization finished
2020-09-06 23:01:48 | [drl] epoch #45 | Computing KL after
2020-09-06 23:01:48 | [drl] epoch #45 | Computing loss after
2020-09-06 23:01:48 | [drl] epoch #45 | Fitting baseline...
2020-09-06 23:01:48 | [drl] epoch #45 | Saving snapshot...
2020-09-06 23:01:48 | [drl] epoch #45 | Saved
2020-09-06 23:01:48 | [drl] epoch #45 | Time 38.42 s
2020-09-06 23:01:48 | [drl] epoch #45 | EpochTime 0.82 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -77151.7
AverageReturn                            -126014
Entropy                                        8.51363
EnvExecTime                                    0.0330219
Extras/EpisodeRewardMean                 -206542
Iteration                                     45
LinearFeatureBaseline/ExplainedVariance       -0.651504
MaxReturn                                -126014
MinReturn                                -126014
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.038538
ProcessExecTime                                0.000991344
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:48 | [drl] epoch #46 | Obtaining samples...
2020-09-06 23:01:48 | [drl] epoch #46 | Obtaining samples for iteration 46...
2020-09-06 23:01:48 | [drl] epoch #46 | Logging diagnostics...
2020-09-06 23:01:48 | [drl] epoch #46 | Optimizing policy...
2020-09-06 23:01:48 | [drl] epoch #46 | Computing loss before
2020-09-06 23:01:48 | [drl] epoch #46 | Computing KL before
2020-09-06 23:01:48 | [drl] epoch #46 | Optimizing
2020-09-06 23:01:48 | [drl] epoch #46 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:48 | [drl] epoch #46 | computing loss before
2020-09-06 23:01:48 | [drl] epoch #46 | computing gradient
2020-09-06 23:01:48 | [drl] epoch #46 | gradient computed
2020-09-06 23:01:48 | [drl] epoch #46 | computing descent direction
2020-09-06 23:01:48 | [drl] epoch #46 | descent direction computed
2020-09-06 23:01:48 | [drl] epoch #46 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:48 | [drl] epoch #46 | Violated because loss is NaN
2020-09-06 23:01:48 | [drl] epoch #46 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:48 | [drl] epoch #46 | backtrack iters: 14
2020-09-06 23:01:48 | [drl] epoch #46 | optimization finished
2020-09-06 23:01:48 | [drl] epoch #46 | Computing KL after
2020-09-06 23:01:48 | [drl] epoch #46 | Computing loss after
2020-09-06 23:01:48 | [drl] epoch #46 | Fitting baseline...
2020-09-06 23:01:48 | [drl] epoch #46 | Saving snapshot...
2020-09-06 23:01:48 | [drl] epoch #46 | Saved
2020-09-06 23:01:48 | [drl] epoch #46 | Time 39.32 s
2020-09-06 23:01:48 | [drl] epoch #46 | EpochTime 0.87 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -165927
AverageReturn                            -271277
Entropy                                        8.51363
EnvExecTime                                    0.0445755
Extras/EpisodeRewardMean                 -207919
Iteration                                     46
LinearFeatureBaseline/ExplainedVariance        0.708287
MaxReturn                                -271277
MinReturn                                -271277
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.044755
ProcessExecTime                                0.000989676
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:48 | [drl] epoch #47 | Obtaining samples...
2020-09-06 23:01:48 | [drl] epoch #47 | Obtaining samples for iteration 47...
2020-09-06 23:01:49 | [drl] epoch #47 | Logging diagnostics...
2020-09-06 23:01:49 | [drl] epoch #47 | Optimizing policy...
2020-09-06 23:01:49 | [drl] epoch #47 | Computing loss before
2020-09-06 23:01:49 | [drl] epoch #47 | Computing KL before
2020-09-06 23:01:49 | [drl] epoch #47 | Optimizing
2020-09-06 23:01:49 | [drl] epoch #47 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:49 | [drl] epoch #47 | computing loss before
2020-09-06 23:01:49 | [drl] epoch #47 | computing gradient
2020-09-06 23:01:49 | [drl] epoch #47 | gradient computed
2020-09-06 23:01:49 | [drl] epoch #47 | computing descent direction
2020-09-06 23:01:49 | [drl] epoch #47 | descent direction computed
2020-09-06 23:01:49 | [drl] epoch #47 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:49 | [drl] epoch #47 | Violated because loss is NaN
2020-09-06 23:01:49 | [drl] epoch #47 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:49 | [drl] epoch #47 | backtrack iters: 14
2020-09-06 23:01:49 | [drl] epoch #47 | optimization finished
2020-09-06 23:01:49 | [drl] epoch #47 | Computing KL after
2020-09-06 23:01:49 | [drl] epoch #47 | Computing loss after
2020-09-06 23:01:49 | [drl] epoch #47 | Fitting baseline...
2020-09-06 23:01:49 | [drl] epoch #47 | Saving snapshot...
2020-09-06 23:01:49 | [drl] epoch #47 | Saved
2020-09-06 23:01:49 | [drl] epoch #47 | Time 40.16 s
2020-09-06 23:01:49 | [drl] epoch #47 | EpochTime 0.83 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -85876.8
AverageReturn                            -140289
Entropy                                        8.51363
EnvExecTime                                    0.0384841
Extras/EpisodeRewardMean                 -206510
Iteration                                     47
LinearFeatureBaseline/ExplainedVariance        0.097853
MaxReturn                                -140289
MinReturn                                -140289
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0682964
ProcessExecTime                                0.000963449
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:49 | [drl] epoch #48 | Obtaining samples...
2020-09-06 23:01:49 | [drl] epoch #48 | Obtaining samples for iteration 48...
2020-09-06 23:01:49 | [drl] epoch #48 | Logging diagnostics...
2020-09-06 23:01:49 | [drl] epoch #48 | Optimizing policy...
2020-09-06 23:01:49 | [drl] epoch #48 | Computing loss before
2020-09-06 23:01:49 | [drl] epoch #48 | Computing KL before
2020-09-06 23:01:49 | [drl] epoch #48 | Optimizing
2020-09-06 23:01:49 | [drl] epoch #48 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:49 | [drl] epoch #48 | computing loss before
2020-09-06 23:01:49 | [drl] epoch #48 | computing gradient
2020-09-06 23:01:49 | [drl] epoch #48 | gradient computed
2020-09-06 23:01:49 | [drl] epoch #48 | computing descent direction
2020-09-06 23:01:50 | [drl] epoch #48 | descent direction computed
2020-09-06 23:01:50 | [drl] epoch #48 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:50 | [drl] epoch #48 | Violated because loss is NaN
2020-09-06 23:01:50 | [drl] epoch #48 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:50 | [drl] epoch #48 | backtrack iters: 14
2020-09-06 23:01:50 | [drl] epoch #48 | optimization finished
2020-09-06 23:01:50 | [drl] epoch #48 | Computing KL after
2020-09-06 23:01:50 | [drl] epoch #48 | Computing loss after
2020-09-06 23:01:50 | [drl] epoch #48 | Fitting baseline...
2020-09-06 23:01:50 | [drl] epoch #48 | Saving snapshot...
2020-09-06 23:01:50 | [drl] epoch #48 | Saved
2020-09-06 23:01:50 | [drl] epoch #48 | Time 41.09 s
2020-09-06 23:01:50 | [drl] epoch #48 | EpochTime 0.92 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -177630
AverageReturn                            -290441
Entropy                                        8.51363
EnvExecTime                                    0.0372069
Extras/EpisodeRewardMean                 -208223
Iteration                                     48
LinearFeatureBaseline/ExplainedVariance        0.72819
MaxReturn                                -290441
MinReturn                                -290441
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0483239
ProcessExecTime                                0.00797081
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:50 | [drl] epoch #49 | Obtaining samples...
2020-09-06 23:01:50 | [drl] epoch #49 | Obtaining samples for iteration 49...
2020-09-06 23:01:50 | [drl] epoch #49 | Logging diagnostics...
2020-09-06 23:01:50 | [drl] epoch #49 | Optimizing policy...
2020-09-06 23:01:50 | [drl] epoch #49 | Computing loss before
2020-09-06 23:01:50 | [drl] epoch #49 | Computing KL before
2020-09-06 23:01:50 | [drl] epoch #49 | Optimizing
2020-09-06 23:01:50 | [drl] epoch #49 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:50 | [drl] epoch #49 | computing loss before
2020-09-06 23:01:50 | [drl] epoch #49 | computing gradient
2020-09-06 23:01:50 | [drl] epoch #49 | gradient computed
2020-09-06 23:01:50 | [drl] epoch #49 | computing descent direction
2020-09-06 23:01:51 | [drl] epoch #49 | descent direction computed
2020-09-06 23:01:51 | [drl] epoch #49 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:51 | [drl] epoch #49 | Violated because loss is NaN
2020-09-06 23:01:51 | [drl] epoch #49 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:51 | [drl] epoch #49 | backtrack iters: 14
2020-09-06 23:01:51 | [drl] epoch #49 | optimization finished
2020-09-06 23:01:51 | [drl] epoch #49 | Computing KL after
2020-09-06 23:01:51 | [drl] epoch #49 | Computing loss after
2020-09-06 23:01:51 | [drl] epoch #49 | Fitting baseline...
2020-09-06 23:01:51 | [drl] epoch #49 | Saving snapshot...
2020-09-06 23:01:51 | [drl] epoch #49 | Saved
2020-09-06 23:01:51 | [drl] epoch #49 | Time 41.87 s
2020-09-06 23:01:51 | [drl] epoch #49 | EpochTime 0.78 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -93604.7
AverageReturn                            -152935
Entropy                                        8.51363
EnvExecTime                                    0.0364201
Extras/EpisodeRewardMean                 -207117
Iteration                                     49
LinearFeatureBaseline/ExplainedVariance        0.165185
MaxReturn                                -152935
MinReturn                                -152935
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0405674
ProcessExecTime                                0.00121832
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:51 | [drl] epoch #50 | Obtaining samples...
2020-09-06 23:01:51 | [drl] epoch #50 | Obtaining samples for iteration 50...
2020-09-06 23:01:51 | [drl] epoch #50 | Logging diagnostics...
2020-09-06 23:01:51 | [drl] epoch #50 | Optimizing policy...
2020-09-06 23:01:51 | [drl] epoch #50 | Computing loss before
2020-09-06 23:01:51 | [drl] epoch #50 | Computing KL before
2020-09-06 23:01:51 | [drl] epoch #50 | Optimizing
2020-09-06 23:01:51 | [drl] epoch #50 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:51 | [drl] epoch #50 | computing loss before
2020-09-06 23:01:51 | [drl] epoch #50 | computing gradient
2020-09-06 23:01:51 | [drl] epoch #50 | gradient computed
2020-09-06 23:01:51 | [drl] epoch #50 | computing descent direction
2020-09-06 23:01:52 | [drl] epoch #50 | descent direction computed
2020-09-06 23:01:52 | [drl] epoch #50 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:52 | [drl] epoch #50 | Violated because loss is NaN
2020-09-06 23:01:52 | [drl] epoch #50 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:52 | [drl] epoch #50 | backtrack iters: 14
2020-09-06 23:01:52 | [drl] epoch #50 | optimization finished
2020-09-06 23:01:52 | [drl] epoch #50 | Computing KL after
2020-09-06 23:01:52 | [drl] epoch #50 | Computing loss after
2020-09-06 23:01:52 | [drl] epoch #50 | Fitting baseline...
2020-09-06 23:01:52 | [drl] epoch #50 | Saving snapshot...
2020-09-06 23:01:52 | [drl] epoch #50 | Saved
2020-09-06 23:01:52 | [drl] epoch #50 | Time 42.70 s
2020-09-06 23:01:52 | [drl] epoch #50 | EpochTime 0.81 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -128502
AverageReturn                            -210039
Entropy                                        8.51363
EnvExecTime                                    0.0415564
Extras/EpisodeRewardMean                 -207175
Iteration                                     50
LinearFeatureBaseline/ExplainedVariance        0.924474
MaxReturn                                -210039
MinReturn                                -210039
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0518711
ProcessExecTime                                0.000991821
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:52 | [drl] epoch #51 | Obtaining samples...
2020-09-06 23:01:52 | [drl] epoch #51 | Obtaining samples for iteration 51...
2020-09-06 23:01:52 | [drl] epoch #51 | Logging diagnostics...
2020-09-06 23:01:52 | [drl] epoch #51 | Optimizing policy...
2020-09-06 23:01:52 | [drl] epoch #51 | Computing loss before
2020-09-06 23:01:52 | [drl] epoch #51 | Computing KL before
2020-09-06 23:01:52 | [drl] epoch #51 | Optimizing
2020-09-06 23:01:52 | [drl] epoch #51 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:52 | [drl] epoch #51 | computing loss before
2020-09-06 23:01:52 | [drl] epoch #51 | computing gradient
2020-09-06 23:01:52 | [drl] epoch #51 | gradient computed
2020-09-06 23:01:52 | [drl] epoch #51 | computing descent direction
2020-09-06 23:01:52 | [drl] epoch #51 | descent direction computed
2020-09-06 23:01:53 | [drl] epoch #51 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:53 | [drl] epoch #51 | Violated because loss is NaN
2020-09-06 23:01:53 | [drl] epoch #51 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:53 | [drl] epoch #51 | backtrack iters: 14
2020-09-06 23:01:53 | [drl] epoch #51 | optimization finished
2020-09-06 23:01:53 | [drl] epoch #51 | Computing KL after
2020-09-06 23:01:53 | [drl] epoch #51 | Computing loss after
2020-09-06 23:01:53 | [drl] epoch #51 | Fitting baseline...
2020-09-06 23:01:53 | [drl] epoch #51 | Saving snapshot...
2020-09-06 23:01:53 | [drl] epoch #51 | Saved
2020-09-06 23:01:53 | [drl] epoch #51 | Time 43.46 s
2020-09-06 23:01:53 | [drl] epoch #51 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -137705
AverageReturn                            -225111
Entropy                                        8.51363
EnvExecTime                                    0.0409269
Extras/EpisodeRewardMean                 -207519
Iteration                                     51
LinearFeatureBaseline/ExplainedVariance        0.995334
MaxReturn                                -225111
MinReturn                                -225111
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0399935
ProcessExecTime                                0.000952959
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:53 | [drl] epoch #52 | Obtaining samples...
2020-09-06 23:01:53 | [drl] epoch #52 | Obtaining samples for iteration 52...
2020-09-06 23:01:53 | [drl] epoch #52 | Logging diagnostics...
2020-09-06 23:01:53 | [drl] epoch #52 | Optimizing policy...
2020-09-06 23:01:53 | [drl] epoch #52 | Computing loss before
2020-09-06 23:01:53 | [drl] epoch #52 | Computing KL before
2020-09-06 23:01:53 | [drl] epoch #52 | Optimizing
2020-09-06 23:01:53 | [drl] epoch #52 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:53 | [drl] epoch #52 | computing loss before
2020-09-06 23:01:53 | [drl] epoch #52 | computing gradient
2020-09-06 23:01:53 | [drl] epoch #52 | gradient computed
2020-09-06 23:01:53 | [drl] epoch #52 | computing descent direction
2020-09-06 23:01:53 | [drl] epoch #52 | descent direction computed
2020-09-06 23:01:53 | [drl] epoch #52 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:53 | [drl] epoch #52 | Violated because loss is NaN
2020-09-06 23:01:53 | [drl] epoch #52 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:53 | [drl] epoch #52 | backtrack iters: 14
2020-09-06 23:01:53 | [drl] epoch #52 | optimization finished
2020-09-06 23:01:53 | [drl] epoch #52 | Computing KL after
2020-09-06 23:01:53 | [drl] epoch #52 | Computing loss after
2020-09-06 23:01:53 | [drl] epoch #52 | Fitting baseline...
2020-09-06 23:01:53 | [drl] epoch #52 | Saving snapshot...
2020-09-06 23:01:53 | [drl] epoch #52 | Saved
2020-09-06 23:01:53 | [drl] epoch #52 | Time 44.19 s
2020-09-06 23:01:53 | [drl] epoch #52 | EpochTime 0.72 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -94635.8
AverageReturn                            -154637
Entropy                                        8.51363
EnvExecTime                                    0.0326991
Extras/EpisodeRewardMean                 -206522
Iteration                                     52
LinearFeatureBaseline/ExplainedVariance        0.785821
MaxReturn                                -154637
MinReturn                                -154637
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0430532
ProcessExecTime                                0.000929117
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:53 | [drl] epoch #53 | Obtaining samples...
2020-09-06 23:01:53 | [drl] epoch #53 | Obtaining samples for iteration 53...
2020-09-06 23:01:53 | [drl] epoch #53 | Logging diagnostics...
2020-09-06 23:01:53 | [drl] epoch #53 | Optimizing policy...
2020-09-06 23:01:53 | [drl] epoch #53 | Computing loss before
2020-09-06 23:01:53 | [drl] epoch #53 | Computing KL before
2020-09-06 23:01:53 | [drl] epoch #53 | Optimizing
2020-09-06 23:01:53 | [drl] epoch #53 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:53 | [drl] epoch #53 | computing loss before
2020-09-06 23:01:53 | [drl] epoch #53 | computing gradient
2020-09-06 23:01:53 | [drl] epoch #53 | gradient computed
2020-09-06 23:01:53 | [drl] epoch #53 | computing descent direction
2020-09-06 23:01:54 | [drl] epoch #53 | descent direction computed
2020-09-06 23:01:54 | [drl] epoch #53 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:54 | [drl] epoch #53 | Violated because loss is NaN
2020-09-06 23:01:54 | [drl] epoch #53 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:54 | [drl] epoch #53 | backtrack iters: 14
2020-09-06 23:01:54 | [drl] epoch #53 | optimization finished
2020-09-06 23:01:54 | [drl] epoch #53 | Computing KL after
2020-09-06 23:01:54 | [drl] epoch #53 | Computing loss after
2020-09-06 23:01:54 | [drl] epoch #53 | Fitting baseline...
2020-09-06 23:01:54 | [drl] epoch #53 | Saving snapshot...
2020-09-06 23:01:54 | [drl] epoch #53 | Saved
2020-09-06 23:01:54 | [drl] epoch #53 | Time 45.12 s
2020-09-06 23:01:54 | [drl] epoch #53 | EpochTime 0.92 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -96025.6
AverageReturn                            -156887
Entropy                                        8.51363
EnvExecTime                                    0.0325582
Extras/EpisodeRewardMean                 -205603
Iteration                                     53
LinearFeatureBaseline/ExplainedVariance        0.999817
MaxReturn                                -156887
MinReturn                                -156887
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0478759
ProcessExecTime                                0.000919104
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:54 | [drl] epoch #54 | Obtaining samples...
2020-09-06 23:01:54 | [drl] epoch #54 | Obtaining samples for iteration 54...
2020-09-06 23:01:54 | [drl] epoch #54 | Logging diagnostics...
2020-09-06 23:01:54 | [drl] epoch #54 | Optimizing policy...
2020-09-06 23:01:54 | [drl] epoch #54 | Computing loss before
2020-09-06 23:01:54 | [drl] epoch #54 | Computing KL before
2020-09-06 23:01:54 | [drl] epoch #54 | Optimizing
2020-09-06 23:01:54 | [drl] epoch #54 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:54 | [drl] epoch #54 | computing loss before
2020-09-06 23:01:54 | [drl] epoch #54 | computing gradient
2020-09-06 23:01:54 | [drl] epoch #54 | gradient computed
2020-09-06 23:01:54 | [drl] epoch #54 | computing descent direction
2020-09-06 23:01:55 | [drl] epoch #54 | descent direction computed
2020-09-06 23:01:55 | [drl] epoch #54 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:55 | [drl] epoch #54 | Violated because loss is NaN
2020-09-06 23:01:55 | [drl] epoch #54 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:55 | [drl] epoch #54 | backtrack iters: 14
2020-09-06 23:01:55 | [drl] epoch #54 | optimization finished
2020-09-06 23:01:55 | [drl] epoch #54 | Computing KL after
2020-09-06 23:01:55 | [drl] epoch #54 | Computing loss after
2020-09-06 23:01:55 | [drl] epoch #54 | Fitting baseline...
2020-09-06 23:01:55 | [drl] epoch #54 | Saving snapshot...
2020-09-06 23:01:55 | [drl] epoch #54 | Saved
2020-09-06 23:01:55 | [drl] epoch #54 | Time 45.88 s
2020-09-06 23:01:55 | [drl] epoch #54 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -94380.9
AverageReturn                            -154213
Entropy                                        8.51363
EnvExecTime                                    0.032752
Extras/EpisodeRewardMean                 -204668
Iteration                                     54
LinearFeatureBaseline/ExplainedVariance        0.999722
MaxReturn                                -154213
MinReturn                                -154213
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.052942
ProcessExecTime                                0.000935793
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:55 | [drl] epoch #55 | Obtaining samples...
2020-09-06 23:01:55 | [drl] epoch #55 | Obtaining samples for iteration 55...
2020-09-06 23:01:55 | [drl] epoch #55 | Logging diagnostics...
2020-09-06 23:01:55 | [drl] epoch #55 | Optimizing policy...
2020-09-06 23:01:55 | [drl] epoch #55 | Computing loss before
2020-09-06 23:01:55 | [drl] epoch #55 | Computing KL before
2020-09-06 23:01:55 | [drl] epoch #55 | Optimizing
2020-09-06 23:01:55 | [drl] epoch #55 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:55 | [drl] epoch #55 | computing loss before
2020-09-06 23:01:55 | [drl] epoch #55 | computing gradient
2020-09-06 23:01:55 | [drl] epoch #55 | gradient computed
2020-09-06 23:01:55 | [drl] epoch #55 | computing descent direction
2020-09-06 23:01:56 | [drl] epoch #55 | descent direction computed
2020-09-06 23:01:56 | [drl] epoch #55 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:56 | [drl] epoch #55 | Violated because loss is NaN
2020-09-06 23:01:56 | [drl] epoch #55 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:56 | [drl] epoch #55 | backtrack iters: 14
2020-09-06 23:01:56 | [drl] epoch #55 | optimization finished
2020-09-06 23:01:56 | [drl] epoch #55 | Computing KL after
2020-09-06 23:01:56 | [drl] epoch #55 | Computing loss after
2020-09-06 23:01:56 | [drl] epoch #55 | Fitting baseline...
2020-09-06 23:01:56 | [drl] epoch #55 | Saving snapshot...
2020-09-06 23:01:56 | [drl] epoch #55 | Saved
2020-09-06 23:01:56 | [drl] epoch #55 | Time 46.75 s
2020-09-06 23:01:56 | [drl] epoch #55 | EpochTime 0.86 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -102312
AverageReturn                            -167192
Entropy                                        8.51363
EnvExecTime                                    0.0323143
Extras/EpisodeRewardMean                 -203999
Iteration                                     55
LinearFeatureBaseline/ExplainedVariance        0.99385
MaxReturn                                -167192
MinReturn                                -167192
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.045424
ProcessExecTime                                0.000941992
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:56 | [drl] epoch #56 | Obtaining samples...
2020-09-06 23:01:56 | [drl] epoch #56 | Obtaining samples for iteration 56...
2020-09-06 23:01:56 | [drl] epoch #56 | Logging diagnostics...
2020-09-06 23:01:56 | [drl] epoch #56 | Optimizing policy...
2020-09-06 23:01:56 | [drl] epoch #56 | Computing loss before
2020-09-06 23:01:56 | [drl] epoch #56 | Computing KL before
2020-09-06 23:01:56 | [drl] epoch #56 | Optimizing
2020-09-06 23:01:56 | [drl] epoch #56 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:56 | [drl] epoch #56 | computing loss before
2020-09-06 23:01:56 | [drl] epoch #56 | computing gradient
2020-09-06 23:01:56 | [drl] epoch #56 | gradient computed
2020-09-06 23:01:56 | [drl] epoch #56 | computing descent direction
2020-09-06 23:01:57 | [drl] epoch #56 | descent direction computed
2020-09-06 23:01:57 | [drl] epoch #56 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:57 | [drl] epoch #56 | Violated because loss is NaN
2020-09-06 23:01:57 | [drl] epoch #56 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:57 | [drl] epoch #56 | backtrack iters: 14
2020-09-06 23:01:57 | [drl] epoch #56 | optimization finished
2020-09-06 23:01:57 | [drl] epoch #56 | Computing KL after
2020-09-06 23:01:57 | [drl] epoch #56 | Computing loss after
2020-09-06 23:01:57 | [drl] epoch #56 | Fitting baseline...
2020-09-06 23:01:57 | [drl] epoch #56 | Saving snapshot...
2020-09-06 23:01:57 | [drl] epoch #56 | Saved
2020-09-06 23:01:57 | [drl] epoch #56 | Time 47.67 s
2020-09-06 23:01:57 | [drl] epoch #56 | EpochTime 0.91 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -98891.9
AverageReturn                            -161580
Entropy                                        8.51363
EnvExecTime                                    0.0530336
Extras/EpisodeRewardMean                 -203255
Iteration                                     56
LinearFeatureBaseline/ExplainedVariance        0.998727
MaxReturn                                -161580
MinReturn                                -161580
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0561595
ProcessExecTime                                0.000967026
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:57 | [drl] epoch #57 | Obtaining samples...
2020-09-06 23:01:57 | [drl] epoch #57 | Obtaining samples for iteration 57...
2020-09-06 23:01:57 | [drl] epoch #57 | Logging diagnostics...
2020-09-06 23:01:57 | [drl] epoch #57 | Optimizing policy...
2020-09-06 23:01:57 | [drl] epoch #57 | Computing loss before
2020-09-06 23:01:57 | [drl] epoch #57 | Computing KL before
2020-09-06 23:01:57 | [drl] epoch #57 | Optimizing
2020-09-06 23:01:57 | [drl] epoch #57 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:57 | [drl] epoch #57 | computing loss before
2020-09-06 23:01:57 | [drl] epoch #57 | computing gradient
2020-09-06 23:01:57 | [drl] epoch #57 | gradient computed
2020-09-06 23:01:57 | [drl] epoch #57 | computing descent direction
2020-09-06 23:01:57 | [drl] epoch #57 | descent direction computed
2020-09-06 23:01:58 | [drl] epoch #57 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:58 | [drl] epoch #57 | Violated because loss is NaN
2020-09-06 23:01:58 | [drl] epoch #57 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:58 | [drl] epoch #57 | backtrack iters: 14
2020-09-06 23:01:58 | [drl] epoch #57 | optimization finished
2020-09-06 23:01:58 | [drl] epoch #57 | Computing KL after
2020-09-06 23:01:58 | [drl] epoch #57 | Computing loss after
2020-09-06 23:01:58 | [drl] epoch #57 | Fitting baseline...
2020-09-06 23:01:58 | [drl] epoch #57 | Saving snapshot...
2020-09-06 23:01:58 | [drl] epoch #57 | Saved
2020-09-06 23:01:58 | [drl] epoch #57 | Time 48.42 s
2020-09-06 23:01:58 | [drl] epoch #57 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -173259
AverageReturn                            -283275
Entropy                                        8.51363
EnvExecTime                                    0.033035
Extras/EpisodeRewardMean                 -204634
Iteration                                     57
LinearFeatureBaseline/ExplainedVariance        0.812135
MaxReturn                                -283275
MinReturn                                -283275
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0383987
ProcessExecTime                                0.000977278
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:58 | [drl] epoch #58 | Obtaining samples...
2020-09-06 23:01:58 | [drl] epoch #58 | Obtaining samples for iteration 58...
2020-09-06 23:01:58 | [drl] epoch #58 | Logging diagnostics...
2020-09-06 23:01:58 | [drl] epoch #58 | Optimizing policy...
2020-09-06 23:01:58 | [drl] epoch #58 | Computing loss before
2020-09-06 23:01:58 | [drl] epoch #58 | Computing KL before
2020-09-06 23:01:58 | [drl] epoch #58 | Optimizing
2020-09-06 23:01:58 | [drl] epoch #58 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:58 | [drl] epoch #58 | computing loss before
2020-09-06 23:01:58 | [drl] epoch #58 | computing gradient
2020-09-06 23:01:58 | [drl] epoch #58 | gradient computed
2020-09-06 23:01:58 | [drl] epoch #58 | computing descent direction
2020-09-06 23:01:58 | [drl] epoch #58 | descent direction computed
2020-09-06 23:01:58 | [drl] epoch #58 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:58 | [drl] epoch #58 | Violated because loss is NaN
2020-09-06 23:01:58 | [drl] epoch #58 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:58 | [drl] epoch #58 | backtrack iters: 14
2020-09-06 23:01:58 | [drl] epoch #58 | optimization finished
2020-09-06 23:01:58 | [drl] epoch #58 | Computing KL after
2020-09-06 23:01:58 | [drl] epoch #58 | Computing loss after
2020-09-06 23:01:58 | [drl] epoch #58 | Fitting baseline...
2020-09-06 23:01:58 | [drl] epoch #58 | Saving snapshot...
2020-09-06 23:01:58 | [drl] epoch #58 | Saved
2020-09-06 23:01:58 | [drl] epoch #58 | Time 49.16 s
2020-09-06 23:01:58 | [drl] epoch #58 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -106860
AverageReturn                            -174630
Entropy                                        8.51363
EnvExecTime                                    0.0340941
Extras/EpisodeRewardMean                 -204126
Iteration                                     58
LinearFeatureBaseline/ExplainedVariance        0.602093
MaxReturn                                -174630
MinReturn                                -174630
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0476332
ProcessExecTime                                0.000956774
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:01:58 | [drl] epoch #59 | Obtaining samples...
2020-09-06 23:01:58 | [drl] epoch #59 | Obtaining samples for iteration 59...
2020-09-06 23:01:58 | [drl] epoch #59 | Logging diagnostics...
2020-09-06 23:01:58 | [drl] epoch #59 | Optimizing policy...
2020-09-06 23:01:58 | [drl] epoch #59 | Computing loss before
2020-09-06 23:01:58 | [drl] epoch #59 | Computing KL before
2020-09-06 23:01:58 | [drl] epoch #59 | Optimizing
2020-09-06 23:01:58 | [drl] epoch #59 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:58 | [drl] epoch #59 | computing loss before
2020-09-06 23:01:58 | [drl] epoch #59 | computing gradient
2020-09-06 23:01:58 | [drl] epoch #59 | gradient computed
2020-09-06 23:01:58 | [drl] epoch #59 | computing descent direction
2020-09-06 23:01:59 | [drl] epoch #59 | descent direction computed
2020-09-06 23:01:59 | [drl] epoch #59 | Line search condition violated. Rejecting the step!
2020-09-06 23:01:59 | [drl] epoch #59 | Violated because loss is NaN
2020-09-06 23:01:59 | [drl] epoch #59 | Violated because constraint mean_kl is NaN
2020-09-06 23:01:59 | [drl] epoch #59 | backtrack iters: 14
2020-09-06 23:01:59 | [drl] epoch #59 | optimization finished
2020-09-06 23:01:59 | [drl] epoch #59 | Computing KL after
2020-09-06 23:01:59 | [drl] epoch #59 | Computing loss after
2020-09-06 23:01:59 | [drl] epoch #59 | Fitting baseline...
2020-09-06 23:01:59 | [drl] epoch #59 | Saving snapshot...
2020-09-06 23:01:59 | [drl] epoch #59 | Saved
2020-09-06 23:01:59 | [drl] epoch #59 | Time 49.92 s
2020-09-06 23:01:59 | [drl] epoch #59 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -85407.1
AverageReturn                            -139527
Entropy                                        8.51363
EnvExecTime                                    0.0334115
Extras/EpisodeRewardMean                 -203049
Iteration                                     59
LinearFeatureBaseline/ExplainedVariance        0.93504
MaxReturn                                -139527
MinReturn                                -139527
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0451214
ProcessExecTime                                0.00104809
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:01:59 | [drl] epoch #60 | Obtaining samples...
2020-09-06 23:01:59 | [drl] epoch #60 | Obtaining samples for iteration 60...
2020-09-06 23:01:59 | [drl] epoch #60 | Logging diagnostics...
2020-09-06 23:01:59 | [drl] epoch #60 | Optimizing policy...
2020-09-06 23:01:59 | [drl] epoch #60 | Computing loss before
2020-09-06 23:01:59 | [drl] epoch #60 | Computing KL before
2020-09-06 23:01:59 | [drl] epoch #60 | Optimizing
2020-09-06 23:01:59 | [drl] epoch #60 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:01:59 | [drl] epoch #60 | computing loss before
2020-09-06 23:01:59 | [drl] epoch #60 | computing gradient
2020-09-06 23:01:59 | [drl] epoch #60 | gradient computed
2020-09-06 23:01:59 | [drl] epoch #60 | computing descent direction
2020-09-06 23:02:00 | [drl] epoch #60 | descent direction computed
2020-09-06 23:02:00 | [drl] epoch #60 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:00 | [drl] epoch #60 | Violated because loss is NaN
2020-09-06 23:02:00 | [drl] epoch #60 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:00 | [drl] epoch #60 | backtrack iters: 14
2020-09-06 23:02:00 | [drl] epoch #60 | optimization finished
2020-09-06 23:02:00 | [drl] epoch #60 | Computing KL after
2020-09-06 23:02:00 | [drl] epoch #60 | Computing loss after
2020-09-06 23:02:00 | [drl] epoch #60 | Fitting baseline...
2020-09-06 23:02:00 | [drl] epoch #60 | Saving snapshot...
2020-09-06 23:02:00 | [drl] epoch #60 | Saved
2020-09-06 23:02:00 | [drl] epoch #60 | Time 50.66 s
2020-09-06 23:02:00 | [drl] epoch #60 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -181040
AverageReturn                            -296004
Entropy                                        8.51363
EnvExecTime                                    0.0414901
Extras/EpisodeRewardMean                 -204573
Iteration                                     60
LinearFeatureBaseline/ExplainedVariance        0.716422
MaxReturn                                -296004
MinReturn                                -296004
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.043788
ProcessExecTime                                0.00103855
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:00 | [drl] epoch #61 | Obtaining samples...
2020-09-06 23:02:00 | [drl] epoch #61 | Obtaining samples for iteration 61...
2020-09-06 23:02:00 | [drl] epoch #61 | Logging diagnostics...
2020-09-06 23:02:00 | [drl] epoch #61 | Optimizing policy...
2020-09-06 23:02:00 | [drl] epoch #61 | Computing loss before
2020-09-06 23:02:00 | [drl] epoch #61 | Computing KL before
2020-09-06 23:02:00 | [drl] epoch #61 | Optimizing
2020-09-06 23:02:00 | [drl] epoch #61 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:00 | [drl] epoch #61 | computing loss before
2020-09-06 23:02:00 | [drl] epoch #61 | computing gradient
2020-09-06 23:02:00 | [drl] epoch #61 | gradient computed
2020-09-06 23:02:00 | [drl] epoch #61 | computing descent direction
2020-09-06 23:02:00 | [drl] epoch #61 | descent direction computed
2020-09-06 23:02:01 | [drl] epoch #61 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:01 | [drl] epoch #61 | Violated because loss is NaN
2020-09-06 23:02:01 | [drl] epoch #61 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:01 | [drl] epoch #61 | backtrack iters: 14
2020-09-06 23:02:01 | [drl] epoch #61 | optimization finished
2020-09-06 23:02:01 | [drl] epoch #61 | Computing KL after
2020-09-06 23:02:01 | [drl] epoch #61 | Computing loss after
2020-09-06 23:02:01 | [drl] epoch #61 | Fitting baseline...
2020-09-06 23:02:01 | [drl] epoch #61 | Saving snapshot...
2020-09-06 23:02:01 | [drl] epoch #61 | Saved
2020-09-06 23:02:01 | [drl] epoch #61 | Time 51.41 s
2020-09-06 23:02:01 | [drl] epoch #61 | EpochTime 0.73 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -163842
AverageReturn                            -267869
Entropy                                        8.51363
EnvExecTime                                    0.0319123
Extras/EpisodeRewardMean                 -205594
Iteration                                     61
LinearFeatureBaseline/ExplainedVariance        0.988761
MaxReturn                                -267869
MinReturn                                -267869
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0435276
ProcessExecTime                                0.00134373
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:01 | [drl] epoch #62 | Obtaining samples...
2020-09-06 23:02:01 | [drl] epoch #62 | Obtaining samples for iteration 62...
2020-09-06 23:02:01 | [drl] epoch #62 | Logging diagnostics...
2020-09-06 23:02:01 | [drl] epoch #62 | Optimizing policy...
2020-09-06 23:02:01 | [drl] epoch #62 | Computing loss before
2020-09-06 23:02:01 | [drl] epoch #62 | Computing KL before
2020-09-06 23:02:01 | [drl] epoch #62 | Optimizing
2020-09-06 23:02:01 | [drl] epoch #62 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:01 | [drl] epoch #62 | computing loss before
2020-09-06 23:02:01 | [drl] epoch #62 | computing gradient
2020-09-06 23:02:01 | [drl] epoch #62 | gradient computed
2020-09-06 23:02:01 | [drl] epoch #62 | computing descent direction
2020-09-06 23:02:01 | [drl] epoch #62 | descent direction computed
2020-09-06 23:02:01 | [drl] epoch #62 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:01 | [drl] epoch #62 | Violated because loss is NaN
2020-09-06 23:02:01 | [drl] epoch #62 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:01 | [drl] epoch #62 | backtrack iters: 14
2020-09-06 23:02:01 | [drl] epoch #62 | optimization finished
2020-09-06 23:02:01 | [drl] epoch #62 | Computing KL after
2020-09-06 23:02:01 | [drl] epoch #62 | Computing loss after
2020-09-06 23:02:01 | [drl] epoch #62 | Fitting baseline...
2020-09-06 23:02:01 | [drl] epoch #62 | Saving snapshot...
2020-09-06 23:02:01 | [drl] epoch #62 | Saved
2020-09-06 23:02:01 | [drl] epoch #62 | Time 52.18 s
2020-09-06 23:02:01 | [drl] epoch #62 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -97578.5
AverageReturn                            -159450
Entropy                                        8.51363
EnvExecTime                                    0.033931
Extras/EpisodeRewardMean                 -204862
Iteration                                     62
LinearFeatureBaseline/ExplainedVariance        0.524721
MaxReturn                                -159450
MinReturn                                -159450
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0460215
ProcessExecTime                                0.000966787
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:01 | [drl] epoch #63 | Obtaining samples...
2020-09-06 23:02:01 | [drl] epoch #63 | Obtaining samples for iteration 63...
2020-09-06 23:02:01 | [drl] epoch #63 | Logging diagnostics...
2020-09-06 23:02:01 | [drl] epoch #63 | Optimizing policy...
2020-09-06 23:02:01 | [drl] epoch #63 | Computing loss before
2020-09-06 23:02:01 | [drl] epoch #63 | Computing KL before
2020-09-06 23:02:01 | [drl] epoch #63 | Optimizing
2020-09-06 23:02:01 | [drl] epoch #63 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:01 | [drl] epoch #63 | computing loss before
2020-09-06 23:02:01 | [drl] epoch #63 | computing gradient
2020-09-06 23:02:01 | [drl] epoch #63 | gradient computed
2020-09-06 23:02:01 | [drl] epoch #63 | computing descent direction
2020-09-06 23:02:02 | [drl] epoch #63 | descent direction computed
2020-09-06 23:02:02 | [drl] epoch #63 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:02 | [drl] epoch #63 | Violated because loss is NaN
2020-09-06 23:02:02 | [drl] epoch #63 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:02 | [drl] epoch #63 | backtrack iters: 14
2020-09-06 23:02:02 | [drl] epoch #63 | optimization finished
2020-09-06 23:02:02 | [drl] epoch #63 | Computing KL after
2020-09-06 23:02:02 | [drl] epoch #63 | Computing loss after
2020-09-06 23:02:02 | [drl] epoch #63 | Fitting baseline...
2020-09-06 23:02:02 | [drl] epoch #63 | Saving snapshot...
2020-09-06 23:02:02 | [drl] epoch #63 | Saved
2020-09-06 23:02:02 | [drl] epoch #63 | Time 52.93 s
2020-09-06 23:02:02 | [drl] epoch #63 | EpochTime 0.74 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -88079
AverageReturn                            -143903
Entropy                                        8.51363
EnvExecTime                                    0.0342748
Extras/EpisodeRewardMean                 -203909
Iteration                                     63
LinearFeatureBaseline/ExplainedVariance        0.988021
MaxReturn                                -143903
MinReturn                                -143903
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0458245
ProcessExecTime                                0.00094676
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:02 | [drl] epoch #64 | Obtaining samples...
2020-09-06 23:02:02 | [drl] epoch #64 | Obtaining samples for iteration 64...
2020-09-06 23:02:02 | [drl] epoch #64 | Logging diagnostics...
2020-09-06 23:02:02 | [drl] epoch #64 | Optimizing policy...
2020-09-06 23:02:02 | [drl] epoch #64 | Computing loss before
2020-09-06 23:02:02 | [drl] epoch #64 | Computing KL before
2020-09-06 23:02:02 | [drl] epoch #64 | Optimizing
2020-09-06 23:02:02 | [drl] epoch #64 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:02 | [drl] epoch #64 | computing loss before
2020-09-06 23:02:02 | [drl] epoch #64 | computing gradient
2020-09-06 23:02:02 | [drl] epoch #64 | gradient computed
2020-09-06 23:02:02 | [drl] epoch #64 | computing descent direction
2020-09-06 23:02:03 | [drl] epoch #64 | descent direction computed
2020-09-06 23:02:03 | [drl] epoch #64 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:03 | [drl] epoch #64 | Violated because loss is NaN
2020-09-06 23:02:03 | [drl] epoch #64 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:03 | [drl] epoch #64 | backtrack iters: 14
2020-09-06 23:02:03 | [drl] epoch #64 | optimization finished
2020-09-06 23:02:03 | [drl] epoch #64 | Computing KL after
2020-09-06 23:02:03 | [drl] epoch #64 | Computing loss after
2020-09-06 23:02:03 | [drl] epoch #64 | Fitting baseline...
2020-09-06 23:02:03 | [drl] epoch #64 | Saving snapshot...
2020-09-06 23:02:03 | [drl] epoch #64 | Saved
2020-09-06 23:02:03 | [drl] epoch #64 | Time 53.69 s
2020-09-06 23:02:03 | [drl] epoch #64 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -87203.5
AverageReturn                            -142464
Entropy                                        8.51363
EnvExecTime                                    0.0431018
Extras/EpisodeRewardMean                 -202964
Iteration                                     64
LinearFeatureBaseline/ExplainedVariance        0.999881
MaxReturn                                -142464
MinReturn                                -142464
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0458927
ProcessExecTime                                0.00100255
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:03 | [drl] epoch #65 | Obtaining samples...
2020-09-06 23:02:03 | [drl] epoch #65 | Obtaining samples for iteration 65...
2020-09-06 23:02:03 | [drl] epoch #65 | Logging diagnostics...
2020-09-06 23:02:03 | [drl] epoch #65 | Optimizing policy...
2020-09-06 23:02:03 | [drl] epoch #65 | Computing loss before
2020-09-06 23:02:03 | [drl] epoch #65 | Computing KL before
2020-09-06 23:02:03 | [drl] epoch #65 | Optimizing
2020-09-06 23:02:03 | [drl] epoch #65 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:03 | [drl] epoch #65 | computing loss before
2020-09-06 23:02:03 | [drl] epoch #65 | computing gradient
2020-09-06 23:02:03 | [drl] epoch #65 | gradient computed
2020-09-06 23:02:03 | [drl] epoch #65 | computing descent direction
2020-09-06 23:02:03 | [drl] epoch #65 | descent direction computed
2020-09-06 23:02:04 | [drl] epoch #65 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:04 | [drl] epoch #65 | Violated because loss is NaN
2020-09-06 23:02:04 | [drl] epoch #65 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:04 | [drl] epoch #65 | backtrack iters: 14
2020-09-06 23:02:04 | [drl] epoch #65 | optimization finished
2020-09-06 23:02:04 | [drl] epoch #65 | Computing KL after
2020-09-06 23:02:04 | [drl] epoch #65 | Computing loss after
2020-09-06 23:02:04 | [drl] epoch #65 | Fitting baseline...
2020-09-06 23:02:04 | [drl] epoch #65 | Saving snapshot...
2020-09-06 23:02:04 | [drl] epoch #65 | Saved
2020-09-06 23:02:04 | [drl] epoch #65 | Time 54.44 s
2020-09-06 23:02:04 | [drl] epoch #65 | EpochTime 0.75 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -164100
AverageReturn                            -268298
Entropy                                        8.51363
EnvExecTime                                    0.0335102
Extras/EpisodeRewardMean                 -203954
Iteration                                     65
LinearFeatureBaseline/ExplainedVariance        0.776063
MaxReturn                                -268298
MinReturn                                -268298
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0457218
ProcessExecTime                                0.00514317
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:04 | [drl] epoch #66 | Obtaining samples...
2020-09-06 23:02:04 | [drl] epoch #66 | Obtaining samples for iteration 66...
2020-09-06 23:02:04 | [drl] epoch #66 | Logging diagnostics...
2020-09-06 23:02:04 | [drl] epoch #66 | Optimizing policy...
2020-09-06 23:02:04 | [drl] epoch #66 | Computing loss before
2020-09-06 23:02:04 | [drl] epoch #66 | Computing KL before
2020-09-06 23:02:04 | [drl] epoch #66 | Optimizing
2020-09-06 23:02:04 | [drl] epoch #66 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:04 | [drl] epoch #66 | computing loss before
2020-09-06 23:02:04 | [drl] epoch #66 | computing gradient
2020-09-06 23:02:04 | [drl] epoch #66 | gradient computed
2020-09-06 23:02:04 | [drl] epoch #66 | computing descent direction
2020-09-06 23:02:04 | [drl] epoch #66 | descent direction computed
2020-09-06 23:02:04 | [drl] epoch #66 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:04 | [drl] epoch #66 | Violated because loss is NaN
2020-09-06 23:02:04 | [drl] epoch #66 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:04 | [drl] epoch #66 | backtrack iters: 14
2020-09-06 23:02:04 | [drl] epoch #66 | optimization finished
2020-09-06 23:02:04 | [drl] epoch #66 | Computing KL after
2020-09-06 23:02:04 | [drl] epoch #66 | Computing loss after
2020-09-06 23:02:04 | [drl] epoch #66 | Fitting baseline...
2020-09-06 23:02:04 | [drl] epoch #66 | Saving snapshot...
2020-09-06 23:02:04 | [drl] epoch #66 | Saved
2020-09-06 23:02:04 | [drl] epoch #66 | Time 55.21 s
2020-09-06 23:02:04 | [drl] epoch #66 | EpochTime 0.76 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -92386
AverageReturn                            -150933
Entropy                                        8.51363
EnvExecTime                                    0.0391407
Extras/EpisodeRewardMean                 -203162
Iteration                                     66
LinearFeatureBaseline/ExplainedVariance        0.374969
MaxReturn                                -150933
MinReturn                                -150933
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0405016
ProcessExecTime                                0.00132322
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:04 | [drl] epoch #67 | Obtaining samples...
2020-09-06 23:02:04 | [drl] epoch #67 | Obtaining samples for iteration 67...
2020-09-06 23:02:04 | [drl] epoch #67 | Logging diagnostics...
2020-09-06 23:02:04 | [drl] epoch #67 | Optimizing policy...
2020-09-06 23:02:04 | [drl] epoch #67 | Computing loss before
2020-09-06 23:02:04 | [drl] epoch #67 | Computing KL before
2020-09-06 23:02:04 | [drl] epoch #67 | Optimizing
2020-09-06 23:02:04 | [drl] epoch #67 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:04 | [drl] epoch #67 | computing loss before
2020-09-06 23:02:04 | [drl] epoch #67 | computing gradient
2020-09-06 23:02:04 | [drl] epoch #67 | gradient computed
2020-09-06 23:02:04 | [drl] epoch #67 | computing descent direction
2020-09-06 23:02:05 | [drl] epoch #67 | descent direction computed
2020-09-06 23:02:05 | [drl] epoch #67 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:05 | [drl] epoch #67 | Violated because loss is NaN
2020-09-06 23:02:05 | [drl] epoch #67 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:05 | [drl] epoch #67 | backtrack iters: 14
2020-09-06 23:02:05 | [drl] epoch #67 | optimization finished
2020-09-06 23:02:05 | [drl] epoch #67 | Computing KL after
2020-09-06 23:02:05 | [drl] epoch #67 | Computing loss after
2020-09-06 23:02:05 | [drl] epoch #67 | Fitting baseline...
2020-09-06 23:02:05 | [drl] epoch #67 | Saving snapshot...
2020-09-06 23:02:05 | [drl] epoch #67 | Saved
2020-09-06 23:02:05 | [drl] epoch #67 | Time 55.98 s
2020-09-06 23:02:05 | [drl] epoch #67 | EpochTime 0.75 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -99646.6
AverageReturn                            -162818
Entropy                                        8.51363
EnvExecTime                                    0.0456209
Extras/EpisodeRewardMean                 -202569
Iteration                                     67
LinearFeatureBaseline/ExplainedVariance        0.994453
MaxReturn                                -162818
MinReturn                                -162818
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0404592
ProcessExecTime                                0.000986576
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:05 | [drl] epoch #68 | Obtaining samples...
2020-09-06 23:02:05 | [drl] epoch #68 | Obtaining samples for iteration 68...
2020-09-06 23:02:05 | [drl] epoch #68 | Logging diagnostics...
2020-09-06 23:02:05 | [drl] epoch #68 | Optimizing policy...
2020-09-06 23:02:05 | [drl] epoch #68 | Computing loss before
2020-09-06 23:02:05 | [drl] epoch #68 | Computing KL before
2020-09-06 23:02:05 | [drl] epoch #68 | Optimizing
2020-09-06 23:02:05 | [drl] epoch #68 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:05 | [drl] epoch #68 | computing loss before
2020-09-06 23:02:05 | [drl] epoch #68 | computing gradient
2020-09-06 23:02:05 | [drl] epoch #68 | gradient computed
2020-09-06 23:02:05 | [drl] epoch #68 | computing descent direction
2020-09-06 23:02:06 | [drl] epoch #68 | descent direction computed
2020-09-06 23:02:06 | [drl] epoch #68 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:06 | [drl] epoch #68 | Violated because loss is NaN
2020-09-06 23:02:06 | [drl] epoch #68 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:06 | [drl] epoch #68 | backtrack iters: 14
2020-09-06 23:02:06 | [drl] epoch #68 | optimization finished
2020-09-06 23:02:06 | [drl] epoch #68 | Computing KL after
2020-09-06 23:02:06 | [drl] epoch #68 | Computing loss after
2020-09-06 23:02:06 | [drl] epoch #68 | Fitting baseline...
2020-09-06 23:02:06 | [drl] epoch #68 | Saving snapshot...
2020-09-06 23:02:06 | [drl] epoch #68 | Saved
2020-09-06 23:02:06 | [drl] epoch #68 | Time 56.78 s
2020-09-06 23:02:06 | [drl] epoch #68 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114481
AverageReturn                            -187102
Entropy                                        8.51363
EnvExecTime                                    0.041805
Extras/EpisodeRewardMean                 -202345
Iteration                                     68
LinearFeatureBaseline/ExplainedVariance        0.982752
MaxReturn                                -187102
MinReturn                                -187102
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0382576
ProcessExecTime                                0.000954151
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:06 | [drl] epoch #69 | Obtaining samples...
2020-09-06 23:02:06 | [drl] epoch #69 | Obtaining samples for iteration 69...
2020-09-06 23:02:06 | [drl] epoch #69 | Logging diagnostics...
2020-09-06 23:02:06 | [drl] epoch #69 | Optimizing policy...
2020-09-06 23:02:06 | [drl] epoch #69 | Computing loss before
2020-09-06 23:02:06 | [drl] epoch #69 | Computing KL before
2020-09-06 23:02:06 | [drl] epoch #69 | Optimizing
2020-09-06 23:02:06 | [drl] epoch #69 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:06 | [drl] epoch #69 | computing loss before
2020-09-06 23:02:06 | [drl] epoch #69 | computing gradient
2020-09-06 23:02:06 | [drl] epoch #69 | gradient computed
2020-09-06 23:02:06 | [drl] epoch #69 | computing descent direction
2020-09-06 23:02:07 | [drl] epoch #69 | descent direction computed
2020-09-06 23:02:07 | [drl] epoch #69 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:07 | [drl] epoch #69 | Violated because loss is NaN
2020-09-06 23:02:07 | [drl] epoch #69 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:07 | [drl] epoch #69 | backtrack iters: 14
2020-09-06 23:02:07 | [drl] epoch #69 | optimization finished
2020-09-06 23:02:07 | [drl] epoch #69 | Computing KL after
2020-09-06 23:02:07 | [drl] epoch #69 | Computing loss after
2020-09-06 23:02:07 | [drl] epoch #69 | Fitting baseline...
2020-09-06 23:02:07 | [drl] epoch #69 | Saving snapshot...
2020-09-06 23:02:07 | [drl] epoch #69 | Saved
2020-09-06 23:02:07 | [drl] epoch #69 | Time 57.60 s
2020-09-06 23:02:07 | [drl] epoch #69 | EpochTime 0.81 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -89373
AverageReturn                            -146017
Entropy                                        8.51363
EnvExecTime                                    0.0356839
Extras/EpisodeRewardMean                 -201540
Iteration                                     69
LinearFeatureBaseline/ExplainedVariance        0.918392
MaxReturn                                -146017
MinReturn                                -146017
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0555656
ProcessExecTime                                0.00221348
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:07 | [drl] epoch #70 | Obtaining samples...
2020-09-06 23:02:07 | [drl] epoch #70 | Obtaining samples for iteration 70...
2020-09-06 23:02:07 | [drl] epoch #70 | Logging diagnostics...
2020-09-06 23:02:07 | [drl] epoch #70 | Optimizing policy...
2020-09-06 23:02:07 | [drl] epoch #70 | Computing loss before
2020-09-06 23:02:07 | [drl] epoch #70 | Computing KL before
2020-09-06 23:02:07 | [drl] epoch #70 | Optimizing
2020-09-06 23:02:07 | [drl] epoch #70 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:07 | [drl] epoch #70 | computing loss before
2020-09-06 23:02:07 | [drl] epoch #70 | computing gradient
2020-09-06 23:02:07 | [drl] epoch #70 | gradient computed
2020-09-06 23:02:07 | [drl] epoch #70 | computing descent direction
2020-09-06 23:02:07 | [drl] epoch #70 | descent direction computed
2020-09-06 23:02:08 | [drl] epoch #70 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:08 | [drl] epoch #70 | Violated because loss is NaN
2020-09-06 23:02:08 | [drl] epoch #70 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:08 | [drl] epoch #70 | backtrack iters: 14
2020-09-06 23:02:08 | [drl] epoch #70 | optimization finished
2020-09-06 23:02:08 | [drl] epoch #70 | Computing KL after
2020-09-06 23:02:08 | [drl] epoch #70 | Computing loss after
2020-09-06 23:02:08 | [drl] epoch #70 | Fitting baseline...
2020-09-06 23:02:08 | [drl] epoch #70 | Saving snapshot...
2020-09-06 23:02:08 | [drl] epoch #70 | Saved
2020-09-06 23:02:08 | [drl] epoch #70 | Time 58.42 s
2020-09-06 23:02:08 | [drl] epoch #70 | EpochTime 0.80 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -182188
AverageReturn                            -297893
Entropy                                        8.51363
EnvExecTime                                    0.0396371
Extras/EpisodeRewardMean                 -202897
Iteration                                     70
LinearFeatureBaseline/ExplainedVariance        0.73593
MaxReturn                                -297893
MinReturn                                -297893
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0586832
ProcessExecTime                                0.00233936
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:08 | [drl] epoch #71 | Obtaining samples...
2020-09-06 23:02:08 | [drl] epoch #71 | Obtaining samples for iteration 71...
2020-09-06 23:02:08 | [drl] epoch #71 | Logging diagnostics...
2020-09-06 23:02:08 | [drl] epoch #71 | Optimizing policy...
2020-09-06 23:02:08 | [drl] epoch #71 | Computing loss before
2020-09-06 23:02:08 | [drl] epoch #71 | Computing KL before
2020-09-06 23:02:08 | [drl] epoch #71 | Optimizing
2020-09-06 23:02:08 | [drl] epoch #71 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:08 | [drl] epoch #71 | computing loss before
2020-09-06 23:02:08 | [drl] epoch #71 | computing gradient
2020-09-06 23:02:08 | [drl] epoch #71 | gradient computed
2020-09-06 23:02:08 | [drl] epoch #71 | computing descent direction
2020-09-06 23:02:08 | [drl] epoch #71 | descent direction computed
2020-09-06 23:02:09 | [drl] epoch #71 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:09 | [drl] epoch #71 | Violated because loss is NaN
2020-09-06 23:02:09 | [drl] epoch #71 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:09 | [drl] epoch #71 | backtrack iters: 14
2020-09-06 23:02:09 | [drl] epoch #71 | optimization finished
2020-09-06 23:02:09 | [drl] epoch #71 | Computing KL after
2020-09-06 23:02:09 | [drl] epoch #71 | Computing loss after
2020-09-06 23:02:09 | [drl] epoch #71 | Fitting baseline...
2020-09-06 23:02:09 | [drl] epoch #71 | Saving snapshot...
2020-09-06 23:02:09 | [drl] epoch #71 | Saved
2020-09-06 23:02:09 | [drl] epoch #71 | Time 59.50 s
2020-09-06 23:02:09 | [drl] epoch #71 | EpochTime 1.07 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101167
AverageReturn                            -165303
Entropy                                        8.51363
EnvExecTime                                    0.0400317
Extras/EpisodeRewardMean                 -202375
Iteration                                     71
LinearFeatureBaseline/ExplainedVariance        0.335713
MaxReturn                                -165303
MinReturn                                -165303
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0395186
ProcessExecTime                                0.000999451
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:09 | [drl] epoch #72 | Obtaining samples...
2020-09-06 23:02:09 | [drl] epoch #72 | Obtaining samples for iteration 72...
2020-09-06 23:02:09 | [drl] epoch #72 | Logging diagnostics...
2020-09-06 23:02:09 | [drl] epoch #72 | Optimizing policy...
2020-09-06 23:02:09 | [drl] epoch #72 | Computing loss before
2020-09-06 23:02:09 | [drl] epoch #72 | Computing KL before
2020-09-06 23:02:09 | [drl] epoch #72 | Optimizing
2020-09-06 23:02:09 | [drl] epoch #72 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:09 | [drl] epoch #72 | computing loss before
2020-09-06 23:02:09 | [drl] epoch #72 | computing gradient
2020-09-06 23:02:09 | [drl] epoch #72 | gradient computed
2020-09-06 23:02:09 | [drl] epoch #72 | computing descent direction
2020-09-06 23:02:09 | [drl] epoch #72 | descent direction computed
2020-09-06 23:02:09 | [drl] epoch #72 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:09 | [drl] epoch #72 | Violated because loss is NaN
2020-09-06 23:02:09 | [drl] epoch #72 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:09 | [drl] epoch #72 | backtrack iters: 14
2020-09-06 23:02:09 | [drl] epoch #72 | optimization finished
2020-09-06 23:02:09 | [drl] epoch #72 | Computing KL after
2020-09-06 23:02:09 | [drl] epoch #72 | Computing loss after
2020-09-06 23:02:10 | [drl] epoch #72 | Fitting baseline...
2020-09-06 23:02:10 | [drl] epoch #72 | Saving snapshot...
2020-09-06 23:02:10 | [drl] epoch #72 | Saved
2020-09-06 23:02:10 | [drl] epoch #72 | Time 60.39 s
2020-09-06 23:02:10 | [drl] epoch #72 | EpochTime 0.87 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -123442
AverageReturn                            -201765
Entropy                                        8.51363
EnvExecTime                                    0.0339191
Extras/EpisodeRewardMean                 -202367
Iteration                                     72
LinearFeatureBaseline/ExplainedVariance        0.966302
MaxReturn                                -201765
MinReturn                                -201765
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0444427
ProcessExecTime                                0.000939131
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:10 | [drl] epoch #73 | Obtaining samples...
2020-09-06 23:02:10 | [drl] epoch #73 | Obtaining samples for iteration 73...
2020-09-06 23:02:10 | [drl] epoch #73 | Logging diagnostics...
2020-09-06 23:02:10 | [drl] epoch #73 | Optimizing policy...
2020-09-06 23:02:10 | [drl] epoch #73 | Computing loss before
2020-09-06 23:02:10 | [drl] epoch #73 | Computing KL before
2020-09-06 23:02:10 | [drl] epoch #73 | Optimizing
2020-09-06 23:02:10 | [drl] epoch #73 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:10 | [drl] epoch #73 | computing loss before
2020-09-06 23:02:10 | [drl] epoch #73 | computing gradient
2020-09-06 23:02:10 | [drl] epoch #73 | gradient computed
2020-09-06 23:02:10 | [drl] epoch #73 | computing descent direction
2020-09-06 23:02:10 | [drl] epoch #73 | descent direction computed
2020-09-06 23:02:10 | [drl] epoch #73 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:10 | [drl] epoch #73 | Violated because loss is NaN
2020-09-06 23:02:10 | [drl] epoch #73 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:10 | [drl] epoch #73 | backtrack iters: 14
2020-09-06 23:02:10 | [drl] epoch #73 | optimization finished
2020-09-06 23:02:10 | [drl] epoch #73 | Computing KL after
2020-09-06 23:02:10 | [drl] epoch #73 | Computing loss after
2020-09-06 23:02:10 | [drl] epoch #73 | Fitting baseline...
2020-09-06 23:02:10 | [drl] epoch #73 | Saving snapshot...
2020-09-06 23:02:10 | [drl] epoch #73 | Saved
2020-09-06 23:02:10 | [drl] epoch #73 | Time 61.16 s
2020-09-06 23:02:10 | [drl] epoch #73 | EpochTime 0.76 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -82541
AverageReturn                            -134836
Entropy                                        8.51363
EnvExecTime                                    0.0393343
Extras/EpisodeRewardMean                 -201454
Iteration                                     73
LinearFeatureBaseline/ExplainedVariance        0.744276
MaxReturn                                -134836
MinReturn                                -134836
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0433388
ProcessExecTime                                0.000964642
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:10 | [drl] epoch #74 | Obtaining samples...
2020-09-06 23:02:10 | [drl] epoch #74 | Obtaining samples for iteration 74...
2020-09-06 23:02:10 | [drl] epoch #74 | Logging diagnostics...
2020-09-06 23:02:10 | [drl] epoch #74 | Optimizing policy...
2020-09-06 23:02:10 | [drl] epoch #74 | Computing loss before
2020-09-06 23:02:10 | [drl] epoch #74 | Computing KL before
2020-09-06 23:02:10 | [drl] epoch #74 | Optimizing
2020-09-06 23:02:10 | [drl] epoch #74 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:10 | [drl] epoch #74 | computing loss before
2020-09-06 23:02:10 | [drl] epoch #74 | computing gradient
2020-09-06 23:02:10 | [drl] epoch #74 | gradient computed
2020-09-06 23:02:10 | [drl] epoch #74 | computing descent direction
2020-09-06 23:02:11 | [drl] epoch #74 | descent direction computed
2020-09-06 23:02:11 | [drl] epoch #74 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:11 | [drl] epoch #74 | Violated because loss is NaN
2020-09-06 23:02:11 | [drl] epoch #74 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:11 | [drl] epoch #74 | backtrack iters: 14
2020-09-06 23:02:11 | [drl] epoch #74 | optimization finished
2020-09-06 23:02:11 | [drl] epoch #74 | Computing KL after
2020-09-06 23:02:11 | [drl] epoch #74 | Computing loss after
2020-09-06 23:02:11 | [drl] epoch #74 | Fitting baseline...
2020-09-06 23:02:11 | [drl] epoch #74 | Saving snapshot...
2020-09-06 23:02:11 | [drl] epoch #74 | Saved
2020-09-06 23:02:11 | [drl] epoch #74 | Time 62.06 s
2020-09-06 23:02:11 | [drl] epoch #74 | EpochTime 0.88 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -145122
AverageReturn                            -237232
Entropy                                        8.51363
EnvExecTime                                    0.0437899
Extras/EpisodeRewardMean                 -201931
Iteration                                     74
LinearFeatureBaseline/ExplainedVariance        0.810021
MaxReturn                                -237232
MinReturn                                -237232
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0449817
ProcessExecTime                                0.00137687
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:11 | [drl] epoch #75 | Obtaining samples...
2020-09-06 23:02:11 | [drl] epoch #75 | Obtaining samples for iteration 75...
2020-09-06 23:02:11 | [drl] epoch #75 | Logging diagnostics...
2020-09-06 23:02:11 | [drl] epoch #75 | Optimizing policy...
2020-09-06 23:02:11 | [drl] epoch #75 | Computing loss before
2020-09-06 23:02:11 | [drl] epoch #75 | Computing KL before
2020-09-06 23:02:11 | [drl] epoch #75 | Optimizing
2020-09-06 23:02:11 | [drl] epoch #75 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:11 | [drl] epoch #75 | computing loss before
2020-09-06 23:02:11 | [drl] epoch #75 | computing gradient
2020-09-06 23:02:11 | [drl] epoch #75 | gradient computed
2020-09-06 23:02:11 | [drl] epoch #75 | computing descent direction
2020-09-06 23:02:12 | [drl] epoch #75 | descent direction computed
2020-09-06 23:02:12 | [drl] epoch #75 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:12 | [drl] epoch #75 | Violated because loss is NaN
2020-09-06 23:02:12 | [drl] epoch #75 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:12 | [drl] epoch #75 | backtrack iters: 14
2020-09-06 23:02:12 | [drl] epoch #75 | optimization finished
2020-09-06 23:02:12 | [drl] epoch #75 | Computing KL after
2020-09-06 23:02:12 | [drl] epoch #75 | Computing loss after
2020-09-06 23:02:12 | [drl] epoch #75 | Fitting baseline...
2020-09-06 23:02:12 | [drl] epoch #75 | Saving snapshot...
2020-09-06 23:02:12 | [drl] epoch #75 | Saved
2020-09-06 23:02:12 | [drl] epoch #75 | Time 62.99 s
2020-09-06 23:02:12 | [drl] epoch #75 | EpochTime 0.92 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -114168
AverageReturn                            -186598
Entropy                                        8.51363
EnvExecTime                                    0.0449617
Extras/EpisodeRewardMean                 -201729
Iteration                                     75
LinearFeatureBaseline/ExplainedVariance        0.924675
MaxReturn                                -186598
MinReturn                                -186598
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0574651
ProcessExecTime                                0.00105333
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:12 | [drl] epoch #76 | Obtaining samples...
2020-09-06 23:02:12 | [drl] epoch #76 | Obtaining samples for iteration 76...
2020-09-06 23:02:12 | [drl] epoch #76 | Logging diagnostics...
2020-09-06 23:02:12 | [drl] epoch #76 | Optimizing policy...
2020-09-06 23:02:12 | [drl] epoch #76 | Computing loss before
2020-09-06 23:02:12 | [drl] epoch #76 | Computing KL before
2020-09-06 23:02:12 | [drl] epoch #76 | Optimizing
2020-09-06 23:02:12 | [drl] epoch #76 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:12 | [drl] epoch #76 | computing loss before
2020-09-06 23:02:12 | [drl] epoch #76 | computing gradient
2020-09-06 23:02:12 | [drl] epoch #76 | gradient computed
2020-09-06 23:02:12 | [drl] epoch #76 | computing descent direction
2020-09-06 23:02:13 | [drl] epoch #76 | descent direction computed
2020-09-06 23:02:13 | [drl] epoch #76 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:13 | [drl] epoch #76 | Violated because loss is NaN
2020-09-06 23:02:13 | [drl] epoch #76 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:13 | [drl] epoch #76 | backtrack iters: 14
2020-09-06 23:02:13 | [drl] epoch #76 | optimization finished
2020-09-06 23:02:13 | [drl] epoch #76 | Computing KL after
2020-09-06 23:02:13 | [drl] epoch #76 | Computing loss after
2020-09-06 23:02:13 | [drl] epoch #76 | Fitting baseline...
2020-09-06 23:02:13 | [drl] epoch #76 | Saving snapshot...
2020-09-06 23:02:13 | [drl] epoch #76 | Saved
2020-09-06 23:02:13 | [drl] epoch #76 | Time 63.85 s
2020-09-06 23:02:13 | [drl] epoch #76 | EpochTime 0.85 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -109992
AverageReturn                            -179751
Entropy                                        8.51363
EnvExecTime                                    0.0381358
Extras/EpisodeRewardMean                 -201444
Iteration                                     76
LinearFeatureBaseline/ExplainedVariance        0.998529
MaxReturn                                -179751
MinReturn                                -179751
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0568805
ProcessExecTime                                0.00103045
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:13 | [drl] epoch #77 | Obtaining samples...
2020-09-06 23:02:13 | [drl] epoch #77 | Obtaining samples for iteration 77...
2020-09-06 23:02:13 | [drl] epoch #77 | Logging diagnostics...
2020-09-06 23:02:13 | [drl] epoch #77 | Optimizing policy...
2020-09-06 23:02:13 | [drl] epoch #77 | Computing loss before
2020-09-06 23:02:13 | [drl] epoch #77 | Computing KL before
2020-09-06 23:02:13 | [drl] epoch #77 | Optimizing
2020-09-06 23:02:13 | [drl] epoch #77 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:13 | [drl] epoch #77 | computing loss before
2020-09-06 23:02:13 | [drl] epoch #77 | computing gradient
2020-09-06 23:02:13 | [drl] epoch #77 | gradient computed
2020-09-06 23:02:13 | [drl] epoch #77 | computing descent direction
2020-09-06 23:02:14 | [drl] epoch #77 | descent direction computed
2020-09-06 23:02:14 | [drl] epoch #77 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:14 | [drl] epoch #77 | Violated because loss is NaN
2020-09-06 23:02:14 | [drl] epoch #77 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:14 | [drl] epoch #77 | backtrack iters: 14
2020-09-06 23:02:14 | [drl] epoch #77 | optimization finished
2020-09-06 23:02:14 | [drl] epoch #77 | Computing KL after
2020-09-06 23:02:14 | [drl] epoch #77 | Computing loss after
2020-09-06 23:02:14 | [drl] epoch #77 | Fitting baseline...
2020-09-06 23:02:14 | [drl] epoch #77 | Saving snapshot...
2020-09-06 23:02:14 | [drl] epoch #77 | Saved
2020-09-06 23:02:14 | [drl] epoch #77 | Time 64.60 s
2020-09-06 23:02:14 | [drl] epoch #77 | EpochTime 0.74 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -100834
AverageReturn                            -164767
Entropy                                        8.51363
EnvExecTime                                    0.0417988
Extras/EpisodeRewardMean                 -200974
Iteration                                     77
LinearFeatureBaseline/ExplainedVariance        0.991394
MaxReturn                                -164767
MinReturn                                -164767
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0412076
ProcessExecTime                                0.000996113
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:14 | [drl] epoch #78 | Obtaining samples...
2020-09-06 23:02:14 | [drl] epoch #78 | Obtaining samples for iteration 78...
2020-09-06 23:02:14 | [drl] epoch #78 | Logging diagnostics...
2020-09-06 23:02:14 | [drl] epoch #78 | Optimizing policy...
2020-09-06 23:02:14 | [drl] epoch #78 | Computing loss before
2020-09-06 23:02:14 | [drl] epoch #78 | Computing KL before
2020-09-06 23:02:14 | [drl] epoch #78 | Optimizing
2020-09-06 23:02:14 | [drl] epoch #78 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:14 | [drl] epoch #78 | computing loss before
2020-09-06 23:02:14 | [drl] epoch #78 | computing gradient
2020-09-06 23:02:14 | [drl] epoch #78 | gradient computed
2020-09-06 23:02:14 | [drl] epoch #78 | computing descent direction
2020-09-06 23:02:14 | [drl] epoch #78 | descent direction computed
2020-09-06 23:02:15 | [drl] epoch #78 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:15 | [drl] epoch #78 | Violated because loss is NaN
2020-09-06 23:02:15 | [drl] epoch #78 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:15 | [drl] epoch #78 | backtrack iters: 14
2020-09-06 23:02:15 | [drl] epoch #78 | optimization finished
2020-09-06 23:02:15 | [drl] epoch #78 | Computing KL after
2020-09-06 23:02:15 | [drl] epoch #78 | Computing loss after
2020-09-06 23:02:15 | [drl] epoch #78 | Fitting baseline...
2020-09-06 23:02:15 | [drl] epoch #78 | Saving snapshot...
2020-09-06 23:02:15 | [drl] epoch #78 | Saved
2020-09-06 23:02:15 | [drl] epoch #78 | Time 65.57 s
2020-09-06 23:02:15 | [drl] epoch #78 | EpochTime 0.95 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -88181.4
AverageReturn                            -144073
Entropy                                        8.51363
EnvExecTime                                    0.0434473
Extras/EpisodeRewardMean                 -200254
Iteration                                     78
LinearFeatureBaseline/ExplainedVariance        0.97888
MaxReturn                                -144073
MinReturn                                -144073
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0512686
ProcessExecTime                                0.00200272
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:15 | [drl] epoch #79 | Obtaining samples...
2020-09-06 23:02:15 | [drl] epoch #79 | Obtaining samples for iteration 79...
2020-09-06 23:02:15 | [drl] epoch #79 | Logging diagnostics...
2020-09-06 23:02:15 | [drl] epoch #79 | Optimizing policy...
2020-09-06 23:02:15 | [drl] epoch #79 | Computing loss before
2020-09-06 23:02:15 | [drl] epoch #79 | Computing KL before
2020-09-06 23:02:15 | [drl] epoch #79 | Optimizing
2020-09-06 23:02:15 | [drl] epoch #79 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:15 | [drl] epoch #79 | computing loss before
2020-09-06 23:02:15 | [drl] epoch #79 | computing gradient
2020-09-06 23:02:15 | [drl] epoch #79 | gradient computed
2020-09-06 23:02:15 | [drl] epoch #79 | computing descent direction
2020-09-06 23:02:15 | [drl] epoch #79 | descent direction computed
2020-09-06 23:02:16 | [drl] epoch #79 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:16 | [drl] epoch #79 | Violated because loss is NaN
2020-09-06 23:02:16 | [drl] epoch #79 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:16 | [drl] epoch #79 | backtrack iters: 14
2020-09-06 23:02:16 | [drl] epoch #79 | optimization finished
2020-09-06 23:02:16 | [drl] epoch #79 | Computing KL after
2020-09-06 23:02:16 | [drl] epoch #79 | Computing loss after
2020-09-06 23:02:16 | [drl] epoch #79 | Fitting baseline...
2020-09-06 23:02:16 | [drl] epoch #79 | Saving snapshot...
2020-09-06 23:02:16 | [drl] epoch #79 | Saved
2020-09-06 23:02:16 | [drl] epoch #79 | Time 66.49 s
2020-09-06 23:02:16 | [drl] epoch #79 | EpochTime 0.90 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -102318
AverageReturn                            -167197
Entropy                                        8.51363
EnvExecTime                                    0.0383193
Extras/EpisodeRewardMean                 -199840
Iteration                                     79
LinearFeatureBaseline/ExplainedVariance        0.980415
MaxReturn                                -167197
MinReturn                                -167197
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.044997
ProcessExecTime                                0.000972986
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:16 | [drl] epoch #80 | Obtaining samples...
2020-09-06 23:02:16 | [drl] epoch #80 | Obtaining samples for iteration 80...
2020-09-06 23:02:16 | [drl] epoch #80 | Logging diagnostics...
2020-09-06 23:02:16 | [drl] epoch #80 | Optimizing policy...
2020-09-06 23:02:16 | [drl] epoch #80 | Computing loss before
2020-09-06 23:02:16 | [drl] epoch #80 | Computing KL before
2020-09-06 23:02:16 | [drl] epoch #80 | Optimizing
2020-09-06 23:02:16 | [drl] epoch #80 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:16 | [drl] epoch #80 | computing loss before
2020-09-06 23:02:16 | [drl] epoch #80 | computing gradient
2020-09-06 23:02:16 | [drl] epoch #80 | gradient computed
2020-09-06 23:02:16 | [drl] epoch #80 | computing descent direction
2020-09-06 23:02:16 | [drl] epoch #80 | descent direction computed
2020-09-06 23:02:17 | [drl] epoch #80 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:17 | [drl] epoch #80 | Violated because loss is NaN
2020-09-06 23:02:17 | [drl] epoch #80 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:17 | [drl] epoch #80 | backtrack iters: 14
2020-09-06 23:02:17 | [drl] epoch #80 | optimization finished
2020-09-06 23:02:17 | [drl] epoch #80 | Computing KL after
2020-09-06 23:02:17 | [drl] epoch #80 | Computing loss after
2020-09-06 23:02:17 | [drl] epoch #80 | Fitting baseline...
2020-09-06 23:02:17 | [drl] epoch #80 | Saving snapshot...
2020-09-06 23:02:17 | [drl] epoch #80 | Saved
2020-09-06 23:02:17 | [drl] epoch #80 | Time 67.45 s
2020-09-06 23:02:17 | [drl] epoch #80 | EpochTime 0.94 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154554
AverageReturn                            -252680
Entropy                                        8.51363
EnvExecTime                                    0.0358653
Extras/EpisodeRewardMean                 -200493
Iteration                                     80
LinearFeatureBaseline/ExplainedVariance        0.883389
MaxReturn                                -252680
MinReturn                                -252680
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0511222
ProcessExecTime                                0.000970364
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:17 | [drl] epoch #81 | Obtaining samples...
2020-09-06 23:02:17 | [drl] epoch #81 | Obtaining samples for iteration 81...
2020-09-06 23:02:17 | [drl] epoch #81 | Logging diagnostics...
2020-09-06 23:02:17 | [drl] epoch #81 | Optimizing policy...
2020-09-06 23:02:17 | [drl] epoch #81 | Computing loss before
2020-09-06 23:02:17 | [drl] epoch #81 | Computing KL before
2020-09-06 23:02:17 | [drl] epoch #81 | Optimizing
2020-09-06 23:02:17 | [drl] epoch #81 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:17 | [drl] epoch #81 | computing loss before
2020-09-06 23:02:17 | [drl] epoch #81 | computing gradient
2020-09-06 23:02:17 | [drl] epoch #81 | gradient computed
2020-09-06 23:02:17 | [drl] epoch #81 | computing descent direction
2020-09-06 23:02:18 | [drl] epoch #81 | descent direction computed
2020-09-06 23:02:18 | [drl] epoch #81 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:18 | [drl] epoch #81 | Violated because loss is NaN
2020-09-06 23:02:18 | [drl] epoch #81 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:18 | [drl] epoch #81 | backtrack iters: 14
2020-09-06 23:02:18 | [drl] epoch #81 | optimization finished
2020-09-06 23:02:18 | [drl] epoch #81 | Computing KL after
2020-09-06 23:02:18 | [drl] epoch #81 | Computing loss after
2020-09-06 23:02:18 | [drl] epoch #81 | Fitting baseline...
2020-09-06 23:02:18 | [drl] epoch #81 | Saving snapshot...
2020-09-06 23:02:18 | [drl] epoch #81 | Saved
2020-09-06 23:02:18 | [drl] epoch #81 | Time 68.95 s
2020-09-06 23:02:18 | [drl] epoch #81 | EpochTime 1.49 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -120394
AverageReturn                            -196788
Entropy                                        8.51363
EnvExecTime                                    0.0629656
Extras/EpisodeRewardMean                 -200447
Iteration                                     81
LinearFeatureBaseline/ExplainedVariance        0.918067
MaxReturn                                -196788
MinReturn                                -196788
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0631945
ProcessExecTime                                0.00108552
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:18 | [drl] epoch #82 | Obtaining samples...
2020-09-06 23:02:18 | [drl] epoch #82 | Obtaining samples for iteration 82...
2020-09-06 23:02:18 | [drl] epoch #82 | Logging diagnostics...
2020-09-06 23:02:18 | [drl] epoch #82 | Optimizing policy...
2020-09-06 23:02:18 | [drl] epoch #82 | Computing loss before
2020-09-06 23:02:18 | [drl] epoch #82 | Computing KL before
2020-09-06 23:02:18 | [drl] epoch #82 | Optimizing
2020-09-06 23:02:18 | [drl] epoch #82 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:18 | [drl] epoch #82 | computing loss before
2020-09-06 23:02:18 | [drl] epoch #82 | computing gradient
2020-09-06 23:02:18 | [drl] epoch #82 | gradient computed
2020-09-06 23:02:18 | [drl] epoch #82 | computing descent direction
2020-09-06 23:02:19 | [drl] epoch #82 | descent direction computed
2020-09-06 23:02:19 | [drl] epoch #82 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:19 | [drl] epoch #82 | Violated because loss is NaN
2020-09-06 23:02:19 | [drl] epoch #82 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:19 | [drl] epoch #82 | backtrack iters: 14
2020-09-06 23:02:19 | [drl] epoch #82 | optimization finished
2020-09-06 23:02:19 | [drl] epoch #82 | Computing KL after
2020-09-06 23:02:19 | [drl] epoch #82 | Computing loss after
2020-09-06 23:02:19 | [drl] epoch #82 | Fitting baseline...
2020-09-06 23:02:19 | [drl] epoch #82 | Saving snapshot...
2020-09-06 23:02:19 | [drl] epoch #82 | Saved
2020-09-06 23:02:19 | [drl] epoch #82 | Time 69.97 s
2020-09-06 23:02:19 | [drl] epoch #82 | EpochTime 1.00 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -117471
AverageReturn                            -191996
Entropy                                        8.51363
EnvExecTime                                    0.0482371
Extras/EpisodeRewardMean                 -200346
Iteration                                     82
LinearFeatureBaseline/ExplainedVariance        0.999319
MaxReturn                                -191996
MinReturn                                -191996
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0561895
ProcessExecTime                                0.000957012
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:19 | [drl] epoch #83 | Obtaining samples...
2020-09-06 23:02:19 | [drl] epoch #83 | Obtaining samples for iteration 83...
2020-09-06 23:02:19 | [drl] epoch #83 | Logging diagnostics...
2020-09-06 23:02:19 | [drl] epoch #83 | Optimizing policy...
2020-09-06 23:02:19 | [drl] epoch #83 | Computing loss before
2020-09-06 23:02:19 | [drl] epoch #83 | Computing KL before
2020-09-06 23:02:19 | [drl] epoch #83 | Optimizing
2020-09-06 23:02:19 | [drl] epoch #83 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:19 | [drl] epoch #83 | computing loss before
2020-09-06 23:02:19 | [drl] epoch #83 | computing gradient
2020-09-06 23:02:19 | [drl] epoch #83 | gradient computed
2020-09-06 23:02:19 | [drl] epoch #83 | computing descent direction
2020-09-06 23:02:20 | [drl] epoch #83 | descent direction computed
2020-09-06 23:02:20 | [drl] epoch #83 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:20 | [drl] epoch #83 | Violated because loss is NaN
2020-09-06 23:02:20 | [drl] epoch #83 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:20 | [drl] epoch #83 | backtrack iters: 14
2020-09-06 23:02:20 | [drl] epoch #83 | optimization finished
2020-09-06 23:02:20 | [drl] epoch #83 | Computing KL after
2020-09-06 23:02:20 | [drl] epoch #83 | Computing loss after
2020-09-06 23:02:20 | [drl] epoch #83 | Fitting baseline...
2020-09-06 23:02:20 | [drl] epoch #83 | Saving snapshot...
2020-09-06 23:02:20 | [drl] epoch #83 | Saved
2020-09-06 23:02:20 | [drl] epoch #83 | Time 70.83 s
2020-09-06 23:02:20 | [drl] epoch #83 | EpochTime 0.85 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -184134
AverageReturn                            -301069
Entropy                                        8.51363
EnvExecTime                                    0.0339422
Extras/EpisodeRewardMean                 -201545
Iteration                                     83
LinearFeatureBaseline/ExplainedVariance        0.866805
MaxReturn                                -301069
MinReturn                                -301069
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0444238
ProcessExecTime                                0.000987053
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:20 | [drl] epoch #84 | Obtaining samples...
2020-09-06 23:02:20 | [drl] epoch #84 | Obtaining samples for iteration 84...
2020-09-06 23:02:20 | [drl] epoch #84 | Logging diagnostics...
2020-09-06 23:02:20 | [drl] epoch #84 | Optimizing policy...
2020-09-06 23:02:20 | [drl] epoch #84 | Computing loss before
2020-09-06 23:02:20 | [drl] epoch #84 | Computing KL before
2020-09-06 23:02:20 | [drl] epoch #84 | Optimizing
2020-09-06 23:02:20 | [drl] epoch #84 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:20 | [drl] epoch #84 | computing loss before
2020-09-06 23:02:20 | [drl] epoch #84 | computing gradient
2020-09-06 23:02:20 | [drl] epoch #84 | gradient computed
2020-09-06 23:02:20 | [drl] epoch #84 | computing descent direction
2020-09-06 23:02:21 | [drl] epoch #84 | descent direction computed
2020-09-06 23:02:21 | [drl] epoch #84 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:21 | [drl] epoch #84 | Violated because loss is NaN
2020-09-06 23:02:21 | [drl] epoch #84 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:21 | [drl] epoch #84 | backtrack iters: 14
2020-09-06 23:02:21 | [drl] epoch #84 | optimization finished
2020-09-06 23:02:21 | [drl] epoch #84 | Computing KL after
2020-09-06 23:02:21 | [drl] epoch #84 | Computing loss after
2020-09-06 23:02:21 | [drl] epoch #84 | Fitting baseline...
2020-09-06 23:02:21 | [drl] epoch #84 | Saving snapshot...
2020-09-06 23:02:21 | [drl] epoch #84 | Saved
2020-09-06 23:02:21 | [drl] epoch #84 | Time 71.62 s
2020-09-06 23:02:21 | [drl] epoch #84 | EpochTime 0.78 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -114705
AverageReturn                            -187460
Entropy                                        8.51363
EnvExecTime                                    0.0450692
Extras/EpisodeRewardMean                 -201379
Iteration                                     84
LinearFeatureBaseline/ExplainedVariance        0.62349
MaxReturn                                -187460
MinReturn                                -187460
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.04388
ProcessExecTime                                0.000962496
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:21 | [drl] epoch #85 | Obtaining samples...
2020-09-06 23:02:21 | [drl] epoch #85 | Obtaining samples for iteration 85...
2020-09-06 23:02:21 | [drl] epoch #85 | Logging diagnostics...
2020-09-06 23:02:21 | [drl] epoch #85 | Optimizing policy...
2020-09-06 23:02:21 | [drl] epoch #85 | Computing loss before
2020-09-06 23:02:21 | [drl] epoch #85 | Computing KL before
2020-09-06 23:02:21 | [drl] epoch #85 | Optimizing
2020-09-06 23:02:21 | [drl] epoch #85 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:21 | [drl] epoch #85 | computing loss before
2020-09-06 23:02:21 | [drl] epoch #85 | computing gradient
2020-09-06 23:02:21 | [drl] epoch #85 | gradient computed
2020-09-06 23:02:21 | [drl] epoch #85 | computing descent direction
2020-09-06 23:02:21 | [drl] epoch #85 | descent direction computed
2020-09-06 23:02:22 | [drl] epoch #85 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:22 | [drl] epoch #85 | Violated because loss is NaN
2020-09-06 23:02:22 | [drl] epoch #85 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:22 | [drl] epoch #85 | backtrack iters: 14
2020-09-06 23:02:22 | [drl] epoch #85 | optimization finished
2020-09-06 23:02:22 | [drl] epoch #85 | Computing KL after
2020-09-06 23:02:22 | [drl] epoch #85 | Computing loss after
2020-09-06 23:02:22 | [drl] epoch #85 | Fitting baseline...
2020-09-06 23:02:22 | [drl] epoch #85 | Saving snapshot...
2020-09-06 23:02:22 | [drl] epoch #85 | Saved
2020-09-06 23:02:22 | [drl] epoch #85 | Time 72.46 s
2020-09-06 23:02:22 | [drl] epoch #85 | EpochTime 0.82 s
---------------------------------------  ---------------
AverageDiscountedReturn                  -187372
AverageReturn                            -306359
Entropy                                        8.51363
EnvExecTime                                    0.0438881
Extras/EpisodeRewardMean                 -202600
Iteration                                     85
LinearFeatureBaseline/ExplainedVariance        0.847244
MaxReturn                                -306359
MinReturn                                -306359
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0452936
ProcessExecTime                                0.0013597
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ---------------
2020-09-06 23:02:22 | [drl] epoch #86 | Obtaining samples...
2020-09-06 23:02:22 | [drl] epoch #86 | Obtaining samples for iteration 86...
2020-09-06 23:02:22 | [drl] epoch #86 | Logging diagnostics...
2020-09-06 23:02:22 | [drl] epoch #86 | Optimizing policy...
2020-09-06 23:02:22 | [drl] epoch #86 | Computing loss before
2020-09-06 23:02:22 | [drl] epoch #86 | Computing KL before
2020-09-06 23:02:22 | [drl] epoch #86 | Optimizing
2020-09-06 23:02:22 | [drl] epoch #86 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:22 | [drl] epoch #86 | computing loss before
2020-09-06 23:02:22 | [drl] epoch #86 | computing gradient
2020-09-06 23:02:22 | [drl] epoch #86 | gradient computed
2020-09-06 23:02:22 | [drl] epoch #86 | computing descent direction
2020-09-06 23:02:22 | [drl] epoch #86 | descent direction computed
2020-09-06 23:02:22 | [drl] epoch #86 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:22 | [drl] epoch #86 | Violated because loss is NaN
2020-09-06 23:02:22 | [drl] epoch #86 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:22 | [drl] epoch #86 | backtrack iters: 14
2020-09-06 23:02:22 | [drl] epoch #86 | optimization finished
2020-09-06 23:02:22 | [drl] epoch #86 | Computing KL after
2020-09-06 23:02:22 | [drl] epoch #86 | Computing loss after
2020-09-06 23:02:22 | [drl] epoch #86 | Fitting baseline...
2020-09-06 23:02:22 | [drl] epoch #86 | Saving snapshot...
2020-09-06 23:02:22 | [drl] epoch #86 | Saved
2020-09-06 23:02:22 | [drl] epoch #86 | Time 73.30 s
2020-09-06 23:02:22 | [drl] epoch #86 | EpochTime 0.83 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -150679
AverageReturn                            -246334
Entropy                                        8.51363
EnvExecTime                                    0.0333743
Extras/EpisodeRewardMean                 -203102
Iteration                                     86
LinearFeatureBaseline/ExplainedVariance        0.93987
MaxReturn                                -246334
MinReturn                                -246334
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0415039
ProcessExecTime                                0.00100756
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:22 | [drl] epoch #87 | Obtaining samples...
2020-09-06 23:02:22 | [drl] epoch #87 | Obtaining samples for iteration 87...
2020-09-06 23:02:23 | [drl] epoch #87 | Logging diagnostics...
2020-09-06 23:02:23 | [drl] epoch #87 | Optimizing policy...
2020-09-06 23:02:23 | [drl] epoch #87 | Computing loss before
2020-09-06 23:02:23 | [drl] epoch #87 | Computing KL before
2020-09-06 23:02:23 | [drl] epoch #87 | Optimizing
2020-09-06 23:02:23 | [drl] epoch #87 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:23 | [drl] epoch #87 | computing loss before
2020-09-06 23:02:23 | [drl] epoch #87 | computing gradient
2020-09-06 23:02:23 | [drl] epoch #87 | gradient computed
2020-09-06 23:02:23 | [drl] epoch #87 | computing descent direction
2020-09-06 23:02:23 | [drl] epoch #87 | descent direction computed
2020-09-06 23:02:23 | [drl] epoch #87 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:23 | [drl] epoch #87 | Violated because loss is NaN
2020-09-06 23:02:23 | [drl] epoch #87 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:23 | [drl] epoch #87 | backtrack iters: 14
2020-09-06 23:02:23 | [drl] epoch #87 | optimization finished
2020-09-06 23:02:23 | [drl] epoch #87 | Computing KL after
2020-09-06 23:02:23 | [drl] epoch #87 | Computing loss after
2020-09-06 23:02:23 | [drl] epoch #87 | Fitting baseline...
2020-09-06 23:02:23 | [drl] epoch #87 | Saving snapshot...
2020-09-06 23:02:23 | [drl] epoch #87 | Saved
2020-09-06 23:02:23 | [drl] epoch #87 | Time 74.19 s
2020-09-06 23:02:23 | [drl] epoch #87 | EpochTime 0.88 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -101874
AverageReturn                            -166476
Entropy                                        8.51363
EnvExecTime                                    0.0356879
Extras/EpisodeRewardMean                 -202686
Iteration                                     87
LinearFeatureBaseline/ExplainedVariance        0.763915
MaxReturn                                -166476
MinReturn                                -166476
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0474172
ProcessExecTime                                0.000963211
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:23 | [drl] epoch #88 | Obtaining samples...
2020-09-06 23:02:23 | [drl] epoch #88 | Obtaining samples for iteration 88...
2020-09-06 23:02:23 | [drl] epoch #88 | Logging diagnostics...
2020-09-06 23:02:23 | [drl] epoch #88 | Optimizing policy...
2020-09-06 23:02:23 | [drl] epoch #88 | Computing loss before
2020-09-06 23:02:23 | [drl] epoch #88 | Computing KL before
2020-09-06 23:02:23 | [drl] epoch #88 | Optimizing
2020-09-06 23:02:23 | [drl] epoch #88 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:23 | [drl] epoch #88 | computing loss before
2020-09-06 23:02:23 | [drl] epoch #88 | computing gradient
2020-09-06 23:02:23 | [drl] epoch #88 | gradient computed
2020-09-06 23:02:23 | [drl] epoch #88 | computing descent direction
2020-09-06 23:02:24 | [drl] epoch #88 | descent direction computed
2020-09-06 23:02:24 | [drl] epoch #88 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:24 | [drl] epoch #88 | Violated because loss is NaN
2020-09-06 23:02:24 | [drl] epoch #88 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:24 | [drl] epoch #88 | backtrack iters: 14
2020-09-06 23:02:24 | [drl] epoch #88 | optimization finished
2020-09-06 23:02:24 | [drl] epoch #88 | Computing KL after
2020-09-06 23:02:24 | [drl] epoch #88 | Computing loss after
2020-09-06 23:02:24 | [drl] epoch #88 | Fitting baseline...
2020-09-06 23:02:24 | [drl] epoch #88 | Saving snapshot...
2020-09-06 23:02:24 | [drl] epoch #88 | Saved
2020-09-06 23:02:24 | [drl] epoch #88 | Time 75.11 s
2020-09-06 23:02:24 | [drl] epoch #88 | EpochTime 0.90 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -170787
AverageReturn                            -279237
Entropy                                        8.51363
EnvExecTime                                    0.0377948
Extras/EpisodeRewardMean                 -203546
Iteration                                     88
LinearFeatureBaseline/ExplainedVariance        0.834356
MaxReturn                                -279237
MinReturn                                -279237
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0506017
ProcessExecTime                                0.000986576
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:24 | [drl] epoch #89 | Obtaining samples...
2020-09-06 23:02:24 | [drl] epoch #89 | Obtaining samples for iteration 89...
2020-09-06 23:02:24 | [drl] epoch #89 | Logging diagnostics...
2020-09-06 23:02:24 | [drl] epoch #89 | Optimizing policy...
2020-09-06 23:02:24 | [drl] epoch #89 | Computing loss before
2020-09-06 23:02:24 | [drl] epoch #89 | Computing KL before
2020-09-06 23:02:24 | [drl] epoch #89 | Optimizing
2020-09-06 23:02:24 | [drl] epoch #89 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:24 | [drl] epoch #89 | computing loss before
2020-09-06 23:02:24 | [drl] epoch #89 | computing gradient
2020-09-06 23:02:24 | [drl] epoch #89 | gradient computed
2020-09-06 23:02:24 | [drl] epoch #89 | computing descent direction
2020-09-06 23:02:25 | [drl] epoch #89 | descent direction computed
2020-09-06 23:02:25 | [drl] epoch #89 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:25 | [drl] epoch #89 | Violated because loss is NaN
2020-09-06 23:02:25 | [drl] epoch #89 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:25 | [drl] epoch #89 | backtrack iters: 14
2020-09-06 23:02:25 | [drl] epoch #89 | optimization finished
2020-09-06 23:02:25 | [drl] epoch #89 | Computing KL after
2020-09-06 23:02:25 | [drl] epoch #89 | Computing loss after
2020-09-06 23:02:25 | [drl] epoch #89 | Fitting baseline...
2020-09-06 23:02:25 | [drl] epoch #89 | Saving snapshot...
2020-09-06 23:02:25 | [drl] epoch #89 | Saved
2020-09-06 23:02:25 | [drl] epoch #89 | Time 76.19 s
2020-09-06 23:02:25 | [drl] epoch #89 | EpochTime 1.06 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -110587
AverageReturn                            -180725
Entropy                                        8.51363
EnvExecTime                                    0.0375817
Extras/EpisodeRewardMean                 -203293
Iteration                                     89
LinearFeatureBaseline/ExplainedVariance        0.694235
MaxReturn                                -180725
MinReturn                                -180725
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0446362
ProcessExecTime                                0.000965595
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:25 | [drl] epoch #90 | Obtaining samples...
2020-09-06 23:02:25 | [drl] epoch #90 | Obtaining samples for iteration 90...
2020-09-06 23:02:25 | [drl] epoch #90 | Logging diagnostics...
2020-09-06 23:02:25 | [drl] epoch #90 | Optimizing policy...
2020-09-06 23:02:25 | [drl] epoch #90 | Computing loss before
2020-09-06 23:02:25 | [drl] epoch #90 | Computing KL before
2020-09-06 23:02:25 | [drl] epoch #90 | Optimizing
2020-09-06 23:02:25 | [drl] epoch #90 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:25 | [drl] epoch #90 | computing loss before
2020-09-06 23:02:25 | [drl] epoch #90 | computing gradient
2020-09-06 23:02:25 | [drl] epoch #90 | gradient computed
2020-09-06 23:02:25 | [drl] epoch #90 | computing descent direction
2020-09-06 23:02:26 | [drl] epoch #90 | descent direction computed
2020-09-06 23:02:26 | [drl] epoch #90 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:26 | [drl] epoch #90 | Violated because loss is NaN
2020-09-06 23:02:26 | [drl] epoch #90 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:26 | [drl] epoch #90 | backtrack iters: 14
2020-09-06 23:02:26 | [drl] epoch #90 | optimization finished
2020-09-06 23:02:26 | [drl] epoch #90 | Computing KL after
2020-09-06 23:02:26 | [drl] epoch #90 | Computing loss after
2020-09-06 23:02:26 | [drl] epoch #90 | Fitting baseline...
2020-09-06 23:02:26 | [drl] epoch #90 | Saving snapshot...
2020-09-06 23:02:26 | [drl] epoch #90 | Saved
2020-09-06 23:02:26 | [drl] epoch #90 | Time 76.99 s
2020-09-06 23:02:26 | [drl] epoch #90 | EpochTime 0.79 s
---------------------------------------  -----------------
AverageDiscountedReturn                   -83137.4
AverageReturn                            -135816
Entropy                                        8.51363
EnvExecTime                                    0.0351269
Extras/EpisodeRewardMean                 -202551
Iteration                                     90
LinearFeatureBaseline/ExplainedVariance        0.887458
MaxReturn                                -135816
MinReturn                                -135816
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0477979
ProcessExecTime                                0.000993967
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:26 | [drl] epoch #91 | Obtaining samples...
2020-09-06 23:02:26 | [drl] epoch #91 | Obtaining samples for iteration 91...
2020-09-06 23:02:26 | [drl] epoch #91 | Logging diagnostics...
2020-09-06 23:02:26 | [drl] epoch #91 | Optimizing policy...
2020-09-06 23:02:26 | [drl] epoch #91 | Computing loss before
2020-09-06 23:02:26 | [drl] epoch #91 | Computing KL before
2020-09-06 23:02:26 | [drl] epoch #91 | Optimizing
2020-09-06 23:02:26 | [drl] epoch #91 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:26 | [drl] epoch #91 | computing loss before
2020-09-06 23:02:26 | [drl] epoch #91 | computing gradient
2020-09-06 23:02:26 | [drl] epoch #91 | gradient computed
2020-09-06 23:02:26 | [drl] epoch #91 | computing descent direction
2020-09-06 23:02:27 | [drl] epoch #91 | descent direction computed
2020-09-06 23:02:27 | [drl] epoch #91 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:27 | [drl] epoch #91 | Violated because loss is NaN
2020-09-06 23:02:27 | [drl] epoch #91 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:27 | [drl] epoch #91 | backtrack iters: 14
2020-09-06 23:02:27 | [drl] epoch #91 | optimization finished
2020-09-06 23:02:27 | [drl] epoch #91 | Computing KL after
2020-09-06 23:02:27 | [drl] epoch #91 | Computing loss after
2020-09-06 23:02:27 | [drl] epoch #91 | Fitting baseline...
2020-09-06 23:02:27 | [drl] epoch #91 | Saving snapshot...
2020-09-06 23:02:27 | [drl] epoch #91 | Saved
2020-09-06 23:02:27 | [drl] epoch #91 | Time 78.20 s
2020-09-06 23:02:27 | [drl] epoch #91 | EpochTime 1.19 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -108717
AverageReturn                            -177663
Entropy                                        8.51363
EnvExecTime                                    0.0436983
Extras/EpisodeRewardMean                 -202281
Iteration                                     91
LinearFeatureBaseline/ExplainedVariance        0.943164
MaxReturn                                -177663
MinReturn                                -177663
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0708959
ProcessExecTime                                0.00121927
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:27 | [drl] epoch #92 | Obtaining samples...
2020-09-06 23:02:27 | [drl] epoch #92 | Obtaining samples for iteration 92...
2020-09-06 23:02:27 | [drl] epoch #92 | Logging diagnostics...
2020-09-06 23:02:27 | [drl] epoch #92 | Optimizing policy...
2020-09-06 23:02:27 | [drl] epoch #92 | Computing loss before
2020-09-06 23:02:27 | [drl] epoch #92 | Computing KL before
2020-09-06 23:02:27 | [drl] epoch #92 | Optimizing
2020-09-06 23:02:27 | [drl] epoch #92 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:27 | [drl] epoch #92 | computing loss before
2020-09-06 23:02:27 | [drl] epoch #92 | computing gradient
2020-09-06 23:02:28 | [drl] epoch #92 | gradient computed
2020-09-06 23:02:28 | [drl] epoch #92 | computing descent direction
2020-09-06 23:02:28 | [drl] epoch #92 | descent direction computed
2020-09-06 23:02:28 | [drl] epoch #92 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:28 | [drl] epoch #92 | Violated because loss is NaN
2020-09-06 23:02:28 | [drl] epoch #92 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:28 | [drl] epoch #92 | backtrack iters: 14
2020-09-06 23:02:28 | [drl] epoch #92 | optimization finished
2020-09-06 23:02:28 | [drl] epoch #92 | Computing KL after
2020-09-06 23:02:28 | [drl] epoch #92 | Computing loss after
2020-09-06 23:02:28 | [drl] epoch #92 | Fitting baseline...
2020-09-06 23:02:28 | [drl] epoch #92 | Saving snapshot...
2020-09-06 23:02:28 | [drl] epoch #92 | Saved
2020-09-06 23:02:28 | [drl] epoch #92 | Time 79.13 s
2020-09-06 23:02:28 | [drl] epoch #92 | EpochTime 0.92 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -154879
AverageReturn                            -253203
Entropy                                        8.51363
EnvExecTime                                    0.0576277
Extras/EpisodeRewardMean                 -202828
Iteration                                     92
LinearFeatureBaseline/ExplainedVariance        0.909495
MaxReturn                                -253203
MinReturn                                -253203
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0468771
ProcessExecTime                                0.000998735
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:28 | [drl] epoch #93 | Obtaining samples...
2020-09-06 23:02:28 | [drl] epoch #93 | Obtaining samples for iteration 93...
2020-09-06 23:02:28 | [drl] epoch #93 | Logging diagnostics...
2020-09-06 23:02:28 | [drl] epoch #93 | Optimizing policy...
2020-09-06 23:02:28 | [drl] epoch #93 | Computing loss before
2020-09-06 23:02:28 | [drl] epoch #93 | Computing KL before
2020-09-06 23:02:28 | [drl] epoch #93 | Optimizing
2020-09-06 23:02:28 | [drl] epoch #93 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:28 | [drl] epoch #93 | computing loss before
2020-09-06 23:02:28 | [drl] epoch #93 | computing gradient
2020-09-06 23:02:28 | [drl] epoch #93 | gradient computed
2020-09-06 23:02:28 | [drl] epoch #93 | computing descent direction
2020-09-06 23:02:29 | [drl] epoch #93 | descent direction computed
2020-09-06 23:02:29 | [drl] epoch #93 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:29 | [drl] epoch #93 | Violated because loss is NaN
2020-09-06 23:02:29 | [drl] epoch #93 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:29 | [drl] epoch #93 | backtrack iters: 14
2020-09-06 23:02:29 | [drl] epoch #93 | optimization finished
2020-09-06 23:02:29 | [drl] epoch #93 | Computing KL after
2020-09-06 23:02:29 | [drl] epoch #93 | Computing loss after
2020-09-06 23:02:29 | [drl] epoch #93 | Fitting baseline...
2020-09-06 23:02:29 | [drl] epoch #93 | Saving snapshot...
2020-09-06 23:02:29 | [drl] epoch #93 | Saved
2020-09-06 23:02:29 | [drl] epoch #93 | Time 80.07 s
2020-09-06 23:02:29 | [drl] epoch #93 | EpochTime 0.92 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -116601
AverageReturn                            -190586
Entropy                                        8.51363
EnvExecTime                                    0.0411861
Extras/EpisodeRewardMean                 -202698
Iteration                                     93
LinearFeatureBaseline/ExplainedVariance        0.890187
MaxReturn                                -190586
MinReturn                                -190586
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0504949
ProcessExecTime                                0.00100231
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:29 | [drl] epoch #94 | Obtaining samples...
2020-09-06 23:02:29 | [drl] epoch #94 | Obtaining samples for iteration 94...
2020-09-06 23:02:29 | [drl] epoch #94 | Logging diagnostics...
2020-09-06 23:02:29 | [drl] epoch #94 | Optimizing policy...
2020-09-06 23:02:29 | [drl] epoch #94 | Computing loss before
2020-09-06 23:02:29 | [drl] epoch #94 | Computing KL before
2020-09-06 23:02:29 | [drl] epoch #94 | Optimizing
2020-09-06 23:02:29 | [drl] epoch #94 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:29 | [drl] epoch #94 | computing loss before
2020-09-06 23:02:29 | [drl] epoch #94 | computing gradient
2020-09-06 23:02:29 | [drl] epoch #94 | gradient computed
2020-09-06 23:02:29 | [drl] epoch #94 | computing descent direction
2020-09-06 23:02:30 | [drl] epoch #94 | descent direction computed
2020-09-06 23:02:30 | [drl] epoch #94 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:30 | [drl] epoch #94 | Violated because loss is NaN
2020-09-06 23:02:30 | [drl] epoch #94 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:30 | [drl] epoch #94 | backtrack iters: 14
2020-09-06 23:02:30 | [drl] epoch #94 | optimization finished
2020-09-06 23:02:30 | [drl] epoch #94 | Computing KL after
2020-09-06 23:02:30 | [drl] epoch #94 | Computing loss after
2020-09-06 23:02:30 | [drl] epoch #94 | Fitting baseline...
2020-09-06 23:02:30 | [drl] epoch #94 | Saving snapshot...
2020-09-06 23:02:30 | [drl] epoch #94 | Saved
2020-09-06 23:02:30 | [drl] epoch #94 | Time 80.88 s
2020-09-06 23:02:30 | [drl] epoch #94 | EpochTime 0.80 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -110733
AverageReturn                            -180965
Entropy                                        8.51363
EnvExecTime                                    0.0346982
Extras/EpisodeRewardMean                 -202469
Iteration                                     94
LinearFeatureBaseline/ExplainedVariance        0.997062
MaxReturn                                -180965
MinReturn                                -180965
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0506139
ProcessExecTime                                0.000975132
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:30 | [drl] epoch #95 | Obtaining samples...
2020-09-06 23:02:30 | [drl] epoch #95 | Obtaining samples for iteration 95...
2020-09-06 23:02:30 | [drl] epoch #95 | Logging diagnostics...
2020-09-06 23:02:30 | [drl] epoch #95 | Optimizing policy...
2020-09-06 23:02:30 | [drl] epoch #95 | Computing loss before
2020-09-06 23:02:30 | [drl] epoch #95 | Computing KL before
2020-09-06 23:02:30 | [drl] epoch #95 | Optimizing
2020-09-06 23:02:30 | [drl] epoch #95 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:30 | [drl] epoch #95 | computing loss before
2020-09-06 23:02:30 | [drl] epoch #95 | computing gradient
2020-09-06 23:02:30 | [drl] epoch #95 | gradient computed
2020-09-06 23:02:30 | [drl] epoch #95 | computing descent direction
2020-09-06 23:02:31 | [drl] epoch #95 | descent direction computed
2020-09-06 23:02:31 | [drl] epoch #95 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:31 | [drl] epoch #95 | Violated because loss is NaN
2020-09-06 23:02:31 | [drl] epoch #95 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:31 | [drl] epoch #95 | backtrack iters: 14
2020-09-06 23:02:31 | [drl] epoch #95 | optimization finished
2020-09-06 23:02:31 | [drl] epoch #95 | Computing KL after
2020-09-06 23:02:31 | [drl] epoch #95 | Computing loss after
2020-09-06 23:02:31 | [drl] epoch #95 | Fitting baseline...
2020-09-06 23:02:31 | [drl] epoch #95 | Saving snapshot...
2020-09-06 23:02:31 | [drl] epoch #95 | Saved
2020-09-06 23:02:31 | [drl] epoch #95 | Time 81.83 s
2020-09-06 23:02:31 | [drl] epoch #95 | EpochTime 0.94 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -160763
AverageReturn                            -262829
Entropy                                        8.51363
EnvExecTime                                    0.0431824
Extras/EpisodeRewardMean                 -203098
Iteration                                     95
LinearFeatureBaseline/ExplainedVariance        0.901363
MaxReturn                                -262829
MinReturn                                -262829
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0490124
ProcessExecTime                                0.00106645
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:31 | [drl] epoch #96 | Obtaining samples...
2020-09-06 23:02:31 | [drl] epoch #96 | Obtaining samples for iteration 96...
2020-09-06 23:02:31 | [drl] epoch #96 | Logging diagnostics...
2020-09-06 23:02:31 | [drl] epoch #96 | Optimizing policy...
2020-09-06 23:02:31 | [drl] epoch #96 | Computing loss before
2020-09-06 23:02:31 | [drl] epoch #96 | Computing KL before
2020-09-06 23:02:31 | [drl] epoch #96 | Optimizing
2020-09-06 23:02:31 | [drl] epoch #96 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:31 | [drl] epoch #96 | computing loss before
2020-09-06 23:02:31 | [drl] epoch #96 | computing gradient
2020-09-06 23:02:31 | [drl] epoch #96 | gradient computed
2020-09-06 23:02:31 | [drl] epoch #96 | computing descent direction
2020-09-06 23:02:32 | [drl] epoch #96 | descent direction computed
2020-09-06 23:02:32 | [drl] epoch #96 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:32 | [drl] epoch #96 | Violated because loss is NaN
2020-09-06 23:02:32 | [drl] epoch #96 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:32 | [drl] epoch #96 | backtrack iters: 14
2020-09-06 23:02:32 | [drl] epoch #96 | optimization finished
2020-09-06 23:02:32 | [drl] epoch #96 | Computing KL after
2020-09-06 23:02:32 | [drl] epoch #96 | Computing loss after
2020-09-06 23:02:32 | [drl] epoch #96 | Fitting baseline...
2020-09-06 23:02:32 | [drl] epoch #96 | Saving snapshot...
2020-09-06 23:02:32 | [drl] epoch #96 | Saved
2020-09-06 23:02:32 | [drl] epoch #96 | Time 82.64 s
2020-09-06 23:02:32 | [drl] epoch #96 | EpochTime 0.80 s
---------------------------------------  ----------------
AverageDiscountedReturn                  -148977
AverageReturn                            -243555
Entropy                                        8.51363
EnvExecTime                                    0.0350955
Extras/EpisodeRewardMean                 -203515
Iteration                                     96
LinearFeatureBaseline/ExplainedVariance        0.99369
MaxReturn                                -243555
MinReturn                                -243555
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0438037
ProcessExecTime                                0.00099206
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:32 | [drl] epoch #97 | Obtaining samples...
2020-09-06 23:02:32 | [drl] epoch #97 | Obtaining samples for iteration 97...
2020-09-06 23:02:32 | [drl] epoch #97 | Logging diagnostics...
2020-09-06 23:02:32 | [drl] epoch #97 | Optimizing policy...
2020-09-06 23:02:32 | [drl] epoch #97 | Computing loss before
2020-09-06 23:02:32 | [drl] epoch #97 | Computing KL before
2020-09-06 23:02:32 | [drl] epoch #97 | Optimizing
2020-09-06 23:02:32 | [drl] epoch #97 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:32 | [drl] epoch #97 | computing loss before
2020-09-06 23:02:32 | [drl] epoch #97 | computing gradient
2020-09-06 23:02:32 | [drl] epoch #97 | gradient computed
2020-09-06 23:02:32 | [drl] epoch #97 | computing descent direction
2020-09-06 23:02:33 | [drl] epoch #97 | descent direction computed
2020-09-06 23:02:33 | [drl] epoch #97 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:33 | [drl] epoch #97 | Violated because loss is NaN
2020-09-06 23:02:33 | [drl] epoch #97 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:33 | [drl] epoch #97 | backtrack iters: 14
2020-09-06 23:02:33 | [drl] epoch #97 | optimization finished
2020-09-06 23:02:33 | [drl] epoch #97 | Computing KL after
2020-09-06 23:02:33 | [drl] epoch #97 | Computing loss after
2020-09-06 23:02:33 | [drl] epoch #97 | Fitting baseline...
2020-09-06 23:02:33 | [drl] epoch #97 | Saving snapshot...
2020-09-06 23:02:33 | [drl] epoch #97 | Saved
2020-09-06 23:02:33 | [drl] epoch #97 | Time 83.84 s
2020-09-06 23:02:33 | [drl] epoch #97 | EpochTime 1.19 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -192232
AverageReturn                            -314329
Entropy                                        8.51363
EnvExecTime                                    0.0415587
Extras/EpisodeRewardMean                 -204646
Iteration                                     97
LinearFeatureBaseline/ExplainedVariance        0.948611
MaxReturn                                -314329
MinReturn                                -314329
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0552008
ProcessExecTime                                0.000995636
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:33 | [drl] epoch #98 | Obtaining samples...
2020-09-06 23:02:33 | [drl] epoch #98 | Obtaining samples for iteration 98...
2020-09-06 23:02:33 | [drl] epoch #98 | Logging diagnostics...
2020-09-06 23:02:33 | [drl] epoch #98 | Optimizing policy...
2020-09-06 23:02:33 | [drl] epoch #98 | Computing loss before
2020-09-06 23:02:33 | [drl] epoch #98 | Computing KL before
2020-09-06 23:02:33 | [drl] epoch #98 | Optimizing
2020-09-06 23:02:33 | [drl] epoch #98 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:33 | [drl] epoch #98 | computing loss before
2020-09-06 23:02:33 | [drl] epoch #98 | computing gradient
2020-09-06 23:02:33 | [drl] epoch #98 | gradient computed
2020-09-06 23:02:33 | [drl] epoch #98 | computing descent direction
2020-09-06 23:02:34 | [drl] epoch #98 | descent direction computed
2020-09-06 23:02:34 | [drl] epoch #98 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:34 | [drl] epoch #98 | Violated because loss is NaN
2020-09-06 23:02:34 | [drl] epoch #98 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:34 | [drl] epoch #98 | backtrack iters: 14
2020-09-06 23:02:34 | [drl] epoch #98 | optimization finished
2020-09-06 23:02:34 | [drl] epoch #98 | Computing KL after
2020-09-06 23:02:34 | [drl] epoch #98 | Computing loss after
2020-09-06 23:02:34 | [drl] epoch #98 | Fitting baseline...
2020-09-06 23:02:34 | [drl] epoch #98 | Saving snapshot...
2020-09-06 23:02:34 | [drl] epoch #98 | Saved
2020-09-06 23:02:34 | [drl] epoch #98 | Time 84.83 s
2020-09-06 23:02:34 | [drl] epoch #98 | EpochTime 0.97 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -79029.2
AverageReturn                            -129087
Entropy                                        8.51363
EnvExecTime                                    0.0582442
Extras/EpisodeRewardMean                 -203883
Iteration                                     98
LinearFeatureBaseline/ExplainedVariance       -1.14135
MaxReturn                                -129087
MinReturn                                -129087
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0701334
ProcessExecTime                                0.00501037
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
2020-09-06 23:02:34 | [drl] epoch #99 | Obtaining samples...
2020-09-06 23:02:34 | [drl] epoch #99 | Obtaining samples for iteration 99...
2020-09-06 23:02:34 | [drl] epoch #99 | Logging diagnostics...
2020-09-06 23:02:34 | [drl] epoch #99 | Optimizing policy...
2020-09-06 23:02:34 | [drl] epoch #99 | Computing loss before
2020-09-06 23:02:34 | [drl] epoch #99 | Computing KL before
2020-09-06 23:02:34 | [drl] epoch #99 | Optimizing
2020-09-06 23:02:34 | [drl] epoch #99 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:34 | [drl] epoch #99 | computing loss before
2020-09-06 23:02:34 | [drl] epoch #99 | computing gradient
2020-09-06 23:02:34 | [drl] epoch #99 | gradient computed
2020-09-06 23:02:34 | [drl] epoch #99 | computing descent direction
2020-09-06 23:02:35 | [drl] epoch #99 | descent direction computed
2020-09-06 23:02:35 | [drl] epoch #99 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:35 | [drl] epoch #99 | Violated because loss is NaN
2020-09-06 23:02:35 | [drl] epoch #99 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:35 | [drl] epoch #99 | backtrack iters: 14
2020-09-06 23:02:35 | [drl] epoch #99 | optimization finished
2020-09-06 23:02:35 | [drl] epoch #99 | Computing KL after
2020-09-06 23:02:35 | [drl] epoch #99 | Computing loss after
2020-09-06 23:02:35 | [drl] epoch #99 | Fitting baseline...
2020-09-06 23:02:35 | [drl] epoch #99 | Saving snapshot...
2020-09-06 23:02:35 | [drl] epoch #99 | Saved
2020-09-06 23:02:35 | [drl] epoch #99 | Time 85.73 s
2020-09-06 23:02:35 | [drl] epoch #99 | EpochTime 0.89 s
---------------------------------------  -----------------
AverageDiscountedReturn                  -149503
AverageReturn                            -244408
Entropy                                        8.51363
EnvExecTime                                    0.0347376
Extras/EpisodeRewardMean                 -204288
Iteration                                     99
LinearFeatureBaseline/ExplainedVariance        0.772612
MaxReturn                                -244408
MinReturn                                -244408
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.0409896
ProcessExecTime                                0.000941753
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  -----------------
2020-09-06 23:02:35 | [drl] epoch #100 | Obtaining samples...
2020-09-06 23:02:35 | [drl] epoch #100 | Obtaining samples for iteration 100...
2020-09-06 23:02:35 | [drl] epoch #100 | Logging diagnostics...
2020-09-06 23:02:35 | [drl] epoch #100 | Optimizing policy...
2020-09-06 23:02:35 | [drl] epoch #100 | Computing loss before
2020-09-06 23:02:35 | [drl] epoch #100 | Computing KL before
2020-09-06 23:02:35 | [drl] epoch #100 | Optimizing
2020-09-06 23:02:35 | [drl] epoch #100 | Start CG optimization: #parameters: 19852, #inputs: 1, #subsample_inputs: 1
2020-09-06 23:02:35 | [drl] epoch #100 | computing loss before
2020-09-06 23:02:35 | [drl] epoch #100 | computing gradient
2020-09-06 23:02:35 | [drl] epoch #100 | gradient computed
2020-09-06 23:02:35 | [drl] epoch #100 | computing descent direction
2020-09-06 23:02:36 | [drl] epoch #100 | descent direction computed
2020-09-06 23:02:36 | [drl] epoch #100 | Line search condition violated. Rejecting the step!
2020-09-06 23:02:36 | [drl] epoch #100 | Violated because loss is NaN
2020-09-06 23:02:36 | [drl] epoch #100 | Violated because constraint mean_kl is NaN
2020-09-06 23:02:36 | [drl] epoch #100 | backtrack iters: 14
2020-09-06 23:02:36 | [drl] epoch #100 | optimization finished
2020-09-06 23:02:36 | [drl] epoch #100 | Computing KL after
2020-09-06 23:02:36 | [drl] epoch #100 | Computing loss after
2020-09-06 23:02:36 | [drl] epoch #100 | Fitting baseline...
2020-09-06 23:02:36 | [drl] epoch #100 | Saving snapshot...
2020-09-06 23:02:36 | [drl] epoch #100 | Saved
2020-09-06 23:02:36 | [drl] epoch #100 | Time 86.68 s
2020-09-06 23:02:36 | [drl] epoch #100 | EpochTime 0.93 s
---------------------------------------  ----------------
AverageDiscountedReturn                   -95810.7
AverageReturn                            -156550
Entropy                                        8.51363
EnvExecTime                                    0.039221
Extras/EpisodeRewardMean                 -203888
Iteration                                    100
LinearFeatureBaseline/ExplainedVariance        0.675819
MaxReturn                                -156550
MinReturn                                -156550
NumTrajs                                       1
Perplexity                                  4982.22
PolicyExecTime                                 0.048862
ProcessExecTime                                0.00099659
StdReturn                                      0
lstm_policy/Entropy                            8.51363
lstm_policy/KL                                 0
lstm_policy/KLBefore                           0
lstm_policy/LossAfter                         -0
lstm_policy/LossBefore                        -0
lstm_policy/dLoss                              0
---------------------------------------  ----------------
